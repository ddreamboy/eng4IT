{
  "text": "convolution neural network tutorial my\nname is richard kirschner with the\nsimply learn team that's\nwww.simplylearn.com\nget certified get ahead today we're\ngoing to be covering the convolutional\nneural network tutorial do you know how\ndeep learning recognizes the objects in\nan image and really this particular\nneural network is how image recognition\nworks it's very central one of the\nbiggest building blocks for image\nrecognition it does it using convolution\nneural network and we over here we have\nthe basic picture of a hummingbird\npixels of an image fed as input you have\nyour input layer coming in so it takes\nthat graphic and puts it into the input\nlayer you have all your hidden layers\nand then you have your output layer and\nyour output layer one of those is going\nto light up and say oh it's a bird we're\ngoing to go into depth we're going to\nactually go back and forth on this a\nnumber of times today so if you're not\ncatching all the image\ndon't worry we're going to get into the\ndetails so we have our input layer\naccepts the pixels of the image as input\nin the form of arrays and you can see up\nhere where they've actually labeled each\nblock of the bird in different arrays so\nwe'll dive into deep as to how that\nlooks like and how those matrixes are\nset up your hidden layer carry out\nfeature extraction by performing certain\ncalculations and manipulation so this is\nthe part that kind of reorganizes that\npicture multiple ways until we get some\ndata that's easy to read for the neural\nnetwork this layer uses a matrix filter\nand performs convolution operation to\ndetect patterns in the image and if you\nremember that convolution means to coil\nor to twist so we're going to twist the\ndata around and alter it and use that\noperation to detect a new pattern there\nare multiple hidden layers like\nconvolution layer rel u is how that is\npronounced when that's the rectified\nlinear unit that has to do with the\nactivation function that's used pooling\nlayer also uses multiple filters to\ndetect edges corners eyes feathers beak\netc and just like the term says pooling\nis pulling information together and\nwe'll look into that a lot closer here\nso if you're if it's a little confusing\nnow we'll dig in deep and try to get you\nsquared away with that and then finally\nthere is a fully connected layer that\nidentifies the object in the image so we\nhave these different layers coming\nthrough in the hidden layers and they\ncome into the final area and that's\nwhere we have the one node or one neural\nnetwork entity that lights up that says\nit's a bird\nwhat's in it for you we're going to\ncover an introduction to the cnn what is\nconvolution neural network how cnn\nrecognizes images we're going to dig\ndeeper into that and really look at the\nindividual layers in the convolutional\nneural network and finally we do a use\ncase implementation using the cnn we'll\nbegin our introduction to the cnn by\nintroducing the pioneer of convolutional\nneural network jan lecun he was the\ndirector of facebook ai research group\nbuilt the first convolutional neural\nnetwork called lynnette in\n1988. so these have been around for a\nwhile and have had a chance to mature\nover the years it was used for character\nrecognition tasks like reading zip code\ndigits imagine processing mail and\nautomating that process\ncnn is a feed forward neural network\nthat is generally used to analyze visual\nimages by producing data with a grid\nlike topology a cnn is also known as a\nconvent and very key to this is we are\nlooking at images that was what this was\ndesigned for and you'll see the\ndifferent layers as we dig in near some\nof the other some of them are actually\nnow used since we're using uh tensorflow\nand karas in our code later on you'll\nsee that some of those layers appear in\na lot of your other neural network\nframeworks but in this case this is very\ncentral to processing images and doing\nso in a variety that captures multiple\nimages and really drills down into their\ndifferent features in this example here\nyou see flowers are two varieties orchid\nand a rose i think the orchid is much\nmore dainty and beautiful and the rose\nsmells quite beautiful i have a couple\nrose bushes in my yard uh they go into\nthe input layer that data is in sent to\nall the different nodes in the next\nlayer one of the hidden layers based on\nits different weights and its setup it\nthen comes out and gives those a new\nvalue those values then are multiplied\nby their weights and go to the next\nhidden layer and so on and then you have\nthe output layer and one of those nodes\ncomes out and says it's an orchid and\nthe other one comes out and says it's a\nrose depending on how it was well it was\ntrained what separates the cnn or the\nconvolutional neural network from other\nneural networks is a convolutional\noperation forms the basis of any\nconvolutional neural network in a cnn\nevery image image is represented in the\nform of arrays of pixel values so here\nwe have a real image of the digit 8.\nthat then gets put on to\nits pixel values represented in the form\nof an array in this case you have a\ntwo-dimensional array and then you can\nsee in the final in form we transform\nthe digit 8 into its representational\nform of pixels of zeros and ones where\nthe ones represent in this case the\nblack part of the eight and the zeros\nrepresent the white background to\nunderstand the convolution neural\nnetwork or how that convolutional\noperation works we're going to take a\nside step and look at matrixes in this\ncase we're going to simplify it and\nwe're going to take two matrices a and b\nof one dimension now kind of separate\nthis from your thinking as we learned\nthat you want to focus just on the\nmatrix aspect of this and then we'll\nbring that back together and see what\nthat looks like when we put the pieces\nfor the convolutional operation here\nwe've set up two arrays we have in this\ncase our single dimension matrix and we\nhave a equals 537597\nand we have b equals one two three so in\nthe convolution as it comes in there's\ngonna look at these two and we're gonna\nstart by doing multiplying them a times\nb and so we multiply the arrays element\nwise and we get five six six\nwhere five is the five times one six is\nthree times two and then the other six\nis two times three and since the two\narrays aren't the same size they're not\nthe same setup we're going to just\ntruncate the first one and we're going\nto look at the second array multiplied\njust by the first three elements of the\nfirst array now that was going to be a\nlittle confusing remember a computer\ngets to repeat these processes hundreds\nof times so we're not going to just\nforget those other numbers later on\nwe'll see we'll bring those back in and\nthen we have the sum of the product in\nthis case 5 plus 6 plus 6 equals 17. so\nin our a times b our very first digit in\nthat matrix of a times b is 17. and if\nyou remember i said we're not going to\nforget the other digits so we now have 3\n2 5 we move one set over and we take 3 2\n5 and we multiply that times b and\nyou'll see that 3 times 1 is 3 2 times 2\nis 4 and so on and so on we sum it up so\nnow we have the second digit of our a\ntimes b product in the matrix and we\ncontinue on with that same thing so on\nand so on so then we would go from 375\nto 759 to 597. this short matrix that we\nhave for a we've now covered all the\ndifferent entities in a that match three\ndifferent levels of b now in a little\nbit we're going to cover where we use\nthis math at this multiplying of\nmatrixes and how that works but it's\nimportant to understand that we're going\nthrough the matrix of multiplying the\ndifferent parts to it to match the\nsmaller matrix with the larger matrix i\nknow a lot of people get lost at is\nwhat's going on here with these matrixes\noh scary math not really that scary when\nyou break it down we're looking at a\nsection of a and we're comparing it to b\nso when you break that down your mind\nlike that you realize okay so i'm just\ntaking these two matrixes and comparing\nthem and i'm bringing the value down\ninto one matrix a times b we're reducing\nthat information in a way that will help\nthe computer see different aspects let's\ngo ahead and flip over again back to our\nimages\nhere we are back to our images talking\nabout going to the most basic\ntwo-dimensional image you can get to\nconsider the following two images the\nimage for the symbol backslash when you\npress the backslash the above image is\nprocessed and you can see there for the\nimage for the forward slash is the\nopposite so we click the forward slash\nbutton that flips uh very basic we have\nfour pixels going in can't get any more\nbasic than that here we have a little\nbit more complicated picture we take a\nreal image of a smiley face um then we\nrepresent that in the form of black and\nwhite pixels so if this was an image in\nthe computer it's black and white and\nlike we saw before we convert this into\nthe zeros and one so where the other one\nwould have just been a matrix of just\nfour dots now we have a significantly\nlarger image coming in so don't worry\nwe're going to bring this all together\nhere in just a little bit layers in\nconvolutional neural network we're\nlooking at this we have our convolution\nlayer and that really is the central\naspect of processing images and the\nconvolutional neural network that's why\nwe have it and then that's going to be\nfeeding in and you have your relu layer\nwhich is you know as we talked about the\nrectified linear unit we'll talk about\nthat a little bit later the release and\nhow it act is how that layer is\nactivated is the math behind it what\nmakes the neurons fire you'll see that a\nlot of other neural networks when you're\nusing it just by itself it's for\nprocessing smaller amounts of data where\nyou use the atom activation feature for\nlarge data coming in now because we're\nprocessing small amounts of data in each\nimage the relu layer works great you\nhave your pooling layer that's where\nyou're pulling the data together pooling\nis a neural network term it's very\ncommonly used i like to use the term\nreduce so if you're coming from the map\nand reduce side you'll see that we're\nmapping all this data through all these\nnetworks and then we're going to reduce\nit we're going to pull it together and\nthen finally we have the fully connected\nlayer that's where our output's going to\ncome out so we have started to look at\nmatrixes we've started to look at the\nconvolutional layer where it fits in and\neverything we've taken a look at images\nso we're going to focus more on the\nconvolution layer since this is a\nconvolutional neural network a\nconvolution layer has a number of\nfilters and perform convolution\noperation every image is considered as a\nmatrix of pixel values consider the\nfollowing 5x5 image whose pixel values\nare only 0 and 1. now obviously when\nwe're dealing with color there's all\nkinds of things that come in on color\nprocessing but we want to keep it simple\nand just keep it black and white and so\nwe have our image pixels\nso we're sliding the filter matrix over\nthe image and computing the dot product\nto detect the patterns and right here\nyou're going to ask where does this\nfilter come from this is a bit confusing\nbecause the filter is going to be\nderived\nlater on we build the filters when we\nprogram or train our model so you don't\nneed to worry what the filter actually\nis but you do need to understand how a\nconvolution layer works is what is the\nfilter doing filter and you'll have mini\nfilters you don't have just one filter\nyou'll have lots of filters that are\ngoing to look for different aspects and\nso the filter might be looking for just\nedges it might be looking for different\nparts we'll cover that a little bit more\ndetail in a minute right now we're just\nfocusing on how the filter works as a\nmatrix remember earlier we talked about\nmultiplying matrixes together and here\nwe have our two dimensional matrix and\nyou can see we take the filter and we\nmultiply it in the upper left image and\nyou can see right here one times one one\ntimes zero one times one we multiply\nthose all together then sum them and we\nend up with the convolved feature of\nfour we're going to take that and\nsliding the filter matrix over the image\nand computing the dot product to detect\npatterns so we're just going to slide\nthis so we're going to predict the first\none and slide it over one notch predict\nthe second one and so on and so on all\nthe way through until we have a new\nmatrix and this matrix which is the same\nsize as the filter has reduced the image\nand whatever filter whatever that's\nfiltering out it's going to be looking\nat just those features reduced down to a\nsmaller matrix so once the feature maps\nare extracted the next step is to move\nthem to the relu layer so the relu layer\nthe next step first is going to perform\nan element-wise operation so each of\nthose maps coming in if there's negative\npixels so it says all the negative\npixels to zero and you can see this nice\ngraph where it just zeros out the\nnegatives and then you have a value that\ngoes from zero up to whatever value is\ncoming out of the matrix this introduces\nnon-linearity to the network\nso up until now we have a we say\nlinearity we're talking about the fact\nthat the feature has a value so it's a\nlinear feature this feature\ncame up and has let's say the feature is\nthe edge of the beak you know it's like\nor the backslash that we saw you'll look\nat that and say okay this feature has a\nvalue from negative 10 to 10 in this\ncase if it was one it'd say yeah this\nmight be a beak it might not might be an\nedge right there a minus five means no\nwe're not even going to look at it to\nzero and so we end up with an output and\nthe output takes all these features all\nthese filtered features remember we're\nnot just running one filter on this\nwe're running a number of filters on\nthis image and so we end up with a\nrectified feature map that is looking at\njust the features coming through and how\nthey weigh in from our filters so here\nwe have an input of a looks like a\ntoucan bird\nvery exotic looking real image is\nscanned in multiple convolution and the\nrelu layers for locating features and\nyou can see up here is turn it into a\nblack and white image and in this case\nwe're looking in the upper right hand\ncorner for a feature and that box scans\nover a lot of times it doesn't scan one\npixel at a time a lot of times it will\nskip by two or three or four pixels uh\nto speed up the process that's one of\nthe ways you can compensate if you don't\nhave enough resources on your\ncomputation for large images and it's\nnot just one filter slowly goes across\nthe image you have multiple filters have\nbeen programmed in there so you're\nlooking at a lot of different filters\ngoing over the different aspects of the\nimage and just sliding across there and\nforming a new matrix\none more aspect to note about the relu\nlayer is we're not just having one value\ncoming in\nso not only do we have multiple features\ngoing through but we're generating\nmultiple relu layers for locating the\nfeatures that's very important to note\nyou know so we have a quite a bundle we\nhave multiple filters multiple rail u\nwhich brings us to the next step forward\npropagation now we're going to look at\nthe pooling layer the rectified feature\nmap now goes through a pooling layer\npooling is a down sampling operation\nthat reduces the dimensionality of the\nfeature map that's all we're trying to\ndo we're trying to take a huge amount of\ninformation and reduce it down to a\nsingle answer this is a specific kind of\nbird this is an iris this is a rose so\nyou have a rectified feature map you see\nhere we have a rectified feature map\ncoming in\nwe set the max pooling with a 2 by 2\nfilters and a stride of two and if you\nremember correctly i talked about not\ngoing one pixel at a time uh well that's\nwhere the stride comes in we end up with\na two by two pooled feature map but\ninstead of moving one over each time and\nlooking at every possible combination we\nskip a st we skip a few there we go by\ntwo we skip every other pixel and we\njust do every other one and this reduces\nour rectified feature map which is you\ncan see over here 16 by 16 to a four by\nfour so we're continually trying to\nfilter and reduce our data so that we\ncan get to something we can manage and\nover here you see that we have the max\nthree four one and two and in the max\npooling we're looking for the max value\na little bit different than what we were\nlooking at before so coming from the\nrectified feature we're now finding the\nmax value and then we're pulling those\nfeatures together so instead of think of\nthis as image of the map think of this\nas how valuable is a feature in that\narea how much of a feature value do we\nhave we just want to find the best or\nthe maximum feature for that area they\nmight have that one piece of the filter\nof the beak said oh i see a one in this\nbeak in this image and then it skips\nover and says i see a three in this\nimage and says oh this one is rated as a\nfour we don't want to sum it together\nbecause then you know you might have\nlike five ones and it'll say ah five but\nyou might have uh four zeros and one ten\nand that ten says well this is\ndefinitely a beak where the ones will\nsay probably not a beak a little strange\nanalogy since we're looking at a bird\nbut you can see how that pulled feature\nmap comes down and we're just looking\nfor the max value in each one of those\nmatrixes pooling layer uses different\nfilters to identify different parts of\nthe image like edges corners body\nfeathers eyes beak etc i know i focus\nmainly on the beak but obviously each\nfeature could be each a different part\nof the bird coming in so let's take a\nlook at what that looks like structure\nof a convolution neural network so far\nthis is where we're at right now we have\nour input image coming in and then we\nuse our filters and there's multiple\nfilters on there that are being\ndeveloped to kind of twist and change\nthat data and so we multiply the\nmatrixes we take that little filter\nmaybe it's a two by two we multiply it\nby each piece of the image and if we\nstep two then it's every other piece of\nthe image that generates multiple\nconvolution layers so we have a number\nof convolution layers we have\nset up in there just looking at that\ndata we then take those convolution\nlayers we run them through the relu\nsetup and then once we've done through\nthe release setup and we have multiple\nvalues going on multiple layers that are\nrelative then we're going to take those\nmultiple layers and we're going to be\npooling them so now we have the pooling\nlayers or multiple poolings going on up\nuntil this point we're dealing with\nsometimes there's multiple dimensions\nyou can have three dimensions some\nstrange data setups that aren't doing\nimages but looking at other things they\ncan have four five six seven dimensions\nso right now we're looking at 2d image\ndimensions coming in into the pooling\nlayer so the next step is we want to\nreduce those dimensions or flatten them\nso flattening flattening is a process of\nconverting all of the resultant\ntwo-dimensional arrays from pooled\nfeature map into a single long\ncontinuous linear vector so over here\nyou see where we have a pooled feature\nmap maybe that's the bird wing and it\nhas values 6847 and we want to just\nflatten this out and turn it into\n6847 or a single linear vector and we\nfind out that not only do we do each of\nthe pooled feature maps we do all of\nthem into one long linear vector so now\nwe've gone through our convolutional\nneural network part and we have the\ninput layer into the next setup all\nwe've done is taken all those different\npooling layers and we flatten them out\nand combine them into a single linear\nvector going in so after we've done the\nflattening we have just a quick recap\nbecause we've covered so much so it's\nimportant to go back and take a look at\neach of the steps we've gone through the\nstructure of the network so far is we\nhave our convolution where we twist it\nand we filter it and multiply the\nmatrixes we end up with our\nconvolutional layer which uses the relu\nto figure out the values going out into\nthe pooling as you have numerous\nconvolution layers that then create\nnumerous pooling layers pulling that\ndata together which is the max value\nwhich one we want to send forward we\nwant to send the best value and then\nwe're going to take all of that from\neach of the pooling layers and we're\ngoing to flatten it and we're going to\ncombine them into a single input going\ninto the final layer once you get to\nthat step you might be looking at that\ngoing boy that looks like the normal\ninto it to most neural network and\nyou're correct it is\nso once we have the flattened matrix\nfrom the pooling layer that becomes our\ninput so the pulling layer is fed as an\ninput to the fully connected layer to\nclassify the image and so you can see as\nour flattened matrix comes in in this\ncase we have the pixels from the\nflattened matrix fed as an input back to\nour toucan or whatever that kind of bird\nthat is i need one of these to identify\nwhat kind of bird that is it comes into\nour forward propagation network\nand that will then have the different\nweights coming down across and then\nfinally it selects that that's a bird\nand that is not a dog or a cat in this\ncase\neven though it's not labeled the final\nlayer there in red is our output layer\nour final output layer that says bird\ncat or dog so quick recap of everything\nwe've covered so far we have our input\nimage which is twisted and multiplied\nthe filters are multiplied times the\nmatrix the two matrixes multiplied all\nthe filters to create our convolution\nlayer our convolution layers there's\nmultiple layers in there because it's\nall building multiple layers off the\ndifferent filters then goes through the\nrelu as this activation and that creates\nour pooling and so once we get into the\npooling layer we then and the pooling\nlook for who's the best what's the max\nvalue coming in from our convolution and\nthen we take that layer and we flatten\nit and then it goes into a fully\nconnected layer our fully connected\nneural network and then to the output\nand here we can see the entire process\nhow the cnn recognizes a bird this is\nkind of nice because it's showing the\nlittle pixels and where they're going\nyou can see the filter is generating\nthis convolution network and that filter\nshows up in the bottom part of the\nconvolution network and then based on\nthat it uses the relu for the pooling\nthe pooling then find out which one's\nthe best and so on all the way to the\nfully connected layer at the end or the\nclassification in the output layer so\nthat'd be a classification neural\nnetwork at the end so we covered a lot\nof theory up till now and you can\nimagine each one of these steps has to\nbe broken down in code so putting that\ntogether can be a little complicated not\nthat each step of the process is overly\ncomplicated but because we have so many\nsteps we have one two three four five\ndifferent steps going on here with sub\nsteps in there we're going to break that\ndown and walk through that in code so in\nour use case implementation using the\ncnn we'll be using the cfar10 dataset\nfrom canadian institute for advanced\nresearch for classifying images across\n10 categories unfortunately they don't\nlet me know whether it's going to be a\ntoucan or some other kind of bird but we\ndo get to find out whether it can\ncategorize between a ship a frog deer\nbird airplane automobile cat dog horse\ntruck so that's a lot of fun and if\nyou're looking anything in the news at\nall of our automated cars and everything\nelse you can see where this kind of\nprocessing is so important in today's\nworld and very cutting edge as far as\nwhat's coming out in the commercial\ndeployment i mean this is really cool\nstuff we're starting to see this just\nabout everywhere in industry so great\ntime to be playing with this and\nfiguring it all out let's go ahead and\ndive into the code and see what that\nlooks like when we're actually writing\nour script\nbefore we go on let's do uh one more\nquick look at what we have here let's\njust take a look at data batch one keys\nand remember in jupiter notebook i can\nget by with not doing the print\nstatement if i put a variable down there\nit'll just display the variable and you\ncan see under data batch one for the\nkeys since this is a dictionary we have\nthe batch one label data and file names\nso you can actually see how it's broken\nup in our data set so for the next step\nor step four as we're calling it uh we\nwant to display the images using matte\nplot library there's many ways to\ndisplay the images you can even uh well\nthere's other ways to drill into it but\nmatplot library is really good for this\nand we'll also look at our first reshape\nuh setup or shaping the data so you can\nhave a little glimpse into what that\nmeans uh so we're gonna start by\nimporting our map plot and of course\nsince i am doing jupiter notebook i need\nto do the matplot inline command so it\nshows up on my page so here we go we're\ngoing to import matplot library.pipelot\nas plt and if you remember matplot\nlibrary the pie plot is like a canvas\nthat we paint stuff onto and there's my\npercentage sign matplot library inline\nso it's going to show up in my notebook\nand then of course we're going to import\nnumpy as np for our numbers python array\nsetup and let's go ahead and set\nx equals to data batch one so this will\npull in all the data going into the x\nvalue and then because this is just a\nlong stream of binary data we need to go\na little bit of reshaping so in here we\nhave to go ahead and reshape the data we\nhave 10 000 images okay that looks\ncorrect and this is kind of an\ninteresting thing it took me a little\nbit to i had to go research this myself\nto figure out what's going on with this\ndata and what it is is it's a 32 by 32\npicture and let me do this let me go\nahead and do a drawing pad on here so we\nhave 32 bits by 32 bits and it's in\ncolor so there's three bits of color now\ni don't know why the data is\nparticularly like this it probably has\nto do with how they originally encoded\nit but most pictures put the three\nafterward so what we're doing here is\nwe're going to take\nthe shape we're going to take the data\nwhich is just a long stream of\ninformation and we're going to break it\nup into 10 000 pieces and those 10 000\npieces then are broken into three pieces\neach and those three pieces then are 32\nby 32. you can look at this like an\nold-fashioned projector where they have\nthe red screen or the red projector the\nblue projector and the green projector\nand they add them all together and each\none of those is a 32 by 32 bit so that's\nprobably how this was originally\nformatted was in that kind of ideal\nthings have changed so we're going to\ntranspose it and we're going to take the\nthree which was here and we're going to\nput it at the end so the first part is\nreshaping the data from a single line of\nbit data or whatever format it is into\n10 000 by three by 32 by 32 and then\nwe're going to transpose the color\nfactor to the last place so it's the\nimage then the 32 by 32 in the middle\nthat's this part right here and then\nfinally we're going to take this which\nis three bits of data and put it at the\nend so it's more like we do process\nimages now and then as type this is\nreally important that we're going to use\nan integer eight you can come in here\nand you'll see a lot of these they'll\ntry to do this with a float or a float\n64. what you got to remember though is a\nfloat uses a lot of memory so once you\nswitch this into uh something that's not\ninteger eight which goes up to 128 you\nare just gonna the the amount of ram let\nme just put that in here is going to go\nway up the amount of ram that it loads\nso you want to go ahead and use this you\ncan try the other ones and see what\nhappens if you have a lot of ram on your\ncomputer but for this exercise this will\nwork just fine and let's go ahead and\ntake that and run this so now our x\nvariable is all loaded and it has all\nthe images in it from the batch one data\nbatch one and just to show we are\ntalking about with the as type on there\nif we go ahead and take x0 and just look\nfor its max value let me go ahead and\nrun that\nyou'll see it doesn't oops i said 128\nit's 255. you'll see it doesn't go over\n255 because it's basically an ascii\ncharacter is what we're keeping that\ndown to we're keeping those values down\nso they're only 255 0 to 255 versus\nfloat value which would bring this up\nexponentially in size and since we're\nusing the matplot library we can do\noops that's not what i wanted since\nwe're using the map plot library we can\ntake our canvas and just do a plt dot im\nfor image show and let's just take a\nlook at what x0 looks like and it comes\nin i'm not sure what that is but you can\nsee it's a very low grade image broken\ndown to the minimal pixels on there and\nif we did the same thing oh let's do uh\nlet's see what one looks like hopefully\nit's a little easier to see run on there\nnot enter let's hit the run on that\nand we can see this is probably a semi\ntruck that's a good guess on there and i\ncan just go back up here instead of\ntyping the same line in over and over\nwe'll look at three that looks like a\ndump truck unloading uh and so on you\ncan do any of the 10 000 images we can\njust jump to 55. uh looks like some kind\nof animal looking at us there probably a\ndog and just for fun let's do just one\nmore uh\nrun on there and we can see a nice car\nfor our image number four uh so you can\nsee we paste through all the different\nimages it's very easy to look at them\nand they've been reshaped to fit our\nview and what the\nmatplot library uses for its format so\nthe next step is we're gonna start\ncreating some helper functions we'll\nstart by a one hot encoder to help us or\nprocessing the data remember that your\nlabels they can't just be words they\nhave to switch it and we use the one hot\nencoder to do that and then we'll also\ncreate a\nclass uh cfar helper so it's going to\nhave an init and a setup for the images\nand then finally we'll go ahead and run\nthat code so you can see what that looks\nlike and then we get into the fun part\nwhere we're actually going to start\ncreating our model our actual neural\nnetwork model so let's start by creating\nour one hot encoder we're going to\ncreate our own here\nand it's going to return an out and\nwe'll have our vector coming in and our\nvalues equal 10. what this means is that\nwe have the 10 values the 10 possible\nlabels and remember we don't look at the\nlabels as a number because a car isn't\none more than a horse i'd be just kind\nof bizarre to have horse equals zero car\nequals one plane equals two cat equals\nthree so a cat plus a car equals what so\ninstead we create a numpy array of zeros\nand there's going to be 10 values so we\nhave 10 different values in there so you\nhave\n0 or 1. 1 means it's a cat 0 means it's\nnot a cat\nin the next line it might be that one\nmeans it's a car zero means it's not a\ncar so instead of having one output with\na value of zero to ten you have ten\noutputs with the values of zero to one\nthat's what the one hot encoder is doing\nhere and we're going to utilize this in\ncode in just a minute so let's go ahead\nand take a look at the next helpers we\nhave a few of these helper functions\nwe're going to build and when you're\nworking with a very complicated python\nproject dividing it up into separate\ndefinitions and classes is very\nimportant otherwise it just becomes\nreally ungainly to work with so let's go\nahead and put in our next helper which\nis a class and this is a lot in this\nclass so we'll break it down here and\nlet's just start oops we put a space\nright in there there we go that was a\nlittle bit more readable at a second\nspace so we're going to create our class\nthe cipher helper and we'll start by\ninitializing it now there's a lot going\non in here so let's start with the init\npart uh self dot i equals zero i'll come\nin a little bit we'll come back to that\nin the lower part we want to initialize\nour training batches so when we went\nthrough this there was like a meta batch\nwe don't need the meta batch but we do\nneed the data batch one two three four\nfive and we do not want the testing\nbatch in here this is just the self all\ntrain batches so we're gonna come make\nan array of all those different images\nand then of course we left the test\nbatch out so we have our self.testbatch\nwe're going to initialize the training\nimages and the training labels and also\nthe test images and the test labels so\nthese are just this is just to\ninitialize these variables in here then\nwe create another definition down here\nand this is going to set up the images\nlet's just take a look and see what's\ngoing on in there now we could have all\njust put this as part of the\ninit part since this is all just helper\nstuff but breaking it up again makes it\neasier to read it also makes it easier\nwhen we start executing the different\npieces to see what's going on so that\nway we have a nice print statement to\nsay hey we're now running this and this\nis what's going on in here we're going\nto set up the self training images at\nthis point and that's going to go to a\nnumpy array v stack and in there we're\ngoing to load up\nin this case the data for d itself all\ntrain batches again that points right up\nto here so we're going to go through\neach one of these\nfiles or each one of these data sets\nbecause they're not a file anymore we've\nbrought them in data batch one points to\nthe actual data and so our self training\nimages is going to stack them all into\nour into a numpy array and then it's\nalways nice to get the training length\nand that's just a total number of uh\nself training images in there and then\nwe're going to take the self training\nimages and let me switch marker colors\nbecause i am getting a little bit too\nmuch on the markers up here oops there\nwe go bring down our marker change\nso we can see it a little better and at\nthis point this should look familiar\nwhere did we see this well when we\nwanted to uh\nlook at this above and we want to look\nat the images in the matplot library we\nhad to reshape it so we're doing the\nsame thing here we're taking our self\ntraining images and uh based on the\ntraining length total number of images\nbecause we stacked them all together so\nnow it's just one large file of images\nwe're going to take and look at it as\nour three video cameras that are each\ndisplaying a 32 by 32 we're going to\nswitch that around so that now we have\neach of our images that stays the same\nplace and then we have our 32 by 32 and\nthen by our three our last are three\ndifferent values for the color and of\ncourse we want to go ahead and they run\nthis where we say divide by 255 that was\nfrom earlier it just brings all the data\ninto zero to one that's what this is\ndoing so we're turning this into a zero\nto one array which is uh all the\npictures 32 by 32 by three and then\nwe're going to take the self training\nlabels and we're going to pump those\nthrough our one hot encoder we just made\nand we're going to stack them together\nand\nagain we're converting this into an\narray that goes from\ninstead of having horse equals one dog\nequals two and then horse plus dog would\nequal three which would be cat\nnow it's going to be you know an array\nof 10 where each one is 0 to 1. then we\nwant to go ahead and set up our test\nimages and labels and when we're doing\nthis you're going to see it's the same\nthing we just did with the rest of them\nwe just changed colors right here this\nis no different than what we're doing up\nhere with our training set we're going\nto stack the different images\nwe're going to get the length of them so\nwe know how many images are in there you\ncertainly could add them by hand but\nit's nice to let the computer do it\nespecially if it ever changes on the\nother end and you're using other data\nand again we reshape them and transpose\nthem and we also do the one hot encoder\nsame thing we just did on our training\nimages so now our test images are in the\nsame format so now we have a definition\nwhich sets up all our images in there\nand then the next step is to go ahead\nand batch them or next batch and let's\ndo another breakout here for batches\nbecause this is really important to\nunderstand tends to throw me for a\nlittle loop when i'm working with\ntensorflow or cross or a lot of these we\nhave our data coming in if you remember\nwe had like 10 000 photos let me just\nput 10 000 down here we don't want to\nrun all 10 000 at once so we want to\nbreak this up into batch sizes and you\nalso remember that we had the number of\nphotos in this case length of test or\nwhatever number is in there we also have\n32 by 32 by 3. so when we're looking at\nthe batch size we want to change this\nfrom 10 000 to\na batch of in this case i think we're\ngoing to do batches of a hundred so we\nwant to look at just 100 the first\nhundred of the photos and if you\nremember we set self i equal to\nzero uh so what we're looking at here is\nwe're going to create x we're going to\nget the next batch from the very\ninitialize we've already initialized it\nfor 0. so we're going to look at x from\n0 to batch size which we set to 100 so\njust the first hundred images and then\nwe're going to reshape that into uh and\nthis is important to let the data know\nthat we're looking at 100 by 32 by 32 by\n3. now we've already formatted it to the\n32 by 32 by 3. this just sets everything\nup correctly so that x has the data in\nthere in the correct order and the\ncorrect shape and then the y just like\nthe x\nis our labels so our training labels\nagain they go from 0 to batch size in\nthis case they do sell fi plus batch\nsize because the cell phi is going to\nkeep changing and then finally we\nincrement the self i because we have\nzero so we so the next time we call it\nwe're going to get the next batch size\nand so basically we have x and y x being\nthe photograph data coming in and y\nbeing the label and that of course is\nlabeled through one hot encoder so if\nyou remember correctly if it was say\nhorse is equal to zero it would be\none for the zero position since this is\nthe horse and then everything else would\nbe zero in here let me just put lines\nthrough there there we go there's our\narray\nhard to see that array so let's go ahead\nand take that and uh we're going to\nfinish loading it since this is our\nclass and now we're armed with all this\nuh\nour setup over here let's go ahead and\nload that up and so we're going to\ncreate a variable ch with the c4 helper\nin it and then we're going to do\nch.setup images\nnow we could have just put all the setup\nimages under the init but by breaking\nthis up into two parts it makes it much\nmore readable and also if you're doing\nother work there's reasons to do that as\nfar as the setup let's go ahead and run\nthat and you can see where it says uh\nsetting up training images and labels\nsetting up test images and that's one of\nthe reasons we broke it up is so that if\nyou're testing this out you can actually\nhave print statements in there telling\nyou what's going on which is really nice\nuh they did a good job with this setup i\nlike the way that it was broken up in\nthe back and then one quick note you\nwant to remember that batch to set up\nthe next batch since we have to run\nbatch equals ch next batch of 100\nbecause we're going to use the 100 size\nbut we'll come back to that we're going\nto use that just remember that that's\npart of our code we're going to be using\nin a minute from the definition we just\nmade so now we're ready to create our\nmodel first thing we want to do is we\nwant to import our tensorflow as tf i'll\njust go ahead and run that so it's\nloaded up and you can see we got a\nwarning here\nthat's because they're making some\nchanges it's always growing and they're\ngoing to be depreciating one of the\nvalues from float 64 to float type or is\ntreated as an np float64 nothing to\nreally worry about this doesn't even\naffect what we're working on because\nwe've set all of our stuff to a 255\nvalue or zero to one and do keep in mind\nthat zero to one value that we converted\nthe 255 is still a float value but it'll\neasily work with either the numpy float\n64 or the numpy d type float it doesn't\nmatter which one it goes through so the\ndepreciation would not affect our code\nas we have it and in our tensorflow uh\nwe'll go ahead and just increase the\nsize in there just a moment so you can\nget a better view of the um what we're\ntyping in uh we're going to set a couple\nplaceholders here and so we have we're\ngoing to set x equals tf placeholder tf\nfloat 32 we just talked about the\nfloat64 versus the numpy float we're\nactually just going to keep this at\nfloat 32 more than a significant number\nof decimals for what we're working with\nand since it's a placeholder we're going\nto set the shape equal to and we've set\nit equal to none\nbecause at this point we're just holding\nthe place on there we'll be setting up\nas we run the batches that's what that\nfirst value is and then 32 by 32 by\nthree that's what we've reshaped our\ndata to fit in and then we have our y\ntrue equals placeholder tf float 32 and\nthe shape equals none comma 10. 10 is\nthe 10 different labels we have so it's\nan array of 10. and then let's create\none more placeholder we'll call this a\nhold prob or hold probability and we're\ngoing to use this we don't have to have\na shape or anything for this this\nplaceholder is for what we call drop out\nif you remember from our theory before\nwe drop out so many nodes is looking at\nor the different values going through\nwhich helps decrease bias so we need to\ngo ahead and put a placeholder for that\nalso and we'll run this so it's all\nloaded up in there so we have our three\ndifferent placeholders and since we're\nin tensorflow when you use keras it does\nsome of this automatically but we're in\ntensorflow direct kara sits on\ntensorflow we're going to go ahead and\ncreate some more helper functions we're\ngoing to create something to help us\ninitialize the weights initialize our\nbias if you remember that each layer has\nto have a bias going in we're going to\ngo ahead and work on our conversional 2d\nour max pool so we have our pooling\nlayer our convolutional layer and then\nour normal full layer so we're going to\ngo ahead and put those all into\ndefinitions and let's see what that\nlooks like in code and you can also grab\nsome of these helper functions from the\nmnist the nist setup let me just put\nthat in there if you're under the\ntensorflow so a lot of these are already\nin there but we're going to go ahead and\ndo our own and we're going to create our\ninit weights and one of the reasons\nwe're doing this is so that you can\nactually start thinking about what's\ngoing on in the back end so even though\nthere's ways to do this with an\nautomation sometimes these have to be\ntweaked and you have to put in your own\nsetup in here now we're not going to be\ndoing that we're just going to recreate\nthem for our code and let's take a look\nat this we have our weights and so it\ncomes in is going to be the shape and\nwhat comes out is going to be\nrandom numbers so we're going to go\nahead and just knit some random numbers\nbased on the shape with a standard\ndeviation of 0.1 kind of a fun way to do\nthat and then the tf variable\ninit random distribution so we're just\ncreating a random distribution on there\nthat's all that is for the weights now\nyou might change that you might have a\nhigher standard deviation in some cases\nyou actually load preset weights that's\npretty rare usually you're testing that\nagainst another model or something like\nthat and you want to see how those\nweights configure with each other now\nremember we have our bias so we need to\ngo ahead and initialize the bias with a\nconstant in this case we're using 0.1 a\nlot of times the bias is just put in as\none and then you have your weights add\non to that but we're going to set this\nas point one so we want to return a\nconvolutional 2d in this case a neural\nnetwork this is uh would be a layer on\nhere what's going on with the con 2d is\nwe're taking our data coming in uh we're\ngoing to filter it strides if you\nremember correctly strides came from\nhere's our image and then we only look\nat this picture here and then maybe we\nhave a stride of one so we look at this\npicture here and we continue to look at\nthe different filters going on there the\nother thing this does is that we have\nour data coming in as 32\nby\n32\nby\n3 and we want to change this so that\nit's just this is three dimensions and\nit's going to reformat this as just two\ndimensions so it's going to take this\nnumber here and combine it with the 32\nby 32 so this is a very important layer\nhere because it's reducing our data down\nusing different means and it connects\ndown i'm just going to jump down one\nhere\nit goes with the convolutional layer so\nyou have your your kind of your\npreformatting and the setup and then you\nhave your actual convolution layer that\ngoes through on there and you can see\nhere we have init weights by the shape a\nknit bias shape of three because we have\nthe three different uh here's our three\nagain and then we return the tfnn relu\nwith the convention 2d so this\nconvolutional\nhas this feeding into it right there\nit's using that as part of it and of\ncourse the input is the x y plus b the\nbias so that's quite a mouthful but\nthese two are the are the keys here to\ncreating the convolutional layers there\nthe convolutional 2d coming in and then\nthe convolutional layer which then steps\nthrough and creates all those filters we\nsaw then of course we have our pooling\nuh so after each time we run it through\nthe convectional layer we want to pull\nthe data if you remember correctly on\nthe on the pool side and let me just get\nrid of all my marks it's getting a\nlittle crazy there and in fact let's go\nahead and jump back to that slide let's\njust take a look at that slide over here\nuh so we have our image coming in we\ncreate our convolutional layer with all\nthe filters remember the filters go um\nyou know the filter is coming in here\nand it looks at these four boxes and\nthen if it's a step let's say step two\nit then goes to these four boxes and\nthen the next step and so on uh so we\nhave our convolutional layer that we\ngenerate or convolutional layers they\nuse the\nrelu function there's other functions\nout there for this though the relu is\nthe most the one that works the best at\nleast so far i'm sure that will change\nthen we have our pooling now if you\nremember correctly the pooling was max\nso if we had the filter coming in and\nthey did the multiplication on there and\nwe have a one and maybe a two here and\nanother one here and a three here three\nis the max and so out of all of these\nyou then create an array that would be\nthree and if the max is over here two or\nwhatever it is that's what goes into the\npooling of what's going on in our\npooling uh so again we're reducing that\ndata down reducing it down as small as\nwe can and then finally we're going to\nflatten it out into a single array and\nthat goes into our fully connected layer\nand you can see that here in the code\nright here we're going to create our\nnormal full layer so at some point we're\ngoing to take from our pooling layer\nthis will go into some kind of\nflattening process and then that will be\nfed into the full the different layers\ngoing in down here\nand so we have our input size you'll see\nour input layer get shape which is just\ngoing to get the shape for whatever's\ncoming in uh and then input size initial\nweights is also based on the input layer\ncoming in and the input size down here\nis based on the input layer shape so\nwe're just going to already use the\nshape and already have our size coming\nin and of course uh you have to make\nsure you knit the bias always put your\nbias on there and we'll do that based on\nthe size so this will return\ntf.matmul\ninput layer w plus b this is just a\nnormal full layer that's what this means\nright down here that's what we're going\nto return so that was a lot of steps we\nwent through let's go ahead and run that\nso those are all loaded in there and\nlet's go ahead and create the layers\nlet's see what that looks like\nnow that we've done all the heavy\nlifting and everything we get to do all\nthe easy part let's go ahead and create\nour layers we'll create a convolution\nlayer one and two two different\nconvolutional layers and then we'll take\nthat and we'll flatten that out and\ncreate a reshape pooling in there for\nour reshape and then we'll have our full\nuh layer at the end so let's start by\ncreating our first convolutional layer\nthen we come in here and let me just run\nthat real quick and i want you to notice\non here the 3\nand the 32 this is important because\ncoming into this convolutional layer we\nhave three different channels and 32\npixels each\nso that has to be in there the four and\nfour you can play with this is your\nfilter size so if you remember you have\na filter and you have your image and the\nfilter slowly steps over and filters out\nthis image depending on what your step\nis for this particular setup 4 4 is just\nfine that should work pretty good for\nwhat we're doing for the size of the\nimage and then of course at the end once\nyou have your convolutional layer set up\nyou also need to pull it and you'll see\nthat the pooling is automatically set up\nso that it would see the different shape\nbased on what's coming in so here we\nhave max toolbar two by two and we put\nin the convolutional one that we just\ncreated the convolutional layer we just\ncreated goes right back into it and that\nright up here as you can see is the x\nthat's coming in from here so it knows\nto look at the first model and set the\nthe data accordingly set that up\nso matches and we went ahead and ran\nthis already i think i read let me go\nand run it again and if we're going to\ndo one layer let's go ahead and do a\nsecond layer down here and it's uh we'll\ncall it convo 2.\nit's also a convolutional layer on this\nand you'll see that we're feeding\nconvolutional one in the pooling so it\ngoes from convolutional one into\nconvolutional one pooling from\nconvolutional one pooling into\nconvolutional two and then from\nconvolutional 2 into convolutional 2\npooling and we'll go ahead and take this\nand run this so these variables are all\nloaded into memory and for our flattened\nlayer let's go ahead and we'll do since\nwe have 64 coming out of here and we\nhave a 4x4 going in let's do 8 by 8 by\n64. so let's do\n4096. this is going to be the flat layer\nso that's how many bits are coming\nthrough on the flat layer and we'll\nreshape this so we'll reshape our\nconvo two pooling and that will feed\ninto here the convo to pulling and then\nwe're going to set it up as a single\nlayer that's\n4096 in size that's what that means\nthere we'll go ahead and run this so\nwe've now created this variable the\nconvo to flat and then we have our first\nfull layer this is the final\nneural network where the flat layer\ngoing in and we're going to again use\nthe relu for our setup on there on a\nneural network for evaluation and you'll\nnotice that we're going to create our\nfirst full layer our normal full layer\nthat's our definition so we created that\nthat's creating the normal full layer\nand our input for the data comes right\nhere from the this goes right into it\nthe convo too flat so this tells it how\nbig the data is and we're going to have\nit come out it's going to have 10 24\nthat's how big the layer is coming out\nwe'll go ahead and run this so now we\nhave our full layer one and with the\nfull layer one we want to also define\nthe full one dropout to go with that so\nour full layer one comes in uh keep\nprobability equals whole probability\nremember we created that earlier and the\nfull layer one is what's coming into it\nand this is going backwards and training\nthe data we're not training every weight\nwe're only training a percentage of them\neach time which helps get rid of the\nbias so let me go ahead and run that and\nfinally we'll go ahead and create a y\npredict which is going to equal the\nnormal full one drop out and 10 because\nwe have 10 labels in there now in this\nneural network we could have added\nadditional layers that would be another\noption to play with you can also play\nwith instead of 10 24 you can use other\nnumbers for the way that sets up and\nwhat's coming out going into the next\none we're only going to do just the one\nlayer and the one layer drop out and you\ncan see if we did another layer it'd be\nreally easy just to feed in the full one\ndrop out into full layer two and then\nfull layer 2 dropout would have full\nlayer 2 feed into it and then you'd\nswitch that here for the y prediction\nfor right now this is great this\nparticular data set is tried and true\nand we know that this will work on it\nand if we just type in y predict and we\nrun that\nwe'll see that this is a tensor object\nuh shape question mark 10 d type 32 a\nquick way to double check what we're\nworking on so now we've got all of our\nwe've done a setup all the way to the y\npredict which we just did we want to go\nahead and apply the loss function and\nmake sure that's set up in there\ncreate the optimizer and then\ntrainer optimizer and create a variable\nto initialize all the global tf\nvariables so before we dive in to the\nloss function let me point out one quick\nthing or just kind of a rehab over a\ncouple things and that is when we're\nplaying with this these setups\nwe pointed out up here we can change the\n4 4 and use different numbers there the\nchange your outcome so depending on what\nnumbers you use here will have a huge\nimpact on how well your model fits and\nthat's the same here of the 1024 also\nthis is also another number that if you\ncontinue to raise that number you'll get\npossibly a better fit you might overfit\nand if you lower that number you'll use\nless resources and generally you want to\nuse this in\nthe exponential growth an exponential\nbeing 2 4 8 16 and in this case the next\none down would be 5 12. you can use any\nnumber there but those would be the\nideal numbers uh when you look at this\ndata so the next step in all this is we\nneed to also create a way of tracking\nhow good our model is and we're going to\ncall this a loss function and so we're\ngoing to create a cross entropy loss\nfunction and so before we discuss\nexactly what that is let's take a look\nand see what we're feeding it\nwe're going to feed it our labels and we\nhave our true labels and our prediction\nlabels so coming in here is where the\ntwo different variables we're sending in\nor the two different probability\ndistributions is one that we know is\ntrue and what we think it's going to be\nnow this function right here when they\ntalk about cross entropy in information\ntheory the cross entropy between two\nprobability distributions over the same\nunderlying set of events measures the\naverage number of bits needed to\nidentify an event drawn from the set\nthat's a mouthful really we're just\nlooking at the amount of error in here\nhow many of these are correct and how\nmany of these are incorrect so how much\nof it matches and we're going to look at\nthat we're just going to look at the\naverage that's what the mean the reduced\nto the mean means here so we're looking\nat the average error on this\nand so the next step\nis we're going to take the error we want\nto know our cross entropy or our loss\nfunction how much loss we have that's\ngoing to be part of how we train the\nmodel so when you know what the loss is\nand we're training it we feed that back\ninto the back propagation setup and so\nwe want to go ahead and optimize that\nhere's our optimizer we're going to\ncreate the optimizer using an atom\noptimizer remember there's a lot of\ndifferent ways of optimizing the data\natoms are most popular used uh so our\noptimizer is going to equal the tf train\natom optimizer if you don't remember\nwhat the learning rate is let me just\npop this back into here here's our\nlearning rate when you have your weights\nyou have all your weights and your\ndifferent nodes that are coming out\nhere's our node coming out\nit has all its weights and then the\nerror is being prop sent back through in\nreverse on our neural network so we take\nthis error and we adjust these weights\nbased on the different formulas in this\ncase the atom formula is what we're\nusing we don't want to just adjust them\ncompletely we don't want to change this\nweight so it exactly fits the data\ncoming through because if we made that\nkind of adjustment it's going to be\nbiased to whatever the last data we sent\nthrough is instead we're going to\nmultiply that by 0.001 and make a very\nsmall shift in this weight so our delta\nw is only 0.001 of the actual delta w of\nthe full change we're going to compute\nfrom the atom and then we want to go\nahead and train it so our training or\nset up a training\nvariable or function and this is going\nto equal our optimizer minimize cross\nentropy and we make sure we go ahead and\nrun this so it's loaded in there and\nthen we're almost ready to train our\nmodel but before we do that we need to\ncreate one more um variable in here and\nwe're going to create a variable to\ninitialize all the global tf variables\nand when we look at this\nthe tf global variable initializer this\nis a tensorflow\nobject it goes through there and it\nlooks at all our different setup that we\nhave going under our tensorflow and then\ninitializes those variables\nso it's kind of like a magic wand\nbecause it's all hidden in the back end\nof tensorflow all you need to know about\nthis is that you have to have the\ninitialization on there which is an\noperation um and you have to run that\nonce you have your setup going so we'll\ngo ahead and run this piece of code and\nthen we're going to go ahead and train\nour data so let me run this let's load\nit up there and so now we're going to go\nahead and run the model by creating a\ngraph session graph session is a\ntensorflow term so you'll see that\ncoming up that's one of the things that\nthrows me because i always think of\ngraphics and spark and graph as just\ngeneral graphing uh but they talk about\na graph session so we're gonna go ahead\nand run the model and let's go ahead and\nwalk through this uh what's going on\nhere and let's paste this data in here\nand here we go so we're going to start\noff with it with a tf session as sess so\nthat's our actual tf session we've\ncreated uh so we're right here with the\ntf uh\nsession our session we're creating we're\ngoing to run tf global variable\ninitializer so right off the bat we're\ninitializing our variables here uh and\nthen we have for i in range 500. so\nwhat's going on here remember 500 we're\ngoing to break the date up and we're\ngoing to batch it in at 500 points each\nwe've created our session run so we're\ngoing to do with tf session as session\nright here we've created our variable\nsession and then we're going to run\nwe're going to go ahead and initialize\nit so we have our tf global variables\ninitializer that we created\nthat initializes our session in here the\nnext thing we're going to do is we're\ngoing to go for i in range of 500 batch\nequals ch.nextbatch\nso if you remember correctly this is\nloading up\n100 pictures at a time and\nthis is going to loop through that 500\ntimes so we are literally doing uh what\nis that 500 times 100 is\n50 000 so that's 50 000 pictures we're\ngoing to process right there and the\nfirst process is we're going to do a\nsession run we're going to take our\ntrain we created our train variable or\noptimizer in there we're going to feed\nit the dictionary we had our feed\ndictionary that we created and we have x\nequals batch zero coming in y true batch\none hold the probability point five and\nthen just so that we can keep track of\nwhat's going on we're going to every 100\nsteps we're going to run a print so\ncurrently on step format\naccuracy is\nand we're going to look at matches\nequals tf.equal tf argument y prediction\none tf dot arg max y true comma 1. so\nwe're going to look at this as how many\nmatches it has and here our acc\nall we're doing here is we're going to\ntake the matches how many matches they\nhave it creates it generates a chart\nwe're going to convert that to float\nthat's what the tfcast does and then we\njust want to know the average we just\nwant to know the average of the accuracy\nand then we'll go ahead and print that\nout\nprint session run accuracy feed\ndictionary so it takes all this and it\nprints out our accuracy on there so\nlet's go ahead and take this oops\nscreens there let's go ahead and take\nthis and let's run it and this is going\nto take a little bit to run\nso let's see what happens on my old\nlaptop and we'll see here that we have\nour current uh we're currently on step\nzero it takes a little bit to get\nthrough the accuracy and this will take\njust a moment to run we can see that on\nour step 0 it has an accuracy of 0.1 or\n0.1028\nand as it's running we'll go ahead you\ndon't need to watch it run all the way\nbut this accuracy is going to change a\nlittle bit up and down so we've actually\nlost some accuracy during our step two\nbut we'll see how that comes out let's\ncome back after we run it all the way\nthrough and see how the different steps\ncome out it's actually reading that\nbackwards\nthe way this works is the closer we get\nto one the more accuracy we have uh so\nyou can see here we've gone from a point\none to a point three nine um and we'll\ngo ahead and pause this and come back\nand see what happens when we're done\nwith the full run all right now that\nwe've\nprepared the meal got it in the oven and\npulled out my finished dish here if\nyou've ever watched any of the old\ncooking shows let's discuss a little bit\nabout this accuracy going on here and\nhow do you interpret that we've done a\ncouple things first we've defined\naccuracy\nthe reason i got it backwards before is\nyou have\nloss or accuracy and with loss you'll\nget a graph that looks like this it goes\noops that's an s by the way there we go\nyou get a graph that curves down like\nthis and with accuracy you get a graph\nthat curves up this is how good it's\ndoing now in this case uh one is\nsupposed to be really good accuracy that\nmeans it gets close to one but it never\ncrosses one so if you have an accuracy\nof one that is phenomenal in fact that's\npretty much impos you know unheard of\nand the same thing with loss if you have\na loss of zero that's also unheard of\nthe zero's actually on this this axis\nright here as we go in there so how do\nwe interpret that because you know if i\nwas looking at this and i go oh 0.51\nthat's uh 51 you're doing 50 50. no this\nis not percentage let me just put that\nin there it is not percentage uh this is\nlog rhythmic what that means is that 0.2\nis twice as good as 0.1 and when we see\n0.4 that's twice as good as 0.2 real way\nto convert this into a percentage you\nreally can't say this is is a direct\npercentage conversion what you can do\nthough is in your head if we were to\ngive this a percentage we might look at\nthis as fifty percent we're just\nguessing equals 0.1 and if 50\nroughly equals 0.1 that's we started up\nhere at the top remember at the top here\nhere's our 0.1028 the accuracy of 50\npercent then 75 percent is about 0.2 and\nso on and so on don't quote those\nnumbers because that doesn't work that\nway they say that if you have .95\nthat's pretty much saying a hundred\npercent and if you have anywhere between\nyou'd have to go look this up let me go\nand remove all my drawings there\nso the magic number is 0.5 we really\nwant to be over a 0.5 in this whole\nthing and we have\nboth 0.504 remember this is accuracy if\nwe were looking at loss then we would be\nlooking the other way but 0.00 you know\ninstead of how high it is we want how\nlow it is uh but with accuracy being\nover 0.5 is pretty valid that means this\nis pretty solid and if you get to a 0.95\nthen it's a direct correlation that's\nwhat we're looking for here in these\nnumbers you can see we finished with\nthis model at\n0.5135 so still good\nand if we look at when they ran this in\nthe other end remember there's a lot of\nrandomness that goes into it when we see\nthe weights they got\n.5251 so a little better than ours but\nthat's fine you'll find your own comes\nup a little bit better or worse\ndepending on just that randomness and so\nwe've gone through the whole model we've\ncreated we trained the model and we've\nalso gone through on every 100th run to\ntest the model to see how accurate it is\nand now that we have a solid running\nmodel and accuracy let's go ahead and\ntake a look at what we covered today we\ndid cover a lot because this is a very\ncomplicated subject and it's not so much\ncomplicated in\nany individual step it just has a lot of\nsteps involved so today we covered what\nis a convolutional neural network and\nyou can see we have the pictures coming\nin to the input layer to the hidden\nlayers to the output layer and then or\nget a rows we talked about the very\nbasics at the beginning and we discussed\nhow a cnn recognizes images very basics\nas we converted the image into a pixel\nmap of zeros and ones then we dive into\nlayers in a convolutional neural network\nand we had our convolutional layer our\nfully convected layer our\nrelu layer and our pooling layer and we\nlooked at pooling layer it reduces\nthe data down to a smaller amount by\nfinding the\nfirst defines the matches and then it\nfinds the maximum value in that match\nand we discussed all the different\nlayers in there we went into the fully\nconnected layer which is your normal the\nneural networks you're probably used to\ndealing with where we're just building a\nforward propagation neural network and\nwe connected them all together and you\ncan see here\nwe took the bird we\ndid our extracting our feature\nextraction and multiple hidden layers\nwhere we had our convolution which then\ngenerated those little individual\nfilters and we had our relu and then we\ntook the real u we max pooled those and\nthen we took all those pooled values at\nthe end so they've been reduced to\nsmaller mappings we've reduced that and\nthen we fed that into the fully\nconnected layer and then finally we went\ninto the use case implementation using\ncnn and we walked through a full demo on\nthe coding on there with that i want to\nthank you for joining us today uh so\nthank you for more information visit\nwww.simplylearn.com\nget certified get ahead you can also\npost questions down below in the youtube\nand we'll try to answer those as best we\ncan\nhi there if you like this video\nsubscribe to the simply learn youtube\nchannel and click here to watch similar\nvideos turn it up and get certified\nclick here\n",
  "words": [
    "convolution",
    "neural",
    "network",
    "tutorial",
    "name",
    "richard",
    "kirschner",
    "simply",
    "learn",
    "team",
    "get",
    "certified",
    "get",
    "ahead",
    "today",
    "going",
    "covering",
    "convolutional",
    "neural",
    "network",
    "tutorial",
    "know",
    "deep",
    "learning",
    "recognizes",
    "objects",
    "image",
    "really",
    "particular",
    "neural",
    "network",
    "image",
    "recognition",
    "works",
    "central",
    "one",
    "biggest",
    "building",
    "blocks",
    "image",
    "recognition",
    "using",
    "convolution",
    "neural",
    "network",
    "basic",
    "picture",
    "hummingbird",
    "pixels",
    "image",
    "fed",
    "input",
    "input",
    "layer",
    "coming",
    "takes",
    "graphic",
    "puts",
    "input",
    "layer",
    "hidden",
    "layers",
    "output",
    "layer",
    "output",
    "layer",
    "one",
    "going",
    "light",
    "say",
    "oh",
    "bird",
    "going",
    "go",
    "depth",
    "going",
    "actually",
    "go",
    "back",
    "forth",
    "number",
    "times",
    "today",
    "catching",
    "image",
    "worry",
    "going",
    "get",
    "details",
    "input",
    "layer",
    "accepts",
    "pixels",
    "image",
    "input",
    "form",
    "arrays",
    "see",
    "actually",
    "labeled",
    "block",
    "bird",
    "different",
    "arrays",
    "dive",
    "deep",
    "looks",
    "like",
    "matrixes",
    "set",
    "hidden",
    "layer",
    "carry",
    "feature",
    "extraction",
    "performing",
    "certain",
    "calculations",
    "manipulation",
    "part",
    "kind",
    "reorganizes",
    "picture",
    "multiple",
    "ways",
    "get",
    "data",
    "easy",
    "read",
    "neural",
    "network",
    "layer",
    "uses",
    "matrix",
    "filter",
    "performs",
    "convolution",
    "operation",
    "detect",
    "patterns",
    "image",
    "remember",
    "convolution",
    "means",
    "coil",
    "twist",
    "going",
    "twist",
    "data",
    "around",
    "alter",
    "use",
    "operation",
    "detect",
    "new",
    "pattern",
    "multiple",
    "hidden",
    "layers",
    "like",
    "convolution",
    "layer",
    "rel",
    "u",
    "pronounced",
    "rectified",
    "linear",
    "unit",
    "activation",
    "function",
    "used",
    "pooling",
    "layer",
    "also",
    "uses",
    "multiple",
    "filters",
    "detect",
    "edges",
    "corners",
    "eyes",
    "feathers",
    "beak",
    "etc",
    "like",
    "term",
    "says",
    "pooling",
    "pulling",
    "information",
    "together",
    "look",
    "lot",
    "closer",
    "little",
    "confusing",
    "dig",
    "deep",
    "try",
    "get",
    "squared",
    "away",
    "finally",
    "fully",
    "connected",
    "layer",
    "identifies",
    "object",
    "image",
    "different",
    "layers",
    "coming",
    "hidden",
    "layers",
    "come",
    "final",
    "area",
    "one",
    "node",
    "one",
    "neural",
    "network",
    "entity",
    "lights",
    "says",
    "bird",
    "going",
    "cover",
    "introduction",
    "cnn",
    "convolution",
    "neural",
    "network",
    "cnn",
    "recognizes",
    "images",
    "going",
    "dig",
    "deeper",
    "really",
    "look",
    "individual",
    "layers",
    "convolutional",
    "neural",
    "network",
    "finally",
    "use",
    "case",
    "implementation",
    "using",
    "cnn",
    "begin",
    "introduction",
    "cnn",
    "introducing",
    "pioneer",
    "convolutional",
    "neural",
    "network",
    "jan",
    "lecun",
    "director",
    "facebook",
    "ai",
    "research",
    "group",
    "built",
    "first",
    "convolutional",
    "neural",
    "network",
    "called",
    "lynnette",
    "around",
    "chance",
    "mature",
    "years",
    "used",
    "character",
    "recognition",
    "tasks",
    "like",
    "reading",
    "zip",
    "code",
    "digits",
    "imagine",
    "processing",
    "mail",
    "automating",
    "process",
    "cnn",
    "feed",
    "forward",
    "neural",
    "network",
    "generally",
    "used",
    "analyze",
    "visual",
    "images",
    "producing",
    "data",
    "grid",
    "like",
    "topology",
    "cnn",
    "also",
    "known",
    "convent",
    "key",
    "looking",
    "images",
    "designed",
    "see",
    "different",
    "layers",
    "dig",
    "near",
    "actually",
    "used",
    "since",
    "using",
    "uh",
    "tensorflow",
    "karas",
    "code",
    "later",
    "see",
    "layers",
    "appear",
    "lot",
    "neural",
    "network",
    "frameworks",
    "case",
    "central",
    "processing",
    "images",
    "variety",
    "captures",
    "multiple",
    "images",
    "really",
    "drills",
    "different",
    "features",
    "example",
    "see",
    "flowers",
    "two",
    "varieties",
    "orchid",
    "rose",
    "think",
    "orchid",
    "much",
    "dainty",
    "beautiful",
    "rose",
    "smells",
    "quite",
    "beautiful",
    "couple",
    "rose",
    "bushes",
    "yard",
    "uh",
    "go",
    "input",
    "layer",
    "data",
    "sent",
    "different",
    "nodes",
    "next",
    "layer",
    "one",
    "hidden",
    "layers",
    "based",
    "different",
    "weights",
    "setup",
    "comes",
    "gives",
    "new",
    "value",
    "values",
    "multiplied",
    "weights",
    "go",
    "next",
    "hidden",
    "layer",
    "output",
    "layer",
    "one",
    "nodes",
    "comes",
    "says",
    "orchid",
    "one",
    "comes",
    "says",
    "rose",
    "depending",
    "well",
    "trained",
    "separates",
    "cnn",
    "convolutional",
    "neural",
    "network",
    "neural",
    "networks",
    "convolutional",
    "operation",
    "forms",
    "basis",
    "convolutional",
    "neural",
    "network",
    "cnn",
    "every",
    "image",
    "image",
    "represented",
    "form",
    "arrays",
    "pixel",
    "values",
    "real",
    "image",
    "digit",
    "gets",
    "put",
    "pixel",
    "values",
    "represented",
    "form",
    "array",
    "case",
    "array",
    "see",
    "final",
    "form",
    "transform",
    "digit",
    "8",
    "representational",
    "form",
    "pixels",
    "zeros",
    "ones",
    "ones",
    "represent",
    "case",
    "black",
    "part",
    "eight",
    "zeros",
    "represent",
    "white",
    "background",
    "understand",
    "convolution",
    "neural",
    "network",
    "convolutional",
    "operation",
    "works",
    "going",
    "take",
    "side",
    "step",
    "look",
    "matrixes",
    "case",
    "going",
    "simplify",
    "going",
    "take",
    "two",
    "matrices",
    "b",
    "one",
    "dimension",
    "kind",
    "separate",
    "thinking",
    "learned",
    "want",
    "focus",
    "matrix",
    "aspect",
    "bring",
    "back",
    "together",
    "see",
    "looks",
    "like",
    "put",
    "pieces",
    "convolutional",
    "operation",
    "set",
    "two",
    "arrays",
    "case",
    "single",
    "dimension",
    "matrix",
    "equals",
    "537597",
    "b",
    "equals",
    "one",
    "two",
    "three",
    "convolution",
    "comes",
    "gon",
    "na",
    "look",
    "two",
    "gon",
    "na",
    "start",
    "multiplying",
    "times",
    "b",
    "multiply",
    "arrays",
    "element",
    "wise",
    "get",
    "five",
    "six",
    "six",
    "five",
    "five",
    "times",
    "one",
    "six",
    "three",
    "times",
    "two",
    "six",
    "two",
    "times",
    "three",
    "since",
    "two",
    "arrays",
    "size",
    "setup",
    "going",
    "truncate",
    "first",
    "one",
    "going",
    "look",
    "second",
    "array",
    "multiplied",
    "first",
    "three",
    "elements",
    "first",
    "array",
    "going",
    "little",
    "confusing",
    "remember",
    "computer",
    "gets",
    "repeat",
    "processes",
    "hundreds",
    "times",
    "going",
    "forget",
    "numbers",
    "later",
    "see",
    "bring",
    "back",
    "sum",
    "product",
    "case",
    "5",
    "plus",
    "6",
    "plus",
    "6",
    "equals",
    "times",
    "b",
    "first",
    "digit",
    "matrix",
    "times",
    "b",
    "remember",
    "said",
    "going",
    "forget",
    "digits",
    "3",
    "2",
    "5",
    "move",
    "one",
    "set",
    "take",
    "3",
    "2",
    "5",
    "multiply",
    "times",
    "b",
    "see",
    "3",
    "times",
    "1",
    "3",
    "2",
    "times",
    "2",
    "4",
    "sum",
    "second",
    "digit",
    "times",
    "b",
    "product",
    "matrix",
    "continue",
    "thing",
    "would",
    "go",
    "375",
    "759",
    "short",
    "matrix",
    "covered",
    "different",
    "entities",
    "match",
    "three",
    "different",
    "levels",
    "b",
    "little",
    "bit",
    "going",
    "cover",
    "use",
    "math",
    "multiplying",
    "matrixes",
    "works",
    "important",
    "understand",
    "going",
    "matrix",
    "multiplying",
    "different",
    "parts",
    "match",
    "smaller",
    "matrix",
    "larger",
    "matrix",
    "know",
    "lot",
    "people",
    "get",
    "lost",
    "going",
    "matrixes",
    "oh",
    "scary",
    "math",
    "really",
    "scary",
    "break",
    "looking",
    "section",
    "comparing",
    "b",
    "break",
    "mind",
    "like",
    "realize",
    "okay",
    "taking",
    "two",
    "matrixes",
    "comparing",
    "bringing",
    "value",
    "one",
    "matrix",
    "times",
    "b",
    "reducing",
    "information",
    "way",
    "help",
    "computer",
    "see",
    "different",
    "aspects",
    "let",
    "go",
    "ahead",
    "flip",
    "back",
    "images",
    "back",
    "images",
    "talking",
    "going",
    "basic",
    "image",
    "get",
    "consider",
    "following",
    "two",
    "images",
    "image",
    "symbol",
    "backslash",
    "press",
    "backslash",
    "image",
    "processed",
    "see",
    "image",
    "forward",
    "slash",
    "opposite",
    "click",
    "forward",
    "slash",
    "button",
    "flips",
    "uh",
    "basic",
    "four",
    "pixels",
    "going",
    "ca",
    "get",
    "basic",
    "little",
    "bit",
    "complicated",
    "picture",
    "take",
    "real",
    "image",
    "smiley",
    "face",
    "um",
    "represent",
    "form",
    "black",
    "white",
    "pixels",
    "image",
    "computer",
    "black",
    "white",
    "like",
    "saw",
    "convert",
    "zeros",
    "one",
    "one",
    "would",
    "matrix",
    "four",
    "dots",
    "significantly",
    "larger",
    "image",
    "coming",
    "worry",
    "going",
    "bring",
    "together",
    "little",
    "bit",
    "layers",
    "convolutional",
    "neural",
    "network",
    "looking",
    "convolution",
    "layer",
    "really",
    "central",
    "aspect",
    "processing",
    "images",
    "convolutional",
    "neural",
    "network",
    "going",
    "feeding",
    "relu",
    "layer",
    "know",
    "talked",
    "rectified",
    "linear",
    "unit",
    "talk",
    "little",
    "bit",
    "later",
    "release",
    "act",
    "layer",
    "activated",
    "math",
    "behind",
    "makes",
    "neurons",
    "fire",
    "see",
    "lot",
    "neural",
    "networks",
    "using",
    "processing",
    "smaller",
    "amounts",
    "data",
    "use",
    "atom",
    "activation",
    "feature",
    "large",
    "data",
    "coming",
    "processing",
    "small",
    "amounts",
    "data",
    "image",
    "relu",
    "layer",
    "works",
    "great",
    "pooling",
    "layer",
    "pulling",
    "data",
    "together",
    "pooling",
    "neural",
    "network",
    "term",
    "commonly",
    "used",
    "like",
    "use",
    "term",
    "reduce",
    "coming",
    "map",
    "reduce",
    "side",
    "see",
    "mapping",
    "data",
    "networks",
    "going",
    "reduce",
    "going",
    "pull",
    "together",
    "finally",
    "fully",
    "connected",
    "layer",
    "output",
    "going",
    "come",
    "started",
    "look",
    "matrixes",
    "started",
    "look",
    "convolutional",
    "layer",
    "fits",
    "everything",
    "taken",
    "look",
    "images",
    "going",
    "focus",
    "convolution",
    "layer",
    "since",
    "convolutional",
    "neural",
    "network",
    "convolution",
    "layer",
    "number",
    "filters",
    "perform",
    "convolution",
    "operation",
    "every",
    "image",
    "considered",
    "matrix",
    "pixel",
    "values",
    "consider",
    "following",
    "5x5",
    "image",
    "whose",
    "pixel",
    "values",
    "0",
    "obviously",
    "dealing",
    "color",
    "kinds",
    "things",
    "come",
    "color",
    "processing",
    "want",
    "keep",
    "simple",
    "keep",
    "black",
    "white",
    "image",
    "pixels",
    "sliding",
    "filter",
    "matrix",
    "image",
    "computing",
    "dot",
    "product",
    "detect",
    "patterns",
    "right",
    "going",
    "ask",
    "filter",
    "come",
    "bit",
    "confusing",
    "filter",
    "going",
    "derived",
    "later",
    "build",
    "filters",
    "program",
    "train",
    "model",
    "need",
    "worry",
    "filter",
    "actually",
    "need",
    "understand",
    "convolution",
    "layer",
    "works",
    "filter",
    "filter",
    "mini",
    "filters",
    "one",
    "filter",
    "lots",
    "filters",
    "going",
    "look",
    "different",
    "aspects",
    "filter",
    "might",
    "looking",
    "edges",
    "might",
    "looking",
    "different",
    "parts",
    "cover",
    "little",
    "bit",
    "detail",
    "minute",
    "right",
    "focusing",
    "filter",
    "works",
    "matrix",
    "remember",
    "earlier",
    "talked",
    "multiplying",
    "matrixes",
    "together",
    "two",
    "dimensional",
    "matrix",
    "see",
    "take",
    "filter",
    "multiply",
    "upper",
    "left",
    "image",
    "see",
    "right",
    "one",
    "times",
    "one",
    "one",
    "times",
    "zero",
    "one",
    "times",
    "one",
    "multiply",
    "together",
    "sum",
    "end",
    "convolved",
    "feature",
    "four",
    "going",
    "take",
    "sliding",
    "filter",
    "matrix",
    "image",
    "computing",
    "dot",
    "product",
    "detect",
    "patterns",
    "going",
    "slide",
    "going",
    "predict",
    "first",
    "one",
    "slide",
    "one",
    "notch",
    "predict",
    "second",
    "one",
    "way",
    "new",
    "matrix",
    "matrix",
    "size",
    "filter",
    "reduced",
    "image",
    "whatever",
    "filter",
    "whatever",
    "filtering",
    "going",
    "looking",
    "features",
    "reduced",
    "smaller",
    "matrix",
    "feature",
    "maps",
    "extracted",
    "next",
    "step",
    "move",
    "relu",
    "layer",
    "relu",
    "layer",
    "next",
    "step",
    "first",
    "going",
    "perform",
    "operation",
    "maps",
    "coming",
    "negative",
    "pixels",
    "says",
    "negative",
    "pixels",
    "zero",
    "see",
    "nice",
    "graph",
    "zeros",
    "negatives",
    "value",
    "goes",
    "zero",
    "whatever",
    "value",
    "coming",
    "matrix",
    "introduces",
    "network",
    "say",
    "linearity",
    "talking",
    "fact",
    "feature",
    "value",
    "linear",
    "feature",
    "feature",
    "came",
    "let",
    "say",
    "feature",
    "edge",
    "beak",
    "know",
    "like",
    "backslash",
    "saw",
    "look",
    "say",
    "okay",
    "feature",
    "value",
    "negative",
    "10",
    "10",
    "case",
    "one",
    "say",
    "yeah",
    "might",
    "beak",
    "might",
    "might",
    "edge",
    "right",
    "minus",
    "five",
    "means",
    "even",
    "going",
    "look",
    "zero",
    "end",
    "output",
    "output",
    "takes",
    "features",
    "filtered",
    "features",
    "remember",
    "running",
    "one",
    "filter",
    "running",
    "number",
    "filters",
    "image",
    "end",
    "rectified",
    "feature",
    "map",
    "looking",
    "features",
    "coming",
    "weigh",
    "filters",
    "input",
    "looks",
    "like",
    "toucan",
    "bird",
    "exotic",
    "looking",
    "real",
    "image",
    "scanned",
    "multiple",
    "convolution",
    "relu",
    "layers",
    "locating",
    "features",
    "see",
    "turn",
    "black",
    "white",
    "image",
    "case",
    "looking",
    "upper",
    "right",
    "hand",
    "corner",
    "feature",
    "box",
    "scans",
    "lot",
    "times",
    "scan",
    "one",
    "pixel",
    "time",
    "lot",
    "times",
    "skip",
    "two",
    "three",
    "four",
    "pixels",
    "uh",
    "speed",
    "process",
    "one",
    "ways",
    "compensate",
    "enough",
    "resources",
    "computation",
    "large",
    "images",
    "one",
    "filter",
    "slowly",
    "goes",
    "across",
    "image",
    "multiple",
    "filters",
    "programmed",
    "looking",
    "lot",
    "different",
    "filters",
    "going",
    "different",
    "aspects",
    "image",
    "sliding",
    "across",
    "forming",
    "new",
    "matrix",
    "one",
    "aspect",
    "note",
    "relu",
    "layer",
    "one",
    "value",
    "coming",
    "multiple",
    "features",
    "going",
    "generating",
    "multiple",
    "relu",
    "layers",
    "locating",
    "features",
    "important",
    "note",
    "know",
    "quite",
    "bundle",
    "multiple",
    "filters",
    "multiple",
    "rail",
    "u",
    "brings",
    "us",
    "next",
    "step",
    "forward",
    "propagation",
    "going",
    "look",
    "pooling",
    "layer",
    "rectified",
    "feature",
    "map",
    "goes",
    "pooling",
    "layer",
    "pooling",
    "sampling",
    "operation",
    "reduces",
    "dimensionality",
    "feature",
    "map",
    "trying",
    "trying",
    "take",
    "huge",
    "amount",
    "information",
    "reduce",
    "single",
    "answer",
    "specific",
    "kind",
    "bird",
    "iris",
    "rose",
    "rectified",
    "feature",
    "map",
    "see",
    "rectified",
    "feature",
    "map",
    "coming",
    "set",
    "max",
    "pooling",
    "2",
    "2",
    "filters",
    "stride",
    "two",
    "remember",
    "correctly",
    "talked",
    "going",
    "one",
    "pixel",
    "time",
    "uh",
    "well",
    "stride",
    "comes",
    "end",
    "two",
    "two",
    "pooled",
    "feature",
    "map",
    "instead",
    "moving",
    "one",
    "time",
    "looking",
    "every",
    "possible",
    "combination",
    "skip",
    "st",
    "skip",
    "go",
    "two",
    "skip",
    "every",
    "pixel",
    "every",
    "one",
    "reduces",
    "rectified",
    "feature",
    "map",
    "see",
    "16",
    "16",
    "four",
    "four",
    "continually",
    "trying",
    "filter",
    "reduce",
    "data",
    "get",
    "something",
    "manage",
    "see",
    "max",
    "three",
    "four",
    "one",
    "two",
    "max",
    "pooling",
    "looking",
    "max",
    "value",
    "little",
    "bit",
    "different",
    "looking",
    "coming",
    "rectified",
    "feature",
    "finding",
    "max",
    "value",
    "pulling",
    "features",
    "together",
    "instead",
    "think",
    "image",
    "map",
    "think",
    "valuable",
    "feature",
    "area",
    "much",
    "feature",
    "value",
    "want",
    "find",
    "best",
    "maximum",
    "feature",
    "area",
    "might",
    "one",
    "piece",
    "filter",
    "beak",
    "said",
    "oh",
    "see",
    "one",
    "beak",
    "image",
    "skips",
    "says",
    "see",
    "three",
    "image",
    "says",
    "oh",
    "one",
    "rated",
    "four",
    "want",
    "sum",
    "together",
    "know",
    "might",
    "like",
    "five",
    "ones",
    "say",
    "ah",
    "five",
    "might",
    "uh",
    "four",
    "zeros",
    "one",
    "ten",
    "ten",
    "says",
    "well",
    "definitely",
    "beak",
    "ones",
    "say",
    "probably",
    "beak",
    "little",
    "strange",
    "analogy",
    "since",
    "looking",
    "bird",
    "see",
    "pulled",
    "feature",
    "map",
    "comes",
    "looking",
    "max",
    "value",
    "one",
    "matrixes",
    "pooling",
    "layer",
    "uses",
    "different",
    "filters",
    "identify",
    "different",
    "parts",
    "image",
    "like",
    "edges",
    "corners",
    "body",
    "feathers",
    "eyes",
    "beak",
    "etc",
    "know",
    "focus",
    "mainly",
    "beak",
    "obviously",
    "feature",
    "could",
    "different",
    "part",
    "bird",
    "coming",
    "let",
    "take",
    "look",
    "looks",
    "like",
    "structure",
    "convolution",
    "neural",
    "network",
    "far",
    "right",
    "input",
    "image",
    "coming",
    "use",
    "filters",
    "multiple",
    "filters",
    "developed",
    "kind",
    "twist",
    "change",
    "data",
    "multiply",
    "matrixes",
    "take",
    "little",
    "filter",
    "maybe",
    "two",
    "two",
    "multiply",
    "piece",
    "image",
    "step",
    "two",
    "every",
    "piece",
    "image",
    "generates",
    "multiple",
    "convolution",
    "layers",
    "number",
    "convolution",
    "layers",
    "set",
    "looking",
    "data",
    "take",
    "convolution",
    "layers",
    "run",
    "relu",
    "setup",
    "done",
    "release",
    "setup",
    "multiple",
    "values",
    "going",
    "multiple",
    "layers",
    "relative",
    "going",
    "take",
    "multiple",
    "layers",
    "going",
    "pooling",
    "pooling",
    "layers",
    "multiple",
    "poolings",
    "going",
    "point",
    "dealing",
    "sometimes",
    "multiple",
    "dimensions",
    "three",
    "dimensions",
    "strange",
    "data",
    "setups",
    "images",
    "looking",
    "things",
    "four",
    "five",
    "six",
    "seven",
    "dimensions",
    "right",
    "looking",
    "2d",
    "image",
    "dimensions",
    "coming",
    "pooling",
    "layer",
    "next",
    "step",
    "want",
    "reduce",
    "dimensions",
    "flatten",
    "flattening",
    "flattening",
    "process",
    "converting",
    "resultant",
    "arrays",
    "pooled",
    "feature",
    "map",
    "single",
    "long",
    "continuous",
    "linear",
    "vector",
    "see",
    "pooled",
    "feature",
    "map",
    "maybe",
    "bird",
    "wing",
    "values",
    "6847",
    "want",
    "flatten",
    "turn",
    "6847",
    "single",
    "linear",
    "vector",
    "find",
    "pooled",
    "feature",
    "maps",
    "one",
    "long",
    "linear",
    "vector",
    "gone",
    "convolutional",
    "neural",
    "network",
    "part",
    "input",
    "layer",
    "next",
    "setup",
    "done",
    "taken",
    "different",
    "pooling",
    "layers",
    "flatten",
    "combine",
    "single",
    "linear",
    "vector",
    "going",
    "done",
    "flattening",
    "quick",
    "recap",
    "covered",
    "much",
    "important",
    "go",
    "back",
    "take",
    "look",
    "steps",
    "gone",
    "structure",
    "network",
    "far",
    "convolution",
    "twist",
    "filter",
    "multiply",
    "matrixes",
    "end",
    "convolutional",
    "layer",
    "uses",
    "relu",
    "figure",
    "values",
    "going",
    "pooling",
    "numerous",
    "convolution",
    "layers",
    "create",
    "numerous",
    "pooling",
    "layers",
    "pulling",
    "data",
    "together",
    "max",
    "value",
    "one",
    "want",
    "send",
    "forward",
    "want",
    "send",
    "best",
    "value",
    "going",
    "take",
    "pooling",
    "layers",
    "going",
    "flatten",
    "going",
    "combine",
    "single",
    "input",
    "going",
    "final",
    "layer",
    "get",
    "step",
    "might",
    "looking",
    "going",
    "boy",
    "looks",
    "like",
    "normal",
    "neural",
    "network",
    "correct",
    "flattened",
    "matrix",
    "pooling",
    "layer",
    "becomes",
    "input",
    "pulling",
    "layer",
    "fed",
    "input",
    "fully",
    "connected",
    "layer",
    "classify",
    "image",
    "see",
    "flattened",
    "matrix",
    "comes",
    "case",
    "pixels",
    "flattened",
    "matrix",
    "fed",
    "input",
    "back",
    "toucan",
    "whatever",
    "kind",
    "bird",
    "need",
    "one",
    "identify",
    "kind",
    "bird",
    "comes",
    "forward",
    "propagation",
    "network",
    "different",
    "weights",
    "coming",
    "across",
    "finally",
    "selects",
    "bird",
    "dog",
    "cat",
    "case",
    "even",
    "though",
    "labeled",
    "final",
    "layer",
    "red",
    "output",
    "layer",
    "final",
    "output",
    "layer",
    "says",
    "bird",
    "cat",
    "dog",
    "quick",
    "recap",
    "everything",
    "covered",
    "far",
    "input",
    "image",
    "twisted",
    "multiplied",
    "filters",
    "multiplied",
    "times",
    "matrix",
    "two",
    "matrixes",
    "multiplied",
    "filters",
    "create",
    "convolution",
    "layer",
    "convolution",
    "layers",
    "multiple",
    "layers",
    "building",
    "multiple",
    "layers",
    "different",
    "filters",
    "goes",
    "relu",
    "activation",
    "creates",
    "pooling",
    "get",
    "pooling",
    "layer",
    "pooling",
    "look",
    "best",
    "max",
    "value",
    "coming",
    "convolution",
    "take",
    "layer",
    "flatten",
    "goes",
    "fully",
    "connected",
    "layer",
    "fully",
    "connected",
    "neural",
    "network",
    "output",
    "see",
    "entire",
    "process",
    "cnn",
    "recognizes",
    "bird",
    "kind",
    "nice",
    "showing",
    "little",
    "pixels",
    "going",
    "see",
    "filter",
    "generating",
    "convolution",
    "network",
    "filter",
    "shows",
    "bottom",
    "part",
    "convolution",
    "network",
    "based",
    "uses",
    "relu",
    "pooling",
    "pooling",
    "find",
    "one",
    "best",
    "way",
    "fully",
    "connected",
    "layer",
    "end",
    "classification",
    "output",
    "layer",
    "classification",
    "neural",
    "network",
    "end",
    "covered",
    "lot",
    "theory",
    "till",
    "imagine",
    "one",
    "steps",
    "broken",
    "code",
    "putting",
    "together",
    "little",
    "complicated",
    "step",
    "process",
    "overly",
    "complicated",
    "many",
    "steps",
    "one",
    "two",
    "three",
    "four",
    "five",
    "different",
    "steps",
    "going",
    "sub",
    "steps",
    "going",
    "break",
    "walk",
    "code",
    "use",
    "case",
    "implementation",
    "using",
    "cnn",
    "using",
    "cfar10",
    "dataset",
    "canadian",
    "institute",
    "advanced",
    "research",
    "classifying",
    "images",
    "across",
    "10",
    "categories",
    "unfortunately",
    "let",
    "know",
    "whether",
    "going",
    "toucan",
    "kind",
    "bird",
    "get",
    "find",
    "whether",
    "categorize",
    "ship",
    "frog",
    "deer",
    "bird",
    "airplane",
    "automobile",
    "cat",
    "dog",
    "horse",
    "truck",
    "lot",
    "fun",
    "looking",
    "anything",
    "news",
    "automated",
    "cars",
    "everything",
    "else",
    "see",
    "kind",
    "processing",
    "important",
    "today",
    "world",
    "cutting",
    "edge",
    "far",
    "coming",
    "commercial",
    "deployment",
    "mean",
    "really",
    "cool",
    "stuff",
    "starting",
    "see",
    "everywhere",
    "industry",
    "great",
    "time",
    "playing",
    "figuring",
    "let",
    "go",
    "ahead",
    "dive",
    "code",
    "see",
    "looks",
    "like",
    "actually",
    "writing",
    "script",
    "go",
    "let",
    "uh",
    "one",
    "quick",
    "look",
    "let",
    "take",
    "look",
    "data",
    "batch",
    "one",
    "keys",
    "remember",
    "jupiter",
    "notebook",
    "get",
    "print",
    "statement",
    "put",
    "variable",
    "display",
    "variable",
    "see",
    "data",
    "batch",
    "one",
    "keys",
    "since",
    "dictionary",
    "batch",
    "one",
    "label",
    "data",
    "file",
    "names",
    "actually",
    "see",
    "broken",
    "data",
    "set",
    "next",
    "step",
    "step",
    "four",
    "calling",
    "uh",
    "want",
    "display",
    "images",
    "using",
    "matte",
    "plot",
    "library",
    "many",
    "ways",
    "display",
    "images",
    "even",
    "uh",
    "well",
    "ways",
    "drill",
    "matplot",
    "library",
    "really",
    "good",
    "also",
    "look",
    "first",
    "reshape",
    "uh",
    "setup",
    "shaping",
    "data",
    "little",
    "glimpse",
    "means",
    "uh",
    "gon",
    "na",
    "start",
    "importing",
    "map",
    "plot",
    "course",
    "since",
    "jupiter",
    "notebook",
    "need",
    "matplot",
    "inline",
    "command",
    "shows",
    "page",
    "go",
    "going",
    "import",
    "matplot",
    "plt",
    "remember",
    "matplot",
    "library",
    "pie",
    "plot",
    "like",
    "canvas",
    "paint",
    "stuff",
    "onto",
    "percentage",
    "sign",
    "matplot",
    "library",
    "inline",
    "going",
    "show",
    "notebook",
    "course",
    "going",
    "import",
    "numpy",
    "np",
    "numbers",
    "python",
    "array",
    "setup",
    "let",
    "go",
    "ahead",
    "set",
    "x",
    "equals",
    "data",
    "batch",
    "one",
    "pull",
    "data",
    "going",
    "x",
    "value",
    "long",
    "stream",
    "binary",
    "data",
    "need",
    "go",
    "little",
    "bit",
    "reshaping",
    "go",
    "ahead",
    "reshape",
    "data",
    "10",
    "000",
    "images",
    "okay",
    "looks",
    "correct",
    "kind",
    "interesting",
    "thing",
    "took",
    "little",
    "bit",
    "go",
    "research",
    "figure",
    "going",
    "data",
    "32",
    "32",
    "picture",
    "let",
    "let",
    "go",
    "ahead",
    "drawing",
    "pad",
    "32",
    "bits",
    "32",
    "bits",
    "color",
    "three",
    "bits",
    "color",
    "know",
    "data",
    "particularly",
    "like",
    "probably",
    "originally",
    "encoded",
    "pictures",
    "put",
    "three",
    "afterward",
    "going",
    "take",
    "shape",
    "going",
    "take",
    "data",
    "long",
    "stream",
    "information",
    "going",
    "break",
    "10",
    "000",
    "pieces",
    "10",
    "000",
    "pieces",
    "broken",
    "three",
    "pieces",
    "three",
    "pieces",
    "32",
    "look",
    "like",
    "projector",
    "red",
    "screen",
    "red",
    "projector",
    "blue",
    "projector",
    "green",
    "projector",
    "add",
    "together",
    "one",
    "32",
    "32",
    "bit",
    "probably",
    "originally",
    "formatted",
    "kind",
    "ideal",
    "things",
    "changed",
    "going",
    "transpose",
    "going",
    "take",
    "three",
    "going",
    "put",
    "end",
    "first",
    "part",
    "reshaping",
    "data",
    "single",
    "line",
    "bit",
    "data",
    "whatever",
    "format",
    "10",
    "000",
    "three",
    "32",
    "32",
    "going",
    "transpose",
    "color",
    "factor",
    "last",
    "place",
    "image",
    "32",
    "32",
    "middle",
    "part",
    "right",
    "finally",
    "going",
    "take",
    "three",
    "bits",
    "data",
    "put",
    "end",
    "like",
    "process",
    "images",
    "type",
    "really",
    "important",
    "going",
    "use",
    "integer",
    "eight",
    "come",
    "see",
    "lot",
    "try",
    "float",
    "float",
    "got",
    "remember",
    "though",
    "float",
    "uses",
    "lot",
    "memory",
    "switch",
    "uh",
    "something",
    "integer",
    "eight",
    "goes",
    "128",
    "gon",
    "na",
    "amount",
    "ram",
    "let",
    "put",
    "going",
    "go",
    "way",
    "amount",
    "ram",
    "loads",
    "want",
    "go",
    "ahead",
    "use",
    "try",
    "ones",
    "see",
    "happens",
    "lot",
    "ram",
    "computer",
    "exercise",
    "work",
    "fine",
    "let",
    "go",
    "ahead",
    "take",
    "run",
    "x",
    "variable",
    "loaded",
    "images",
    "batch",
    "one",
    "data",
    "batch",
    "one",
    "show",
    "talking",
    "type",
    "go",
    "ahead",
    "take",
    "x0",
    "look",
    "max",
    "value",
    "let",
    "go",
    "ahead",
    "run",
    "see",
    "oops",
    "said",
    "128",
    "see",
    "go",
    "255",
    "basically",
    "ascii",
    "character",
    "keeping",
    "keeping",
    "values",
    "255",
    "0",
    "255",
    "versus",
    "float",
    "value",
    "would",
    "bring",
    "exponentially",
    "size",
    "since",
    "using",
    "matplot",
    "library",
    "oops",
    "wanted",
    "since",
    "using",
    "map",
    "plot",
    "library",
    "take",
    "canvas",
    "plt",
    "dot",
    "im",
    "image",
    "show",
    "let",
    "take",
    "look",
    "x0",
    "looks",
    "like",
    "comes",
    "sure",
    "see",
    "low",
    "grade",
    "image",
    "broken",
    "minimal",
    "pixels",
    "thing",
    "oh",
    "let",
    "uh",
    "let",
    "see",
    "one",
    "looks",
    "like",
    "hopefully",
    "little",
    "easier",
    "see",
    "run",
    "enter",
    "let",
    "hit",
    "run",
    "see",
    "probably",
    "semi",
    "truck",
    "good",
    "guess",
    "go",
    "back",
    "instead",
    "typing",
    "line",
    "look",
    "three",
    "looks",
    "like",
    "dump",
    "truck",
    "unloading",
    "uh",
    "10",
    "000",
    "images",
    "jump",
    "uh",
    "looks",
    "like",
    "kind",
    "animal",
    "looking",
    "us",
    "probably",
    "dog",
    "fun",
    "let",
    "one",
    "uh",
    "run",
    "see",
    "nice",
    "car",
    "image",
    "number",
    "four",
    "uh",
    "see",
    "paste",
    "different",
    "images",
    "easy",
    "look",
    "reshaped",
    "fit",
    "view",
    "matplot",
    "library",
    "uses",
    "format",
    "next",
    "step",
    "gon",
    "na",
    "start",
    "creating",
    "helper",
    "functions",
    "start",
    "one",
    "hot",
    "encoder",
    "help",
    "us",
    "processing",
    "data",
    "remember",
    "labels",
    "ca",
    "words",
    "switch",
    "use",
    "one",
    "hot",
    "encoder",
    "also",
    "create",
    "class",
    "uh",
    "cfar",
    "helper",
    "going",
    "init",
    "setup",
    "images",
    "finally",
    "go",
    "ahead",
    "run",
    "code",
    "see",
    "looks",
    "like",
    "get",
    "fun",
    "part",
    "actually",
    "going",
    "start",
    "creating",
    "model",
    "actual",
    "neural",
    "network",
    "model",
    "let",
    "start",
    "creating",
    "one",
    "hot",
    "encoder",
    "going",
    "create",
    "going",
    "return",
    "vector",
    "coming",
    "values",
    "equal",
    "means",
    "10",
    "values",
    "10",
    "possible",
    "labels",
    "remember",
    "look",
    "labels",
    "number",
    "car",
    "one",
    "horse",
    "kind",
    "bizarre",
    "horse",
    "equals",
    "zero",
    "car",
    "equals",
    "one",
    "plane",
    "equals",
    "two",
    "cat",
    "equals",
    "three",
    "cat",
    "plus",
    "car",
    "equals",
    "instead",
    "create",
    "numpy",
    "array",
    "zeros",
    "going",
    "10",
    "values",
    "10",
    "different",
    "values",
    "0",
    "1",
    "1",
    "means",
    "cat",
    "0",
    "means",
    "cat",
    "next",
    "line",
    "might",
    "one",
    "means",
    "car",
    "zero",
    "means",
    "car",
    "instead",
    "one",
    "output",
    "value",
    "zero",
    "ten",
    "ten",
    "outputs",
    "values",
    "zero",
    "one",
    "one",
    "hot",
    "encoder",
    "going",
    "utilize",
    "code",
    "minute",
    "let",
    "go",
    "ahead",
    "take",
    "look",
    "next",
    "helpers",
    "helper",
    "functions",
    "going",
    "build",
    "working",
    "complicated",
    "python",
    "project",
    "dividing",
    "separate",
    "definitions",
    "classes",
    "important",
    "otherwise",
    "becomes",
    "really",
    "ungainly",
    "work",
    "let",
    "go",
    "ahead",
    "put",
    "next",
    "helper",
    "class",
    "lot",
    "class",
    "break",
    "let",
    "start",
    "oops",
    "put",
    "space",
    "right",
    "go",
    "little",
    "bit",
    "readable",
    "second",
    "space",
    "going",
    "create",
    "class",
    "cipher",
    "helper",
    "start",
    "initializing",
    "lot",
    "going",
    "let",
    "start",
    "init",
    "part",
    "uh",
    "self",
    "dot",
    "equals",
    "zero",
    "come",
    "little",
    "bit",
    "come",
    "back",
    "lower",
    "part",
    "want",
    "initialize",
    "training",
    "batches",
    "went",
    "like",
    "meta",
    "batch",
    "need",
    "meta",
    "batch",
    "need",
    "data",
    "batch",
    "one",
    "two",
    "three",
    "four",
    "five",
    "want",
    "testing",
    "batch",
    "self",
    "train",
    "batches",
    "gon",
    "na",
    "come",
    "make",
    "array",
    "different",
    "images",
    "course",
    "left",
    "test",
    "batch",
    "going",
    "initialize",
    "training",
    "images",
    "training",
    "labels",
    "also",
    "test",
    "images",
    "test",
    "labels",
    "initialize",
    "variables",
    "create",
    "another",
    "definition",
    "going",
    "set",
    "images",
    "let",
    "take",
    "look",
    "see",
    "going",
    "could",
    "put",
    "part",
    "init",
    "part",
    "since",
    "helper",
    "stuff",
    "breaking",
    "makes",
    "easier",
    "read",
    "also",
    "makes",
    "easier",
    "start",
    "executing",
    "different",
    "pieces",
    "see",
    "going",
    "way",
    "nice",
    "print",
    "statement",
    "say",
    "hey",
    "running",
    "going",
    "going",
    "set",
    "self",
    "training",
    "images",
    "point",
    "going",
    "go",
    "numpy",
    "array",
    "v",
    "stack",
    "going",
    "load",
    "case",
    "data",
    "train",
    "batches",
    "points",
    "right",
    "going",
    "go",
    "one",
    "files",
    "one",
    "data",
    "sets",
    "file",
    "anymore",
    "brought",
    "data",
    "batch",
    "one",
    "points",
    "actual",
    "data",
    "self",
    "training",
    "images",
    "going",
    "stack",
    "numpy",
    "array",
    "always",
    "nice",
    "get",
    "training",
    "length",
    "total",
    "number",
    "uh",
    "self",
    "training",
    "images",
    "going",
    "take",
    "self",
    "training",
    "images",
    "let",
    "switch",
    "marker",
    "colors",
    "getting",
    "little",
    "bit",
    "much",
    "markers",
    "oops",
    "go",
    "bring",
    "marker",
    "change",
    "see",
    "little",
    "better",
    "point",
    "look",
    "familiar",
    "see",
    "well",
    "wanted",
    "uh",
    "look",
    "want",
    "look",
    "images",
    "matplot",
    "library",
    "reshape",
    "thing",
    "taking",
    "self",
    "training",
    "images",
    "uh",
    "based",
    "training",
    "length",
    "total",
    "number",
    "images",
    "stacked",
    "together",
    "one",
    "large",
    "file",
    "images",
    "going",
    "take",
    "look",
    "three",
    "video",
    "cameras",
    "displaying",
    "32",
    "32",
    "going",
    "switch",
    "around",
    "images",
    "stays",
    "place",
    "32",
    "32",
    "three",
    "last",
    "three",
    "different",
    "values",
    "color",
    "course",
    "want",
    "go",
    "ahead",
    "run",
    "say",
    "divide",
    "255",
    "earlier",
    "brings",
    "data",
    "zero",
    "one",
    "turning",
    "zero",
    "one",
    "array",
    "uh",
    "pictures",
    "32",
    "32",
    "three",
    "going",
    "take",
    "self",
    "training",
    "labels",
    "going",
    "pump",
    "one",
    "hot",
    "encoder",
    "made",
    "going",
    "stack",
    "together",
    "converting",
    "array",
    "goes",
    "instead",
    "horse",
    "equals",
    "one",
    "dog",
    "equals",
    "two",
    "horse",
    "plus",
    "dog",
    "would",
    "equal",
    "three",
    "would",
    "cat",
    "going",
    "know",
    "array",
    "10",
    "one",
    "0",
    "want",
    "go",
    "ahead",
    "set",
    "test",
    "images",
    "labels",
    "going",
    "see",
    "thing",
    "rest",
    "changed",
    "colors",
    "right",
    "different",
    "training",
    "set",
    "going",
    "stack",
    "different",
    "images",
    "going",
    "get",
    "length",
    "know",
    "many",
    "images",
    "certainly",
    "could",
    "add",
    "hand",
    "nice",
    "let",
    "computer",
    "especially",
    "ever",
    "changes",
    "end",
    "using",
    "data",
    "reshape",
    "transpose",
    "also",
    "one",
    "hot",
    "encoder",
    "thing",
    "training",
    "images",
    "test",
    "images",
    "format",
    "definition",
    "sets",
    "images",
    "next",
    "step",
    "go",
    "ahead",
    "batch",
    "next",
    "batch",
    "let",
    "another",
    "breakout",
    "batches",
    "really",
    "important",
    "understand",
    "tends",
    "throw",
    "little",
    "loop",
    "working",
    "tensorflow",
    "cross",
    "lot",
    "data",
    "coming",
    "remember",
    "like",
    "10",
    "000",
    "photos",
    "let",
    "put",
    "10",
    "000",
    "want",
    "run",
    "10",
    "000",
    "want",
    "break",
    "batch",
    "sizes",
    "also",
    "remember",
    "number",
    "photos",
    "case",
    "length",
    "test",
    "whatever",
    "number",
    "also",
    "32",
    "32",
    "looking",
    "batch",
    "size",
    "want",
    "change",
    "10",
    "000",
    "batch",
    "case",
    "think",
    "going",
    "batches",
    "hundred",
    "want",
    "look",
    "100",
    "first",
    "hundred",
    "photos",
    "remember",
    "set",
    "self",
    "equal",
    "zero",
    "uh",
    "looking",
    "going",
    "create",
    "x",
    "going",
    "get",
    "next",
    "batch",
    "initialize",
    "already",
    "initialized",
    "going",
    "look",
    "x",
    "0",
    "batch",
    "size",
    "set",
    "100",
    "first",
    "hundred",
    "images",
    "going",
    "reshape",
    "uh",
    "important",
    "let",
    "data",
    "know",
    "looking",
    "100",
    "32",
    "32",
    "already",
    "formatted",
    "32",
    "32",
    "sets",
    "everything",
    "correctly",
    "x",
    "data",
    "correct",
    "order",
    "correct",
    "shape",
    "like",
    "x",
    "labels",
    "training",
    "labels",
    "go",
    "0",
    "batch",
    "size",
    "case",
    "sell",
    "fi",
    "plus",
    "batch",
    "size",
    "cell",
    "phi",
    "going",
    "keep",
    "changing",
    "finally",
    "increment",
    "self",
    "zero",
    "next",
    "time",
    "call",
    "going",
    "get",
    "next",
    "batch",
    "size",
    "basically",
    "x",
    "x",
    "photograph",
    "data",
    "coming",
    "label",
    "course",
    "labeled",
    "one",
    "hot",
    "encoder",
    "remember",
    "correctly",
    "say",
    "horse",
    "equal",
    "zero",
    "would",
    "one",
    "zero",
    "position",
    "since",
    "horse",
    "everything",
    "else",
    "would",
    "zero",
    "let",
    "put",
    "lines",
    "go",
    "array",
    "hard",
    "see",
    "array",
    "let",
    "go",
    "ahead",
    "take",
    "uh",
    "going",
    "finish",
    "loading",
    "since",
    "class",
    "armed",
    "uh",
    "setup",
    "let",
    "go",
    "ahead",
    "load",
    "going",
    "create",
    "variable",
    "ch",
    "c4",
    "helper",
    "going",
    "images",
    "could",
    "put",
    "setup",
    "images",
    "init",
    "breaking",
    "two",
    "parts",
    "makes",
    "much",
    "readable",
    "also",
    "work",
    "reasons",
    "far",
    "setup",
    "let",
    "go",
    "ahead",
    "run",
    "see",
    "says",
    "uh",
    "setting",
    "training",
    "images",
    "labels",
    "setting",
    "test",
    "images",
    "one",
    "reasons",
    "broke",
    "testing",
    "actually",
    "print",
    "statements",
    "telling",
    "going",
    "really",
    "nice",
    "uh",
    "good",
    "job",
    "setup",
    "like",
    "way",
    "broken",
    "back",
    "one",
    "quick",
    "note",
    "want",
    "remember",
    "batch",
    "set",
    "next",
    "batch",
    "since",
    "run",
    "batch",
    "equals",
    "ch",
    "next",
    "batch",
    "100",
    "going",
    "use",
    "100",
    "size",
    "come",
    "back",
    "going",
    "use",
    "remember",
    "part",
    "code",
    "going",
    "using",
    "minute",
    "definition",
    "made",
    "ready",
    "create",
    "model",
    "first",
    "thing",
    "want",
    "want",
    "import",
    "tensorflow",
    "tf",
    "go",
    "ahead",
    "run",
    "loaded",
    "see",
    "got",
    "warning",
    "making",
    "changes",
    "always",
    "growing",
    "going",
    "depreciating",
    "one",
    "values",
    "float",
    "64",
    "float",
    "type",
    "treated",
    "np",
    "float64",
    "nothing",
    "really",
    "worry",
    "even",
    "affect",
    "working",
    "set",
    "stuff",
    "255",
    "value",
    "zero",
    "one",
    "keep",
    "mind",
    "zero",
    "one",
    "value",
    "converted",
    "255",
    "still",
    "float",
    "value",
    "easily",
    "work",
    "either",
    "numpy",
    "float",
    "64",
    "numpy",
    "type",
    "float",
    "matter",
    "one",
    "goes",
    "depreciation",
    "would",
    "affect",
    "code",
    "tensorflow",
    "uh",
    "go",
    "ahead",
    "increase",
    "size",
    "moment",
    "get",
    "better",
    "view",
    "um",
    "typing",
    "uh",
    "going",
    "set",
    "couple",
    "placeholders",
    "going",
    "set",
    "x",
    "equals",
    "tf",
    "placeholder",
    "tf",
    "float",
    "32",
    "talked",
    "float64",
    "versus",
    "numpy",
    "float",
    "actually",
    "going",
    "keep",
    "float",
    "32",
    "significant",
    "number",
    "decimals",
    "working",
    "since",
    "placeholder",
    "going",
    "set",
    "shape",
    "equal",
    "set",
    "equal",
    "none",
    "point",
    "holding",
    "place",
    "setting",
    "run",
    "batches",
    "first",
    "value",
    "32",
    "32",
    "three",
    "reshaped",
    "data",
    "fit",
    "true",
    "equals",
    "placeholder",
    "tf",
    "float",
    "32",
    "shape",
    "equals",
    "none",
    "comma",
    "10",
    "10",
    "10",
    "different",
    "labels",
    "array",
    "let",
    "create",
    "one",
    "placeholder",
    "call",
    "hold",
    "prob",
    "hold",
    "probability",
    "going",
    "use",
    "shape",
    "anything",
    "placeholder",
    "call",
    "drop",
    "remember",
    "theory",
    "drop",
    "many",
    "nodes",
    "looking",
    "different",
    "values",
    "going",
    "helps",
    "decrease",
    "bias",
    "need",
    "go",
    "ahead",
    "put",
    "placeholder",
    "also",
    "run",
    "loaded",
    "three",
    "different",
    "placeholders",
    "since",
    "tensorflow",
    "use",
    "keras",
    "automatically",
    "tensorflow",
    "direct",
    "kara",
    "sits",
    "tensorflow",
    "going",
    "go",
    "ahead",
    "create",
    "helper",
    "functions",
    "going",
    "create",
    "something",
    "help",
    "us",
    "initialize",
    "weights",
    "initialize",
    "bias",
    "remember",
    "layer",
    "bias",
    "going",
    "going",
    "go",
    "ahead",
    "work",
    "conversional",
    "2d",
    "max",
    "pool",
    "pooling",
    "layer",
    "convolutional",
    "layer",
    "normal",
    "full",
    "layer",
    "going",
    "go",
    "ahead",
    "put",
    "definitions",
    "let",
    "see",
    "looks",
    "like",
    "code",
    "also",
    "grab",
    "helper",
    "functions",
    "mnist",
    "nist",
    "setup",
    "let",
    "put",
    "tensorflow",
    "lot",
    "already",
    "going",
    "go",
    "ahead",
    "going",
    "create",
    "init",
    "weights",
    "one",
    "reasons",
    "actually",
    "start",
    "thinking",
    "going",
    "back",
    "end",
    "even",
    "though",
    "ways",
    "automation",
    "sometimes",
    "tweaked",
    "put",
    "setup",
    "going",
    "going",
    "recreate",
    "code",
    "let",
    "take",
    "look",
    "weights",
    "comes",
    "going",
    "shape",
    "comes",
    "going",
    "random",
    "numbers",
    "going",
    "go",
    "ahead",
    "knit",
    "random",
    "numbers",
    "based",
    "shape",
    "standard",
    "deviation",
    "kind",
    "fun",
    "way",
    "tf",
    "variable",
    "init",
    "random",
    "distribution",
    "creating",
    "random",
    "distribution",
    "weights",
    "might",
    "change",
    "might",
    "higher",
    "standard",
    "deviation",
    "cases",
    "actually",
    "load",
    "preset",
    "weights",
    "pretty",
    "rare",
    "usually",
    "testing",
    "another",
    "model",
    "something",
    "like",
    "want",
    "see",
    "weights",
    "configure",
    "remember",
    "bias",
    "need",
    "go",
    "ahead",
    "initialize",
    "bias",
    "constant",
    "case",
    "using",
    "lot",
    "times",
    "bias",
    "put",
    "one",
    "weights",
    "add",
    "going",
    "set",
    "point",
    "one",
    "want",
    "return",
    "convolutional",
    "2d",
    "case",
    "neural",
    "network",
    "uh",
    "would",
    "layer",
    "going",
    "con",
    "2d",
    "taking",
    "data",
    "coming",
    "uh",
    "going",
    "filter",
    "strides",
    "remember",
    "correctly",
    "strides",
    "came",
    "image",
    "look",
    "picture",
    "maybe",
    "stride",
    "one",
    "look",
    "picture",
    "continue",
    "look",
    "different",
    "filters",
    "going",
    "thing",
    "data",
    "coming",
    "32",
    "32",
    "3",
    "want",
    "change",
    "three",
    "dimensions",
    "going",
    "reformat",
    "two",
    "dimensions",
    "going",
    "take",
    "number",
    "combine",
    "32",
    "32",
    "important",
    "layer",
    "reducing",
    "data",
    "using",
    "different",
    "means",
    "connects",
    "going",
    "jump",
    "one",
    "goes",
    "convolutional",
    "layer",
    "kind",
    "preformatting",
    "setup",
    "actual",
    "convolution",
    "layer",
    "goes",
    "see",
    "init",
    "weights",
    "shape",
    "knit",
    "bias",
    "shape",
    "three",
    "three",
    "different",
    "uh",
    "three",
    "return",
    "tfnn",
    "relu",
    "convention",
    "2d",
    "convolutional",
    "feeding",
    "right",
    "using",
    "part",
    "course",
    "input",
    "x",
    "plus",
    "b",
    "bias",
    "quite",
    "mouthful",
    "two",
    "keys",
    "creating",
    "convolutional",
    "layers",
    "convolutional",
    "2d",
    "coming",
    "convolutional",
    "layer",
    "steps",
    "creates",
    "filters",
    "saw",
    "course",
    "pooling",
    "uh",
    "time",
    "run",
    "convectional",
    "layer",
    "want",
    "pull",
    "data",
    "remember",
    "correctly",
    "pool",
    "side",
    "let",
    "get",
    "rid",
    "marks",
    "getting",
    "little",
    "crazy",
    "fact",
    "let",
    "go",
    "ahead",
    "jump",
    "back",
    "slide",
    "let",
    "take",
    "look",
    "slide",
    "uh",
    "image",
    "coming",
    "create",
    "convolutional",
    "layer",
    "filters",
    "remember",
    "filters",
    "go",
    "um",
    "know",
    "filter",
    "coming",
    "looks",
    "four",
    "boxes",
    "step",
    "let",
    "say",
    "step",
    "two",
    "goes",
    "four",
    "boxes",
    "next",
    "step",
    "uh",
    "convolutional",
    "layer",
    "generate",
    "convolutional",
    "layers",
    "use",
    "relu",
    "function",
    "functions",
    "though",
    "relu",
    "one",
    "works",
    "best",
    "least",
    "far",
    "sure",
    "change",
    "pooling",
    "remember",
    "correctly",
    "pooling",
    "max",
    "filter",
    "coming",
    "multiplication",
    "one",
    "maybe",
    "two",
    "another",
    "one",
    "three",
    "three",
    "max",
    "create",
    "array",
    "would",
    "three",
    "max",
    "two",
    "whatever",
    "goes",
    "pooling",
    "going",
    "pooling",
    "uh",
    "reducing",
    "data",
    "reducing",
    "small",
    "finally",
    "going",
    "flatten",
    "single",
    "array",
    "goes",
    "fully",
    "connected",
    "layer",
    "see",
    "code",
    "right",
    "going",
    "create",
    "normal",
    "full",
    "layer",
    "point",
    "going",
    "take",
    "pooling",
    "layer",
    "go",
    "kind",
    "flattening",
    "process",
    "fed",
    "full",
    "different",
    "layers",
    "going",
    "input",
    "size",
    "see",
    "input",
    "layer",
    "get",
    "shape",
    "going",
    "get",
    "shape",
    "whatever",
    "coming",
    "uh",
    "input",
    "size",
    "initial",
    "weights",
    "also",
    "based",
    "input",
    "layer",
    "coming",
    "input",
    "size",
    "based",
    "input",
    "layer",
    "shape",
    "going",
    "already",
    "use",
    "shape",
    "already",
    "size",
    "coming",
    "course",
    "uh",
    "make",
    "sure",
    "knit",
    "bias",
    "always",
    "put",
    "bias",
    "based",
    "size",
    "return",
    "input",
    "layer",
    "w",
    "plus",
    "b",
    "normal",
    "full",
    "layer",
    "means",
    "right",
    "going",
    "return",
    "lot",
    "steps",
    "went",
    "let",
    "go",
    "ahead",
    "run",
    "loaded",
    "let",
    "go",
    "ahead",
    "create",
    "layers",
    "let",
    "see",
    "looks",
    "like",
    "done",
    "heavy",
    "lifting",
    "everything",
    "get",
    "easy",
    "part",
    "let",
    "go",
    "ahead",
    "create",
    "layers",
    "create",
    "convolution",
    "layer",
    "one",
    "two",
    "two",
    "different",
    "convolutional",
    "layers",
    "take",
    "flatten",
    "create",
    "reshape",
    "pooling",
    "reshape",
    "full",
    "uh",
    "layer",
    "end",
    "let",
    "start",
    "creating",
    "first",
    "convolutional",
    "layer",
    "come",
    "let",
    "run",
    "real",
    "quick",
    "want",
    "notice",
    "3",
    "32",
    "important",
    "coming",
    "convolutional",
    "layer",
    "three",
    "different",
    "channels",
    "32",
    "pixels",
    "four",
    "four",
    "play",
    "filter",
    "size",
    "remember",
    "filter",
    "image",
    "filter",
    "slowly",
    "steps",
    "filters",
    "image",
    "depending",
    "step",
    "particular",
    "setup",
    "4",
    "4",
    "fine",
    "work",
    "pretty",
    "good",
    "size",
    "image",
    "course",
    "end",
    "convolutional",
    "layer",
    "set",
    "also",
    "need",
    "pull",
    "see",
    "pooling",
    "automatically",
    "set",
    "would",
    "see",
    "different",
    "shape",
    "based",
    "coming",
    "max",
    "toolbar",
    "two",
    "two",
    "put",
    "convolutional",
    "one",
    "created",
    "convolutional",
    "layer",
    "created",
    "goes",
    "right",
    "back",
    "right",
    "see",
    "x",
    "coming",
    "knows",
    "look",
    "first",
    "model",
    "set",
    "data",
    "accordingly",
    "set",
    "matches",
    "went",
    "ahead",
    "ran",
    "already",
    "think",
    "read",
    "let",
    "go",
    "run",
    "going",
    "one",
    "layer",
    "let",
    "go",
    "ahead",
    "second",
    "layer",
    "uh",
    "call",
    "convo",
    "also",
    "convolutional",
    "layer",
    "see",
    "feeding",
    "convolutional",
    "one",
    "pooling",
    "goes",
    "convolutional",
    "one",
    "convolutional",
    "one",
    "pooling",
    "convolutional",
    "one",
    "pooling",
    "convolutional",
    "two",
    "convolutional",
    "2",
    "convolutional",
    "2",
    "pooling",
    "go",
    "ahead",
    "take",
    "run",
    "variables",
    "loaded",
    "memory",
    "flattened",
    "layer",
    "let",
    "go",
    "ahead",
    "since",
    "64",
    "coming",
    "4x4",
    "going",
    "let",
    "8",
    "8",
    "let",
    "going",
    "flat",
    "layer",
    "many",
    "bits",
    "coming",
    "flat",
    "layer",
    "reshape",
    "reshape",
    "convo",
    "two",
    "pooling",
    "feed",
    "convo",
    "pulling",
    "going",
    "set",
    "single",
    "layer",
    "4096",
    "size",
    "means",
    "go",
    "ahead",
    "run",
    "created",
    "variable",
    "convo",
    "flat",
    "first",
    "full",
    "layer",
    "final",
    "neural",
    "network",
    "flat",
    "layer",
    "going",
    "going",
    "use",
    "relu",
    "setup",
    "neural",
    "network",
    "evaluation",
    "notice",
    "going",
    "create",
    "first",
    "full",
    "layer",
    "normal",
    "full",
    "layer",
    "definition",
    "created",
    "creating",
    "normal",
    "full",
    "layer",
    "input",
    "data",
    "comes",
    "right",
    "goes",
    "right",
    "convo",
    "flat",
    "tells",
    "big",
    "data",
    "going",
    "come",
    "going",
    "10",
    "24",
    "big",
    "layer",
    "coming",
    "go",
    "ahead",
    "run",
    "full",
    "layer",
    "one",
    "full",
    "layer",
    "one",
    "want",
    "also",
    "define",
    "full",
    "one",
    "dropout",
    "go",
    "full",
    "layer",
    "one",
    "comes",
    "uh",
    "keep",
    "probability",
    "equals",
    "whole",
    "probability",
    "remember",
    "created",
    "earlier",
    "full",
    "layer",
    "one",
    "coming",
    "going",
    "backwards",
    "training",
    "data",
    "training",
    "every",
    "weight",
    "training",
    "percentage",
    "time",
    "helps",
    "get",
    "rid",
    "bias",
    "let",
    "go",
    "ahead",
    "run",
    "finally",
    "go",
    "ahead",
    "create",
    "predict",
    "going",
    "equal",
    "normal",
    "full",
    "one",
    "drop",
    "10",
    "10",
    "labels",
    "neural",
    "network",
    "could",
    "added",
    "additional",
    "layers",
    "would",
    "another",
    "option",
    "play",
    "also",
    "play",
    "instead",
    "10",
    "24",
    "use",
    "numbers",
    "way",
    "sets",
    "coming",
    "going",
    "next",
    "one",
    "going",
    "one",
    "layer",
    "one",
    "layer",
    "drop",
    "see",
    "another",
    "layer",
    "really",
    "easy",
    "feed",
    "full",
    "one",
    "drop",
    "full",
    "layer",
    "two",
    "full",
    "layer",
    "2",
    "dropout",
    "would",
    "full",
    "layer",
    "2",
    "feed",
    "switch",
    "prediction",
    "right",
    "great",
    "particular",
    "data",
    "set",
    "tried",
    "true",
    "know",
    "work",
    "type",
    "predict",
    "run",
    "see",
    "tensor",
    "object",
    "uh",
    "shape",
    "question",
    "mark",
    "10",
    "type",
    "32",
    "quick",
    "way",
    "double",
    "check",
    "working",
    "got",
    "done",
    "setup",
    "way",
    "predict",
    "want",
    "go",
    "ahead",
    "apply",
    "loss",
    "function",
    "make",
    "sure",
    "set",
    "create",
    "optimizer",
    "trainer",
    "optimizer",
    "create",
    "variable",
    "initialize",
    "global",
    "tf",
    "variables",
    "dive",
    "loss",
    "function",
    "let",
    "point",
    "one",
    "quick",
    "thing",
    "kind",
    "rehab",
    "couple",
    "things",
    "playing",
    "setups",
    "pointed",
    "change",
    "4",
    "4",
    "use",
    "different",
    "numbers",
    "change",
    "outcome",
    "depending",
    "numbers",
    "use",
    "huge",
    "impact",
    "well",
    "model",
    "fits",
    "1024",
    "also",
    "also",
    "another",
    "number",
    "continue",
    "raise",
    "number",
    "get",
    "possibly",
    "better",
    "fit",
    "might",
    "overfit",
    "lower",
    "number",
    "use",
    "less",
    "resources",
    "generally",
    "want",
    "use",
    "exponential",
    "growth",
    "exponential",
    "2",
    "4",
    "8",
    "16",
    "case",
    "next",
    "one",
    "would",
    "5",
    "use",
    "number",
    "would",
    "ideal",
    "numbers",
    "uh",
    "look",
    "data",
    "next",
    "step",
    "need",
    "also",
    "create",
    "way",
    "tracking",
    "good",
    "model",
    "going",
    "call",
    "loss",
    "function",
    "going",
    "create",
    "cross",
    "entropy",
    "loss",
    "function",
    "discuss",
    "exactly",
    "let",
    "take",
    "look",
    "see",
    "feeding",
    "going",
    "feed",
    "labels",
    "true",
    "labels",
    "prediction",
    "labels",
    "coming",
    "two",
    "different",
    "variables",
    "sending",
    "two",
    "different",
    "probability",
    "distributions",
    "one",
    "know",
    "true",
    "think",
    "going",
    "function",
    "right",
    "talk",
    "cross",
    "entropy",
    "information",
    "theory",
    "cross",
    "entropy",
    "two",
    "probability",
    "distributions",
    "underlying",
    "set",
    "events",
    "measures",
    "average",
    "number",
    "bits",
    "needed",
    "identify",
    "event",
    "drawn",
    "set",
    "mouthful",
    "really",
    "looking",
    "amount",
    "error",
    "many",
    "correct",
    "many",
    "incorrect",
    "much",
    "matches",
    "going",
    "look",
    "going",
    "look",
    "average",
    "mean",
    "reduced",
    "mean",
    "means",
    "looking",
    "average",
    "error",
    "next",
    "step",
    "going",
    "take",
    "error",
    "want",
    "know",
    "cross",
    "entropy",
    "loss",
    "function",
    "much",
    "loss",
    "going",
    "part",
    "train",
    "model",
    "know",
    "loss",
    "training",
    "feed",
    "back",
    "back",
    "propagation",
    "setup",
    "want",
    "go",
    "ahead",
    "optimize",
    "optimizer",
    "going",
    "create",
    "optimizer",
    "using",
    "atom",
    "optimizer",
    "remember",
    "lot",
    "different",
    "ways",
    "optimizing",
    "data",
    "atoms",
    "popular",
    "used",
    "uh",
    "optimizer",
    "going",
    "equal",
    "tf",
    "train",
    "atom",
    "optimizer",
    "remember",
    "learning",
    "rate",
    "let",
    "pop",
    "back",
    "learning",
    "rate",
    "weights",
    "weights",
    "different",
    "nodes",
    "coming",
    "node",
    "coming",
    "weights",
    "error",
    "prop",
    "sent",
    "back",
    "reverse",
    "neural",
    "network",
    "take",
    "error",
    "adjust",
    "weights",
    "based",
    "different",
    "formulas",
    "case",
    "atom",
    "formula",
    "using",
    "want",
    "adjust",
    "completely",
    "want",
    "change",
    "weight",
    "exactly",
    "fits",
    "data",
    "coming",
    "made",
    "kind",
    "adjustment",
    "going",
    "biased",
    "whatever",
    "last",
    "data",
    "sent",
    "instead",
    "going",
    "multiply",
    "make",
    "small",
    "shift",
    "weight",
    "delta",
    "w",
    "actual",
    "delta",
    "w",
    "full",
    "change",
    "going",
    "compute",
    "atom",
    "want",
    "go",
    "ahead",
    "train",
    "training",
    "set",
    "training",
    "variable",
    "function",
    "going",
    "equal",
    "optimizer",
    "minimize",
    "cross",
    "entropy",
    "make",
    "sure",
    "go",
    "ahead",
    "run",
    "loaded",
    "almost",
    "ready",
    "train",
    "model",
    "need",
    "create",
    "one",
    "um",
    "variable",
    "going",
    "create",
    "variable",
    "initialize",
    "global",
    "tf",
    "variables",
    "look",
    "tf",
    "global",
    "variable",
    "initializer",
    "tensorflow",
    "object",
    "goes",
    "looks",
    "different",
    "setup",
    "going",
    "tensorflow",
    "initializes",
    "variables",
    "kind",
    "like",
    "magic",
    "wand",
    "hidden",
    "back",
    "end",
    "tensorflow",
    "need",
    "know",
    "initialization",
    "operation",
    "um",
    "run",
    "setup",
    "going",
    "go",
    "ahead",
    "run",
    "piece",
    "code",
    "going",
    "go",
    "ahead",
    "train",
    "data",
    "let",
    "run",
    "let",
    "load",
    "going",
    "go",
    "ahead",
    "run",
    "model",
    "creating",
    "graph",
    "session",
    "graph",
    "session",
    "tensorflow",
    "term",
    "see",
    "coming",
    "one",
    "things",
    "throws",
    "always",
    "think",
    "graphics",
    "spark",
    "graph",
    "general",
    "graphing",
    "uh",
    "talk",
    "graph",
    "session",
    "gon",
    "na",
    "go",
    "ahead",
    "run",
    "model",
    "let",
    "go",
    "ahead",
    "walk",
    "uh",
    "going",
    "let",
    "paste",
    "data",
    "go",
    "going",
    "start",
    "tf",
    "session",
    "sess",
    "actual",
    "tf",
    "session",
    "created",
    "uh",
    "right",
    "tf",
    "uh",
    "session",
    "session",
    "creating",
    "going",
    "run",
    "tf",
    "global",
    "variable",
    "initializer",
    "right",
    "bat",
    "initializing",
    "variables",
    "uh",
    "range",
    "going",
    "remember",
    "500",
    "going",
    "break",
    "date",
    "going",
    "batch",
    "500",
    "points",
    "created",
    "session",
    "run",
    "going",
    "tf",
    "session",
    "session",
    "right",
    "created",
    "variable",
    "session",
    "going",
    "run",
    "going",
    "go",
    "ahead",
    "initialize",
    "tf",
    "global",
    "variables",
    "initializer",
    "created",
    "initializes",
    "session",
    "next",
    "thing",
    "going",
    "going",
    "go",
    "range",
    "500",
    "batch",
    "equals",
    "remember",
    "correctly",
    "loading",
    "100",
    "pictures",
    "time",
    "going",
    "loop",
    "500",
    "times",
    "literally",
    "uh",
    "500",
    "times",
    "100",
    "50",
    "000",
    "50",
    "000",
    "pictures",
    "going",
    "process",
    "right",
    "first",
    "process",
    "going",
    "session",
    "run",
    "going",
    "take",
    "train",
    "created",
    "train",
    "variable",
    "optimizer",
    "going",
    "feed",
    "dictionary",
    "feed",
    "dictionary",
    "created",
    "x",
    "equals",
    "batch",
    "zero",
    "coming",
    "true",
    "batch",
    "one",
    "hold",
    "probability",
    "point",
    "five",
    "keep",
    "track",
    "going",
    "going",
    "every",
    "100",
    "steps",
    "going",
    "run",
    "print",
    "currently",
    "step",
    "format",
    "accuracy",
    "going",
    "look",
    "matches",
    "equals",
    "tf",
    "argument",
    "prediction",
    "one",
    "tf",
    "dot",
    "arg",
    "max",
    "true",
    "comma",
    "going",
    "look",
    "many",
    "matches",
    "acc",
    "going",
    "take",
    "matches",
    "many",
    "matches",
    "creates",
    "generates",
    "chart",
    "going",
    "convert",
    "float",
    "tfcast",
    "want",
    "know",
    "average",
    "want",
    "know",
    "average",
    "accuracy",
    "go",
    "ahead",
    "print",
    "print",
    "session",
    "run",
    "accuracy",
    "feed",
    "dictionary",
    "takes",
    "prints",
    "accuracy",
    "let",
    "go",
    "ahead",
    "take",
    "oops",
    "screens",
    "let",
    "go",
    "ahead",
    "take",
    "let",
    "run",
    "going",
    "take",
    "little",
    "bit",
    "run",
    "let",
    "see",
    "happens",
    "old",
    "laptop",
    "see",
    "current",
    "uh",
    "currently",
    "step",
    "zero",
    "takes",
    "little",
    "bit",
    "get",
    "accuracy",
    "take",
    "moment",
    "run",
    "see",
    "step",
    "0",
    "accuracy",
    "running",
    "go",
    "ahead",
    "need",
    "watch",
    "run",
    "way",
    "accuracy",
    "going",
    "change",
    "little",
    "bit",
    "actually",
    "lost",
    "accuracy",
    "step",
    "two",
    "see",
    "comes",
    "let",
    "come",
    "back",
    "run",
    "way",
    "see",
    "different",
    "steps",
    "come",
    "actually",
    "reading",
    "backwards",
    "way",
    "works",
    "closer",
    "get",
    "one",
    "accuracy",
    "uh",
    "see",
    "gone",
    "point",
    "one",
    "point",
    "three",
    "nine",
    "um",
    "go",
    "ahead",
    "pause",
    "come",
    "back",
    "see",
    "happens",
    "done",
    "full",
    "run",
    "right",
    "prepared",
    "meal",
    "got",
    "oven",
    "pulled",
    "finished",
    "dish",
    "ever",
    "watched",
    "old",
    "cooking",
    "shows",
    "let",
    "discuss",
    "little",
    "bit",
    "accuracy",
    "going",
    "interpret",
    "done",
    "couple",
    "things",
    "first",
    "defined",
    "accuracy",
    "reason",
    "got",
    "backwards",
    "loss",
    "accuracy",
    "loss",
    "get",
    "graph",
    "looks",
    "like",
    "goes",
    "oops",
    "way",
    "go",
    "get",
    "graph",
    "curves",
    "like",
    "accuracy",
    "get",
    "graph",
    "curves",
    "good",
    "case",
    "uh",
    "one",
    "supposed",
    "really",
    "good",
    "accuracy",
    "means",
    "gets",
    "close",
    "one",
    "never",
    "crosses",
    "one",
    "accuracy",
    "one",
    "phenomenal",
    "fact",
    "pretty",
    "much",
    "impos",
    "know",
    "unheard",
    "thing",
    "loss",
    "loss",
    "zero",
    "also",
    "unheard",
    "zero",
    "actually",
    "axis",
    "right",
    "go",
    "interpret",
    "know",
    "looking",
    "go",
    "oh",
    "uh",
    "51",
    "50",
    "percentage",
    "let",
    "put",
    "percentage",
    "uh",
    "log",
    "rhythmic",
    "means",
    "twice",
    "good",
    "see",
    "twice",
    "good",
    "real",
    "way",
    "convert",
    "percentage",
    "really",
    "ca",
    "say",
    "direct",
    "percentage",
    "conversion",
    "though",
    "head",
    "give",
    "percentage",
    "might",
    "look",
    "fifty",
    "percent",
    "guessing",
    "equals",
    "50",
    "roughly",
    "equals",
    "started",
    "top",
    "remember",
    "top",
    "accuracy",
    "50",
    "percent",
    "75",
    "percent",
    "quote",
    "numbers",
    "work",
    "way",
    "say",
    "pretty",
    "much",
    "saying",
    "hundred",
    "percent",
    "anywhere",
    "go",
    "look",
    "let",
    "go",
    "remove",
    "drawings",
    "magic",
    "number",
    "really",
    "want",
    "whole",
    "thing",
    "remember",
    "accuracy",
    "looking",
    "loss",
    "would",
    "looking",
    "way",
    "know",
    "instead",
    "high",
    "want",
    "low",
    "uh",
    "accuracy",
    "pretty",
    "valid",
    "means",
    "pretty",
    "solid",
    "get",
    "direct",
    "correlation",
    "looking",
    "numbers",
    "see",
    "finished",
    "model",
    "still",
    "good",
    "look",
    "ran",
    "end",
    "remember",
    "lot",
    "randomness",
    "goes",
    "see",
    "weights",
    "got",
    "little",
    "better",
    "fine",
    "find",
    "comes",
    "little",
    "bit",
    "better",
    "worse",
    "depending",
    "randomness",
    "gone",
    "whole",
    "model",
    "created",
    "trained",
    "model",
    "also",
    "gone",
    "every",
    "100th",
    "run",
    "test",
    "model",
    "see",
    "accurate",
    "solid",
    "running",
    "model",
    "accuracy",
    "let",
    "go",
    "ahead",
    "take",
    "look",
    "covered",
    "today",
    "cover",
    "lot",
    "complicated",
    "subject",
    "much",
    "complicated",
    "individual",
    "step",
    "lot",
    "steps",
    "involved",
    "today",
    "covered",
    "convolutional",
    "neural",
    "network",
    "see",
    "pictures",
    "coming",
    "input",
    "layer",
    "hidden",
    "layers",
    "output",
    "layer",
    "get",
    "rows",
    "talked",
    "basics",
    "beginning",
    "discussed",
    "cnn",
    "recognizes",
    "images",
    "basics",
    "converted",
    "image",
    "pixel",
    "map",
    "zeros",
    "ones",
    "dive",
    "layers",
    "convolutional",
    "neural",
    "network",
    "convolutional",
    "layer",
    "fully",
    "convected",
    "layer",
    "relu",
    "layer",
    "pooling",
    "layer",
    "looked",
    "pooling",
    "layer",
    "reduces",
    "data",
    "smaller",
    "amount",
    "finding",
    "first",
    "defines",
    "matches",
    "finds",
    "maximum",
    "value",
    "match",
    "discussed",
    "different",
    "layers",
    "went",
    "fully",
    "connected",
    "layer",
    "normal",
    "neural",
    "networks",
    "probably",
    "used",
    "dealing",
    "building",
    "forward",
    "propagation",
    "neural",
    "network",
    "connected",
    "together",
    "see",
    "took",
    "bird",
    "extracting",
    "feature",
    "extraction",
    "multiple",
    "hidden",
    "layers",
    "convolution",
    "generated",
    "little",
    "individual",
    "filters",
    "relu",
    "took",
    "real",
    "u",
    "max",
    "pooled",
    "took",
    "pooled",
    "values",
    "end",
    "reduced",
    "smaller",
    "mappings",
    "reduced",
    "fed",
    "fully",
    "connected",
    "layer",
    "finally",
    "went",
    "use",
    "case",
    "implementation",
    "using",
    "cnn",
    "walked",
    "full",
    "demo",
    "coding",
    "want",
    "thank",
    "joining",
    "us",
    "today",
    "uh",
    "thank",
    "information",
    "visit",
    "get",
    "certified",
    "get",
    "ahead",
    "also",
    "post",
    "questions",
    "youtube",
    "try",
    "answer",
    "best",
    "hi",
    "like",
    "video",
    "subscribe",
    "simply",
    "learn",
    "youtube",
    "channel",
    "click",
    "watch",
    "similar",
    "videos",
    "turn",
    "get",
    "certified",
    "click"
  ],
  "keywords": [
    "convolution",
    "neural",
    "network",
    "get",
    "ahead",
    "today",
    "going",
    "convolutional",
    "know",
    "image",
    "really",
    "works",
    "one",
    "using",
    "picture",
    "pixels",
    "input",
    "layer",
    "coming",
    "hidden",
    "layers",
    "output",
    "say",
    "oh",
    "bird",
    "go",
    "actually",
    "back",
    "number",
    "times",
    "form",
    "arrays",
    "see",
    "different",
    "looks",
    "like",
    "matrixes",
    "set",
    "feature",
    "part",
    "kind",
    "multiple",
    "ways",
    "data",
    "uses",
    "matrix",
    "filter",
    "operation",
    "remember",
    "means",
    "use",
    "rectified",
    "linear",
    "function",
    "used",
    "pooling",
    "also",
    "filters",
    "beak",
    "says",
    "pulling",
    "information",
    "together",
    "look",
    "lot",
    "little",
    "finally",
    "fully",
    "connected",
    "come",
    "final",
    "cnn",
    "images",
    "case",
    "first",
    "code",
    "processing",
    "process",
    "feed",
    "forward",
    "looking",
    "since",
    "uh",
    "tensorflow",
    "features",
    "two",
    "think",
    "much",
    "next",
    "based",
    "weights",
    "setup",
    "comes",
    "value",
    "values",
    "well",
    "every",
    "pixel",
    "real",
    "put",
    "array",
    "zeros",
    "ones",
    "take",
    "step",
    "b",
    "want",
    "pieces",
    "single",
    "equals",
    "three",
    "gon",
    "na",
    "start",
    "multiply",
    "five",
    "size",
    "numbers",
    "plus",
    "3",
    "2",
    "4",
    "thing",
    "would",
    "covered",
    "bit",
    "important",
    "break",
    "way",
    "let",
    "four",
    "complicated",
    "um",
    "relu",
    "reduce",
    "map",
    "everything",
    "0",
    "color",
    "things",
    "keep",
    "right",
    "train",
    "model",
    "need",
    "might",
    "zero",
    "end",
    "whatever",
    "nice",
    "graph",
    "goes",
    "10",
    "time",
    "max",
    "correctly",
    "pooled",
    "instead",
    "best",
    "probably",
    "far",
    "change",
    "run",
    "done",
    "point",
    "dimensions",
    "2d",
    "flatten",
    "quick",
    "steps",
    "create",
    "normal",
    "dog",
    "cat",
    "many",
    "horse",
    "batch",
    "print",
    "variable",
    "library",
    "matplot",
    "good",
    "reshape",
    "course",
    "percentage",
    "numpy",
    "x",
    "000",
    "32",
    "bits",
    "shape",
    "type",
    "float",
    "got",
    "work",
    "loaded",
    "oops",
    "255",
    "car",
    "creating",
    "helper",
    "hot",
    "encoder",
    "labels",
    "init",
    "equal",
    "self",
    "initialize",
    "training",
    "batches",
    "test",
    "variables",
    "another",
    "cross",
    "100",
    "already",
    "tf",
    "placeholder",
    "true",
    "probability",
    "bias",
    "full",
    "pretty",
    "created",
    "matches",
    "loss",
    "optimizer",
    "session",
    "accuracy"
  ]
}