{
  "text": "SHILPA KANCHARLA: Hi.\nMy name is Shilpa Kancharla.\nAnd I'm an engineer on\nthe TensorFlow team.\nToday, we're going to\nlearn how to pre-process\nand load video data\ninto a TensorFlow model.\nYou'll be able to use\nthe skills you learn here\nto develop video classification\nmodels like this one.\nThis model uses the UDF101 data\nset and predicts the action\nthe person is taking.\nFor example, on the left,\nyou'd classify this video\nas band marching.\nAnd on the right, you'd\nclassify it as apply eye makeup.\nI'll outline the data set\nyou'll use, how to create frames\nfrom videos, how to\nvisualize those frames,\nand how to configure the\ndata set for performance.\nYou can find complete\ndetails on all these steps\nin the associated tutorial.\nHere, I'll cover the\nkey idea for you.\nOK.\nLet's get started.\nToday, we'll be using the UCF101\naction recognition data set.\nThis data set contains\n101 different actions\nfrom diverse categories.\nEach category has\nabout 25 examples\nof that action which are split\ninto four to seven videos\nfor each example.\nTo keep things simple\nfor this tutorial,\nwe'll be using the first\n10 classes listed here\nto keep the data set\nsize small, so our model\ncan be trained quickly.\nLet's take a look at the\nshape of the video data\nthat we're going to pass\ninto the model as well.\nLoading video data into\na deep learning model\nis similar to how you\nwould load an image data,\nbut with an extra dimension.\nIn a later video,\nI'll explain how\nto set up 3D CNN\nclassifier which accepts\ndata of the following shape--\nbatch size times the\nnumber of frames times\nheight by width by channels.\nThe number of frames\ndimension can also\nbe synonymous with time.\nVideos can be split up\ninto a series of frames\nwhich are essentially images.\nWe use the OpenCV library\nto help us with this task.\nWhen we call this\nfunction, we specify\nthe number of frames we\nwant, the output size\nof the frame we want to\nproduce, and the number\nof steps between each frame.\nThese are user\ndefined parameters\nthat are heavily\ndependent on the data set.\nIf the video isn't long enough\nfor us to collect frames from,\nwe start collecting\nthem from the beginning.\nOtherwise, we can pick a\nrandom time in the video\nto start getting frames from.\nWe apply a couple\nof transformations\nusing TensorFlow functions\nto get our frames\nto be the size we specified.\nFinally, we return a NumPy\narray of these frames.\nUse the to_gif function to\ncreate a visualization of some\nof the frames you've generated.\nCall the frames from\nvideo file function first.\nTake the output of that, and\nplace it to_gif function.\nThe FrameGenerator class\nuses a generator function\nthat will yield the frame array\nand an encoded label associated\nwith that set of frames.\nUse this class to create a\nTensorFlow data input pipeline.\nIt allows you to feed\nin data into your model.\nConsider using\nbuffered prefetching,\nso you can yield\ndata from the disk\nwithout having an\ninput-output bottleneck.\nPrefetching allows\nyou to grab the data\na step ahead of when it's\ninputted into the model,\ntherefore reducing\nthe amount of time\nbetween consuming a data\npoint and producing another.\nCaching allows you to store\ndata in memory or local storage.\nTherefore, saving\nsome operations,\nlike file opening, from\nbeing performed every epoch.\nOverall, these additional\npreprocessing steps\nallow for work on the CPU\nand GPU to run in parallel.\nSo your processor\ncan prepare data\nwhile your GPU is classifying.\nEfficientNet is a convolutional\nneural network architecture\nmethod that uniformly scales all\ndimensions of your input data.\nWe can treat it as the\nHello World example\nof using video data for now.\nLet's try putting\nour training data\nset into a pre-trained\nEfficientNet model, which\ntrains our data to a high\naccuracy in just a few minutes.\nYou can also take a look\nat an additional model\nof video classification I\nwrote in the description.\nYou can try applying what\nyou've learned in this video\nand tutorial to other\nkinds of video data.\nSee if you can use a generator\nclass we've created here\nin your own machine learning\npipelines for video.\nMoreover, video data has\nan extra time dimension\nunlike image data.\nVolumetric data,\nsuch as MRI scans,\nalso have an extra\ndimension of volume\nunlike image data as well.\nSo you could attempt to\nuse the code shown here\nfor volumetric data.\nIf possible, I'd\nlike to invite you\nto share links of your\nopen source projects\ndown in the comments as well.\nThanks very much for watching.\n[AUDIO LOGO]\n",
  "words": [
    "shilpa",
    "kancharla",
    "hi",
    "name",
    "shilpa",
    "kancharla",
    "engineer",
    "tensorflow",
    "team",
    "today",
    "going",
    "learn",
    "load",
    "video",
    "data",
    "tensorflow",
    "model",
    "able",
    "use",
    "skills",
    "learn",
    "develop",
    "video",
    "classification",
    "models",
    "like",
    "one",
    "model",
    "uses",
    "udf101",
    "data",
    "set",
    "predicts",
    "action",
    "person",
    "taking",
    "example",
    "left",
    "classify",
    "video",
    "band",
    "marching",
    "right",
    "classify",
    "apply",
    "eye",
    "makeup",
    "outline",
    "data",
    "set",
    "use",
    "create",
    "frames",
    "videos",
    "visualize",
    "frames",
    "configure",
    "data",
    "set",
    "performance",
    "find",
    "complete",
    "details",
    "steps",
    "associated",
    "tutorial",
    "cover",
    "key",
    "idea",
    "let",
    "get",
    "started",
    "today",
    "using",
    "ucf101",
    "action",
    "recognition",
    "data",
    "set",
    "data",
    "set",
    "contains",
    "101",
    "different",
    "actions",
    "diverse",
    "categories",
    "category",
    "25",
    "examples",
    "action",
    "split",
    "four",
    "seven",
    "videos",
    "example",
    "keep",
    "things",
    "simple",
    "tutorial",
    "using",
    "first",
    "10",
    "classes",
    "listed",
    "keep",
    "data",
    "set",
    "size",
    "small",
    "model",
    "trained",
    "quickly",
    "let",
    "take",
    "look",
    "shape",
    "video",
    "data",
    "going",
    "pass",
    "model",
    "well",
    "loading",
    "video",
    "data",
    "deep",
    "learning",
    "model",
    "similar",
    "would",
    "load",
    "image",
    "data",
    "extra",
    "dimension",
    "later",
    "video",
    "explain",
    "set",
    "3d",
    "cnn",
    "classifier",
    "accepts",
    "data",
    "following",
    "shape",
    "batch",
    "size",
    "times",
    "number",
    "frames",
    "times",
    "height",
    "width",
    "channels",
    "number",
    "frames",
    "dimension",
    "also",
    "synonymous",
    "time",
    "videos",
    "split",
    "series",
    "frames",
    "essentially",
    "images",
    "use",
    "opencv",
    "library",
    "help",
    "us",
    "task",
    "call",
    "function",
    "specify",
    "number",
    "frames",
    "want",
    "output",
    "size",
    "frame",
    "want",
    "produce",
    "number",
    "steps",
    "frame",
    "user",
    "defined",
    "parameters",
    "heavily",
    "dependent",
    "data",
    "set",
    "video",
    "long",
    "enough",
    "us",
    "collect",
    "frames",
    "start",
    "collecting",
    "beginning",
    "otherwise",
    "pick",
    "random",
    "time",
    "video",
    "start",
    "getting",
    "frames",
    "apply",
    "couple",
    "transformations",
    "using",
    "tensorflow",
    "functions",
    "get",
    "frames",
    "size",
    "specified",
    "finally",
    "return",
    "numpy",
    "array",
    "frames",
    "use",
    "function",
    "create",
    "visualization",
    "frames",
    "generated",
    "call",
    "frames",
    "video",
    "file",
    "function",
    "first",
    "take",
    "output",
    "place",
    "function",
    "framegenerator",
    "class",
    "uses",
    "generator",
    "function",
    "yield",
    "frame",
    "array",
    "encoded",
    "label",
    "associated",
    "set",
    "frames",
    "use",
    "class",
    "create",
    "tensorflow",
    "data",
    "input",
    "pipeline",
    "allows",
    "feed",
    "data",
    "model",
    "consider",
    "using",
    "buffered",
    "prefetching",
    "yield",
    "data",
    "disk",
    "without",
    "bottleneck",
    "prefetching",
    "allows",
    "grab",
    "data",
    "step",
    "ahead",
    "inputted",
    "model",
    "therefore",
    "reducing",
    "amount",
    "time",
    "consuming",
    "data",
    "point",
    "producing",
    "another",
    "caching",
    "allows",
    "store",
    "data",
    "memory",
    "local",
    "storage",
    "therefore",
    "saving",
    "operations",
    "like",
    "file",
    "opening",
    "performed",
    "every",
    "epoch",
    "overall",
    "additional",
    "preprocessing",
    "steps",
    "allow",
    "work",
    "cpu",
    "gpu",
    "run",
    "parallel",
    "processor",
    "prepare",
    "data",
    "gpu",
    "classifying",
    "efficientnet",
    "convolutional",
    "neural",
    "network",
    "architecture",
    "method",
    "uniformly",
    "scales",
    "dimensions",
    "input",
    "data",
    "treat",
    "hello",
    "world",
    "example",
    "using",
    "video",
    "data",
    "let",
    "try",
    "putting",
    "training",
    "data",
    "set",
    "efficientnet",
    "model",
    "trains",
    "data",
    "high",
    "accuracy",
    "minutes",
    "also",
    "take",
    "look",
    "additional",
    "model",
    "video",
    "classification",
    "wrote",
    "description",
    "try",
    "applying",
    "learned",
    "video",
    "tutorial",
    "kinds",
    "video",
    "data",
    "see",
    "use",
    "generator",
    "class",
    "created",
    "machine",
    "learning",
    "pipelines",
    "video",
    "moreover",
    "video",
    "data",
    "extra",
    "time",
    "dimension",
    "unlike",
    "image",
    "data",
    "volumetric",
    "data",
    "mri",
    "scans",
    "also",
    "extra",
    "dimension",
    "volume",
    "unlike",
    "image",
    "data",
    "well",
    "could",
    "attempt",
    "use",
    "code",
    "shown",
    "volumetric",
    "data",
    "possible",
    "like",
    "invite",
    "share",
    "links",
    "open",
    "source",
    "projects",
    "comments",
    "well",
    "thanks",
    "much",
    "watching",
    "audio",
    "logo"
  ],
  "keywords": [
    "shilpa",
    "kancharla",
    "tensorflow",
    "today",
    "going",
    "learn",
    "load",
    "video",
    "data",
    "model",
    "use",
    "classification",
    "like",
    "uses",
    "set",
    "action",
    "example",
    "classify",
    "apply",
    "create",
    "frames",
    "videos",
    "steps",
    "associated",
    "tutorial",
    "let",
    "get",
    "using",
    "split",
    "keep",
    "first",
    "size",
    "take",
    "look",
    "shape",
    "well",
    "learning",
    "image",
    "extra",
    "dimension",
    "times",
    "number",
    "also",
    "time",
    "us",
    "call",
    "function",
    "want",
    "output",
    "frame",
    "start",
    "array",
    "file",
    "class",
    "generator",
    "yield",
    "input",
    "allows",
    "prefetching",
    "therefore",
    "additional",
    "gpu",
    "efficientnet",
    "try",
    "unlike",
    "volumetric"
  ]
}