{
  "text": "if you're new to this channel you may\nconsider subscribing and hit the Bell\nicon so that you continue to receive the\nupdates also after watching this video\nyou may want to refer to some of the\nplaylists that we have created for\npeople who are interested in in-depth\nknowledge these are the videos in the\nright sequence which will give you\nthorough knowledge of the subject please\nshare it with all others who might\nbenefit let's get started so finally\nwe've made it to the last leg of\nensembling techniques and we're going to\ntalk about the composite techniques in\nthis video it has two broad categories\nblending and stacking and they have\ncertain common characteristics so we'll\ntalk about these two together and then\nI'll specifically talk about the\ndifference between these two techniques\nit's going to be a lot interesting\nneedless to emphasize one more sign that\nthis is something that you need to know\nif you are a data science practitioner\nlet's Deep dive so talking about the\nmodels that we use for blending and\nstocking these are going to be different\ntypes of Base models where else we\ntalked about different types of Base\nmodels we talked about it in case of\nvoting but what makes blending and\nstacking different from voting is the\nway we deal with the data in this\nsituation so we use a combination of\nsequential and parallel approaches so we\nuse certain base models in parallel the\npredictions of these base models are\nthen passed on to a meta model which\ngenerates the final predictions and this\nwill become clearer as I continue to\nexplain this to you so just bear with me\nlet's start with some data and let's\nzoom in to what does do this data\ncontain so this is the same example that\nwe've been talking about we have a\ncredit score we have the average account\nbalance in thousands of dollars we have\nthe work experience of the individual\nand we are checking for the loan amount\neligibility it could be a personal loan\nso this is how our data would be you've\njust taken one sample record you can\nimagine all the rows in the data could\nbe hundreds of thousands of rows would\nbe like this now in order to be able to\npredict the load amount given the\nfactors like trade score average balance\nand work experience we would need\ndifferent models let's say the first\nmodel that we call is a linear\nregression model the second model that\nwe call is a decision free regressor and\nthe third model is a KNN regressor all\nthese are called base models and please\nnote these models are all learning in\nparallel which means they are not\ninfluenced by each other's outcomes\nlinear regression has no influence of\nthe other two models whatsoever and any\nmodel is not influenced by the other\nmodels so this is the parallel learning\npiece that we are talking about now when\neach record is passed to these models\neach of these models is capable of\ngenerating a prediction so let's say\ngiven the credit score average balance\nand work experience we populate a table\nwhich captures the predictions made by\neach of these models for example a\nlinear regression when given these\ninputs generates a prediction which is\nlet's say 28,000 decision tree regressor\ngenerates a prediction which is\n34,000 and Cann generates a prediction\nwhich is 31,000 please note at all times\nwe always have the target column\navailable because we are talking about\nsupervised learning so at this stage\nwhat you're seeing is basically how the\ndata is being generated for The Meta\nmodel we had the original data we gave\nthat as an input to the base models and\nbase models generated the predictions so\nfor the meta model now we don't need the\noriginal data anymore we can simply\nignore it and we have to concentrate\nentirely on the data so generated out of\nthese predictions so this is what we're\ngoing to focus on now the problem\nstatement for The Meta model reduces to\nwhat is the loan amount eligibility\ngiven that we have predictions from\nthese three base models so these\npredictions from the base models are\nacting as features for the meta model so\njust to sum it up one more time we had a\ndata and this data got passed to three\ndifferent models which learn in parallel\nthese models generated some prediction\nand that's another data just like we saw\nthere were three features containing\npredictions from each of these models\nthis data is given as an input to a meta\nmodel this model could be a different\nmodel we've let's say taken a support\nVector regressor in this case now if you\nlook at this while the base models learn\nin parallel The Meta model is actually\nbeing given the input in a sequential\nway so this is why we call it a\ncomposite technique because it's\nlearning both parall and sequentially\nNow we move to the final stage this meta\nmodel is going to generate the\nprediction which would determine the\nloan amount eligibility the amount that\nthe bank is willing to approve this meta\nmodels prediction is taken as the final\nresult but generally when you do these\nthings practically you understand that\nwe always divide the data into train\ntest and we try to learn on the train we\ntry to make our predictions on the test\nhow does that work in case of blending\nand stacking let's understand that so\nwe'll take an example of blending for\nfirst and and then I'll just tell you\nwhat is it that's different in case of\nstacking let's start with the data so we\nhave the data first of all we divide\nthis data into three parts train\nvalidation and test generally as a\nconvention we always keep a larger\nportion of the data as the train data\nnow this train data will be given as\ninput to each of these base models which\nare parallel models so base models learn\nusing the train set now once the base\nmodels have been trained\nthey generate predictions on the\nvalidation set remember this data that's\nbeing generated in the form of\npredictions is the data or the input for\nThe Meta model so the outputs from the\nvalidation set are being supplied to The\nMeta model and finally when the meta\nmodel has been trained The Meta model\nwould generate predictions for the test\nset so this is how it overall Works in\nterms of train validation and test this\napproach where we part the portion of\nthe train data for validation purposes\nis also known as the hold out approach\nand the approach that you just saw is\ncalled\nblending then what's different between\nblending and stacking there's one major\ndifference and that is in case of\nstacking instead of just taking one\nportion as validation you do something\ncalled as cross validation now we've\ncovered cross validation as a separate\ntutorial from a general perspective of\nsupervised learning you may refer to it\nbut stacking instead of just taking one\ncut of the train and parking it as\nvalidation does a cross validation\nessentially it kind of repeats the\nprocess multiple times it could be kfold\ncross validation where the value of K\ncould be five or 10 commonly as we go\nabout there's one more difference in\nstacking and blending that in case of\nstacking we once again train the base\nmodels on the overall data so we do the\nsame cycle we come up to the stage of a\nmeta mod and we once again train the\nbase models on the entire data so that's\none more difference but if that gets too\ncomplicated for you to follow you may\njust keep this in mind that this is what\nby enlarge blending and stacking to the\nbasic structure is that we have a set of\nBase models which learn in parallel and\nthen we have a meta model now there\ncould also be variations of how you want\nto do this you may create another layer\nof Base models so you can do multiple\nlayers of Base models and then finally\ndo a meta model choice of these models\nthat we mentioned here is not again a\nmandate we could try a different mix of\ndifferent types of models and look at\nwhich combination gives us the best\nresults while this might sound like a\nrelatively heavy concept to understand\nin terms of coding it's very very\nsimplified so when we do the Hands-On\nexercise you will see it's pretty\nstraightforward that's it about blending\nand stacking and this is the last video\nin the sequence of ensembling technique\nvideos\n",
  "words": [
    "new",
    "channel",
    "may",
    "consider",
    "subscribing",
    "hit",
    "bell",
    "icon",
    "continue",
    "receive",
    "updates",
    "also",
    "watching",
    "video",
    "may",
    "want",
    "refer",
    "playlists",
    "created",
    "people",
    "interested",
    "knowledge",
    "videos",
    "right",
    "sequence",
    "give",
    "thorough",
    "knowledge",
    "subject",
    "please",
    "share",
    "others",
    "might",
    "benefit",
    "let",
    "get",
    "started",
    "finally",
    "made",
    "last",
    "leg",
    "ensembling",
    "techniques",
    "going",
    "talk",
    "composite",
    "techniques",
    "video",
    "two",
    "broad",
    "categories",
    "blending",
    "stacking",
    "certain",
    "common",
    "characteristics",
    "talk",
    "two",
    "together",
    "specifically",
    "talk",
    "difference",
    "two",
    "techniques",
    "going",
    "lot",
    "interesting",
    "needless",
    "emphasize",
    "one",
    "sign",
    "something",
    "need",
    "know",
    "data",
    "science",
    "practitioner",
    "let",
    "deep",
    "dive",
    "talking",
    "models",
    "use",
    "blending",
    "stocking",
    "going",
    "different",
    "types",
    "base",
    "models",
    "else",
    "talked",
    "different",
    "types",
    "base",
    "models",
    "talked",
    "case",
    "voting",
    "makes",
    "blending",
    "stacking",
    "different",
    "voting",
    "way",
    "deal",
    "data",
    "situation",
    "use",
    "combination",
    "sequential",
    "parallel",
    "approaches",
    "use",
    "certain",
    "base",
    "models",
    "parallel",
    "predictions",
    "base",
    "models",
    "passed",
    "meta",
    "model",
    "generates",
    "final",
    "predictions",
    "become",
    "clearer",
    "continue",
    "explain",
    "bear",
    "let",
    "start",
    "data",
    "let",
    "zoom",
    "data",
    "contain",
    "example",
    "talking",
    "credit",
    "score",
    "average",
    "account",
    "balance",
    "thousands",
    "dollars",
    "work",
    "experience",
    "individual",
    "checking",
    "loan",
    "amount",
    "eligibility",
    "could",
    "personal",
    "loan",
    "data",
    "would",
    "taken",
    "one",
    "sample",
    "record",
    "imagine",
    "rows",
    "data",
    "could",
    "hundreds",
    "thousands",
    "rows",
    "would",
    "like",
    "order",
    "able",
    "predict",
    "load",
    "amount",
    "given",
    "factors",
    "like",
    "trade",
    "score",
    "average",
    "balance",
    "work",
    "experience",
    "would",
    "need",
    "different",
    "models",
    "let",
    "say",
    "first",
    "model",
    "call",
    "linear",
    "regression",
    "model",
    "second",
    "model",
    "call",
    "decision",
    "free",
    "regressor",
    "third",
    "model",
    "knn",
    "regressor",
    "called",
    "base",
    "models",
    "please",
    "note",
    "models",
    "learning",
    "parallel",
    "means",
    "influenced",
    "outcomes",
    "linear",
    "regression",
    "influence",
    "two",
    "models",
    "whatsoever",
    "model",
    "influenced",
    "models",
    "parallel",
    "learning",
    "piece",
    "talking",
    "record",
    "passed",
    "models",
    "models",
    "capable",
    "generating",
    "prediction",
    "let",
    "say",
    "given",
    "credit",
    "score",
    "average",
    "balance",
    "work",
    "experience",
    "populate",
    "table",
    "captures",
    "predictions",
    "made",
    "models",
    "example",
    "linear",
    "regression",
    "given",
    "inputs",
    "generates",
    "prediction",
    "let",
    "say",
    "decision",
    "tree",
    "regressor",
    "generates",
    "prediction",
    "cann",
    "generates",
    "prediction",
    "please",
    "note",
    "times",
    "always",
    "target",
    "column",
    "available",
    "talking",
    "supervised",
    "learning",
    "stage",
    "seeing",
    "basically",
    "data",
    "generated",
    "meta",
    "model",
    "original",
    "data",
    "gave",
    "input",
    "base",
    "models",
    "base",
    "models",
    "generated",
    "predictions",
    "meta",
    "model",
    "need",
    "original",
    "data",
    "anymore",
    "simply",
    "ignore",
    "concentrate",
    "entirely",
    "data",
    "generated",
    "predictions",
    "going",
    "focus",
    "problem",
    "statement",
    "meta",
    "model",
    "reduces",
    "loan",
    "amount",
    "eligibility",
    "given",
    "predictions",
    "three",
    "base",
    "models",
    "predictions",
    "base",
    "models",
    "acting",
    "features",
    "meta",
    "model",
    "sum",
    "one",
    "time",
    "data",
    "data",
    "got",
    "passed",
    "three",
    "different",
    "models",
    "learn",
    "parallel",
    "models",
    "generated",
    "prediction",
    "another",
    "data",
    "like",
    "saw",
    "three",
    "features",
    "containing",
    "predictions",
    "models",
    "data",
    "given",
    "input",
    "meta",
    "model",
    "model",
    "could",
    "different",
    "model",
    "let",
    "say",
    "taken",
    "support",
    "vector",
    "regressor",
    "case",
    "look",
    "base",
    "models",
    "learn",
    "parallel",
    "meta",
    "model",
    "actually",
    "given",
    "input",
    "sequential",
    "way",
    "call",
    "composite",
    "technique",
    "learning",
    "parall",
    "sequentially",
    "move",
    "final",
    "stage",
    "meta",
    "model",
    "going",
    "generate",
    "prediction",
    "would",
    "determine",
    "loan",
    "amount",
    "eligibility",
    "amount",
    "bank",
    "willing",
    "approve",
    "meta",
    "models",
    "prediction",
    "taken",
    "final",
    "result",
    "generally",
    "things",
    "practically",
    "understand",
    "always",
    "divide",
    "data",
    "train",
    "test",
    "try",
    "learn",
    "train",
    "try",
    "make",
    "predictions",
    "test",
    "work",
    "case",
    "blending",
    "stacking",
    "let",
    "understand",
    "take",
    "example",
    "blending",
    "first",
    "tell",
    "different",
    "case",
    "stacking",
    "let",
    "start",
    "data",
    "data",
    "first",
    "divide",
    "data",
    "three",
    "parts",
    "train",
    "validation",
    "test",
    "generally",
    "convention",
    "always",
    "keep",
    "larger",
    "portion",
    "data",
    "train",
    "data",
    "train",
    "data",
    "given",
    "input",
    "base",
    "models",
    "parallel",
    "models",
    "base",
    "models",
    "learn",
    "using",
    "train",
    "set",
    "base",
    "models",
    "trained",
    "generate",
    "predictions",
    "validation",
    "set",
    "remember",
    "data",
    "generated",
    "form",
    "predictions",
    "data",
    "input",
    "meta",
    "model",
    "outputs",
    "validation",
    "set",
    "supplied",
    "meta",
    "model",
    "finally",
    "meta",
    "model",
    "trained",
    "meta",
    "model",
    "would",
    "generate",
    "predictions",
    "test",
    "set",
    "overall",
    "works",
    "terms",
    "train",
    "validation",
    "test",
    "approach",
    "part",
    "portion",
    "train",
    "data",
    "validation",
    "purposes",
    "also",
    "known",
    "hold",
    "approach",
    "approach",
    "saw",
    "called",
    "blending",
    "different",
    "blending",
    "stacking",
    "one",
    "major",
    "difference",
    "case",
    "stacking",
    "instead",
    "taking",
    "one",
    "portion",
    "validation",
    "something",
    "called",
    "cross",
    "validation",
    "covered",
    "cross",
    "validation",
    "separate",
    "tutorial",
    "general",
    "perspective",
    "supervised",
    "learning",
    "may",
    "refer",
    "stacking",
    "instead",
    "taking",
    "one",
    "cut",
    "train",
    "parking",
    "validation",
    "cross",
    "validation",
    "essentially",
    "kind",
    "repeats",
    "process",
    "multiple",
    "times",
    "could",
    "kfold",
    "cross",
    "validation",
    "value",
    "k",
    "could",
    "five",
    "10",
    "commonly",
    "go",
    "one",
    "difference",
    "stacking",
    "blending",
    "case",
    "stacking",
    "train",
    "base",
    "models",
    "overall",
    "data",
    "cycle",
    "come",
    "stage",
    "meta",
    "mod",
    "train",
    "base",
    "models",
    "entire",
    "data",
    "one",
    "difference",
    "gets",
    "complicated",
    "follow",
    "may",
    "keep",
    "mind",
    "enlarge",
    "blending",
    "stacking",
    "basic",
    "structure",
    "set",
    "base",
    "models",
    "learn",
    "parallel",
    "meta",
    "model",
    "could",
    "also",
    "variations",
    "want",
    "may",
    "create",
    "another",
    "layer",
    "base",
    "models",
    "multiple",
    "layers",
    "base",
    "models",
    "finally",
    "meta",
    "model",
    "choice",
    "models",
    "mentioned",
    "mandate",
    "could",
    "try",
    "different",
    "mix",
    "different",
    "types",
    "models",
    "look",
    "combination",
    "gives",
    "us",
    "best",
    "results",
    "might",
    "sound",
    "like",
    "relatively",
    "heavy",
    "concept",
    "understand",
    "terms",
    "coding",
    "simplified",
    "exercise",
    "see",
    "pretty",
    "straightforward",
    "blending",
    "stacking",
    "last",
    "video",
    "sequence",
    "ensembling",
    "technique",
    "videos"
  ],
  "keywords": [
    "may",
    "also",
    "video",
    "please",
    "let",
    "finally",
    "techniques",
    "going",
    "talk",
    "two",
    "blending",
    "stacking",
    "difference",
    "one",
    "need",
    "data",
    "talking",
    "models",
    "use",
    "different",
    "types",
    "base",
    "case",
    "parallel",
    "predictions",
    "passed",
    "meta",
    "model",
    "generates",
    "final",
    "example",
    "score",
    "average",
    "balance",
    "work",
    "experience",
    "loan",
    "amount",
    "eligibility",
    "could",
    "would",
    "taken",
    "like",
    "given",
    "say",
    "first",
    "call",
    "linear",
    "regression",
    "regressor",
    "called",
    "learning",
    "prediction",
    "always",
    "stage",
    "generated",
    "input",
    "three",
    "learn",
    "generate",
    "understand",
    "train",
    "test",
    "try",
    "validation",
    "portion",
    "set",
    "approach",
    "cross"
  ]
}