{
  "text": "hi today we're going to build a beginner machine \nlearning project we'll start out with a seven-step  \nprocess that you can use to build an effective \nproject then we'll build an end-to-end project  \nusing python and jupiter notebook let's \nget started now we can talk about the seven  \nsteps that we'll need to undertake to build a \ncomplete machine learning project step one is to  \nform a hypothesis and a hypothesis is a statement \nthat we can prove or disprove using data in this  \ncase let's make our hypothesis that we can predict \nhow many metals a country will win in the olympics  \nusing data we have our hypothesis we need to \nfind the data to prove or disprove it in this  \ncase we can use data from the summer olympics \nthis data set contains more than 2000 rows  \nwhere each row is a single country in a single \nolympic game so as you can see this first row  \nis team usa from 2008 and we also have some data \non how they did in the olympics and the second row  \nis team usa from the 2012 summer olympics now \nlet's go through the columns in this data set  \nso the first column is the team code so it's a \nthree letter code that indicates which country  \nparticipated in the olympics the second column \nindicates which year these olympic games took  \nplace the third column indicates how many athletes \nthat country entered into the olympics the fourth  \ncolumn indicates how many medals they won in the \nprevious olympics so for the first row which is  \nfor the year 2008 previous medals would indicate \nhow many medals team usa won in the 2004 olympics  \nand then the final column is what we're going to \ntry to predict it's how many medals the given team  \nwon in these olympics so again going back to our \nfirst row you can see that team usa in 2008 won  \n317 olympic medals once we have the data we need \nto reshape it to make machine learning predictions  \npossible in this case we don't need to do a lot of \nreshaping since what we're going to predict is the  \nfinal column the metals column and we're going to \nuse the athletes and previous metals columns to do  \nthat so our data is already in the form it needs \nto be in where we can pull data from a single row  \nto make the predictions that we need sometimes \ndata will be in a position where the target column  \nwhat you're trying to predict isn't available in \na single row or the predictors what you're trying  \nto use to predict the target aren't available \nin a single row in this case our data is clean  \nand everything is available in a single row \nso we'll be able to use the athletes column  \nand the previous metals column to predict how many \nmedals a team will win in a given year once we've  \nreshaped our data we can start to clean it and \ncleaning the data involves making sure that our  \ndata is ready for machine learning in this case \na lot of our data contains missing values so  \nif you look at the previous metals column for \nsome teams we can't actually find a value for  \nprevious metals and that's because that team \ndid not compete in the previous olympics  \nso alb is albania and albania did not compete in \nthe 1988 olympics so there's no value for previous  \nmedals because previous medals is how many medals \nalbania would have received in the 1988 olympics  \nso for this first row previous medals is missing \nsame thing for the other rows these countries did  \nnot compete in the prior summer olympics therefore \nwe don't have a value for previous metals  \nmost machine learning algorithms \ncannot work with missing data  \nso our fourth step is we're going to need to \nclean the data to handle those missing values  \nand the fifth step is going to be finding an error \nmetric that we can use to evaluate the performance  \nof our machine learning model so our machine \nlearning model is going to create predictions  \nso we're going to predict how many metals we think \na country should have earned in a given olympics  \nand those predictions are going to be different \nfrom the actual medal counts and we need a way  \nto figure out if those predictions are good or not \nand the way we do that is to use an error metric  \nthe error metric we'll be using is called mean \nabsolute error and you can see the formula for  \nit on the left don't be intimidated though \nwe'll break down what that formula means  \nand how we're going to use it so the formula can \nlook a little complex but i'll explain how it's  \nactually going to work so i just added a column \nto our table called error so error is just the  \nthe actual metals so that the value in the \nmetals column minus the predictions and if  \nthere's a negative we just drop the negative sign \nand that's that's creating the the absolute error  \nso that's everything in the formula to the right \nof the the sum sign which looks like a big e so  \nthat's all we're doing is subtracting the the \npredictions from the actual values and then after  \nwe do that we go ahead and take the mean of all \nthe individual errors so what we do is we add up  \nall of the error values and then we divide by the \ntotal number of predictions we made and that gives  \nus what's called the mean absolute error so that's \nthe metric we're going to use to evaluate if our  \nalgorithm is making predictions effectively step 6 \nis splitting the data so we need to split the data  \nbecause we want to train on one part of the data \nand make predictions on another part of the data  \nand the reason we want to do that is if we train \nthe algorithm on the same data that we use to  \nevaluate it it's like the algorithm having \nan open book on a test so if you're studying  \nfor a test and you're given a practice test to \ntake and you can memorize all the questions on  \nthe practice test if you're doing well on the \npractice test it might just be because you've  \nmemorized all the questions it not it might not \nbe because you understand the material on the test  \nso what we want to do is give the algorithm \na new set of data that it hasn't been trained  \non to make predictions on and that new set \nof data will tell us how well the algorithm  \nis performing so we're going to train the \nalgorithm on the training data and then test  \nit on the test data and we'll measure the mean \nabsolute error so how well the algorithm makes  \npredictions on the test data and that will tell \nus if we've built the algorithm properly or not  \nand then the final step step seven is the fun \npart actually training the model so we're going  \nto use linear regression which is a very popular \nmachine learning model and linear regression works  \nwith an equation so if you look at the top left \nthe equation y equals ax plus b is the equation  \nthat we're going to use to train our model and \nthere's a simple example of how that can work  \nbelow so you see the axis metals is on the \ny-axis and previous metals some metals in the  \nlast olympics is on the x-axis so for example if \na country a country may have gotten one medal in  \nthe last olympics and three medals in the current \nolympics and you see that at the 0.13 on the left\nso a linear regression model will draw a line  \nbetween the points and we can \nuse that line to make predictions\nso you can see that we've now drawn a line \nand this line is a linear regression line  \nand what this line does is it \nlets us predict new data using  \npast data so we've trained the slope of this line \nusing the equation at the top left so the this  \nequation at the top left dictates the \ny-intercept and the slope of the line  \nand we can use this line to predict data that we \nhaven't trained it on so for example if a country  \ngot six medals in the last olympics we can look at \nthe line and we can see that that corresponds to  \nabout six medals in this olympics so we would \npredict that that country would get six medals  \nin the current olympics so for example if a \ncountry got six medals in the 2016 olympics  \nusing this line we might predict that they'll \nalso get six medals in the 2020 olympics  \nso the way that we build a linear regression \nis we train it using data that we already have  \nand then we use what we've trained the \nline to make predictions on future data  \nnow the model we're going to train is going to \nbe slightly more complicated than this model  \nthis is what's called univariate or \nsingle variable linear regression  \nwhere we're only using previous metals so \nthe metals a country got in the last olympics  \nto predict the metals they'll get in this \nolympics but we're going to do something a  \nlittle bit more complicated in our actual model \nand we're actually going to use two predictors\nso we're going to use this equation instead \nwhich enables us to use two predictors so  \nthe number of athletes a country is entered into \nthe olympics and how many medals they got in the  \nprevious olympics so we're going to train a model \nthat takes into account both of those factors  \nand then we're going to make predictions all \nright so that's the setup and hopefully now  \nyou have a good overview of the steps we're \ngoing to take let's dive in and start coding\nokay let's go ahead and get started so the first \nthing we're going to do is we're going to import  \npandas as pd and pandas is an amazing \npython and data analysis library and  \nwe're going to use it to read in and explore \nour data so we're going to read our data in  \nteams.csv is the file that contains our data \nand the download link is in the description if  \nyou want to go ahead and download that data \nso let's take a look at the teams data this  \nis similar to what we saw in the table in the \nintroduction except there's a few extra columns  \nlet's go ahead and remove those columns \njust to make this a little bit simpler  \nthose extra columns are columns you can use to \ncontinue building this model out on your own  \nbut for the purposes of this video i'm \ngoing to just take those extra columns out  \nso let's use the same subset of columns \nthat we saw in the table earlier\nwith a couple of additions so i'll \nexplain the additions in just a second\nokay so let's take a look here\nokay so we have team which is the three-letter \ncode for the country we have country which is just  \nthe longer country name we have the year so this \nis the year that the summer olympic games happened  \nwe have the number of athletes the team \nentered into the summer olympic games  \nwe have the average age of those athletes that \nwere entered we have how many medals the country  \ngot in the previous olympics and we have the \nnumber of medals the country got in these olympics  \nso we're going to be trying to predict metals \nand we're going to use previous metals and  \nathletes to do so so we're going to use two \ncolumns to try to predict the number of metals a  \ncountry got in the olympics and before we dive in \nand do that let's take a quick look to see if it's  \neven possible to make these predictions so what \nwe're looking at here is the correlation between  \nthe metals column and the other columns in our \ndata so when we're building a linear model we want  \nto look for strong correlations between the column \nwe're trying to predict and the columns we're  \ntrying to use to predict that value because that \nenables a linear model to make good predictions  \nto draw the line in a place that makes sense so \nthese correlations are on a zero to one scale  \nand you can see the correlation for athletes and \nfor previous metals is very high which indicates  \nthat yes we probably can use these columns to make \npredictions let's take a closer look at the graph  \nof how these columns look versus the metals column \nand we'll talk a little bit more about correlation  \nso we're going to import a python graphing library \ncalled seaborn and then what we can do is use  \nseaborn and the pandas data frame to actually plot \nathletes on the x-axis and metals on the y-axis\nand then we're going to use our \nteams data frame as the data source  \nand what we're going to say is fit regression \nequals true which will fit a nice regression  \nline like we did earlier in the intro and we'll \nsay ci equals none if we don't say ci equals  \nnone seaborn will give us a confidence interval \naround the line which is not what we want  \nso we can see that there is a rough linear \nrelationship between the number of athletes  \na country enters into the olympics and \nthe number of medals the country earns  \nwhich makes a lot of sense right if you enter \nmore athletes into the olympics you have a higher  \nchance of winning medals if you only enter \none athlete the maximum number of medals you  \ncan win is one whereas if you enter a thousand the \nmaximum number of medals you can win is a thousand  \nso this shows us that there is a relationship as \nthe number of athletes increases the number of  \nmedals also seems to increase and this is good \nnews for us because we want to make predictions  \nusing athletes so this the existence \nof this relationship is great  \nnow we can look at a column where there isn't as \nstrong of a correlation we can look at age so you  \ncan see there's a very very weak correlation \nbetween age and metals it's .02 out of out of  \none which is very low let's make another plot and \nlook at the relationship between these two columns\nso we'll say fit reg equals true again and we'll \nsay ci equals not so let's go ahead and plot that  \nand we can see here there really isn't a \nlinear relationship between age and metals  \nso as age increases the number of metals doesn't \nreally increase you can see when age is low the  \nnumber of metals is also low and when age is \nhigh the number of metals is also high there  \ncould be an interesting non-linear correlation \nhere where if age is between 20 and 30 it seems  \nlike potentially the number of metals could be \nhigh but it's hard to tell this may be something  \nworth investigating later on your own but for now \nwe just won't use age as a predictor in our model  \nnow one last bit of exploration we'll do \nbefore we go ahead and do the machine learning  \nis we'll make a quick histogram to look at how \nmany countries fall into each bin for number of  \nmetals they earned so to explain this histogram \nyou can see a lot of countries almost 2 000 in  \nour data set have earned between zero and 50 \nmedals in an olympics and there's very very few  \ncountries that have earned a lot of metals so our \ndata is a little bit unbalanced in the sense that  \nsome countries have earned a lot of metals and \nmost countries have earned very very few medals  \nso this may impact the usefulness of our model and \nour accuracy and we'll look into that later and  \nsee if this affects it at all but it's usually a \ngood idea to look at your the column you're trying  \nto predict the target and see how balanced \nit is all right now it's on to the next step  \nwe've we've found the data we've explored it our \nnext step is doing a little bit of data cleaning  \nso i mentioned earlier that there are some missing \nvalues in our data and we actually want to go  \nahead and remove those missing values so what \ni'm going to do is first find the missing values  \nso what this code does is it finds \nany rows that have missing values  \nso let's go ahead and run that and you can see  \nthere are a few rows about 130 that have \nmissing values for the previous metals column  \nand i mentioned earlier why the previous metals \ncolumn might have missing values so albania for  \nexample didn't participate in the 1988 olympics \nwhich were the olympics previous to this so  \nit didn't we don't have any data on metals \nthat they received or didn't receive in 1988  \nsame thing with algeria and andorra and so on so \nwhat we're going to do with this missing data is  \nwe're just going to drop any rows that have a \nmissing value so the way we'll do that is we'll  \nsay teams equals teams dot drop n a and that'll \njust remove all of these rows from our data  \nso we're left with 2014 rows and previous \nmetals doesn't have any missing values anymore\nthe next thing we're going to do is go ahead and \nsplit our data up and because this data is time  \nseries data right some rows come before other rows \nwe want to split it in a way that respects that  \nso we want to take the last two years of \ndata we have 2012 and 2016 and put them  \nin our test data set and take the previous \nyears and put them in our train data set  \nand the reason we want to do that is in the \nreal world if we're trying to predict who's  \ngoing to win the most metals in the olympics \nin 2024 we don't have access to data from 2028  \nright we only have access to data from the past so \nwhen we train our machine learning model we want  \nto respect the order of the data and make sure \nthat we don't use future data to predict the past  \nso we're splitting up our training and test set \nhere and the reason we're splitting them up is we  \nwant to be able to train our model on the training \nset and then use a different set to evaluate how  \nwell the model is doing and that's going to be \nthe test set we don't want to train the model on  \nthe train set and evaluate how well it's doing on \nthe train set because that's like giving somebody  \nall the answers to the test before they take the \ntest we want the model to be evaluated on data  \nthat it hasn't seen before that it has not been \ntrained on okay so we can look at train dot shape  \nand we can see our training set has 600 rows and \nour test set has about 400 rows so that's an about  \n80 20 split of our data which is perfect that's \nvery very close to what the default split is  \npeople usually just do a default 80 20 train \ntest split so this will give us a good way to  \ntrain our algorithm and evaluate the error okay \nnow let's move on to actually training the model  \nso earlier we picked mean absolute error as our \nerror metric so we're going to use that metric to  \nevaluate our model after we train it so to train \nour model we can import from sklearn.linearmodel  \nwe can import linear regression and the \nlinear regression class is going to enable us  \nto train and make predictions with a linear model \nso i showed you earlier what a linear model looks  \nlike you draw a line and then you use that line \nto make predictions so we're going to initialize  \nour linear regression class reg equals linear \nregression and we're using scikit-learn which is  \nan amazing python machine learning library that \nhas lots of built-in algorithms that all have a  \nsimilar interface so you could easily switch \nfrom a linear regression to a different model  \nnow we're going to define our predictors so \nthese are the columns that we're going to use  \nto predict our target and our predictors \nare going to be athletes and previous medals  \nthen we're going to define our target which if \nyou remember our target was the metals column  \nso we're going to train a linear regression \nmodel to use these two columns to predict  \nthis column let's go ahead and run that now we \ncan do is we can call the fit method to actually  \nfit our linear regression model so \nwe'll call we'll call the fit method  \nand we'll pass in the columns from the training \ndata set that we want to use as predictors  \nso this is this is the data we're going to use to \ntrain the algorithm and then this is the target  \nso this is the data this is the target \nthat we're going to pass into the algorithm  \nand the algorithm is going to be trained on the \ntraining data set so let's go ahead and run that  \nnow that we fit our algorithm we can use that \nto actually make predictions so we can type  \npredictions equals reg.predict test predictors \nso you'll notice this we're calling the predict  \nmethod of our linear regression class and we're \nonly passing in the predictors for test we're not  \npassing in the actual values and that's because \nwe want the algorithm to create predictions  \nwithout knowing what the actual answers are so \nwe're going to use this to generate predictions\nnow let's take a look at our \npredictions so this is a numpy array  \nand it is kind of hard to read but you may \nnotice a couple of things one these values  \nare not rounded right which doesn't really make \nsense given our scenario our scenario is we're  \ntrying to predict the number of medals a country \nwill win and countries can only win a whole number  \nof medals you can't win a half medal the second \nthing is that some of these numbers are negative  \nand countries cannot get a negative number of \nmetals so we're just going to do a some quick  \ncorrection to correct the model to just prevent \nany negatives and to round our numbers and the  \neasiest way to do this is to just manually correct \nit so we'll just do a couple of things to actually  \nrescale our predictions and make sure that \nthey make sense so the first thing that we're  \ngoing to do is we'll go ahead and assign our \npredictions to a column in our test data frame\nand this will let us just take a look at our \npredictions more easily we can see them there on  \nthe right and then what we'll say is test.loc test \npredictions less than zero predictions equals zero  \nso what this is going to do is it's going to index \nour test data frame it's going to find any rows  \nwhere the predictions column is less than zero \nand it's going to replace the predictions value in  \nthat row with a zero so basically if predictions \nwas less than zero it will be turned into a zero  \nthen what we'll do is we'll say test \npredictions equals test predictions  \ndot round just to make this data make more sense \nwe'll round all the predictions to the nearest  \nwhole number so we can take a look at tests \nnow and predictions make a lot more sense now  \nzero is the minimum and we can see that the \nvalues are rounded to the nearest whole number  \nnow we can do is we can go ahead and look \nat mean absolute error mean absolute error  \nso we will import mean absolute error \nfrom scikit-learn and then we can write  \nwe can call the function and then pass in \nour actual values which are the number of  \nmetals the team actually won in the test \nset and then we can pass in our predictions\nall right and we'll get a number back \nindicating our mean absolute error  \nnow what does this actually mean so this \nmeans that on average we were within  \n3.3 metals of how many metals a team actually \nwon in the olympics now whether or not that's  \na good value let's find out so we're going \nto dig a little bit deeper into the data set  \nand investigate if that is actually a good \nerror or not so first let's take a look at our  \nmetals column in a little more depth using the \npandas describe method and what this shows us is  \nthe minimum value in the column the percentiles \nand the standard deviation so it's usually nice  \nto just do a quick sanity check and make sure \nthat your error is below the standard deviation  \nif it's higher than the standard deviation usually \nsomething's wrong either you're using predictors  \nthat just don't give you any information to \npredict the target or you you mess something up  \nwith your model in this case things look okay \nour error is far below the standard deviation\nthen what we can do is look team by team  \nto see how our predictions look for \ndifferent countries so let's look at the usa\nso we can see in 2012 the us got 248 medals but \nwe predicted 285 and in 2016 they got 264 medals  \nbut we predicted 236. that's not bad right \nwe're we're not we're not absolutely correct  \nbut we're not super far off so we are about \n40 medals off here but in percentage terms  \nit's not that high of a percentage and same here \nthe percentage that we're off is not very high  \nnow we can look at another country like india that \ndoesn't enter as many athletes into the olympics  \nand see how we did there so with india in 2012 \nindia got six medals and we predicted they  \nwould get seven which is which is good right we're \npretty close in percentage terms but in 2016 india  \ngot two medals in the olympics and we predicted \n12. so we're off by a factor of six and this is  \nwhere mean absolute error can be very different \nfor different countries on a percentage basis so  \nif a country only got two medals an average error \nof four medals is huge right that's a factor of  \ntwo either way whereas for a country that gets 300 \nmedals earns 300 medals in an olympics an average  \nerror of four is not that big a deal right in \npercentage terms it's pretty small so what we can  \ndo now is look at our errors by country just to \nsee how we're doing on a country by country basis\nokay so this is just finding the mean the absolute \nerror so we're subtracting our predictions from  \nour actual metals and we're taking the absolute \nvalue we saw the formula for this earlier  \nand i'll we'll take a look at errors so this is \njust the difference between our predicted number  \nof metals and our actual number of metals and \ni'll i'll use the column and test instead of the  \npredictions variable because that's \nthe one that we rounded all nicely  \nso this just gives us our difference between how \nmany metals we predicted and how many metals were  \nactually earned by the team what we can now \ndo is group this by team so we can create a  \nvariable called error by team and we'll say \nerrors dot group by test team so group by  \nis a pandas method that creates a separate group \nfor each team and then we will calculate the mean  \nso this will create a separate group \nfor each team and then find the mean  \nerror for that team so if we look at error by team\nwe now have how many metals off we \nwere on average for each country\nnow we can do is we can look at how many \nmetals each country earned on average\nso we can do the same thing with the \nmetals column we can group it by team  \nand then we can find the mean and \nthis will tell us how many metals  \neach country earned on average in the olympics \nand then we can find the ratio between our errors  \nerror by team divided by medals \nby team call this medals team\nand let's call this error ratio okay so now we \ncan take a look at error ratio and see what it is  \nif i run it properly and we can see \nthere's a lot of nan values here  \nand this is because a lot of teams there the \naverage number of metals they earn is zero  \nso we're dividing by zero and \nwe're getting a missing value\nso what we need to do here is import \nwhat we can do is we can say error ratio\nso we can take only values that are not missing \nso this gives us 102 countries where we don't have  \nmissing values in our predictions here we also get \nsome infinite values so we need to figure out how  \nto remove those as well so for whatever reason \nif a country has an average ratio of zero metals  \nso if if our average error was zero and our \ntotal number of metals was zero then we'll  \nget an nan while doing this division in \npandas but if instead the error by team is  \none and metals by team is zero then we get \nan infinite value like in this case so we  \njust need to clean up our infinite values as \nwell so what we'll say here is error ratio\nequals error ratio np dot is finite error \nratio okay and then i'll import numpy as np\nall right so now we can take a look at \nerror ratio okay so we now have 97 values  \nwe've removed all our missing \nvalues and our infinite values  \nso that gives us only the countries \nthat we have an actual error ratio for  \nand now what we can do is we can go ahead \nand create another histogram of this\nand what this tells us is an error ratio of 0 \nto let's say 0.5 means that you are within 50  \nof the actual metal count but in some \ncases here error ratio is 2 and above  \nwhich means that our predictions were twice \nas high as the predicted metals or half of  \nthe predicted metals so it means that we're pretty \nfar off the true value so what you'll want to do  \nto determine if this model works for your purposes \nis look through the error ratios for the countries  \nthat you want to make predictions for and for \nsome countries the error ratios are pretty good  \nright so for the u.s we're within 12 of the true \nmetal count for australia we're within 36 percent  \nbut for other countries the error is higher right \nand we're much further off the true metal count so  \nwhether or not this model is good depends on if it \ncan do well in what you want it to to do well in  \nso sometimes you need to go a layer deeper and get \na little bit below just the mean absolute error or  \nthe all-in-one error metric and actually figure \nout what that metric means and how it breaks down  \namong specific groups in your data so in \nthis case if we wanted to make predictions  \nfor countries that tend to earn a \nlot of metals we would do pretty well  \nand we can see this by typing \nerror ratio.sort values\nso countries that tend to get a lot of medals in \nthe olympics like france canada russia our error  \nis pretty low whereas for other countries \nwhich maybe we don't have as much data for  \nor don't send as many athletes to the \nolympics our error is much higher so  \nfor countries that send a lot of athletes to \nthe olympics our model performs pretty well  \nbut there is a lot we could do to continue to \nimprove it if we want if we want it all right  \nso at this point we've gone through the \nseven main steps in building a machine  \nlearning model and now we can talk about if \nwe wanted to extend this what we would do\nso there's a couple of things you can do to \nimprove the accuracy and performance of this model  \nso you can add in more predictors to the model  \nso you'll notice there are a few columns we \ndidn't use so that would be columns like events  \nand age or height so that's that's one option \nyou could try different machine learning models  \nso models like a random forest or a neural network \nto see if they perform better you could go back to  \nthe original athlete level data and actually try \nto build a different kind of model so the data  \nthat we're using the teams.csv data i actually \nsummarized from a different athlete level data set  \nso we can go ahead and take a look at that data \nset that's this athlete events dot csv data set  \nand this data set has information about individual \nathletes in the olympics so each row is a specific  \nathlete and what you could do is build a model \nto predict if a specific athlete will win a medal  \nand you could add the results of that model \ntogether to figure out how many medals each  \ncountry will win and that model could be more \naccurate than a top down just looking at the  \ntotal number of athletes in a country model so \nyou could build a specific athlete level model  \nyou could also try to reshape some of these \ncolumns some some of these columns may have  \nnon-linear correlations with our target with \nmetals so you could try reshaping those columns  \nusing different mathematical transformations to \nsee if that creates a more linear correlation  \nall right the final thing you can do is measure \nthe error more predictably so you can build a  \nsystem like a back testing system which i've \ntalked about in other videos or another kind  \nof system that can measure error across the \nwhole data set not just on a 20 subset of it  \nyou could also train a model for different types \nof countries so you could train different models  \nfor countries that earn low numbers of \nmetals versus high numbers of metals etc  \nso all of these ideas could \nhelp you build a more accurate  \nmodel well i hope this was a good beginner \nintroduction to machine learning and that  \nyou understand the main steps in building a \nmachine learning model thanks a lot for watching\n",
  "words": [
    "hi",
    "today",
    "going",
    "build",
    "beginner",
    "machine",
    "learning",
    "project",
    "start",
    "process",
    "use",
    "build",
    "effective",
    "project",
    "build",
    "project",
    "using",
    "python",
    "jupiter",
    "notebook",
    "let",
    "get",
    "started",
    "talk",
    "seven",
    "steps",
    "need",
    "undertake",
    "build",
    "complete",
    "machine",
    "learning",
    "project",
    "step",
    "one",
    "form",
    "hypothesis",
    "hypothesis",
    "statement",
    "prove",
    "disprove",
    "using",
    "data",
    "case",
    "let",
    "make",
    "hypothesis",
    "predict",
    "many",
    "metals",
    "country",
    "win",
    "olympics",
    "using",
    "data",
    "hypothesis",
    "need",
    "find",
    "data",
    "prove",
    "disprove",
    "case",
    "use",
    "data",
    "summer",
    "olympics",
    "data",
    "set",
    "contains",
    "2000",
    "rows",
    "row",
    "single",
    "country",
    "single",
    "olympic",
    "game",
    "see",
    "first",
    "row",
    "team",
    "usa",
    "2008",
    "also",
    "data",
    "olympics",
    "second",
    "row",
    "team",
    "usa",
    "2012",
    "summer",
    "olympics",
    "let",
    "go",
    "columns",
    "data",
    "set",
    "first",
    "column",
    "team",
    "code",
    "three",
    "letter",
    "code",
    "indicates",
    "country",
    "participated",
    "olympics",
    "second",
    "column",
    "indicates",
    "year",
    "olympic",
    "games",
    "took",
    "place",
    "third",
    "column",
    "indicates",
    "many",
    "athletes",
    "country",
    "entered",
    "olympics",
    "fourth",
    "column",
    "indicates",
    "many",
    "medals",
    "previous",
    "olympics",
    "first",
    "row",
    "year",
    "2008",
    "previous",
    "medals",
    "would",
    "indicate",
    "many",
    "medals",
    "team",
    "usa",
    "2004",
    "olympics",
    "final",
    "column",
    "going",
    "try",
    "predict",
    "many",
    "medals",
    "given",
    "team",
    "olympics",
    "going",
    "back",
    "first",
    "row",
    "see",
    "team",
    "usa",
    "2008",
    "317",
    "olympic",
    "medals",
    "data",
    "need",
    "reshape",
    "make",
    "machine",
    "learning",
    "predictions",
    "possible",
    "case",
    "need",
    "lot",
    "reshaping",
    "since",
    "going",
    "predict",
    "final",
    "column",
    "metals",
    "column",
    "going",
    "use",
    "athletes",
    "previous",
    "metals",
    "columns",
    "data",
    "already",
    "form",
    "needs",
    "pull",
    "data",
    "single",
    "row",
    "make",
    "predictions",
    "need",
    "sometimes",
    "data",
    "position",
    "target",
    "column",
    "trying",
    "predict",
    "available",
    "single",
    "row",
    "predictors",
    "trying",
    "use",
    "predict",
    "target",
    "available",
    "single",
    "row",
    "case",
    "data",
    "clean",
    "everything",
    "available",
    "single",
    "row",
    "able",
    "use",
    "athletes",
    "column",
    "previous",
    "metals",
    "column",
    "predict",
    "many",
    "medals",
    "team",
    "win",
    "given",
    "year",
    "reshaped",
    "data",
    "start",
    "clean",
    "cleaning",
    "data",
    "involves",
    "making",
    "sure",
    "data",
    "ready",
    "machine",
    "learning",
    "case",
    "lot",
    "data",
    "contains",
    "missing",
    "values",
    "look",
    "previous",
    "metals",
    "column",
    "teams",
    "ca",
    "actually",
    "find",
    "value",
    "previous",
    "metals",
    "team",
    "compete",
    "previous",
    "olympics",
    "alb",
    "albania",
    "albania",
    "compete",
    "1988",
    "olympics",
    "value",
    "previous",
    "medals",
    "previous",
    "medals",
    "many",
    "medals",
    "albania",
    "would",
    "received",
    "1988",
    "olympics",
    "first",
    "row",
    "previous",
    "medals",
    "missing",
    "thing",
    "rows",
    "countries",
    "compete",
    "prior",
    "summer",
    "olympics",
    "therefore",
    "value",
    "previous",
    "metals",
    "machine",
    "learning",
    "algorithms",
    "work",
    "missing",
    "data",
    "fourth",
    "step",
    "going",
    "need",
    "clean",
    "data",
    "handle",
    "missing",
    "values",
    "fifth",
    "step",
    "going",
    "finding",
    "error",
    "metric",
    "use",
    "evaluate",
    "performance",
    "machine",
    "learning",
    "model",
    "machine",
    "learning",
    "model",
    "going",
    "create",
    "predictions",
    "going",
    "predict",
    "many",
    "metals",
    "think",
    "country",
    "earned",
    "given",
    "olympics",
    "predictions",
    "going",
    "different",
    "actual",
    "medal",
    "counts",
    "need",
    "way",
    "figure",
    "predictions",
    "good",
    "way",
    "use",
    "error",
    "metric",
    "error",
    "metric",
    "using",
    "called",
    "mean",
    "absolute",
    "error",
    "see",
    "formula",
    "left",
    "intimidated",
    "though",
    "break",
    "formula",
    "means",
    "going",
    "use",
    "formula",
    "look",
    "little",
    "complex",
    "explain",
    "actually",
    "going",
    "work",
    "added",
    "column",
    "table",
    "called",
    "error",
    "error",
    "actual",
    "metals",
    "value",
    "metals",
    "column",
    "minus",
    "predictions",
    "negative",
    "drop",
    "negative",
    "sign",
    "creating",
    "absolute",
    "error",
    "everything",
    "formula",
    "right",
    "sum",
    "sign",
    "looks",
    "like",
    "big",
    "e",
    "subtracting",
    "predictions",
    "actual",
    "values",
    "go",
    "ahead",
    "take",
    "mean",
    "individual",
    "errors",
    "add",
    "error",
    "values",
    "divide",
    "total",
    "number",
    "predictions",
    "made",
    "gives",
    "us",
    "called",
    "mean",
    "absolute",
    "error",
    "metric",
    "going",
    "use",
    "evaluate",
    "algorithm",
    "making",
    "predictions",
    "effectively",
    "step",
    "6",
    "splitting",
    "data",
    "need",
    "split",
    "data",
    "want",
    "train",
    "one",
    "part",
    "data",
    "make",
    "predictions",
    "another",
    "part",
    "data",
    "reason",
    "want",
    "train",
    "algorithm",
    "data",
    "use",
    "evaluate",
    "like",
    "algorithm",
    "open",
    "book",
    "test",
    "studying",
    "test",
    "given",
    "practice",
    "test",
    "take",
    "memorize",
    "questions",
    "practice",
    "test",
    "well",
    "practice",
    "test",
    "might",
    "memorized",
    "questions",
    "might",
    "understand",
    "material",
    "test",
    "want",
    "give",
    "algorithm",
    "new",
    "set",
    "data",
    "trained",
    "make",
    "predictions",
    "new",
    "set",
    "data",
    "tell",
    "us",
    "well",
    "algorithm",
    "performing",
    "going",
    "train",
    "algorithm",
    "training",
    "data",
    "test",
    "test",
    "data",
    "measure",
    "mean",
    "absolute",
    "error",
    "well",
    "algorithm",
    "makes",
    "predictions",
    "test",
    "data",
    "tell",
    "us",
    "built",
    "algorithm",
    "properly",
    "final",
    "step",
    "step",
    "seven",
    "fun",
    "part",
    "actually",
    "training",
    "model",
    "going",
    "use",
    "linear",
    "regression",
    "popular",
    "machine",
    "learning",
    "model",
    "linear",
    "regression",
    "works",
    "equation",
    "look",
    "top",
    "left",
    "equation",
    "equals",
    "ax",
    "plus",
    "b",
    "equation",
    "going",
    "use",
    "train",
    "model",
    "simple",
    "example",
    "work",
    "see",
    "axis",
    "metals",
    "previous",
    "metals",
    "metals",
    "last",
    "olympics",
    "example",
    "country",
    "country",
    "may",
    "gotten",
    "one",
    "medal",
    "last",
    "olympics",
    "three",
    "medals",
    "current",
    "olympics",
    "see",
    "left",
    "linear",
    "regression",
    "model",
    "draw",
    "line",
    "points",
    "use",
    "line",
    "make",
    "predictions",
    "see",
    "drawn",
    "line",
    "line",
    "linear",
    "regression",
    "line",
    "line",
    "lets",
    "us",
    "predict",
    "new",
    "data",
    "using",
    "past",
    "data",
    "trained",
    "slope",
    "line",
    "using",
    "equation",
    "top",
    "left",
    "equation",
    "top",
    "left",
    "dictates",
    "slope",
    "line",
    "use",
    "line",
    "predict",
    "data",
    "trained",
    "example",
    "country",
    "got",
    "six",
    "medals",
    "last",
    "olympics",
    "look",
    "line",
    "see",
    "corresponds",
    "six",
    "medals",
    "olympics",
    "would",
    "predict",
    "country",
    "would",
    "get",
    "six",
    "medals",
    "current",
    "olympics",
    "example",
    "country",
    "got",
    "six",
    "medals",
    "2016",
    "olympics",
    "using",
    "line",
    "might",
    "predict",
    "also",
    "get",
    "six",
    "medals",
    "2020",
    "olympics",
    "way",
    "build",
    "linear",
    "regression",
    "train",
    "using",
    "data",
    "already",
    "use",
    "trained",
    "line",
    "make",
    "predictions",
    "future",
    "data",
    "model",
    "going",
    "train",
    "going",
    "slightly",
    "complicated",
    "model",
    "called",
    "univariate",
    "single",
    "variable",
    "linear",
    "regression",
    "using",
    "previous",
    "metals",
    "metals",
    "country",
    "got",
    "last",
    "olympics",
    "predict",
    "metals",
    "get",
    "olympics",
    "going",
    "something",
    "little",
    "bit",
    "complicated",
    "actual",
    "model",
    "actually",
    "going",
    "use",
    "two",
    "predictors",
    "going",
    "use",
    "equation",
    "instead",
    "enables",
    "us",
    "use",
    "two",
    "predictors",
    "number",
    "athletes",
    "country",
    "entered",
    "olympics",
    "many",
    "medals",
    "got",
    "previous",
    "olympics",
    "going",
    "train",
    "model",
    "takes",
    "account",
    "factors",
    "going",
    "make",
    "predictions",
    "right",
    "setup",
    "hopefully",
    "good",
    "overview",
    "steps",
    "going",
    "take",
    "let",
    "dive",
    "start",
    "coding",
    "okay",
    "let",
    "go",
    "ahead",
    "get",
    "started",
    "first",
    "thing",
    "going",
    "going",
    "import",
    "pandas",
    "pd",
    "pandas",
    "amazing",
    "python",
    "data",
    "analysis",
    "library",
    "going",
    "use",
    "read",
    "explore",
    "data",
    "going",
    "read",
    "data",
    "file",
    "contains",
    "data",
    "download",
    "link",
    "description",
    "want",
    "go",
    "ahead",
    "download",
    "data",
    "let",
    "take",
    "look",
    "teams",
    "data",
    "similar",
    "saw",
    "table",
    "introduction",
    "except",
    "extra",
    "columns",
    "let",
    "go",
    "ahead",
    "remove",
    "columns",
    "make",
    "little",
    "bit",
    "simpler",
    "extra",
    "columns",
    "columns",
    "use",
    "continue",
    "building",
    "model",
    "purposes",
    "video",
    "going",
    "take",
    "extra",
    "columns",
    "let",
    "use",
    "subset",
    "columns",
    "saw",
    "table",
    "earlier",
    "couple",
    "additions",
    "explain",
    "additions",
    "second",
    "okay",
    "let",
    "take",
    "look",
    "okay",
    "team",
    "code",
    "country",
    "country",
    "longer",
    "country",
    "name",
    "year",
    "year",
    "summer",
    "olympic",
    "games",
    "happened",
    "number",
    "athletes",
    "team",
    "entered",
    "summer",
    "olympic",
    "games",
    "average",
    "age",
    "athletes",
    "entered",
    "many",
    "medals",
    "country",
    "got",
    "previous",
    "olympics",
    "number",
    "medals",
    "country",
    "got",
    "olympics",
    "going",
    "trying",
    "predict",
    "metals",
    "going",
    "use",
    "previous",
    "metals",
    "athletes",
    "going",
    "use",
    "two",
    "columns",
    "try",
    "predict",
    "number",
    "metals",
    "country",
    "got",
    "olympics",
    "dive",
    "let",
    "take",
    "quick",
    "look",
    "see",
    "even",
    "possible",
    "make",
    "predictions",
    "looking",
    "correlation",
    "metals",
    "column",
    "columns",
    "data",
    "building",
    "linear",
    "model",
    "want",
    "look",
    "strong",
    "correlations",
    "column",
    "trying",
    "predict",
    "columns",
    "trying",
    "use",
    "predict",
    "value",
    "enables",
    "linear",
    "model",
    "make",
    "good",
    "predictions",
    "draw",
    "line",
    "place",
    "makes",
    "sense",
    "correlations",
    "zero",
    "one",
    "scale",
    "see",
    "correlation",
    "athletes",
    "previous",
    "metals",
    "high",
    "indicates",
    "yes",
    "probably",
    "use",
    "columns",
    "make",
    "predictions",
    "let",
    "take",
    "closer",
    "look",
    "graph",
    "columns",
    "look",
    "versus",
    "metals",
    "column",
    "talk",
    "little",
    "bit",
    "correlation",
    "going",
    "import",
    "python",
    "graphing",
    "library",
    "called",
    "seaborn",
    "use",
    "seaborn",
    "pandas",
    "data",
    "frame",
    "actually",
    "plot",
    "athletes",
    "metals",
    "going",
    "use",
    "teams",
    "data",
    "frame",
    "data",
    "source",
    "going",
    "say",
    "fit",
    "regression",
    "equals",
    "true",
    "fit",
    "nice",
    "regression",
    "line",
    "like",
    "earlier",
    "intro",
    "say",
    "ci",
    "equals",
    "none",
    "say",
    "ci",
    "equals",
    "none",
    "seaborn",
    "give",
    "us",
    "confidence",
    "interval",
    "around",
    "line",
    "want",
    "see",
    "rough",
    "linear",
    "relationship",
    "number",
    "athletes",
    "country",
    "enters",
    "olympics",
    "number",
    "medals",
    "country",
    "earns",
    "makes",
    "lot",
    "sense",
    "right",
    "enter",
    "athletes",
    "olympics",
    "higher",
    "chance",
    "winning",
    "medals",
    "enter",
    "one",
    "athlete",
    "maximum",
    "number",
    "medals",
    "win",
    "one",
    "whereas",
    "enter",
    "thousand",
    "maximum",
    "number",
    "medals",
    "win",
    "thousand",
    "shows",
    "us",
    "relationship",
    "number",
    "athletes",
    "increases",
    "number",
    "medals",
    "also",
    "seems",
    "increase",
    "good",
    "news",
    "us",
    "want",
    "make",
    "predictions",
    "using",
    "athletes",
    "existence",
    "relationship",
    "great",
    "look",
    "column",
    "strong",
    "correlation",
    "look",
    "age",
    "see",
    "weak",
    "correlation",
    "age",
    "metals",
    "one",
    "low",
    "let",
    "make",
    "another",
    "plot",
    "look",
    "relationship",
    "two",
    "columns",
    "say",
    "fit",
    "reg",
    "equals",
    "true",
    "say",
    "ci",
    "equals",
    "let",
    "go",
    "ahead",
    "plot",
    "see",
    "really",
    "linear",
    "relationship",
    "age",
    "metals",
    "age",
    "increases",
    "number",
    "metals",
    "really",
    "increase",
    "see",
    "age",
    "low",
    "number",
    "metals",
    "also",
    "low",
    "age",
    "high",
    "number",
    "metals",
    "also",
    "high",
    "could",
    "interesting",
    "correlation",
    "age",
    "20",
    "30",
    "seems",
    "like",
    "potentially",
    "number",
    "metals",
    "could",
    "high",
    "hard",
    "tell",
    "may",
    "something",
    "worth",
    "investigating",
    "later",
    "wo",
    "use",
    "age",
    "predictor",
    "model",
    "one",
    "last",
    "bit",
    "exploration",
    "go",
    "ahead",
    "machine",
    "learning",
    "make",
    "quick",
    "histogram",
    "look",
    "many",
    "countries",
    "fall",
    "bin",
    "number",
    "metals",
    "earned",
    "explain",
    "histogram",
    "see",
    "lot",
    "countries",
    "almost",
    "2",
    "000",
    "data",
    "set",
    "earned",
    "zero",
    "50",
    "medals",
    "olympics",
    "countries",
    "earned",
    "lot",
    "metals",
    "data",
    "little",
    "bit",
    "unbalanced",
    "sense",
    "countries",
    "earned",
    "lot",
    "metals",
    "countries",
    "earned",
    "medals",
    "may",
    "impact",
    "usefulness",
    "model",
    "accuracy",
    "look",
    "later",
    "see",
    "affects",
    "usually",
    "good",
    "idea",
    "look",
    "column",
    "trying",
    "predict",
    "target",
    "see",
    "balanced",
    "right",
    "next",
    "step",
    "found",
    "data",
    "explored",
    "next",
    "step",
    "little",
    "bit",
    "data",
    "cleaning",
    "mentioned",
    "earlier",
    "missing",
    "values",
    "data",
    "actually",
    "want",
    "go",
    "ahead",
    "remove",
    "missing",
    "values",
    "going",
    "first",
    "find",
    "missing",
    "values",
    "code",
    "finds",
    "rows",
    "missing",
    "values",
    "let",
    "go",
    "ahead",
    "run",
    "see",
    "rows",
    "130",
    "missing",
    "values",
    "previous",
    "metals",
    "column",
    "mentioned",
    "earlier",
    "previous",
    "metals",
    "column",
    "might",
    "missing",
    "values",
    "albania",
    "example",
    "participate",
    "1988",
    "olympics",
    "olympics",
    "previous",
    "data",
    "metals",
    "received",
    "receive",
    "1988",
    "thing",
    "algeria",
    "andorra",
    "going",
    "missing",
    "data",
    "going",
    "drop",
    "rows",
    "missing",
    "value",
    "way",
    "say",
    "teams",
    "equals",
    "teams",
    "dot",
    "drop",
    "n",
    "remove",
    "rows",
    "data",
    "left",
    "2014",
    "rows",
    "previous",
    "metals",
    "missing",
    "values",
    "anymore",
    "next",
    "thing",
    "going",
    "go",
    "ahead",
    "split",
    "data",
    "data",
    "time",
    "series",
    "data",
    "right",
    "rows",
    "come",
    "rows",
    "want",
    "split",
    "way",
    "respects",
    "want",
    "take",
    "last",
    "two",
    "years",
    "data",
    "2012",
    "2016",
    "put",
    "test",
    "data",
    "set",
    "take",
    "previous",
    "years",
    "put",
    "train",
    "data",
    "set",
    "reason",
    "want",
    "real",
    "world",
    "trying",
    "predict",
    "going",
    "win",
    "metals",
    "olympics",
    "2024",
    "access",
    "data",
    "2028",
    "right",
    "access",
    "data",
    "past",
    "train",
    "machine",
    "learning",
    "model",
    "want",
    "respect",
    "order",
    "data",
    "make",
    "sure",
    "use",
    "future",
    "data",
    "predict",
    "past",
    "splitting",
    "training",
    "test",
    "set",
    "reason",
    "splitting",
    "want",
    "able",
    "train",
    "model",
    "training",
    "set",
    "use",
    "different",
    "set",
    "evaluate",
    "well",
    "model",
    "going",
    "test",
    "set",
    "want",
    "train",
    "model",
    "train",
    "set",
    "evaluate",
    "well",
    "train",
    "set",
    "like",
    "giving",
    "somebody",
    "answers",
    "test",
    "take",
    "test",
    "want",
    "model",
    "evaluated",
    "data",
    "seen",
    "trained",
    "okay",
    "look",
    "train",
    "dot",
    "shape",
    "see",
    "training",
    "set",
    "600",
    "rows",
    "test",
    "set",
    "400",
    "rows",
    "80",
    "20",
    "split",
    "data",
    "perfect",
    "close",
    "default",
    "split",
    "people",
    "usually",
    "default",
    "80",
    "20",
    "train",
    "test",
    "split",
    "give",
    "us",
    "good",
    "way",
    "train",
    "algorithm",
    "evaluate",
    "error",
    "okay",
    "let",
    "move",
    "actually",
    "training",
    "model",
    "earlier",
    "picked",
    "mean",
    "absolute",
    "error",
    "error",
    "metric",
    "going",
    "use",
    "metric",
    "evaluate",
    "model",
    "train",
    "train",
    "model",
    "import",
    "import",
    "linear",
    "regression",
    "linear",
    "regression",
    "class",
    "going",
    "enable",
    "us",
    "train",
    "make",
    "predictions",
    "linear",
    "model",
    "showed",
    "earlier",
    "linear",
    "model",
    "looks",
    "like",
    "draw",
    "line",
    "use",
    "line",
    "make",
    "predictions",
    "going",
    "initialize",
    "linear",
    "regression",
    "class",
    "reg",
    "equals",
    "linear",
    "regression",
    "using",
    "amazing",
    "python",
    "machine",
    "learning",
    "library",
    "lots",
    "algorithms",
    "similar",
    "interface",
    "could",
    "easily",
    "switch",
    "linear",
    "regression",
    "different",
    "model",
    "going",
    "define",
    "predictors",
    "columns",
    "going",
    "use",
    "predict",
    "target",
    "predictors",
    "going",
    "athletes",
    "previous",
    "medals",
    "going",
    "define",
    "target",
    "remember",
    "target",
    "metals",
    "column",
    "going",
    "train",
    "linear",
    "regression",
    "model",
    "use",
    "two",
    "columns",
    "predict",
    "column",
    "let",
    "go",
    "ahead",
    "run",
    "call",
    "fit",
    "method",
    "actually",
    "fit",
    "linear",
    "regression",
    "model",
    "call",
    "call",
    "fit",
    "method",
    "pass",
    "columns",
    "training",
    "data",
    "set",
    "want",
    "use",
    "predictors",
    "data",
    "going",
    "use",
    "train",
    "algorithm",
    "target",
    "data",
    "target",
    "going",
    "pass",
    "algorithm",
    "algorithm",
    "going",
    "trained",
    "training",
    "data",
    "set",
    "let",
    "go",
    "ahead",
    "run",
    "fit",
    "algorithm",
    "use",
    "actually",
    "make",
    "predictions",
    "type",
    "predictions",
    "equals",
    "test",
    "predictors",
    "notice",
    "calling",
    "predict",
    "method",
    "linear",
    "regression",
    "class",
    "passing",
    "predictors",
    "test",
    "passing",
    "actual",
    "values",
    "want",
    "algorithm",
    "create",
    "predictions",
    "without",
    "knowing",
    "actual",
    "answers",
    "going",
    "use",
    "generate",
    "predictions",
    "let",
    "take",
    "look",
    "predictions",
    "numpy",
    "array",
    "kind",
    "hard",
    "read",
    "may",
    "notice",
    "couple",
    "things",
    "one",
    "values",
    "rounded",
    "right",
    "really",
    "make",
    "sense",
    "given",
    "scenario",
    "scenario",
    "trying",
    "predict",
    "number",
    "medals",
    "country",
    "win",
    "countries",
    "win",
    "whole",
    "number",
    "medals",
    "ca",
    "win",
    "half",
    "medal",
    "second",
    "thing",
    "numbers",
    "negative",
    "countries",
    "get",
    "negative",
    "number",
    "metals",
    "going",
    "quick",
    "correction",
    "correct",
    "model",
    "prevent",
    "negatives",
    "round",
    "numbers",
    "easiest",
    "way",
    "manually",
    "correct",
    "couple",
    "things",
    "actually",
    "rescale",
    "predictions",
    "make",
    "sure",
    "make",
    "sense",
    "first",
    "thing",
    "going",
    "go",
    "ahead",
    "assign",
    "predictions",
    "column",
    "test",
    "data",
    "frame",
    "let",
    "us",
    "take",
    "look",
    "predictions",
    "easily",
    "see",
    "right",
    "say",
    "test",
    "predictions",
    "less",
    "zero",
    "predictions",
    "equals",
    "zero",
    "going",
    "going",
    "index",
    "test",
    "data",
    "frame",
    "going",
    "find",
    "rows",
    "predictions",
    "column",
    "less",
    "zero",
    "going",
    "replace",
    "predictions",
    "value",
    "row",
    "zero",
    "basically",
    "predictions",
    "less",
    "zero",
    "turned",
    "zero",
    "say",
    "test",
    "predictions",
    "equals",
    "test",
    "predictions",
    "dot",
    "round",
    "make",
    "data",
    "make",
    "sense",
    "round",
    "predictions",
    "nearest",
    "whole",
    "number",
    "take",
    "look",
    "tests",
    "predictions",
    "make",
    "lot",
    "sense",
    "zero",
    "minimum",
    "see",
    "values",
    "rounded",
    "nearest",
    "whole",
    "number",
    "go",
    "ahead",
    "look",
    "mean",
    "absolute",
    "error",
    "mean",
    "absolute",
    "error",
    "import",
    "mean",
    "absolute",
    "error",
    "write",
    "call",
    "function",
    "pass",
    "actual",
    "values",
    "number",
    "metals",
    "team",
    "actually",
    "test",
    "set",
    "pass",
    "predictions",
    "right",
    "get",
    "number",
    "back",
    "indicating",
    "mean",
    "absolute",
    "error",
    "actually",
    "mean",
    "means",
    "average",
    "within",
    "metals",
    "many",
    "metals",
    "team",
    "actually",
    "olympics",
    "whether",
    "good",
    "value",
    "let",
    "find",
    "going",
    "dig",
    "little",
    "bit",
    "deeper",
    "data",
    "set",
    "investigate",
    "actually",
    "good",
    "error",
    "first",
    "let",
    "take",
    "look",
    "metals",
    "column",
    "little",
    "depth",
    "using",
    "pandas",
    "describe",
    "method",
    "shows",
    "us",
    "minimum",
    "value",
    "column",
    "percentiles",
    "standard",
    "deviation",
    "usually",
    "nice",
    "quick",
    "sanity",
    "check",
    "make",
    "sure",
    "error",
    "standard",
    "deviation",
    "higher",
    "standard",
    "deviation",
    "usually",
    "something",
    "wrong",
    "either",
    "using",
    "predictors",
    "give",
    "information",
    "predict",
    "target",
    "mess",
    "something",
    "model",
    "case",
    "things",
    "look",
    "okay",
    "error",
    "far",
    "standard",
    "deviation",
    "look",
    "team",
    "team",
    "see",
    "predictions",
    "look",
    "different",
    "countries",
    "let",
    "look",
    "usa",
    "see",
    "2012",
    "us",
    "got",
    "248",
    "medals",
    "predicted",
    "285",
    "2016",
    "got",
    "264",
    "medals",
    "predicted",
    "bad",
    "right",
    "absolutely",
    "correct",
    "super",
    "far",
    "40",
    "medals",
    "percentage",
    "terms",
    "high",
    "percentage",
    "percentage",
    "high",
    "look",
    "another",
    "country",
    "like",
    "india",
    "enter",
    "many",
    "athletes",
    "olympics",
    "see",
    "india",
    "2012",
    "india",
    "got",
    "six",
    "medals",
    "predicted",
    "would",
    "get",
    "seven",
    "good",
    "right",
    "pretty",
    "close",
    "percentage",
    "terms",
    "2016",
    "india",
    "got",
    "two",
    "medals",
    "olympics",
    "predicted",
    "factor",
    "six",
    "mean",
    "absolute",
    "error",
    "different",
    "different",
    "countries",
    "percentage",
    "basis",
    "country",
    "got",
    "two",
    "medals",
    "average",
    "error",
    "four",
    "medals",
    "huge",
    "right",
    "factor",
    "two",
    "either",
    "way",
    "whereas",
    "country",
    "gets",
    "300",
    "medals",
    "earns",
    "300",
    "medals",
    "olympics",
    "average",
    "error",
    "four",
    "big",
    "deal",
    "right",
    "percentage",
    "terms",
    "pretty",
    "small",
    "look",
    "errors",
    "country",
    "see",
    "country",
    "country",
    "basis",
    "okay",
    "finding",
    "mean",
    "absolute",
    "error",
    "subtracting",
    "predictions",
    "actual",
    "metals",
    "taking",
    "absolute",
    "value",
    "saw",
    "formula",
    "earlier",
    "take",
    "look",
    "errors",
    "difference",
    "predicted",
    "number",
    "metals",
    "actual",
    "number",
    "metals",
    "use",
    "column",
    "test",
    "instead",
    "predictions",
    "variable",
    "one",
    "rounded",
    "nicely",
    "gives",
    "us",
    "difference",
    "many",
    "metals",
    "predicted",
    "many",
    "metals",
    "actually",
    "earned",
    "team",
    "group",
    "team",
    "create",
    "variable",
    "called",
    "error",
    "team",
    "say",
    "errors",
    "dot",
    "group",
    "test",
    "team",
    "group",
    "pandas",
    "method",
    "creates",
    "separate",
    "group",
    "team",
    "calculate",
    "mean",
    "create",
    "separate",
    "group",
    "team",
    "find",
    "mean",
    "error",
    "team",
    "look",
    "error",
    "team",
    "many",
    "metals",
    "average",
    "country",
    "look",
    "many",
    "metals",
    "country",
    "earned",
    "average",
    "thing",
    "metals",
    "column",
    "group",
    "team",
    "find",
    "mean",
    "tell",
    "us",
    "many",
    "metals",
    "country",
    "earned",
    "average",
    "olympics",
    "find",
    "ratio",
    "errors",
    "error",
    "team",
    "divided",
    "medals",
    "team",
    "call",
    "medals",
    "team",
    "let",
    "call",
    "error",
    "ratio",
    "okay",
    "take",
    "look",
    "error",
    "ratio",
    "see",
    "run",
    "properly",
    "see",
    "lot",
    "nan",
    "values",
    "lot",
    "teams",
    "average",
    "number",
    "metals",
    "earn",
    "zero",
    "dividing",
    "zero",
    "getting",
    "missing",
    "value",
    "need",
    "import",
    "say",
    "error",
    "ratio",
    "take",
    "values",
    "missing",
    "gives",
    "us",
    "102",
    "countries",
    "missing",
    "values",
    "predictions",
    "also",
    "get",
    "infinite",
    "values",
    "need",
    "figure",
    "remove",
    "well",
    "whatever",
    "reason",
    "country",
    "average",
    "ratio",
    "zero",
    "metals",
    "average",
    "error",
    "zero",
    "total",
    "number",
    "metals",
    "zero",
    "get",
    "nan",
    "division",
    "pandas",
    "instead",
    "error",
    "team",
    "one",
    "metals",
    "team",
    "zero",
    "get",
    "infinite",
    "value",
    "like",
    "case",
    "need",
    "clean",
    "infinite",
    "values",
    "well",
    "say",
    "error",
    "ratio",
    "equals",
    "error",
    "ratio",
    "np",
    "dot",
    "finite",
    "error",
    "ratio",
    "okay",
    "import",
    "numpy",
    "np",
    "right",
    "take",
    "look",
    "error",
    "ratio",
    "okay",
    "97",
    "values",
    "removed",
    "missing",
    "values",
    "infinite",
    "values",
    "gives",
    "us",
    "countries",
    "actual",
    "error",
    "ratio",
    "go",
    "ahead",
    "create",
    "another",
    "histogram",
    "tells",
    "us",
    "error",
    "ratio",
    "0",
    "let",
    "say",
    "means",
    "within",
    "50",
    "actual",
    "metal",
    "count",
    "cases",
    "error",
    "ratio",
    "2",
    "means",
    "predictions",
    "twice",
    "high",
    "predicted",
    "metals",
    "half",
    "predicted",
    "metals",
    "means",
    "pretty",
    "far",
    "true",
    "value",
    "want",
    "determine",
    "model",
    "works",
    "purposes",
    "look",
    "error",
    "ratios",
    "countries",
    "want",
    "make",
    "predictions",
    "countries",
    "error",
    "ratios",
    "pretty",
    "good",
    "right",
    "within",
    "12",
    "true",
    "metal",
    "count",
    "australia",
    "within",
    "36",
    "percent",
    "countries",
    "error",
    "higher",
    "right",
    "much",
    "true",
    "metal",
    "count",
    "whether",
    "model",
    "good",
    "depends",
    "well",
    "want",
    "well",
    "sometimes",
    "need",
    "go",
    "layer",
    "deeper",
    "get",
    "little",
    "bit",
    "mean",
    "absolute",
    "error",
    "error",
    "metric",
    "actually",
    "figure",
    "metric",
    "means",
    "breaks",
    "among",
    "specific",
    "groups",
    "data",
    "case",
    "wanted",
    "make",
    "predictions",
    "countries",
    "tend",
    "earn",
    "lot",
    "metals",
    "would",
    "pretty",
    "well",
    "see",
    "typing",
    "error",
    "values",
    "countries",
    "tend",
    "get",
    "lot",
    "medals",
    "olympics",
    "like",
    "france",
    "canada",
    "russia",
    "error",
    "pretty",
    "low",
    "whereas",
    "countries",
    "maybe",
    "much",
    "data",
    "send",
    "many",
    "athletes",
    "olympics",
    "error",
    "much",
    "higher",
    "countries",
    "send",
    "lot",
    "athletes",
    "olympics",
    "model",
    "performs",
    "pretty",
    "well",
    "lot",
    "could",
    "continue",
    "improve",
    "want",
    "want",
    "right",
    "point",
    "gone",
    "seven",
    "main",
    "steps",
    "building",
    "machine",
    "learning",
    "model",
    "talk",
    "wanted",
    "extend",
    "would",
    "couple",
    "things",
    "improve",
    "accuracy",
    "performance",
    "model",
    "add",
    "predictors",
    "model",
    "notice",
    "columns",
    "use",
    "would",
    "columns",
    "like",
    "events",
    "age",
    "height",
    "one",
    "option",
    "could",
    "try",
    "different",
    "machine",
    "learning",
    "models",
    "models",
    "like",
    "random",
    "forest",
    "neural",
    "network",
    "see",
    "perform",
    "better",
    "could",
    "go",
    "back",
    "original",
    "athlete",
    "level",
    "data",
    "actually",
    "try",
    "build",
    "different",
    "kind",
    "model",
    "data",
    "using",
    "data",
    "actually",
    "summarized",
    "different",
    "athlete",
    "level",
    "data",
    "set",
    "go",
    "ahead",
    "take",
    "look",
    "data",
    "set",
    "athlete",
    "events",
    "dot",
    "csv",
    "data",
    "set",
    "data",
    "set",
    "information",
    "individual",
    "athletes",
    "olympics",
    "row",
    "specific",
    "athlete",
    "could",
    "build",
    "model",
    "predict",
    "specific",
    "athlete",
    "win",
    "medal",
    "could",
    "add",
    "results",
    "model",
    "together",
    "figure",
    "many",
    "medals",
    "country",
    "win",
    "model",
    "could",
    "accurate",
    "top",
    "looking",
    "total",
    "number",
    "athletes",
    "country",
    "model",
    "could",
    "build",
    "specific",
    "athlete",
    "level",
    "model",
    "could",
    "also",
    "try",
    "reshape",
    "columns",
    "columns",
    "may",
    "correlations",
    "target",
    "metals",
    "could",
    "try",
    "reshaping",
    "columns",
    "using",
    "different",
    "mathematical",
    "transformations",
    "see",
    "creates",
    "linear",
    "correlation",
    "right",
    "final",
    "thing",
    "measure",
    "error",
    "predictably",
    "build",
    "system",
    "like",
    "back",
    "testing",
    "system",
    "talked",
    "videos",
    "another",
    "kind",
    "system",
    "measure",
    "error",
    "across",
    "whole",
    "data",
    "set",
    "20",
    "subset",
    "could",
    "also",
    "train",
    "model",
    "different",
    "types",
    "countries",
    "could",
    "train",
    "different",
    "models",
    "countries",
    "earn",
    "low",
    "numbers",
    "metals",
    "versus",
    "high",
    "numbers",
    "metals",
    "etc",
    "ideas",
    "could",
    "help",
    "build",
    "accurate",
    "model",
    "well",
    "hope",
    "good",
    "beginner",
    "introduction",
    "machine",
    "learning",
    "understand",
    "main",
    "steps",
    "building",
    "machine",
    "learning",
    "model",
    "thanks",
    "lot",
    "watching"
  ],
  "keywords": [
    "going",
    "build",
    "machine",
    "learning",
    "use",
    "using",
    "let",
    "get",
    "need",
    "step",
    "one",
    "data",
    "case",
    "make",
    "predict",
    "many",
    "metals",
    "country",
    "win",
    "olympics",
    "find",
    "summer",
    "set",
    "rows",
    "row",
    "single",
    "olympic",
    "see",
    "first",
    "team",
    "usa",
    "also",
    "go",
    "columns",
    "column",
    "indicates",
    "year",
    "athletes",
    "medals",
    "previous",
    "would",
    "try",
    "given",
    "predictions",
    "lot",
    "target",
    "trying",
    "predictors",
    "missing",
    "values",
    "look",
    "teams",
    "actually",
    "value",
    "thing",
    "countries",
    "error",
    "metric",
    "evaluate",
    "model",
    "create",
    "earned",
    "different",
    "actual",
    "way",
    "good",
    "called",
    "mean",
    "absolute",
    "formula",
    "left",
    "means",
    "little",
    "right",
    "like",
    "ahead",
    "take",
    "errors",
    "number",
    "us",
    "algorithm",
    "split",
    "want",
    "train",
    "another",
    "test",
    "well",
    "trained",
    "training",
    "linear",
    "regression",
    "equation",
    "equals",
    "example",
    "last",
    "may",
    "line",
    "got",
    "six",
    "bit",
    "two",
    "okay",
    "import",
    "pandas",
    "earlier",
    "average",
    "age",
    "correlation",
    "sense",
    "zero",
    "high",
    "say",
    "fit",
    "true",
    "relationship",
    "athlete",
    "low",
    "could",
    "dot",
    "call",
    "method",
    "predicted",
    "percentage",
    "pretty",
    "group",
    "ratio"
  ]
}