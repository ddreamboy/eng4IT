{
  "text": "pie torch an open source deep learning\nframework used to build some of the\nworld's most famous artificial\nintelligence products it was created at\nThe Meta AI research lab in 2016 but is\nactually derived from the Lua based\ntorch library that dates back to 2002.\nfundamentally it's a library for\nprogramming with tensors which are\nbasically just multi-dimensional arrays\nthat represent data and parameters in\ndeep neural networks sounds complicated\nbut its focused on usability will have\nyou training machine learning models\nwith just a few lines of python in\naddition it facilitates high performance\nparallel Computing on a GPU thanks to\nnvidia's Cuda platform developers love\nprototyping with it because it supports\na dynamic computational graph allowing\nmodels to be optimized at runtime it\ndoes this by constructing a directed\nacyclic graph consisting of functions\nthat keeps track of all the executed\noperations on the tensors allowing you\nto change the shape size and operations\nafter every iteration if needed pytorch\nhas been used to train models for\ncomputer vision AI like Tesla autopilot\nimage generators like stable diffusion\nand speech recognition models like open\nAI whisper just to name a few to get\nstarted install Pi torque and optionally\nCuda if you want to accelerate Computing\non your GPU now import it into a python\nfile or notebook like I mentioned a\ntensor is similar to a multi-dimensional\narray create a 2d array or Matrix with\npython then use torch to convert it into\na tensor now we can run all kinds of\ncomputations on it like we might convert\nall these integers into random floating\npoints we can also perform linear\nalgebra by taking multiple tensors and\nmultiplying them together what you came\nhere to do though is build a deep neural\nnetwork like an image classifier to\nhandle that we can define a new class\nthat inherits from the neural network\nmodule class inside the Constructor we\ncan build it out layer by layer the\nflattened layer will take a\nmulti-dimensional input like an image\nand convert it to one dimension from\nthere sequential is used to create a\ncontainer of layers that the data will\nflow through each layer has multiple\nnodes where each node is like its own\nmini statistical model as each data\npoint flows through it it'll try to\nguess the output and gradually update a\nmapping of weights to determine in the\nimportance of a given variable linear is\na fully connected layer that takes the\nflat and 28 by 28 image and transforms\nit to an output of 512. this layer is\nfollowed by a non-linear activation\nfunction when activated it means that\nfeature might be important and outputs\nthe node otherwise it just outputs zero\nand finally we finish with a fully\nconnected layer that outputs the 10\nlabels the model is trying to predict\nwith these pieces in place that next\nstep is to define a forward method that\ndescribes the flow of data and now\ninstantiate the model to a GPU and pass\nit some input data this will\nautomatically call its forward method\nfor training and prediction\ncongratulations you just built a neural\nnetwork this has been pytorch in 100\nseconds thanks for watching and I will\nsee you in the next one\n",
  "words": [
    "pie",
    "torch",
    "open",
    "source",
    "deep",
    "learning",
    "framework",
    "used",
    "build",
    "world",
    "famous",
    "artificial",
    "intelligence",
    "products",
    "created",
    "meta",
    "ai",
    "research",
    "lab",
    "2016",
    "actually",
    "derived",
    "lua",
    "based",
    "torch",
    "library",
    "dates",
    "back",
    "fundamentally",
    "library",
    "programming",
    "tensors",
    "basically",
    "arrays",
    "represent",
    "data",
    "parameters",
    "deep",
    "neural",
    "networks",
    "sounds",
    "complicated",
    "focused",
    "usability",
    "training",
    "machine",
    "learning",
    "models",
    "lines",
    "python",
    "addition",
    "facilitates",
    "high",
    "performance",
    "parallel",
    "computing",
    "gpu",
    "thanks",
    "nvidia",
    "cuda",
    "platform",
    "developers",
    "love",
    "prototyping",
    "supports",
    "dynamic",
    "computational",
    "graph",
    "allowing",
    "models",
    "optimized",
    "runtime",
    "constructing",
    "directed",
    "acyclic",
    "graph",
    "consisting",
    "functions",
    "keeps",
    "track",
    "executed",
    "operations",
    "tensors",
    "allowing",
    "change",
    "shape",
    "size",
    "operations",
    "every",
    "iteration",
    "needed",
    "pytorch",
    "used",
    "train",
    "models",
    "computer",
    "vision",
    "ai",
    "like",
    "tesla",
    "autopilot",
    "image",
    "generators",
    "like",
    "stable",
    "diffusion",
    "speech",
    "recognition",
    "models",
    "like",
    "open",
    "ai",
    "whisper",
    "name",
    "get",
    "started",
    "install",
    "pi",
    "torque",
    "optionally",
    "cuda",
    "want",
    "accelerate",
    "computing",
    "gpu",
    "import",
    "python",
    "file",
    "notebook",
    "like",
    "mentioned",
    "tensor",
    "similar",
    "array",
    "create",
    "2d",
    "array",
    "matrix",
    "python",
    "use",
    "torch",
    "convert",
    "tensor",
    "run",
    "kinds",
    "computations",
    "like",
    "might",
    "convert",
    "integers",
    "random",
    "floating",
    "points",
    "also",
    "perform",
    "linear",
    "algebra",
    "taking",
    "multiple",
    "tensors",
    "multiplying",
    "together",
    "came",
    "though",
    "build",
    "deep",
    "neural",
    "network",
    "like",
    "image",
    "classifier",
    "handle",
    "define",
    "new",
    "class",
    "inherits",
    "neural",
    "network",
    "module",
    "class",
    "inside",
    "constructor",
    "build",
    "layer",
    "layer",
    "flattened",
    "layer",
    "take",
    "input",
    "like",
    "image",
    "convert",
    "one",
    "dimension",
    "sequential",
    "used",
    "create",
    "container",
    "layers",
    "data",
    "flow",
    "layer",
    "multiple",
    "nodes",
    "node",
    "like",
    "mini",
    "statistical",
    "model",
    "data",
    "point",
    "flows",
    "try",
    "guess",
    "output",
    "gradually",
    "update",
    "mapping",
    "weights",
    "determine",
    "importance",
    "given",
    "variable",
    "linear",
    "fully",
    "connected",
    "layer",
    "takes",
    "flat",
    "28",
    "28",
    "image",
    "transforms",
    "output",
    "layer",
    "followed",
    "activation",
    "function",
    "activated",
    "means",
    "feature",
    "might",
    "important",
    "outputs",
    "node",
    "otherwise",
    "outputs",
    "zero",
    "finally",
    "finish",
    "fully",
    "connected",
    "layer",
    "outputs",
    "10",
    "labels",
    "model",
    "trying",
    "predict",
    "pieces",
    "place",
    "next",
    "step",
    "define",
    "forward",
    "method",
    "describes",
    "flow",
    "data",
    "instantiate",
    "model",
    "gpu",
    "pass",
    "input",
    "data",
    "automatically",
    "call",
    "forward",
    "method",
    "training",
    "prediction",
    "congratulations",
    "built",
    "neural",
    "network",
    "pytorch",
    "100",
    "seconds",
    "thanks",
    "watching",
    "see",
    "next",
    "one"
  ],
  "keywords": [
    "torch",
    "open",
    "deep",
    "learning",
    "used",
    "build",
    "ai",
    "library",
    "tensors",
    "data",
    "neural",
    "training",
    "models",
    "python",
    "computing",
    "gpu",
    "thanks",
    "cuda",
    "graph",
    "allowing",
    "operations",
    "pytorch",
    "like",
    "image",
    "tensor",
    "array",
    "create",
    "convert",
    "might",
    "linear",
    "multiple",
    "network",
    "define",
    "class",
    "layer",
    "input",
    "one",
    "flow",
    "node",
    "model",
    "output",
    "fully",
    "connected",
    "28",
    "outputs",
    "next",
    "forward",
    "method"
  ]
}