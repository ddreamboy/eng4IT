{
  "text": "hey elon you need some help uh landing\nthe starship\nyeah well uh check this out\ni was very sad to see that\nworth a try what's happening guys my\nname is nicholas renate and in this\nvideo\nwe're going to be going through\nreinforcement learning for beginners\nand who knows along the way we might\neven help elon out let's take a deeper\nlook at what we'll be going through\nso in this video we're going to be\ncovering three key things so first up\nwe're going to start out by\ninstalling the stable baselines package\nso this is going to be\na package that makes it a whole heap\neasier\nto get started with reinforcement\nlearning then what we're going to do is\nwe're going to set up the open ai gym\nluna lander environment so this allows\nus to build a model that allows us to\nactually try to land a spaceship on the\nsurface of the moon\nso we're actually going to try to build\nan ai model and specifically a\nreinforcement learning model\nthat's able to land that spaceship\nsuccessfully then what we're going to do\nis once we've gone and built that model\nand trained it up we're going to test it\nout and run it and you'll be able to see\nhow our ai performs in real time\nlet's take a look as to how this is all\ngoing to fit together so first up what\nwe're going to be doing is we're going\nto be setting up our lunar lander\nenvironment and you can see on the slide\nthis is a little spaceship that we're\ngoing to be trying to land between the\nflags\nso the main goal is that we'll have our\nlanders sort of pop up onto the screen\nand the goal is to direct\nthe jets on that particular lunar lander\nso that we're able to land it\nsuccessfully within those flags so if\nour ai and our reinforcement learning\nmodel\nis able to do that then we've completed\nthe task successfully\nso in order to do that we're going to be\ntraining a reinforcement learning model\nfrom the\nstable baselines package and we'll go\nthrough setting all that up\nonce we've trained it then we'll unleash\nour reinforcement learning model on the\nlunar lander environment so hopefully we\ncan land it between those flags\nready to do it let's get to it alrighty\nso in order to kick off our\nreinforcement learning for beginners\ntutorial there's going to be\nfour key things that we need to do so\nfirst up what we're going to need to do\nis\ninstall and import our dependencies then\nwhat we're going to do is test out our\nenvironment so specifically we're going\nto be passing through random actions to\nour environment there so if you've seen\nthe reinforcement learning crash course\nvideo that i did again\nlink will be in the description below\nyou'll see how we wrote this code but as\nalways\nall the code that we write in this\nparticular video is going to be\navailable\nin the description below via my github\naccount\nso once we've tested out our environment\nwhat we're then going to do is build and\ntrain our model and this is going to be\nwhere we use some of the algorithms from\nstable baselines\nto actually go on ahead and train a\nreinforcement learning agent\nthen last but not least we'll save and\ntest it out so we'll actually be able to\nsee our lunar land up model\nactually working in real time now on\nthat note so our core dependencies\nare going to be stable baseline so\nstable baselines is just\na ridiculously useful reinforcement\nlearning library that has some really\nreally good algorithms\navailable in it so if you actually\nscroll on down go to\nstable dash baselines.read\nyou'll be able to access this\ndocumentation but again this link will\nbe in the description\nbelow you'll see that we've got a whole\nbunch of rl algorithms that we can work\non so we're going to be working with\nacer but ppo2 i've had really good\nresults with that and a2c\nas well the other dependency that we're\ngoing to be working with\nis open ai gym so this is obviously one\nof the most\npopular libraries when it comes to\nreinforcement learning environments\nand the environment that we're going to\nbe working with is luna lander so you\ncan see that we've got this little\nspaceship that's trying to land\njust in general but also in between\nthese flags so if you land within the\nflags then you get\nmore points but ideally the goal is to\ntake this little purple spaceship that\nyou can see here\nand get it to land successfully without\nbreaking its little legs so what we're\ngoing to do\nis we're going to be trying to build our\nreinforcement learning agent to be able\nto solve that problem\nand we're going to approach this in a\nreasonably straightforward manner so\nwe're going to leverage stable baselines\nto help us to do that\nall righty without further ado let's\nfirst go ahead and\ninstall and import our dependencies so\ni'm going to write the line of code and\nthen we'll take a step back and we'll\ntake a look at what we've got\nalrighty so before we go ahead and run\nthat let's take a look at the code that\nwe've actually written so first up we've\ngot exclamation mark let's just make\nsure this is zoomed in perfect cool\nso we've got exclamation mark pip\ninstall\ntensorflow equals equals 1.15.0\nthis is a key thing to note so if you're\nworking with stable baselines you need\nto be using\na tensorflow version which is before\ntensorflow 2.0 so ideally\nwhat you want to be doing is using 1.15\nso what we've got here in this line is\nwe're going to install tensorflow 1.15.0\nand tensorflow gpu 1.15 and to do that\nwe've written tensorflow\nequals equals 1.15.0 tensorflow\ngpu equals equals 1.15.0 so this pip\ninstall line is going to go on ahead and\ninstall both of those\nand this really just covers all bases\nwhether or not you're using gpu or a\nnon-gpu machine\nthen the next package that we're\ninstalling is stable underscore baseline\nso this is going to install\nall of our algorithms that we saw on\nstable baselines\nthen the next thing that we're\ninstalling is gym so this is open ai gym\nand we're also installing box 2d dash pi\nso this is a dependency that you're\ngoing to need if you're using\nthe lunar lander environment so we're\njust going to install it just to make\nsure our lives\nremain easy as we're going through this\nand then i'm also passing\nuser so this is going to use the user\nflag to install it for me as a user\njust avoids any administrator\ndependencies if that happens to\noccur on your machine so in this case\nwe're going to hit shift enter and\nrun that cell and that's going to go\nahead and install our dependencies\nnow you can see that that's run pretty\nquickly and that's because i've got\nalready got it installed so we can go\non ahead to our next step which is\nimporting these dependencies so let's go\nahead and do that\nalrighty so those are our dependencies\nnow imported so what we've done is we've\nwritten four lines of code there\nand specifically what we've gone and\nimported is open ai gym\nand then a whole bunch of different\ndependencies from stable baselines\nso our first line of code that we've\nwritten is import gym\nso this is going to import open air gym\nand it's going to allow us to create a\nlunar lander\nenvironment that we can then apply our\nreinforcement learning models to\nthen what we've gone and written is from\nstable underscore baselines\nimport acer so this is importing the\nacer policy or asap\nagent that's going to allow us to train\nour reinforcement learning agent\nso think about this as a algorithm so\nsimilar if you've done any machine\nlearning before think of this as a\nspecific machine learning type of\nalgorithm so in this case we could also\nsub\nout and we could use something like\nuh let's take a look we could do\nsomething like dqn\nppo ddpg so think of them as different\nalgorithms in this case we're going to\nbe using acer but you could try\ndifferent ones if you wanted to then the\nnext line that we've written is from\nstable underscore baselines dot common\ndot vect underscore env import\ndummy vec env so this is basically a\nwrapper that goes around our open ai gym\nenvironment\nthat allows us to create a dummy\nvectorized environment\nfor stable baselines so when we're\nworking with certain stable baselines\nalgorithms it's expecting that our open\nai gym\nis vectorized now in this case we're not\ngoing to explicitly\nvectorize our lunar lander environment\nbut instead we're going to wrap it\ninside of our dummy vec\nenvironment you'll see that once we go\nto set that up\nand then the last dependency that we've\nimported is evaluate policy so to do\nthat we've written from\nstable underscore baselines dot common\ndot evaluation\nimport evaluate underscore policy and\nthe evaluate policy method just makes it\nreally easy to test out our model and\nsee how it's performing\nso we'll use that right in step three\nwhere we go on ahead and test out our\nmodel\nall right so those are our dependencies\ndone now what we're going to do is we're\ngoing to set up a variable that's going\nto hold the name of our environment\nand in this case our environment is\ngoing to be named lunalander v2 so we\ncan actually just copy that\nand we're going to create a new variable\ncalled environment name\ncreate an empty string and then paste\nthat in so\nthis basically is just going to save us\ntime from writing luna lander dash v2\neach time we want to create an\ninstance of our environment now that's\npretty much step zero done so we've gone\nand\ninstalled our dependencies we've also\ngone and imported a whole bunch of stuff\nand we've created our environment\nvariable\nnow the next step that we need to go\nthrough is to test out our environment\nand i've said random environment but\nreally it is a standard environment\nwhat we're actually doing though is\nwe're actually just going to go and take\na bunch of random steps inside of that\nenvironment\nbecause if you take a look you can see\nthat our lunarland is taking random\nsteps here in this particular\nvideo on the open ai gym web page\nwe're going to try to replicate that\njust to see what our environment looks\nlike and how it actually operates\nso what we can do in order to do that is\njust run this cell\nwhich is going to use jim dot make and\nthen it's going to pass through our\nlunar lander string here\nto be able to go and head and create our\nenvironment so if we run that cell\nthat's created our environment now what\nwe can actually do is we can actually go\non ahead\nand run this block of code so what it's\ngoing to do is\nit's going to attempt to land our lunar\nlander three times so we've gone and set\nup\nepisodes equals three and this basically\nmeans that we're going to try it three\ntimes to try to land it successfully\nwe're initially going to reset our\nenvironment set done and score to\nfalse and zero respectively so this is\njust resetting variables\nand then what it's going to try to do is\nactually go on ahead and land it and\nspecifically\nwe're only just going to take random\nsteps so there's no logic\nor reasoning behind how it's going to\nland it's just going to take random\nsteps so you see that it won't actually\nperform that well\nwhen we go and run this code now ideally\nwhat should happen is once we finish\ntraining our model and we go and apply\nit in a similar way\nwe'll actually be able to land our\nlander more appropriately when it comes\nto doing that\nso let's go ahead and run this and see\nhow it actually looks like so i'm going\nto set it\nepisodes back to 10 so this is going to\ngive us a little time\nto actually see the pop-up um appear at\nthe bottom of our screen\nso when you run this you'll get a little\npython pop-up and this is actually going\nto be the screen that we're able to see\nour environment in so if i run this you\ncan see we've got that little pop-up\nyou can see our lunar lander right now\nit's nowhere near landing so\nif so ideally our goal is to either land\nit anywhere\nideally we want to land it between these\nflags and our model will learn to do\nthat\nbut right now it's not even getting\nclose right it's crashing each and every\nsingle time\nand our score isn't getting anywhere\ninto the positive numbers\nso those are our goals right so we want\nto be able to land our lander\nideally get it between the two flags and\nthat should mean that our score\nis no longer in the negatives but we're\nnow in the positive values\nso now that that's done and we've tested\nout our code that's step\none done or this particular step done\nthe next thing that we want to go ahead\nand do is actually build and train our\nmodel\nso let's go ahead and write that code\nthen we'll take a step back and see what\nwe've written\nall righty so we've gone and written\nthree lines of code there and the nice\nthing about stable bass lines is that it\nmakes it reasonably simple to get up and\nrunning\nso this particular step you could really\nskip this testing out of your\nenvironment but it's a good idea to\nunderstand how the environment actually\noperates\nthese three lines here actually create\nour environment set up our model\nand really if we wanted to there's one\nadditional line which we'll do in a sec\nwhich is going to go on ahead and kick\noff our training\nto be able to train our reinforcement\nlearning algorithm so let's take a quick\nstep\nback and see what we've written here so\nfirst up we've written env\nequals gym dot make and then we'll pass\nyou our environment name which we had up\nhere\nthen as i said what we did is we're\ngoing to wrap our environment inside of\nthis dummy vec\nenvironment and our dummy vec\nenvironment is actually\nexpecting an environment generator as\nits input so what we've done rather than\nwriting a full-blown function\nwe've just wrote lambda and then we're\ncreating a new environment each time we\nloop through that\nso ideally what you're going to get out\nof this is a number of environments\ngenerated in this case it's just going\nto be one because we're only passing it\nthrough once\nand then we're effectively going to\nreset our environment variable equal to\ne\nand v then what we're doing is we're\ncreating a new instance\nof our asa algorithm and remember this\nis the algorithm that we imported up\nhere\nand if you wanted to you could swap this\nout for any one of these algorithms that\nyou see there\nso again play around with them you're\ngoing to probably get differing results\nand differing\ntraining times depending on which\nalgorithm you use but in this case we're\ngoing to be using acer which you can see\nhere\nthen to that algorithm we've gone and\npassed three key\nvariables so specifically two arguments\nand one keyword argument\nso to do that we've written model equals\nacer\nand this is our algorithm that we\nbrought in up here\nand then we're passing through the\npolicy so think of this as the neural\nnetwork\nthat sits behind this algorithm in this\ncase we're using a\nmulti-layer perceptron policy i believe\nthat's what it stands for\nbut you could just as easily use a cnn\npolicy which is going to work with\nimage-based environments you could also\nuse an lstm based policy which is going\nto give you a recurrent neural network\nwhich is particularly good if you've got\nsort of time series based environments\nor environments that rely\non previous states to that we're then\nalso passing our environment which we\ncreated over here\nand we're setting verbose equal to one\nbecause this is going to give us a whole\nbunch of additional information\nwhen we kick off our training run so\nbasically in a nutshell\ncreating our environment wrapping it\ninside our dummy vec environment\nthen setting up our model initially so\nthe next thing that we need to do is\nactually go on ahead and\nkick off our training so let's go ahead\nand write that line of code\nand we'll see what it looks like\nso that's really the last line of code\nthat we need to write to be able to\nbuild\nand train a model so to do that what\nwe've written is model\ndot learn so this is akin to a fit\nmethod and what it's effectively going\nto go on ahead and do\nis kick off that training run now to\nthat we've passed through\none keyword argument which is total\nunderscore time\nsteps and then to that we've passed\nthrough a hundred thousand\nso this basically means that our\nreinforcement learning model is going to\ngo on ahead and try to train\nfor a hundred thousand different steps\nusing our lunar lander model\nso what we can now go ahead and do is\nrun that cell and it's going to kick off\nour training\nrun now if you wanted to you could train\nfor a shorter amount of time or train\nfor a longer amount of time\nbut ideally what we want out of our\nmodel is as high possible\nexplained variance which we'll see in a\nsec and as high a possible\nmean episode reward so let's go ahead\nand kick this off\ni'll show you what the results look like\ninitially and then we'll let it run and\nwe'll be right back\nall right so that's our model kicked off\nso you can see here that as\nour model runs we get these little bits\nof information and this is because we\nset verbose equals to one up here\nnow as i was saying what we want out of\nthis is as higher possible explained\nvariance\nand as high of possible mean episode\nreward so right now\ni explained variance is not that great\nso we've got\nin the zero 0.000 399\nand mean episode reward is currently\nzero so ideally we want our mean episode\nreward to be in the positive numbers and\nnot negatives\nand explain variance to be as high as\npossible so ideally\nuh the closer to the number one we get\nthe better it's going to be\nso let's go on ahead and let that run\nand we'll be right back\nalrighty so in the end what i ended up\ndoing is pausing the training a little\nbit earlier as we're already getting\nreasonably good performance so ideally\nwhat you want to do\nis once your model starts performing\nreasonably well you don't want to\nover train it because sometimes what\nthat will mean is that your model starts\nperforming\nmore poorly and starts to overfit the\nparticular environment\nso in the end what we did is we got our\nexplained variance to\n0.831 which is pretty good and we also\ngot our main\nepisode reward to a 122.\nso this should ideally mean that we're\nable to successfully\nland our lunar rover pretty accurately\nso\nthe next thing that we actually want to\ngo and do now that we've gone and\ntrained our model\nis we actually want to go on ahead and\ntest it out and this is where the\nevaluate policy method comes in so what\nwe're now going to go ahead and do is go\non ahead and test out our\nevaluate policy method so the other\nthing also to note when you're running\nmodel.learn is you can also\nrun a callback so this will allow you to\ngo on ahead and automatically pause your\ntraining\nonce you sort of get to the optimal\nlevel if you'd like to see a video on\nthat by all means\nleave a mention in the comments below\nand i'll get to it\nso the next thing that we're going to do\nis now run evaluate policies so let's go\nahead and write that loan\ncode and see how model is actually\nperforming\nokay so before we run that let's take a\nlook at our code as usual so what we've\ngone and written is\nevaluate underscore policies so this is\nusing\nour evaluate policy method that we\nbrought in up here in our imports\nand then to that we're passing through\ntwo arguments and\ntrue keyword arguments so specifically\nwe're passing through our model\nour environment which we defined earlier\nwe're then defining\nhow many evaluation episodes we want to\nrun through so that this is how many\nchances\nwe want to give our model to be able to\nprove its performance in this case we're\nsetting that to 10\nand we're specifying render equals true\nbecause we want to visualize our\nperformance and our results\nso what we should effectively see is our\nai or our reinforcement learning model\ntrying to land our lunar lander and then\nwe're running env.close to be able to\nclose it off so let's go ahead and run\nthis line of code and let's see our\nperformance\nso again we should get the little pop-up\ndown below and you can see our model is\nattempting to land outlander\nthey go so it's landed successfully and\nyou can see it's now\nmore accurately adjusting each one of\nthose boosters to be able to go on ahead\nand land our lander between the flag so\nthat's two successful landings now so\nas you can see it's performing pretty\nwell even though we didn't hit the\nelusive 0.99 explained variance and\nridiculously high accuracy or\nridiculously high\nmean episode reward you can see that\nwe're still getting there in this case\nit's trying to push the booster\nto try to get it between the flags but\nin this case it's performing a lot\nbetter\nonce it's adjusting while it's still in\nthe sky so you can see this one's\nobviously performing really well it's\ngetting quite close\ncome on yes all right elon come on you\ngot to come and hire us now\nokay\npretty cool right so performing\nreasonably well\nnot quite falcon heavy but we're getting\nthere right\nand so again we've done this on luna\nlander but you could try this out\nobviously we had a last minute crash\nlanding there but you can see that\nobviously our reinforcement learning\nmodel was performing a lot better than\nwhat we had\nwhen we were just going and running our\nrandom environment up here\nso now that that's all done the next\nthing that we want to do is go on ahead\nand\nsave our model so again this is all part\nof a good data science workflow you want\nto be able to\nreload your model and try it out\nparticularly if you wanted to go and\ndeploy this into production later on\nso let's go ahead and save our model so\nto do that we can just write model dot\nsave and then in this case just name it\nwhatever you'd like so we'll call it\nacer\nunderscore model if we now go into the\nsame folder as our jupyter notebook you\ncan see that it has in fact saved so\nthis is our acer model here\nwe can now delete our model if we try\nrunning our model you can see it's not\ngoing to work\nand then we can reload it so again this\nis all to do with being able to reuse\nyour model later on\nso to do that we can just type in\nmodel.load\nand then copy this\nand we also need to pass through our\nenvironment when we're reloading it\nsorry acer.load so again it's our\nalgorithm that we're going to use\ndot load and then the name of the model\nthat we say so to be able to save it\nit's model.save\nto reload name of the algorithm.load so\nin this case\nthis should reload our model which again\nwe've now reloaded we'll just throw it\ninside of a variable called model\nequals and now we can actually start\ntesting this out again\nso rather than using evaluate policy\nthis time i'm going to write out a\nlittle bit of a flow which sort of\nclosely mimics this\nand really ideally mimics how you might\nput this into production particularly if\nyou got sensors on a particular\nenvironment\nso let's go ahead and write this and see\nhow a model performs there\nokay so that's our last bit of code\ndone now before we go ahead and run that\nlet's take a look at what we've written\nso first up what we've gone and done is\nwe've gone and reset our environment so\nwhenever we're going out and testing our\nnew code or\ntesting out our rl model we want to\nreset our environment back to its base\nstate\nand this is exactly what this line is\ndoing here then what we're doing is out\nof that base state was capturing those\nobservations\ninside of a variable called obs and so\nthe full line is\nobs equals env dot reset\nand then we're going through and kicking\noff a loop so this basically just going\nto keep\nrunning different instances of our lunar\nlander environment\nmultiple times so we'll actually have to\nforce stop this if we want it to stop\nrunning\nso written while true and then with a\ncolon and then what we're doing\nis we're using a model that we've\ntrained up here and we're using the\npredict method\nto go and generate an action based on\nthe observations\nfrom our environment space so think\nabout this as\nour model receiving the inputs from our\nlunar lander environment\nthen trying to predict what the best\naction should be\nto be able to land our rover\nsuccessfully and out of that what we're\ngoing to get\nis the most appropriate type of action\nand the current state of our model so\nwhat we're then going to go ahead and do\nis apply that action to our environment\nwhich you can see there\nbased on env dot step so we're going to\nour environment we're taking a step\nusing the action that our model has just\npredicted and out of that we're going to\nget new observations\nrewards whether or not our particular\nepisode is done\nand any additional info and then we're\ngoing to render the current frame so\nthis will allow us to see\nhow model is performing in real time so\nlet's go ahead and run this and then\neventually we'll have to kill it off to\nstop it running and we can then close it\nso\nagain it should look pretty similar to\nour evaluate policy except this time\nit's just going to keep running so let's\nkick it off\nand again to open up our window and it's\ngoing to try to land our lander\nand again working pretty successfully\nyou can see that it's landed and it's\njust going to restart so this is just a\nslightly different way\nto go on ahead and kick off your code\nagain that's another successful landing\nagain it's looking like it's performing\nreasonably well now\nall right and we'll stop that there and\nif we wanted to you can see that our\nlittle icon is still open so to close\nthat we can just type in env.close\nand that will close the little pop up\nthere so that you can then go on ahead\nand kick off\nevaluate policy or that whole loop all\nover again\nand that about wraps it up so what we've\nnow gone and done is we've gone and\ninstalled and imported our dependency\nwe've gone and tested out our random\nenvironment\nand again all this code is going to be\navailable inside of the description\nbelow just check that out you'll be able\nto grab it\nso on step two we built and trained our\nmodel and really these four core lines\nwere the core components to actually\ngoing ahead\nbuild our environment and train our\nreinforcement learning model\nwe then went and saved and tested it out\nand we tested it using\nthe evaluate policy method and we also\nwrote our own custom code to go on ahead\nand test it out\nand that about wraps it up thanks so\nmuch for tuning in guys hopefully you\nfound this video useful if you did be\nsure to give it a thumbs up hit\nsubscribe and tick that bell for more\nawesome reinforcement learning content\nand let me know how you went about\nbuilding your own reinforcement learning\nmodel\nthanks again for tuning in peace\n",
  "words": [
    "hey",
    "elon",
    "need",
    "help",
    "uh",
    "landing",
    "starship",
    "yeah",
    "well",
    "uh",
    "check",
    "sad",
    "see",
    "worth",
    "try",
    "happening",
    "guys",
    "name",
    "nicholas",
    "renate",
    "video",
    "going",
    "going",
    "reinforcement",
    "learning",
    "beginners",
    "knows",
    "along",
    "way",
    "might",
    "even",
    "help",
    "elon",
    "let",
    "take",
    "deeper",
    "look",
    "going",
    "video",
    "going",
    "covering",
    "three",
    "key",
    "things",
    "first",
    "going",
    "start",
    "installing",
    "stable",
    "baselines",
    "package",
    "going",
    "package",
    "makes",
    "whole",
    "heap",
    "easier",
    "get",
    "started",
    "reinforcement",
    "learning",
    "going",
    "going",
    "set",
    "open",
    "ai",
    "gym",
    "luna",
    "lander",
    "environment",
    "allows",
    "us",
    "build",
    "model",
    "allows",
    "us",
    "actually",
    "try",
    "land",
    "spaceship",
    "surface",
    "moon",
    "actually",
    "going",
    "try",
    "build",
    "ai",
    "model",
    "specifically",
    "reinforcement",
    "learning",
    "model",
    "able",
    "land",
    "spaceship",
    "successfully",
    "going",
    "gone",
    "built",
    "model",
    "trained",
    "going",
    "test",
    "run",
    "able",
    "see",
    "ai",
    "performs",
    "real",
    "time",
    "let",
    "take",
    "look",
    "going",
    "fit",
    "together",
    "first",
    "going",
    "going",
    "setting",
    "lunar",
    "lander",
    "environment",
    "see",
    "slide",
    "little",
    "spaceship",
    "going",
    "trying",
    "land",
    "flags",
    "main",
    "goal",
    "landers",
    "sort",
    "pop",
    "onto",
    "screen",
    "goal",
    "direct",
    "jets",
    "particular",
    "lunar",
    "lander",
    "able",
    "land",
    "successfully",
    "within",
    "flags",
    "ai",
    "reinforcement",
    "learning",
    "model",
    "able",
    "completed",
    "task",
    "successfully",
    "order",
    "going",
    "training",
    "reinforcement",
    "learning",
    "model",
    "stable",
    "baselines",
    "package",
    "go",
    "setting",
    "trained",
    "unleash",
    "reinforcement",
    "learning",
    "model",
    "lunar",
    "lander",
    "environment",
    "hopefully",
    "land",
    "flags",
    "ready",
    "let",
    "get",
    "alrighty",
    "order",
    "kick",
    "reinforcement",
    "learning",
    "beginners",
    "tutorial",
    "going",
    "four",
    "key",
    "things",
    "need",
    "first",
    "going",
    "need",
    "install",
    "import",
    "dependencies",
    "going",
    "test",
    "environment",
    "specifically",
    "going",
    "passing",
    "random",
    "actions",
    "environment",
    "seen",
    "reinforcement",
    "learning",
    "crash",
    "course",
    "video",
    "link",
    "description",
    "see",
    "wrote",
    "code",
    "always",
    "code",
    "write",
    "particular",
    "video",
    "going",
    "available",
    "description",
    "via",
    "github",
    "account",
    "tested",
    "environment",
    "going",
    "build",
    "train",
    "model",
    "going",
    "use",
    "algorithms",
    "stable",
    "baselines",
    "actually",
    "go",
    "ahead",
    "train",
    "reinforcement",
    "learning",
    "agent",
    "last",
    "least",
    "save",
    "test",
    "actually",
    "able",
    "see",
    "lunar",
    "land",
    "model",
    "actually",
    "working",
    "real",
    "time",
    "note",
    "core",
    "dependencies",
    "going",
    "stable",
    "baseline",
    "stable",
    "baselines",
    "ridiculously",
    "useful",
    "reinforcement",
    "learning",
    "library",
    "really",
    "really",
    "good",
    "algorithms",
    "available",
    "actually",
    "scroll",
    "go",
    "stable",
    "dash",
    "able",
    "access",
    "documentation",
    "link",
    "description",
    "see",
    "got",
    "whole",
    "bunch",
    "rl",
    "algorithms",
    "work",
    "going",
    "working",
    "acer",
    "ppo2",
    "really",
    "good",
    "results",
    "a2c",
    "well",
    "dependency",
    "going",
    "working",
    "open",
    "ai",
    "gym",
    "obviously",
    "one",
    "popular",
    "libraries",
    "comes",
    "reinforcement",
    "learning",
    "environments",
    "environment",
    "going",
    "working",
    "luna",
    "lander",
    "see",
    "got",
    "little",
    "spaceship",
    "trying",
    "land",
    "general",
    "also",
    "flags",
    "land",
    "within",
    "flags",
    "get",
    "points",
    "ideally",
    "goal",
    "take",
    "little",
    "purple",
    "spaceship",
    "see",
    "get",
    "land",
    "successfully",
    "without",
    "breaking",
    "little",
    "legs",
    "going",
    "going",
    "trying",
    "build",
    "reinforcement",
    "learning",
    "agent",
    "able",
    "solve",
    "problem",
    "going",
    "approach",
    "reasonably",
    "straightforward",
    "manner",
    "going",
    "leverage",
    "stable",
    "baselines",
    "help",
    "us",
    "righty",
    "without",
    "ado",
    "let",
    "first",
    "go",
    "ahead",
    "install",
    "import",
    "dependencies",
    "going",
    "write",
    "line",
    "code",
    "take",
    "step",
    "back",
    "take",
    "look",
    "got",
    "alrighty",
    "go",
    "ahead",
    "run",
    "let",
    "take",
    "look",
    "code",
    "actually",
    "written",
    "first",
    "got",
    "exclamation",
    "mark",
    "let",
    "make",
    "sure",
    "zoomed",
    "perfect",
    "cool",
    "got",
    "exclamation",
    "mark",
    "pip",
    "install",
    "tensorflow",
    "equals",
    "equals",
    "key",
    "thing",
    "note",
    "working",
    "stable",
    "baselines",
    "need",
    "using",
    "tensorflow",
    "version",
    "tensorflow",
    "ideally",
    "want",
    "using",
    "got",
    "line",
    "going",
    "install",
    "tensorflow",
    "tensorflow",
    "gpu",
    "written",
    "tensorflow",
    "equals",
    "equals",
    "tensorflow",
    "gpu",
    "equals",
    "equals",
    "pip",
    "install",
    "line",
    "going",
    "go",
    "ahead",
    "install",
    "really",
    "covers",
    "bases",
    "whether",
    "using",
    "gpu",
    "machine",
    "next",
    "package",
    "installing",
    "stable",
    "underscore",
    "baseline",
    "going",
    "install",
    "algorithms",
    "saw",
    "stable",
    "baselines",
    "next",
    "thing",
    "installing",
    "gym",
    "open",
    "ai",
    "gym",
    "also",
    "installing",
    "box",
    "2d",
    "dash",
    "pi",
    "dependency",
    "going",
    "need",
    "using",
    "lunar",
    "lander",
    "environment",
    "going",
    "install",
    "make",
    "sure",
    "lives",
    "remain",
    "easy",
    "going",
    "also",
    "passing",
    "user",
    "going",
    "use",
    "user",
    "flag",
    "install",
    "user",
    "avoids",
    "administrator",
    "dependencies",
    "happens",
    "occur",
    "machine",
    "case",
    "going",
    "hit",
    "shift",
    "enter",
    "run",
    "cell",
    "going",
    "go",
    "ahead",
    "install",
    "dependencies",
    "see",
    "run",
    "pretty",
    "quickly",
    "got",
    "already",
    "got",
    "installed",
    "go",
    "ahead",
    "next",
    "step",
    "importing",
    "dependencies",
    "let",
    "go",
    "ahead",
    "alrighty",
    "dependencies",
    "imported",
    "done",
    "written",
    "four",
    "lines",
    "code",
    "specifically",
    "gone",
    "imported",
    "open",
    "ai",
    "gym",
    "whole",
    "bunch",
    "different",
    "dependencies",
    "stable",
    "baselines",
    "first",
    "line",
    "code",
    "written",
    "import",
    "gym",
    "going",
    "import",
    "open",
    "air",
    "gym",
    "going",
    "allow",
    "us",
    "create",
    "lunar",
    "lander",
    "environment",
    "apply",
    "reinforcement",
    "learning",
    "models",
    "gone",
    "written",
    "stable",
    "underscore",
    "baselines",
    "import",
    "acer",
    "importing",
    "acer",
    "policy",
    "asap",
    "agent",
    "going",
    "allow",
    "us",
    "train",
    "reinforcement",
    "learning",
    "agent",
    "think",
    "algorithm",
    "similar",
    "done",
    "machine",
    "learning",
    "think",
    "specific",
    "machine",
    "learning",
    "type",
    "algorithm",
    "case",
    "could",
    "also",
    "sub",
    "could",
    "use",
    "something",
    "like",
    "uh",
    "let",
    "take",
    "look",
    "could",
    "something",
    "like",
    "dqn",
    "ppo",
    "ddpg",
    "think",
    "different",
    "algorithms",
    "case",
    "going",
    "using",
    "acer",
    "could",
    "try",
    "different",
    "ones",
    "wanted",
    "next",
    "line",
    "written",
    "stable",
    "underscore",
    "baselines",
    "dot",
    "common",
    "dot",
    "vect",
    "underscore",
    "env",
    "import",
    "dummy",
    "vec",
    "env",
    "basically",
    "wrapper",
    "goes",
    "around",
    "open",
    "ai",
    "gym",
    "environment",
    "allows",
    "us",
    "create",
    "dummy",
    "vectorized",
    "environment",
    "stable",
    "baselines",
    "working",
    "certain",
    "stable",
    "baselines",
    "algorithms",
    "expecting",
    "open",
    "ai",
    "gym",
    "vectorized",
    "case",
    "going",
    "explicitly",
    "vectorize",
    "lunar",
    "lander",
    "environment",
    "instead",
    "going",
    "wrap",
    "inside",
    "dummy",
    "vec",
    "environment",
    "see",
    "go",
    "set",
    "last",
    "dependency",
    "imported",
    "evaluate",
    "policy",
    "written",
    "stable",
    "underscore",
    "baselines",
    "dot",
    "common",
    "dot",
    "evaluation",
    "import",
    "evaluate",
    "underscore",
    "policy",
    "evaluate",
    "policy",
    "method",
    "makes",
    "really",
    "easy",
    "test",
    "model",
    "see",
    "performing",
    "use",
    "right",
    "step",
    "three",
    "go",
    "ahead",
    "test",
    "model",
    "right",
    "dependencies",
    "done",
    "going",
    "going",
    "set",
    "variable",
    "going",
    "hold",
    "name",
    "environment",
    "case",
    "environment",
    "going",
    "named",
    "lunalander",
    "v2",
    "actually",
    "copy",
    "going",
    "create",
    "new",
    "variable",
    "called",
    "environment",
    "name",
    "create",
    "empty",
    "string",
    "paste",
    "basically",
    "going",
    "save",
    "us",
    "time",
    "writing",
    "luna",
    "lander",
    "dash",
    "v2",
    "time",
    "want",
    "create",
    "instance",
    "environment",
    "pretty",
    "much",
    "step",
    "zero",
    "done",
    "gone",
    "installed",
    "dependencies",
    "also",
    "gone",
    "imported",
    "whole",
    "bunch",
    "stuff",
    "created",
    "environment",
    "variable",
    "next",
    "step",
    "need",
    "go",
    "test",
    "environment",
    "said",
    "random",
    "environment",
    "really",
    "standard",
    "environment",
    "actually",
    "though",
    "actually",
    "going",
    "go",
    "take",
    "bunch",
    "random",
    "steps",
    "inside",
    "environment",
    "take",
    "look",
    "see",
    "lunarland",
    "taking",
    "random",
    "steps",
    "particular",
    "video",
    "open",
    "ai",
    "gym",
    "web",
    "page",
    "going",
    "try",
    "replicate",
    "see",
    "environment",
    "looks",
    "like",
    "actually",
    "operates",
    "order",
    "run",
    "cell",
    "going",
    "use",
    "jim",
    "dot",
    "make",
    "going",
    "pass",
    "lunar",
    "lander",
    "string",
    "able",
    "go",
    "head",
    "create",
    "environment",
    "run",
    "cell",
    "created",
    "environment",
    "actually",
    "actually",
    "go",
    "ahead",
    "run",
    "block",
    "code",
    "going",
    "going",
    "attempt",
    "land",
    "lunar",
    "lander",
    "three",
    "times",
    "gone",
    "set",
    "episodes",
    "equals",
    "three",
    "basically",
    "means",
    "going",
    "try",
    "three",
    "times",
    "try",
    "land",
    "successfully",
    "initially",
    "going",
    "reset",
    "environment",
    "set",
    "done",
    "score",
    "false",
    "zero",
    "respectively",
    "resetting",
    "variables",
    "going",
    "try",
    "actually",
    "go",
    "ahead",
    "land",
    "specifically",
    "going",
    "take",
    "random",
    "steps",
    "logic",
    "reasoning",
    "behind",
    "going",
    "land",
    "going",
    "take",
    "random",
    "steps",
    "see",
    "wo",
    "actually",
    "perform",
    "well",
    "go",
    "run",
    "code",
    "ideally",
    "happen",
    "finish",
    "training",
    "model",
    "go",
    "apply",
    "similar",
    "way",
    "actually",
    "able",
    "land",
    "lander",
    "appropriately",
    "comes",
    "let",
    "go",
    "ahead",
    "run",
    "see",
    "actually",
    "looks",
    "like",
    "going",
    "set",
    "episodes",
    "back",
    "10",
    "going",
    "give",
    "us",
    "little",
    "time",
    "actually",
    "see",
    "um",
    "appear",
    "bottom",
    "screen",
    "run",
    "get",
    "little",
    "python",
    "actually",
    "going",
    "screen",
    "able",
    "see",
    "environment",
    "run",
    "see",
    "got",
    "little",
    "see",
    "lunar",
    "lander",
    "right",
    "nowhere",
    "near",
    "landing",
    "ideally",
    "goal",
    "either",
    "land",
    "anywhere",
    "ideally",
    "want",
    "land",
    "flags",
    "model",
    "learn",
    "right",
    "even",
    "getting",
    "close",
    "right",
    "crashing",
    "every",
    "single",
    "time",
    "score",
    "getting",
    "anywhere",
    "positive",
    "numbers",
    "goals",
    "right",
    "want",
    "able",
    "land",
    "lander",
    "ideally",
    "get",
    "two",
    "flags",
    "mean",
    "score",
    "longer",
    "negatives",
    "positive",
    "values",
    "done",
    "tested",
    "code",
    "step",
    "one",
    "done",
    "particular",
    "step",
    "done",
    "next",
    "thing",
    "want",
    "go",
    "ahead",
    "actually",
    "build",
    "train",
    "model",
    "let",
    "go",
    "ahead",
    "write",
    "code",
    "take",
    "step",
    "back",
    "see",
    "written",
    "righty",
    "gone",
    "written",
    "three",
    "lines",
    "code",
    "nice",
    "thing",
    "stable",
    "bass",
    "lines",
    "makes",
    "reasonably",
    "simple",
    "get",
    "running",
    "particular",
    "step",
    "could",
    "really",
    "skip",
    "testing",
    "environment",
    "good",
    "idea",
    "understand",
    "environment",
    "actually",
    "operates",
    "three",
    "lines",
    "actually",
    "create",
    "environment",
    "set",
    "model",
    "really",
    "wanted",
    "one",
    "additional",
    "line",
    "sec",
    "going",
    "go",
    "ahead",
    "kick",
    "training",
    "able",
    "train",
    "reinforcement",
    "learning",
    "algorithm",
    "let",
    "take",
    "quick",
    "step",
    "back",
    "see",
    "written",
    "first",
    "written",
    "env",
    "equals",
    "gym",
    "dot",
    "make",
    "pass",
    "environment",
    "name",
    "said",
    "going",
    "wrap",
    "environment",
    "inside",
    "dummy",
    "vec",
    "environment",
    "dummy",
    "vec",
    "environment",
    "actually",
    "expecting",
    "environment",
    "generator",
    "input",
    "done",
    "rather",
    "writing",
    "function",
    "wrote",
    "lambda",
    "creating",
    "new",
    "environment",
    "time",
    "loop",
    "ideally",
    "going",
    "get",
    "number",
    "environments",
    "generated",
    "case",
    "going",
    "one",
    "passing",
    "effectively",
    "going",
    "reset",
    "environment",
    "variable",
    "equal",
    "e",
    "v",
    "creating",
    "new",
    "instance",
    "asa",
    "algorithm",
    "remember",
    "algorithm",
    "imported",
    "wanted",
    "could",
    "swap",
    "one",
    "algorithms",
    "see",
    "play",
    "around",
    "going",
    "probably",
    "get",
    "differing",
    "results",
    "differing",
    "training",
    "times",
    "depending",
    "algorithm",
    "use",
    "case",
    "going",
    "using",
    "acer",
    "see",
    "algorithm",
    "gone",
    "passed",
    "three",
    "key",
    "variables",
    "specifically",
    "two",
    "arguments",
    "one",
    "keyword",
    "argument",
    "written",
    "model",
    "equals",
    "acer",
    "algorithm",
    "brought",
    "passing",
    "policy",
    "think",
    "neural",
    "network",
    "sits",
    "behind",
    "algorithm",
    "case",
    "using",
    "perceptron",
    "policy",
    "believe",
    "stands",
    "could",
    "easily",
    "use",
    "cnn",
    "policy",
    "going",
    "work",
    "environments",
    "could",
    "also",
    "use",
    "lstm",
    "based",
    "policy",
    "going",
    "give",
    "recurrent",
    "neural",
    "network",
    "particularly",
    "good",
    "got",
    "sort",
    "time",
    "series",
    "based",
    "environments",
    "environments",
    "rely",
    "previous",
    "states",
    "also",
    "passing",
    "environment",
    "created",
    "setting",
    "verbose",
    "equal",
    "one",
    "going",
    "give",
    "us",
    "whole",
    "bunch",
    "additional",
    "information",
    "kick",
    "training",
    "run",
    "basically",
    "nutshell",
    "creating",
    "environment",
    "wrapping",
    "inside",
    "dummy",
    "vec",
    "environment",
    "setting",
    "model",
    "initially",
    "next",
    "thing",
    "need",
    "actually",
    "go",
    "ahead",
    "kick",
    "training",
    "let",
    "go",
    "ahead",
    "write",
    "line",
    "code",
    "see",
    "looks",
    "like",
    "really",
    "last",
    "line",
    "code",
    "need",
    "write",
    "able",
    "build",
    "train",
    "model",
    "written",
    "model",
    "dot",
    "learn",
    "akin",
    "fit",
    "method",
    "effectively",
    "going",
    "go",
    "ahead",
    "kick",
    "training",
    "run",
    "passed",
    "one",
    "keyword",
    "argument",
    "total",
    "underscore",
    "time",
    "steps",
    "passed",
    "hundred",
    "thousand",
    "basically",
    "means",
    "reinforcement",
    "learning",
    "model",
    "going",
    "go",
    "ahead",
    "try",
    "train",
    "hundred",
    "thousand",
    "different",
    "steps",
    "using",
    "lunar",
    "lander",
    "model",
    "go",
    "ahead",
    "run",
    "cell",
    "going",
    "kick",
    "training",
    "run",
    "wanted",
    "could",
    "train",
    "shorter",
    "amount",
    "time",
    "train",
    "longer",
    "amount",
    "time",
    "ideally",
    "want",
    "model",
    "high",
    "possible",
    "explained",
    "variance",
    "see",
    "sec",
    "high",
    "possible",
    "mean",
    "episode",
    "reward",
    "let",
    "go",
    "ahead",
    "kick",
    "show",
    "results",
    "look",
    "like",
    "initially",
    "let",
    "run",
    "right",
    "back",
    "right",
    "model",
    "kicked",
    "see",
    "model",
    "runs",
    "get",
    "little",
    "bits",
    "information",
    "set",
    "verbose",
    "equals",
    "one",
    "saying",
    "want",
    "higher",
    "possible",
    "explained",
    "variance",
    "high",
    "possible",
    "mean",
    "episode",
    "reward",
    "right",
    "explained",
    "variance",
    "great",
    "got",
    "zero",
    "399",
    "mean",
    "episode",
    "reward",
    "currently",
    "zero",
    "ideally",
    "want",
    "mean",
    "episode",
    "reward",
    "positive",
    "numbers",
    "negatives",
    "explain",
    "variance",
    "high",
    "possible",
    "ideally",
    "uh",
    "closer",
    "number",
    "one",
    "get",
    "better",
    "going",
    "let",
    "go",
    "ahead",
    "let",
    "run",
    "right",
    "back",
    "alrighty",
    "end",
    "ended",
    "pausing",
    "training",
    "little",
    "bit",
    "earlier",
    "already",
    "getting",
    "reasonably",
    "good",
    "performance",
    "ideally",
    "want",
    "model",
    "starts",
    "performing",
    "reasonably",
    "well",
    "want",
    "train",
    "sometimes",
    "mean",
    "model",
    "starts",
    "performing",
    "poorly",
    "starts",
    "overfit",
    "particular",
    "environment",
    "end",
    "got",
    "explained",
    "variance",
    "pretty",
    "good",
    "also",
    "got",
    "main",
    "episode",
    "reward",
    "ideally",
    "mean",
    "able",
    "successfully",
    "land",
    "lunar",
    "rover",
    "pretty",
    "accurately",
    "next",
    "thing",
    "actually",
    "want",
    "go",
    "gone",
    "trained",
    "model",
    "actually",
    "want",
    "go",
    "ahead",
    "test",
    "evaluate",
    "policy",
    "method",
    "comes",
    "going",
    "go",
    "ahead",
    "go",
    "ahead",
    "test",
    "evaluate",
    "policy",
    "method",
    "thing",
    "also",
    "note",
    "running",
    "also",
    "run",
    "callback",
    "allow",
    "go",
    "ahead",
    "automatically",
    "pause",
    "training",
    "sort",
    "get",
    "optimal",
    "level",
    "like",
    "see",
    "video",
    "means",
    "leave",
    "mention",
    "comments",
    "get",
    "next",
    "thing",
    "going",
    "run",
    "evaluate",
    "policies",
    "let",
    "go",
    "ahead",
    "write",
    "loan",
    "code",
    "see",
    "model",
    "actually",
    "performing",
    "okay",
    "run",
    "let",
    "take",
    "look",
    "code",
    "usual",
    "gone",
    "written",
    "evaluate",
    "underscore",
    "policies",
    "using",
    "evaluate",
    "policy",
    "method",
    "brought",
    "imports",
    "passing",
    "two",
    "arguments",
    "true",
    "keyword",
    "arguments",
    "specifically",
    "passing",
    "model",
    "environment",
    "defined",
    "earlier",
    "defining",
    "many",
    "evaluation",
    "episodes",
    "want",
    "run",
    "many",
    "chances",
    "want",
    "give",
    "model",
    "able",
    "prove",
    "performance",
    "case",
    "setting",
    "10",
    "specifying",
    "render",
    "equals",
    "true",
    "want",
    "visualize",
    "performance",
    "results",
    "effectively",
    "see",
    "ai",
    "reinforcement",
    "learning",
    "model",
    "trying",
    "land",
    "lunar",
    "lander",
    "running",
    "able",
    "close",
    "let",
    "go",
    "ahead",
    "run",
    "line",
    "code",
    "let",
    "see",
    "performance",
    "get",
    "little",
    "see",
    "model",
    "attempting",
    "land",
    "outlander",
    "go",
    "landed",
    "successfully",
    "see",
    "accurately",
    "adjusting",
    "one",
    "boosters",
    "able",
    "go",
    "ahead",
    "land",
    "lander",
    "flag",
    "two",
    "successful",
    "landings",
    "see",
    "performing",
    "pretty",
    "well",
    "even",
    "though",
    "hit",
    "elusive",
    "explained",
    "variance",
    "ridiculously",
    "high",
    "accuracy",
    "ridiculously",
    "high",
    "mean",
    "episode",
    "reward",
    "see",
    "still",
    "getting",
    "case",
    "trying",
    "push",
    "booster",
    "try",
    "get",
    "flags",
    "case",
    "performing",
    "lot",
    "better",
    "adjusting",
    "still",
    "sky",
    "see",
    "one",
    "obviously",
    "performing",
    "really",
    "well",
    "getting",
    "quite",
    "close",
    "come",
    "yes",
    "right",
    "elon",
    "come",
    "got",
    "come",
    "hire",
    "us",
    "okay",
    "pretty",
    "cool",
    "right",
    "performing",
    "reasonably",
    "well",
    "quite",
    "falcon",
    "heavy",
    "getting",
    "right",
    "done",
    "luna",
    "lander",
    "could",
    "try",
    "obviously",
    "last",
    "minute",
    "crash",
    "landing",
    "see",
    "obviously",
    "reinforcement",
    "learning",
    "model",
    "performing",
    "lot",
    "better",
    "going",
    "running",
    "random",
    "environment",
    "done",
    "next",
    "thing",
    "want",
    "go",
    "ahead",
    "save",
    "model",
    "part",
    "good",
    "data",
    "science",
    "workflow",
    "want",
    "able",
    "reload",
    "model",
    "try",
    "particularly",
    "wanted",
    "go",
    "deploy",
    "production",
    "later",
    "let",
    "go",
    "ahead",
    "save",
    "model",
    "write",
    "model",
    "dot",
    "save",
    "case",
    "name",
    "whatever",
    "like",
    "call",
    "acer",
    "underscore",
    "model",
    "go",
    "folder",
    "jupyter",
    "notebook",
    "see",
    "fact",
    "saved",
    "acer",
    "model",
    "delete",
    "model",
    "try",
    "running",
    "model",
    "see",
    "going",
    "work",
    "reload",
    "able",
    "reuse",
    "model",
    "later",
    "type",
    "copy",
    "also",
    "need",
    "pass",
    "environment",
    "reloading",
    "sorry",
    "algorithm",
    "going",
    "use",
    "dot",
    "load",
    "name",
    "model",
    "say",
    "able",
    "save",
    "reload",
    "name",
    "case",
    "reload",
    "model",
    "reloaded",
    "throw",
    "inside",
    "variable",
    "called",
    "model",
    "equals",
    "actually",
    "start",
    "testing",
    "rather",
    "using",
    "evaluate",
    "policy",
    "time",
    "going",
    "write",
    "little",
    "bit",
    "flow",
    "sort",
    "closely",
    "mimics",
    "really",
    "ideally",
    "mimics",
    "might",
    "put",
    "production",
    "particularly",
    "got",
    "sensors",
    "particular",
    "environment",
    "let",
    "go",
    "ahead",
    "write",
    "see",
    "model",
    "performs",
    "okay",
    "last",
    "bit",
    "code",
    "done",
    "go",
    "ahead",
    "run",
    "let",
    "take",
    "look",
    "written",
    "first",
    "gone",
    "done",
    "gone",
    "reset",
    "environment",
    "whenever",
    "going",
    "testing",
    "new",
    "code",
    "testing",
    "rl",
    "model",
    "want",
    "reset",
    "environment",
    "back",
    "base",
    "state",
    "exactly",
    "line",
    "base",
    "state",
    "capturing",
    "observations",
    "inside",
    "variable",
    "called",
    "obs",
    "full",
    "line",
    "obs",
    "equals",
    "env",
    "dot",
    "reset",
    "going",
    "kicking",
    "loop",
    "basically",
    "going",
    "keep",
    "running",
    "different",
    "instances",
    "lunar",
    "lander",
    "environment",
    "multiple",
    "times",
    "actually",
    "force",
    "stop",
    "want",
    "stop",
    "running",
    "written",
    "true",
    "colon",
    "using",
    "model",
    "trained",
    "using",
    "predict",
    "method",
    "go",
    "generate",
    "action",
    "based",
    "observations",
    "environment",
    "space",
    "think",
    "model",
    "receiving",
    "inputs",
    "lunar",
    "lander",
    "environment",
    "trying",
    "predict",
    "best",
    "action",
    "able",
    "land",
    "rover",
    "successfully",
    "going",
    "get",
    "appropriate",
    "type",
    "action",
    "current",
    "state",
    "model",
    "going",
    "go",
    "ahead",
    "apply",
    "action",
    "environment",
    "see",
    "based",
    "env",
    "dot",
    "step",
    "going",
    "environment",
    "taking",
    "step",
    "using",
    "action",
    "model",
    "predicted",
    "going",
    "get",
    "new",
    "observations",
    "rewards",
    "whether",
    "particular",
    "episode",
    "done",
    "additional",
    "info",
    "going",
    "render",
    "current",
    "frame",
    "allow",
    "us",
    "see",
    "model",
    "performing",
    "real",
    "time",
    "let",
    "go",
    "ahead",
    "run",
    "eventually",
    "kill",
    "stop",
    "running",
    "close",
    "look",
    "pretty",
    "similar",
    "evaluate",
    "policy",
    "except",
    "time",
    "going",
    "keep",
    "running",
    "let",
    "kick",
    "open",
    "window",
    "going",
    "try",
    "land",
    "lander",
    "working",
    "pretty",
    "successfully",
    "see",
    "landed",
    "going",
    "restart",
    "slightly",
    "different",
    "way",
    "go",
    "ahead",
    "kick",
    "code",
    "another",
    "successful",
    "landing",
    "looking",
    "like",
    "performing",
    "reasonably",
    "well",
    "right",
    "stop",
    "wanted",
    "see",
    "little",
    "icon",
    "still",
    "open",
    "close",
    "type",
    "close",
    "little",
    "pop",
    "go",
    "ahead",
    "kick",
    "evaluate",
    "policy",
    "whole",
    "loop",
    "wraps",
    "gone",
    "done",
    "gone",
    "installed",
    "imported",
    "dependency",
    "gone",
    "tested",
    "random",
    "environment",
    "code",
    "going",
    "available",
    "inside",
    "description",
    "check",
    "able",
    "grab",
    "step",
    "two",
    "built",
    "trained",
    "model",
    "really",
    "four",
    "core",
    "lines",
    "core",
    "components",
    "actually",
    "going",
    "ahead",
    "build",
    "environment",
    "train",
    "reinforcement",
    "learning",
    "model",
    "went",
    "saved",
    "tested",
    "tested",
    "using",
    "evaluate",
    "policy",
    "method",
    "also",
    "wrote",
    "custom",
    "code",
    "go",
    "ahead",
    "test",
    "wraps",
    "thanks",
    "much",
    "tuning",
    "guys",
    "hopefully",
    "found",
    "video",
    "useful",
    "sure",
    "give",
    "thumbs",
    "hit",
    "subscribe",
    "tick",
    "bell",
    "awesome",
    "reinforcement",
    "learning",
    "content",
    "let",
    "know",
    "went",
    "building",
    "reinforcement",
    "learning",
    "model",
    "thanks",
    "tuning",
    "peace"
  ],
  "keywords": [
    "need",
    "uh",
    "landing",
    "well",
    "see",
    "try",
    "name",
    "video",
    "going",
    "reinforcement",
    "learning",
    "let",
    "take",
    "look",
    "three",
    "key",
    "first",
    "installing",
    "stable",
    "baselines",
    "package",
    "whole",
    "get",
    "set",
    "open",
    "ai",
    "gym",
    "luna",
    "lander",
    "environment",
    "us",
    "build",
    "model",
    "actually",
    "land",
    "spaceship",
    "specifically",
    "able",
    "successfully",
    "gone",
    "trained",
    "test",
    "run",
    "time",
    "setting",
    "lunar",
    "little",
    "trying",
    "flags",
    "goal",
    "sort",
    "particular",
    "training",
    "go",
    "alrighty",
    "kick",
    "install",
    "import",
    "dependencies",
    "passing",
    "random",
    "description",
    "code",
    "write",
    "tested",
    "train",
    "use",
    "algorithms",
    "ahead",
    "agent",
    "last",
    "save",
    "working",
    "really",
    "good",
    "got",
    "bunch",
    "acer",
    "results",
    "dependency",
    "obviously",
    "one",
    "environments",
    "also",
    "ideally",
    "reasonably",
    "line",
    "step",
    "back",
    "written",
    "make",
    "tensorflow",
    "equals",
    "thing",
    "using",
    "want",
    "machine",
    "next",
    "underscore",
    "case",
    "cell",
    "pretty",
    "imported",
    "done",
    "lines",
    "different",
    "allow",
    "create",
    "policy",
    "think",
    "algorithm",
    "type",
    "could",
    "like",
    "wanted",
    "dot",
    "env",
    "dummy",
    "vec",
    "basically",
    "inside",
    "evaluate",
    "method",
    "performing",
    "right",
    "variable",
    "new",
    "zero",
    "steps",
    "times",
    "reset",
    "give",
    "getting",
    "close",
    "two",
    "mean",
    "running",
    "testing",
    "based",
    "high",
    "possible",
    "explained",
    "variance",
    "episode",
    "reward",
    "performance",
    "reload",
    "stop",
    "action"
  ]
}