{
  "text": "I am Shusen Wang.\nI am an assistant professor at Stevens Institute of Technology.\nIn this lecture, I will give a short introduction to few-shot learning.\nFew-shot learning means making classification or regression based on a very small number of samples.\nBefore getting started, let’s play a game.\nI show you 4 images. Please look carefully.\nThe left two images are Armadillos.\nThe right two are Pangolins.\nYou may have never heard of Armadillo or Pangolin, but it doesn’t matter.\nYou just want to pay attention to their differences and try to distinguish the two animals.\nIf you don’t know their difference, I can give you some hint.\nLook at their ears and size of the scales.\nNow, I give you a query image.\nDo you think it is Armadillo or Pangolin?\nMost people don’t know the difference between Armadillo and Pangolin.\nThey may have not even heard of Armadillo or Pangolin.\nBut human can learn to distinguish the two animals using merely 4 training samples.\nFor a human, making a prediction based on 4 training samples is not hard.\nBut can computers do this as well?\nIf a class has only two samples, can computers make the correct prediction?\nThis is harder than the standard classification problem.\nThe number of samples is too small for training a deep neural network.\nPlease keep the terminologies in mind: support set and query.\nSupport set is a small set of samples.\nIt is too small for training a model.\nFew-shot learning is the problem of making predictions based on a limited number of samples.\nFew-shot learning is different from the standard supervised learning.\nThe goal of few-shot learning is not to let the model recognize the images in the training set and then generalize to the test set.\nInstead, the goal is to learn to learn.\n“Learn to learn” sounds hard to understand.\nYou can think of it in this way.\nI train the model on a big training set.\nThe goal of training is not to know what elephant is and what tiger is.\nThe goal is not to be able to recognize unseen elephants and tigers.\nInstead, the goal is to know the similarity and difference between objects.\nAfter training, you can show the two images to the model and ask whether the two are the same kind of animals.\nThe model has learned the similarity and difference between objects.\nSo the model is able to tell that the contents in the two images are the same kind of objects.\nTake a look at our training data again.\nThe training data has 5 classes which do not include the squirrel class.\nThus, the model is unable to recognize squirrels.\nIf you show an image of the squirrel to the model, the model does not know it is a squirrel.\nWhen the model sees the two images, it does not know they are squirrels.\nHowever, the model knows they look alike.\nThe model can tell you with high confidence that they are the same kind of objects.\nFor the same reason, the model has never seen a rabbit during training,\nso it does not know the two images are rabbits.\nBut the model knows the similarity and difference between things.\nThe model knows that the contents of the two images are very alike.\nSo the model can tell that they are the same object.\nThen I show the two images to the model.\nWhile the model has never seen pangolin and bulldog,\nthe model knows the two animals look quite different.\nThe model believes they are different objects.\nNow, I ask a different question.\nI have a query image.\nI show it to the model and ask what it is.\nThe model is unable to answer my question.\nThe model has not seen this kind of object during training.\nThen, I provide the model with additional information.\nI show additional 6 images to the model.\nI tell the model that they are fox, squirrel, rabbit, hamster, otter, and beaver.\nNow, the model can answer my question.\nThe model compares the query image with each of the 6 images.\nThe model finds the query most similar to the otter image.\nSo the model believes the query is an otter.\n\"Support set\" is meta learning’s jargon.\nThe small set of labeled images is called support set.\nNote the difference between the training set and support set.\nThe training set is big.\nEvery class in the training set has many samples.\nThe training set is big enough for learning a deep neural network.\nIn contrast, the support set is small.\nEvery class has at most a few samples.\nIn this example, every class has only one sample.\nIt is impossible to train a deep neural network using such a small set of data.\nThe support set can only provide additional information at test time.\nHere is the basic idea of few-shot learning.\nWe train a big model using a big training set.\nRather than training the model to recognize specific objects such as tiger and elephant in the training set,\nwe train the model to know the similarity and difference between objects\nWith the additional information provided by the support set, the model can tell the query image is an otter\nalthough otter is not among the classes in the training set\nI am going to explain what few-shot learning and meta-learning are.\nYou may have heard of meta-learning.\nFew-shot learning is a kind of meta-learning.\nMeta-learning is different from traditional supervised learning.\nTraditional supervised learning asks the model to recognize the training data and then generalize to unseen test data.\nDifferently, meta learning’s goal is to learn to learn.\nHow to understand \"learn to learn\"?\nYou bring your kid to the zoo.\nHe’s excited to see the fluffy animal in the water which he has never seen before.\nHe asked you: daddy, what’s this?\nAlthough he has never seen this animal before, he is a smart kid and can learn by himself.\nNow, you give the kid a set of cards.\nOn every card, there is an animal and its name.\nThe kid has never seen the animal in the water.\nHe has never seen the animals on the cards, either.\nBut the kid is so smart that by taking a look at all the cards, he knows the animal in the water is an otter.\nThe animal in the water is most similar to the otter on the card.\nTeaching the kid to learn by himself is called meta-learning.\nBefore going to the zoo, the kid was already able to learn by himself.\nHe knew the similarity and difference between animals.\nAlthough he has never seen otter before, he could learn by himself.\nBy reading the cards, he knows the animal is an otter.\nThe kid wants to know the animal in the water which he has never seen before.\nIn meta-learning, the unknown animal is called a query.\nYou give him a set of cards and let him learn by himself.\nThe set of cards is the support set.\nWhat is meta-learning?\nLearning to learn by himself is called meta-learning.\nIn this example, letting the kid distinguish different animals is meta-learning.\nBefore going to the zoo, the kid has not heard of otter,\nbut he knew how to related the otter in the water with the otter on the card.\nIn this example, the kid learns to recognize otter using a set of cards.\nThere is only one card for every species.\nHe learns to recognize otter using only one card.\nThis is called one-shot learning.\nHere I compare traditional supervised learning with few-shot learning.\nTraditional supervised learning is like this.\nFirst, learn a model using a big training set.\nAfter the model is trained, we can use the model for making predictions.\nWe show a test sample to the model.\nThe test sample is never-seen-before; it is not in the training set.\nFortunately, this test sample is from a known class.\nThe test sample is a husky.\nIt belongs to this class.\nThere are hundreds of samples under the class “husky”.\nAlthough the model has never seen this husky, the model has seen hundreds of huskies.\nIt is not hard for the model to tell this test sample is a husky.\nFew-shot learning is a different problem.\nThe query sample is never seen before.\nFurthermore, the query sample is from an unknown class.\nThe query sample is a rabbit.\nIt is not among the classes in the training set.\nThe model has never seen any rabbit during training.\nThis is the main difference from traditional supervised learning.\nThe training set does not have a rabbit class,\nso the model does not know that the query sample is.\nWe need to provide the model with more information.\nWe can show the cards to the model.\nEvery card has an image and a name.\nThe set of cards is the support set.\nBy comparing the query with the cards, the model finds the query most similar to the rabbit card.\nSo the model predicts that the query is a rabbit.\nWay and shot are terminologies of few-shot learning.\nK-way means the support set has k classes.\nIn this example, the support set has 6 classes: fox, squirrel, rabbit, hamster, otter, and beaver.\nSo K is 6.\nN-shot means every class has n samples.\nIn this example, every class has only one sample.\nSo n is 1.\nThis support set is called 6-way and 1-shot.\nTake a look at another support set.\nIt has 4 classes: squirrel, rabbit, hamster, and otter.\nSo it is 4-way.\nThere are two samples in every class.\nSo it is 2-shot.\nThe support set is called 4-way 2-shot.\nWhen performing few-shot learning, the prediction accuracy depends on the number of ways and the number of shots.\nIn this figure, the x-axis is the number of ways,\nthat is, the number of classes in the support set.\nThe y-axis is the prediction accuracy.\nAs the number of ways increases, the prediction accuracy drops.\nWhy does this happen?\nThere is an otter in the zoo.\nThe kid does not know what it is.\nI give the kid 3 cards and ask the kid to choose one out of the three.\nThis is 3-way 1-shot learning.\nWhat if I give the kid 6 cards?\nThen this would be 6-way 1-shot learning.\nWhich one do you think is easier, 3-way or 6-way?\nObviously, 3-way is easier than 6-way.\nChoosing one out of 3 is easier than choosing one out of 6.\nThus 3-way has higher accuracy than 6-way.\nIn this figure, the x-axis is the number of shots,\nthat is, the number of samples per class.\nThe y-axis is the prediction accuracy.\nAs the number of shots increases, the prediction accuracy improves.\nThe phenomenon is easy to interpret.\nThe above is a 2-shot support set.\nThe below is a 1-shot support set.\nWith more samples, the prediction becomes easier.\nThus 2-shot is easier than 1-shot.\nThe basic idea of few-shot learning is to train a function that predicts similarity.\nDenote the similarity function by sim(x, x’).\nIt measures the similarity between the two samples, x and x’.\nHere are 3 images.\nThey are bulldog, bulldog, and fox.\nDenote them by x1, x2, and x3.\nIdeally, taking x1 and x2 as input, the similarity function outputs one,\nwhich means the two animals are the same.\nTaking x1 and x3 as input, or taking x2 and x3 as input,\nthe similarity function outputs zero,\nwhich means the two animals are different.\nThe idea can be implemented in this way.\nFirst, learn a similarity function from a large-scale training dataset.\nThe similarity function tells us how similar two images are.\nIn the next lecture, we will study the Siamese network which can be a similarity function.\nThe network can be trained using a large-scale dataset such as ImageNet.\nAfter training, the learned similarity function can be used for making predictions for unseen queries.\nWe can use the similarity function to compare the query with every sample in the support set and calculate the similarity scores.\nThen find the sample with the highest similarity score, and use it as the prediction.\nI use this example to demonstrate how to make a prediction.\nGiven this query image, I want to know what the image is.\nWe can compare the query with every sample in the support set.\nCompare the query with greyhound.\nThe similarity function outputs a similarity score of 0.2.\nThe similarity score between the query and the bulldog is 0.1.\nThe similarity between the query and the armadillo is 0.03.\nDo the same for all the samples in the support set to get all the similarity scores.\nAmong those similarity scores, this 0.7 is the biggest.\nThus, the model predicts the query is an otter.\nOne-shot learning can be performed in this way.\nGiven a support set,\nwe can compute the similarity between the query and every sample in the support set to find the most similar sample.\nIf you do research on meta-learning, then you will need datasets for evaluating your model.\nHere I introduce 2 datasets which are most widely used in research papers.\nOmniglot is the most frequently used dataset.\nThe dataset is small; only a few megabytes.\nOmniglot is a hand-written dataset similar to MNIST.\nMNIST dataset is for digit recognition.\nMNIST has 10 classes; each class has 6 thousand samples.\nIn contrast, Omniglot has over 1 thousand classes.\nBut each class has only 20 digits.\nThis makes the classification for Omniglot harder than MNIST.\nYou can download the dataset using the link or import the dataset using TensorFlow.\nThe dataset has 50 alphabets such as Hebrew, Greek, Latin, etc.\nEvery alphabet has many characters.\nFor example, Greek has 24 letters such as alpha, beta, gamma, all the way to omega.\nFor every character, there are 20 digits written by different people.\nHere is a summary of Omniglot.\nIt has 50 alphabets including various languages like Latin, Greek, and Hebrew.\nEvery alphabet has multiple characters, for example, Greek has 24 letters.\nThe 50 alphabets have a total of 1623 unique characters.\nTherefore, the dataset has 1623 classes.\nEach character was written by 20 different people.\nIt means each class has 20 samples.\nAll the samples are 105-by-105 images.\nThe training set has 30 alphabets, which contain 964 characters and thus 964 classes.\nThe training set contains a total of 19,280 samples.\nThe test set has 20 alphabets, which contain 659 characters and thus 659 classes.\nThe test set has a total of 13,180 samples.\nAnother commonly used dataset is Mini-ImageNet.\nIt has 100 classes such as mushroom, orange, corn, bird, and snake.\nEvery class has 600 samples.\nThe dataset has a total of 60 thousand samples.\nWe have learned the basic concepts of few-shot learning and meta-learning.\nIn the next class, we will study the Siamese network for few-shot learning.\n",
  "words": [
    "shusen",
    "wang",
    "assistant",
    "professor",
    "stevens",
    "institute",
    "technology",
    "lecture",
    "give",
    "short",
    "introduction",
    "learning",
    "learning",
    "means",
    "making",
    "classification",
    "regression",
    "based",
    "small",
    "number",
    "samples",
    "getting",
    "started",
    "let",
    "play",
    "game",
    "show",
    "4",
    "images",
    "please",
    "look",
    "carefully",
    "left",
    "two",
    "images",
    "armadillos",
    "right",
    "two",
    "pangolins",
    "may",
    "never",
    "heard",
    "armadillo",
    "pangolin",
    "matter",
    "want",
    "pay",
    "attention",
    "differences",
    "try",
    "distinguish",
    "two",
    "animals",
    "know",
    "difference",
    "give",
    "hint",
    "look",
    "ears",
    "size",
    "scales",
    "give",
    "query",
    "image",
    "think",
    "armadillo",
    "pangolin",
    "people",
    "know",
    "difference",
    "armadillo",
    "pangolin",
    "may",
    "even",
    "heard",
    "armadillo",
    "pangolin",
    "human",
    "learn",
    "distinguish",
    "two",
    "animals",
    "using",
    "merely",
    "4",
    "training",
    "samples",
    "human",
    "making",
    "prediction",
    "based",
    "4",
    "training",
    "samples",
    "hard",
    "computers",
    "well",
    "class",
    "two",
    "samples",
    "computers",
    "make",
    "correct",
    "prediction",
    "harder",
    "standard",
    "classification",
    "problem",
    "number",
    "samples",
    "small",
    "training",
    "deep",
    "neural",
    "network",
    "please",
    "keep",
    "terminologies",
    "mind",
    "support",
    "set",
    "query",
    "support",
    "set",
    "small",
    "set",
    "samples",
    "small",
    "training",
    "model",
    "learning",
    "problem",
    "making",
    "predictions",
    "based",
    "limited",
    "number",
    "samples",
    "learning",
    "different",
    "standard",
    "supervised",
    "learning",
    "goal",
    "learning",
    "let",
    "model",
    "recognize",
    "images",
    "training",
    "set",
    "generalize",
    "test",
    "set",
    "instead",
    "goal",
    "learn",
    "learn",
    "learn",
    "learn",
    "sounds",
    "hard",
    "understand",
    "think",
    "way",
    "train",
    "model",
    "big",
    "training",
    "set",
    "goal",
    "training",
    "know",
    "elephant",
    "tiger",
    "goal",
    "able",
    "recognize",
    "unseen",
    "elephants",
    "tigers",
    "instead",
    "goal",
    "know",
    "similarity",
    "difference",
    "objects",
    "training",
    "show",
    "two",
    "images",
    "model",
    "ask",
    "whether",
    "two",
    "kind",
    "animals",
    "model",
    "learned",
    "similarity",
    "difference",
    "objects",
    "model",
    "able",
    "tell",
    "contents",
    "two",
    "images",
    "kind",
    "objects",
    "take",
    "look",
    "training",
    "data",
    "training",
    "data",
    "5",
    "classes",
    "include",
    "squirrel",
    "class",
    "thus",
    "model",
    "unable",
    "recognize",
    "squirrels",
    "show",
    "image",
    "squirrel",
    "model",
    "model",
    "know",
    "squirrel",
    "model",
    "sees",
    "two",
    "images",
    "know",
    "squirrels",
    "however",
    "model",
    "knows",
    "look",
    "alike",
    "model",
    "tell",
    "high",
    "confidence",
    "kind",
    "objects",
    "reason",
    "model",
    "never",
    "seen",
    "rabbit",
    "training",
    "know",
    "two",
    "images",
    "rabbits",
    "model",
    "knows",
    "similarity",
    "difference",
    "things",
    "model",
    "knows",
    "contents",
    "two",
    "images",
    "alike",
    "model",
    "tell",
    "object",
    "show",
    "two",
    "images",
    "model",
    "model",
    "never",
    "seen",
    "pangolin",
    "bulldog",
    "model",
    "knows",
    "two",
    "animals",
    "look",
    "quite",
    "different",
    "model",
    "believes",
    "different",
    "objects",
    "ask",
    "different",
    "question",
    "query",
    "image",
    "show",
    "model",
    "ask",
    "model",
    "unable",
    "answer",
    "question",
    "model",
    "seen",
    "kind",
    "object",
    "training",
    "provide",
    "model",
    "additional",
    "information",
    "show",
    "additional",
    "6",
    "images",
    "model",
    "tell",
    "model",
    "fox",
    "squirrel",
    "rabbit",
    "hamster",
    "otter",
    "beaver",
    "model",
    "answer",
    "question",
    "model",
    "compares",
    "query",
    "image",
    "6",
    "images",
    "model",
    "finds",
    "query",
    "similar",
    "otter",
    "image",
    "model",
    "believes",
    "query",
    "otter",
    "support",
    "set",
    "meta",
    "learning",
    "jargon",
    "small",
    "set",
    "labeled",
    "images",
    "called",
    "support",
    "set",
    "note",
    "difference",
    "training",
    "set",
    "support",
    "set",
    "training",
    "set",
    "big",
    "every",
    "class",
    "training",
    "set",
    "many",
    "samples",
    "training",
    "set",
    "big",
    "enough",
    "learning",
    "deep",
    "neural",
    "network",
    "contrast",
    "support",
    "set",
    "small",
    "every",
    "class",
    "samples",
    "example",
    "every",
    "class",
    "one",
    "sample",
    "impossible",
    "train",
    "deep",
    "neural",
    "network",
    "using",
    "small",
    "set",
    "data",
    "support",
    "set",
    "provide",
    "additional",
    "information",
    "test",
    "time",
    "basic",
    "idea",
    "learning",
    "train",
    "big",
    "model",
    "using",
    "big",
    "training",
    "set",
    "rather",
    "training",
    "model",
    "recognize",
    "specific",
    "objects",
    "tiger",
    "elephant",
    "training",
    "set",
    "train",
    "model",
    "know",
    "similarity",
    "difference",
    "objects",
    "additional",
    "information",
    "provided",
    "support",
    "set",
    "model",
    "tell",
    "query",
    "image",
    "otter",
    "although",
    "otter",
    "among",
    "classes",
    "training",
    "set",
    "going",
    "explain",
    "learning",
    "may",
    "heard",
    "learning",
    "kind",
    "different",
    "traditional",
    "supervised",
    "learning",
    "traditional",
    "supervised",
    "learning",
    "asks",
    "model",
    "recognize",
    "training",
    "data",
    "generalize",
    "unseen",
    "test",
    "data",
    "differently",
    "meta",
    "learning",
    "goal",
    "learn",
    "learn",
    "understand",
    "learn",
    "learn",
    "bring",
    "kid",
    "zoo",
    "excited",
    "see",
    "fluffy",
    "animal",
    "water",
    "never",
    "seen",
    "asked",
    "daddy",
    "although",
    "never",
    "seen",
    "animal",
    "smart",
    "kid",
    "learn",
    "give",
    "kid",
    "set",
    "cards",
    "every",
    "card",
    "animal",
    "name",
    "kid",
    "never",
    "seen",
    "animal",
    "water",
    "never",
    "seen",
    "animals",
    "cards",
    "either",
    "kid",
    "smart",
    "taking",
    "look",
    "cards",
    "knows",
    "animal",
    "water",
    "otter",
    "animal",
    "water",
    "similar",
    "otter",
    "card",
    "teaching",
    "kid",
    "learn",
    "called",
    "going",
    "zoo",
    "kid",
    "already",
    "able",
    "learn",
    "knew",
    "similarity",
    "difference",
    "animals",
    "although",
    "never",
    "seen",
    "otter",
    "could",
    "learn",
    "reading",
    "cards",
    "knows",
    "animal",
    "otter",
    "kid",
    "wants",
    "know",
    "animal",
    "water",
    "never",
    "seen",
    "unknown",
    "animal",
    "called",
    "query",
    "give",
    "set",
    "cards",
    "let",
    "learn",
    "set",
    "cards",
    "support",
    "set",
    "learning",
    "learn",
    "called",
    "example",
    "letting",
    "kid",
    "distinguish",
    "different",
    "animals",
    "going",
    "zoo",
    "kid",
    "heard",
    "otter",
    "knew",
    "related",
    "otter",
    "water",
    "otter",
    "card",
    "example",
    "kid",
    "learns",
    "recognize",
    "otter",
    "using",
    "set",
    "cards",
    "one",
    "card",
    "every",
    "species",
    "learns",
    "recognize",
    "otter",
    "using",
    "one",
    "card",
    "called",
    "learning",
    "compare",
    "traditional",
    "supervised",
    "learning",
    "learning",
    "traditional",
    "supervised",
    "learning",
    "like",
    "first",
    "learn",
    "model",
    "using",
    "big",
    "training",
    "set",
    "model",
    "trained",
    "use",
    "model",
    "making",
    "predictions",
    "show",
    "test",
    "sample",
    "model",
    "test",
    "sample",
    "training",
    "set",
    "fortunately",
    "test",
    "sample",
    "known",
    "class",
    "test",
    "sample",
    "husky",
    "belongs",
    "class",
    "hundreds",
    "samples",
    "class",
    "husky",
    "although",
    "model",
    "never",
    "seen",
    "husky",
    "model",
    "seen",
    "hundreds",
    "huskies",
    "hard",
    "model",
    "tell",
    "test",
    "sample",
    "husky",
    "learning",
    "different",
    "problem",
    "query",
    "sample",
    "never",
    "seen",
    "furthermore",
    "query",
    "sample",
    "unknown",
    "class",
    "query",
    "sample",
    "rabbit",
    "among",
    "classes",
    "training",
    "set",
    "model",
    "never",
    "seen",
    "rabbit",
    "training",
    "main",
    "difference",
    "traditional",
    "supervised",
    "learning",
    "training",
    "set",
    "rabbit",
    "class",
    "model",
    "know",
    "query",
    "sample",
    "need",
    "provide",
    "model",
    "information",
    "show",
    "cards",
    "model",
    "every",
    "card",
    "image",
    "name",
    "set",
    "cards",
    "support",
    "set",
    "comparing",
    "query",
    "cards",
    "model",
    "finds",
    "query",
    "similar",
    "rabbit",
    "card",
    "model",
    "predicts",
    "query",
    "rabbit",
    "way",
    "shot",
    "terminologies",
    "learning",
    "means",
    "support",
    "set",
    "k",
    "classes",
    "example",
    "support",
    "set",
    "6",
    "classes",
    "fox",
    "squirrel",
    "rabbit",
    "hamster",
    "otter",
    "beaver",
    "k",
    "means",
    "every",
    "class",
    "n",
    "samples",
    "example",
    "every",
    "class",
    "one",
    "sample",
    "n",
    "support",
    "set",
    "called",
    "take",
    "look",
    "another",
    "support",
    "set",
    "4",
    "classes",
    "squirrel",
    "rabbit",
    "hamster",
    "otter",
    "two",
    "samples",
    "every",
    "class",
    "support",
    "set",
    "called",
    "performing",
    "learning",
    "prediction",
    "accuracy",
    "depends",
    "number",
    "ways",
    "number",
    "shots",
    "figure",
    "number",
    "ways",
    "number",
    "classes",
    "support",
    "set",
    "prediction",
    "accuracy",
    "number",
    "ways",
    "increases",
    "prediction",
    "accuracy",
    "drops",
    "happen",
    "otter",
    "zoo",
    "kid",
    "know",
    "give",
    "kid",
    "3",
    "cards",
    "ask",
    "kid",
    "choose",
    "one",
    "three",
    "learning",
    "give",
    "kid",
    "6",
    "cards",
    "would",
    "learning",
    "one",
    "think",
    "easier",
    "obviously",
    "easier",
    "choosing",
    "one",
    "3",
    "easier",
    "choosing",
    "one",
    "thus",
    "higher",
    "accuracy",
    "figure",
    "number",
    "shots",
    "number",
    "samples",
    "per",
    "class",
    "prediction",
    "accuracy",
    "number",
    "shots",
    "increases",
    "prediction",
    "accuracy",
    "improves",
    "phenomenon",
    "easy",
    "interpret",
    "support",
    "set",
    "support",
    "set",
    "samples",
    "prediction",
    "becomes",
    "easier",
    "thus",
    "easier",
    "basic",
    "idea",
    "learning",
    "train",
    "function",
    "predicts",
    "similarity",
    "denote",
    "similarity",
    "function",
    "sim",
    "x",
    "x",
    "measures",
    "similarity",
    "two",
    "samples",
    "x",
    "x",
    "3",
    "images",
    "bulldog",
    "bulldog",
    "fox",
    "denote",
    "x1",
    "x2",
    "x3",
    "ideally",
    "taking",
    "x1",
    "x2",
    "input",
    "similarity",
    "function",
    "outputs",
    "one",
    "means",
    "two",
    "animals",
    "taking",
    "x1",
    "x3",
    "input",
    "taking",
    "x2",
    "x3",
    "input",
    "similarity",
    "function",
    "outputs",
    "zero",
    "means",
    "two",
    "animals",
    "different",
    "idea",
    "implemented",
    "way",
    "first",
    "learn",
    "similarity",
    "function",
    "training",
    "dataset",
    "similarity",
    "function",
    "tells",
    "us",
    "similar",
    "two",
    "images",
    "next",
    "lecture",
    "study",
    "siamese",
    "network",
    "similarity",
    "function",
    "network",
    "trained",
    "using",
    "dataset",
    "imagenet",
    "training",
    "learned",
    "similarity",
    "function",
    "used",
    "making",
    "predictions",
    "unseen",
    "queries",
    "use",
    "similarity",
    "function",
    "compare",
    "query",
    "every",
    "sample",
    "support",
    "set",
    "calculate",
    "similarity",
    "scores",
    "find",
    "sample",
    "highest",
    "similarity",
    "score",
    "use",
    "prediction",
    "use",
    "example",
    "demonstrate",
    "make",
    "prediction",
    "given",
    "query",
    "image",
    "want",
    "know",
    "image",
    "compare",
    "query",
    "every",
    "sample",
    "support",
    "set",
    "compare",
    "query",
    "greyhound",
    "similarity",
    "function",
    "outputs",
    "similarity",
    "score",
    "similarity",
    "score",
    "query",
    "bulldog",
    "similarity",
    "query",
    "armadillo",
    "samples",
    "support",
    "set",
    "get",
    "similarity",
    "scores",
    "among",
    "similarity",
    "scores",
    "biggest",
    "thus",
    "model",
    "predicts",
    "query",
    "otter",
    "learning",
    "performed",
    "way",
    "given",
    "support",
    "set",
    "compute",
    "similarity",
    "query",
    "every",
    "sample",
    "support",
    "set",
    "find",
    "similar",
    "sample",
    "research",
    "need",
    "datasets",
    "evaluating",
    "model",
    "introduce",
    "2",
    "datasets",
    "widely",
    "used",
    "research",
    "papers",
    "omniglot",
    "frequently",
    "used",
    "dataset",
    "dataset",
    "small",
    "megabytes",
    "omniglot",
    "dataset",
    "similar",
    "mnist",
    "mnist",
    "dataset",
    "digit",
    "recognition",
    "mnist",
    "10",
    "classes",
    "class",
    "6",
    "thousand",
    "samples",
    "contrast",
    "omniglot",
    "1",
    "thousand",
    "classes",
    "class",
    "20",
    "digits",
    "makes",
    "classification",
    "omniglot",
    "harder",
    "mnist",
    "download",
    "dataset",
    "using",
    "link",
    "import",
    "dataset",
    "using",
    "tensorflow",
    "dataset",
    "50",
    "alphabets",
    "hebrew",
    "greek",
    "latin",
    "etc",
    "every",
    "alphabet",
    "many",
    "characters",
    "example",
    "greek",
    "24",
    "letters",
    "alpha",
    "beta",
    "gamma",
    "way",
    "omega",
    "every",
    "character",
    "20",
    "digits",
    "written",
    "different",
    "people",
    "summary",
    "omniglot",
    "50",
    "alphabets",
    "including",
    "various",
    "languages",
    "like",
    "latin",
    "greek",
    "hebrew",
    "every",
    "alphabet",
    "multiple",
    "characters",
    "example",
    "greek",
    "24",
    "letters",
    "50",
    "alphabets",
    "total",
    "1623",
    "unique",
    "characters",
    "therefore",
    "dataset",
    "1623",
    "classes",
    "character",
    "written",
    "20",
    "different",
    "people",
    "means",
    "class",
    "20",
    "samples",
    "samples",
    "images",
    "training",
    "set",
    "30",
    "alphabets",
    "contain",
    "964",
    "characters",
    "thus",
    "964",
    "classes",
    "training",
    "set",
    "contains",
    "total",
    "samples",
    "test",
    "set",
    "20",
    "alphabets",
    "contain",
    "659",
    "characters",
    "thus",
    "659",
    "classes",
    "test",
    "set",
    "total",
    "samples",
    "another",
    "commonly",
    "used",
    "dataset",
    "100",
    "classes",
    "mushroom",
    "orange",
    "corn",
    "bird",
    "snake",
    "every",
    "class",
    "600",
    "samples",
    "dataset",
    "total",
    "60",
    "thousand",
    "samples",
    "learned",
    "basic",
    "concepts",
    "learning",
    "next",
    "class",
    "study",
    "siamese",
    "network",
    "learning"
  ],
  "keywords": [
    "give",
    "learning",
    "means",
    "making",
    "small",
    "number",
    "samples",
    "show",
    "4",
    "images",
    "look",
    "two",
    "never",
    "heard",
    "armadillo",
    "pangolin",
    "animals",
    "know",
    "difference",
    "query",
    "image",
    "learn",
    "using",
    "training",
    "prediction",
    "class",
    "network",
    "support",
    "set",
    "model",
    "different",
    "supervised",
    "goal",
    "recognize",
    "test",
    "way",
    "train",
    "big",
    "similarity",
    "objects",
    "ask",
    "kind",
    "tell",
    "data",
    "classes",
    "squirrel",
    "thus",
    "knows",
    "seen",
    "rabbit",
    "bulldog",
    "additional",
    "information",
    "6",
    "otter",
    "similar",
    "called",
    "every",
    "example",
    "one",
    "sample",
    "although",
    "traditional",
    "kid",
    "zoo",
    "animal",
    "water",
    "cards",
    "card",
    "taking",
    "compare",
    "use",
    "husky",
    "accuracy",
    "easier",
    "function",
    "x",
    "dataset",
    "used",
    "omniglot",
    "mnist",
    "20",
    "alphabets",
    "greek",
    "characters",
    "total"
  ]
}