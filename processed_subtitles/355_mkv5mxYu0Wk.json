{
  "text": "hello and welcome to this session on\ndata science with python so what are we\ngoing to do in this session we will talk\nabout what is data science and some of\nthe basics of python as you may be aware\ndata science we use either python or r\nas some of the tools and programming\nlanguages so this session the focus is\non python so we will talk about the\nbasics of python why to learn python how\nto install python and then we will talk\nabout some of the important libraries\nwhich are required for data analysis and\nthen we will go into little bit of\ndetails about exploratory data analysis\nand we will take an example there of\nloan prediction and we will see a little\nbit about data wrangling using pandas\nwhich is one of the libraries of python\nand then we will end up with small\npredictive model or logistic regression\nmodel which is a part of machine\nlearning and in case you need more\ndetails about machine learning in this\nsession we will probably not go into the\ndetails of machine learning there is a\nseparate session you might want to look\nat there is a separate video on machine\nlearning you might want to take a look\nat that if you need more details here we\nare just giving a quick overview to see\nhow we can use the scikit-learn library\nso we will not go into a lot of details\nabout the basics of machine learning all\nright so with that let's move forward so\nwhat is data science data science is\nabout finding insights from the data so\nif there is a lot of data if you have\nsufficient data how to analyze and find\nsome insights out of it this is what is\ndata science all about a couple of\nexamples here customer prediction now\nlet's say you have a customer base and\nyou want to find out who are most likely\nto buy your product so you can use from\nyour past behavior you can probably\ndevelop a model and try to predict who\nare the people out of the thousand leads\nor\npotential customers who will actually\nbuy so there may be some patterns that\nyou can use to predict similarly service\nplanning so for example you're running a\nrestaurant and you want to know how many\npeople will be coming or how many\ncustomers will be visiting your\nrestaurant on a given day now based on\nyour historical data you can build a\nmodel to predict that as well so that\nthere is no wastage of food and so on\nand so forth so these are\nvery quick and easy examples of how data\nscience can be used in business now\nlet's talk about python for doing data\nscience we need some kind of a\nprogramming language or a tool and so on\nso this session will be about python\nthere are other tools like for example r\nand we will probably do a separate video\non that but this session is on python\nand you must have already heard python\nis really becoming very popular\neverybody is talking about python not\nonly data science in iot and ai and many\nother places so it's a very popular it's\ngetting very popular so if you are not\nyet familiar with python this may be a\ngood time to get started with it so why\ndo we want to use python so basically\npython is used as a programming language\nbecause it is for data science because\nit has some rich tools from a\nmathematics and from a statistical\nperspective it has some rich tools so\nthat is one of the reasons why we use\npython and if you see some of the trends\nif you're probably tracking some of the\ntrends you will see that over the last\nfew years python has become programming\nlanguage of choice and especially for\ndata science sas was earlier one of the\nmost popular tools but now increasingly\npython is being used for doing data\nscience and of course as well as r one\nof the reasons of course is that python\nand r are open source compared to sas\nwhich is a commercial product so that\ncould definitely be one explanation but\nbeyond that i think it is the ease of\nunderstanding this language the ease of\nusing this language which is also making\nit very popular in addition to the\navailability of fantastic libraries for\nperforming data science what are the\nother factors there are speed then there\nare availability of number of packages\nand then of course the design goal all\nright so what are each of these design\ngoal primarily the syntax rules in\npython are relatively intuitive and easy\nto understand thereby it helps in\nbuilding applications with con size and\nreadable code base so with a few lines\nof code you can really achieve a lot of\nstuff and then there are a lot of\npackages that are available that have\nbeen developed by other people which can\nbe reused so we don't have to reinvent\nthe wheel and last but not least the\nspeed so python is a relatively faster\nlanguage of course it is not as fast as\nlet's say crc plus plus but then\nrelatively it is still faster so these\nare the three factors which make python\nthe programming language of choice so if\nyou want to get started with python the\nfirst thing obviously is to install\npython so there is some documentation\nand there are some steps that you need\nto follow so we will try to briefly\ntouch upon that otherwise of course\nthere is a lot of material available on\nhow to install python and so on you can\nalways look around but this is one of\nthe again there are different ways in\nwhich you can also install python so we\nwill use the anaconda path there is a\npackaging tool called anaconda so we\nwill use that path you can also directly\ninstall python but in our session we\nwill use the anaconda route so the first\nthing you need to do is download\nanaconda and this is the path for that\nand\nonce you click on this you will come to\na page somewhat like this and download\nyou can do the corresponding download\nbased on whether you have a windows or\nubuntu there is a also a downloader\npossible for our package available for\nubuntu if you are doing something on\nubuntu so based on which operating\nsystem in fact this page will\nautomatically detect which operating\nsystem you are having and it will\nactually suggest so for example you see\nhere if you are running mac os then it\nwill automatically detect that you have\nmax and the corresponding installers\nwill be displayed here similarly if\nyou're on some flavor of linux like\nubuntu or any other then you will get\nthe corresponding download links here\nand then beyond that you can also select\nwhich version of python you want to\ninstall of course the latest version is\nin the three point x range at the time\nof recording this 3.6 is one of the\nlatest versions but some of you may want\nto do or start with the earlier version\nwhich is python 2.7 to point x and you\ncan download that as well if you don't\nhave anything installed then my\nsuggestion is start with python 3.6 all\nright so once you do that you will be\nable to install python and you will be\nable to run jupyter notebook okay so now\nthat you know how to install python and\nif you have installed python let's take\na look at what are the various libraries\nthat are available so python is a very\neasy language to\nlearn and there are some basic stuff\nthat you can do for example adding or\nprinting a hello world statement and so\non without importing any specific\nlibraries but if you want to perform\ndata analysis you need to include or\nimport some specific libraries so we are\ngoing to talk about those as we move\nforward so pandas for example is used\nfor structured data operations so if you\nlet's say are performing something on a\ncsv file you import a csv file create a\ndata frame and then you can do a lot of\nstuffs like data munching and data\npreparation before you do any other\nstuff like for example machine learning\nor so on so that's pandas scipy as the\nname suggests it is kind of it provides\nmore scientific capabilities like for\nexample it has a linear algebra it has\nfourier transform and so on and so forth\nthen you have numpy which is a very\npowerful library for performing\nn-dimensional or creating n-dimensional\narrays and it also has some of the stuff\nthat is there in sci-fi like for example\nlinear algebra and fourier transform and\nso on and so forth then you have\nmatplotlib which is primarily for\nvisualization purpose it has again very\npowerful features for visualizing your\ndata for doing the initial what is known\nas exploratory data analysis for doing\nunivariate analysis bivariate analysis\nso this is extremely useful for\nvisualizing the data and then\nscikit-learn is used for performing all\nthe machine learning activities if you\nwant to do anything like linear\nregression classification or any of this\nstuff then the scikit-learn library will\nbe extremely helpful in addition to that\nthere are a few other libraries for\nexample networks and igraph then of\ncourse a very important one is\ntensorflow so if you are interested in\ndoing some deep learning or ai related\nstuff then it would be a good idea to\nlearn about tensorflow and tensorflow is\none of the libraries there is a separate\nvideo on tensorflow you can look for\nthat and this is uh one of the libraries\ncreated by google open source library so\nonce you're familiar with machine\nlearning data analysis machine learning\nthen that may be the next step to go to\ndeep learning and ai so that's where\ntensorflow will be used then you have\nbeautiful soup which is primarily used\nfor web scraping and then you take the\ndata and then analyze and so on then os\nlibrary is a very common library as the\nname suggests it is for operating system\nso if you want to do something on\ncreating directories or folders and\nthings like that that's when you would\nuse os all right so moving on let's talk\nin a little bit more detail about each\nof these libraries so scipy as the name\nsuggests is a scientific library and it\nvery specifically it has some special\nfunctions for integration and for\nordinary differential equations so as\nyou can see these are mathematical\noperations or mathematical functions so\nthese are readily available in this\nlibrary and it has linear algebra\nmodules and it is built on top of numpy\nso we will see what is there in numpy so\nthis is a again as the name suggests\nthat num comes from numbers so it is a\nmathematical library and one of its key\nfeatures is availability of an\nn-dimensional array object that is a\nvery powerful object and we will see how\nto use this and then of course you can\ncreate other let's say objects and so on\nand\nit has tools for integrating with cc\nplus plus and also for tran code and\nthen it of course also has linear\nalgebra and fourier transformation and\nso on all these scientific capabilities\nokay what else pandas is another very\npowerful library primarily for data\nmanipulation so\nif you're importing any files you will\nwant to create it like a table so you\nwill create what is known as data frames\nthese are very powerful data structures\nthat are used in python programming so\npandas library provides uh this\ncapability and once you import a data\nimport the data into data frame you can\npretty much do whatever you're doing\nlike in a regular database so people who\nare coming from a database background or\nsql background would really like this\nbecause it is very they will feel very\nmuch at home because it feels like\nyou're using you're viewing a table or\nusing a table and you can do a lot of\nstuff using the pandas library now there\nare two important terms or components in\npandas series and the data frame i was\njust talking about the data frame so\nlet's take a look at what are series and\nwhat is a data frame so within pandas we\nhave series and data frames so series is\nprimarily some of you may also be\nknowing this as let's say an array so\nit's a one-dimensional\nstructure data structure if you will so\nin some other languages we may call it\nas an array or maybe some others\nprobably an equivalent of a list in r\nperhaps i'm not very sure on that aspect\nbut yes so this is like a\none-dimensional storage of information\nso that is what is series whereas data\nframe is like a table so you have a\ntwo-dimensional structure you have rows\nand you have columns and this is very\npeople as i said who are familiar with\nsql and databases will be able to relate\nto this very quickly so you have like a\ntable you have rows and columns and then\nyou can manipulate the data so if you\nwant to create a series this is how you\nwould create a code snippet and as you\ncan see the programming in python is\nvery simple there are no major overheads\nyou just need to import some libraries\nwhichever essential and then start\ncreating objects so you don't have to do\nadditional declaration of variables and\nthings like that so that is i think one\nkey difference between python and other\nprogramming languages and what does this\nseries contain it has to contain these\nnumbers 6 3 4 6 and x is my object\nconsisting of the series so if you\ndisplay if you just say x it will\ndisplay the contents of x and you will\nsee here that it creates a default index\nthen you have data frames so if you want\nto create a data frame as you can see\nthe series is like a one-dimensional\nstructure there is just like a row one\nrow of items whereas a data frame looks\nsomewhat like this it is a\ntwo-dimensional structure so you have\ncolumns in one dimension and then you\nhave rows in the other dimension how do\nyou create a data frame you need to\ncreate you need to rather import pandas\nand then you import in this case we are\nbasically creating our own data so\nthat's the reason we are importing numpy\nwhich is one of the libraries we just\nrefer to a little bit before so\nwe are using one of the functionalities\nwithin numpy to create some random\nnumbers otherwise this is not really\nmandatory you probably will be importing\nthe data from outside maybe some csv\nfile and import into the data frame so\nthat's what we are doing here so in this\ncase we are creating our own test data\nthat's the reason we are importing numpy\nas np and then i create a data frame\nsaying pd dot data frame so this is the\nkeyword here similarly here in this case\nwhile creating series we said pd.series\nand then you pass the values similarly\nhere using pd.dataframe now in order to\ncreate the data frame it needs the\nvalues in each of these cells what are\nthe values in the rows and what are the\nvalues in the column so that in our\nexample we are providing using this\nrandom number generator so np dot random\nis like a class or a method that is\navailable in numpy and then you are\nsaying okay generate some random numbers\nin the form of a four by three matrix or\nfour by three data frame the four here\nindicates the number of rows and the\nthree here indicates the number of\ncolumns so these are the columns 0 1 2\nare the columns and these are the rows\nhere 0 this is 1 this is 2 this is 3\nokay and once again it will when you\ndisplay df it will give us a default\nindex there are ways to omit that but at\nthis point we will just keep it simple\nso it will display the default index and\nthen the actual values in each of these\nrows and columns so this is the way you\ncreate a data frame so now that we have\nlearned some of the basics of pandas\nlet's take a quick look at how we use\nthis in real life so let's assume we\nhave a situation where we have some\ncustomer data and we want to kind of\npredict whether a customer's loan will\nbe approved or not so we have some\nhistorical data about the loans and\nabout the customers and using that we\nwill try to come up with a way to maybe\npredict whether loan will be approved or\nnot so let's see how we can do that so\nthis is a part of exploratory analysis\nso we will first start with exploratory\nanalysis we will try to see how the data\nis looking so what kind of data so we\nwill of course i'll take you into the\njupiter notebook and give you a quick\nlive demo but before that let's quickly\nwalk through some of the pieces of this\nprogram in slides and then i will take\nyou actually into the actual code and do\na demo of that so the python program\nstructure looks somewhat like this the\nfirst step is to import your all the\nrequired libraries now of course it is\nnot necessary that you have to import\nall your libraries right at the top of\nthe code but it is a good practice so if\nyou know you are going to need a certain\nset of libraries it may be a good idea\nto put from a readability perspective\nit's a good practice to put all the\nlibraries that you're importing at the\nbeginning of your code however it is not\nmandatory so in the middle of the code\nsomewhere if you feel that you need a\nparticular library you can import that\nlibrary and then start using it in the\nmiddle of the code so that's also\nperfectly fine it will not give any\nerrors or anything however as i said\nit's not such a good practice so we will\nimport all the required libraries in\nthis case we are importing pandas numpy\nand matplotlib and in addition if we\ninclude this piece of code percentage\nmatplotlib inline what will happen is\nall the graphs that we are going to\ncreate the visualizations that we are\ngoing to create will be displayed within\nthe notebook so if you want to have that\nkind of a provision you need to have\nthis line so it's always a good idea\nwhen you're starting off i think it's a\ngood idea to just include this line so\nthat your graphs are shown in line okay\nso these are the four we will start with\nthese four lines of code then the next\nstep is to import your data so in our\ncase there is a training data for loans\nby the name loan p underscore train dot\ncsv and we are reading this data so in\nthis case you see here unlike the\nprevious example where we created a data\nframe with some data that we created\nourselves here we are actually creating\na data frame using some external data\nand it's the method is very very\nstraightforward so you use the read\nunderscore csv method and it is a very\nintuitive function name and you say pd\ndot read underscore csv and give the\npath of the file csv file that's about\nit and then that is read into the data\nframe df this can be any name we are\ncalling it df you can call xyz anything\nthere's a name just name of the object\nso head is one of the methods within the\ndata frame and it will give us the first\nfive so this is just to take a quick\nlook now you have imported the data you\nwant to initially have a quick look how\nyour data is looking what are the values\nin some of the columns and so on and so\nforth right so typically you would do a\nhead df dot head to get the sample of\nlet's say the first few lines of your\ndata so that's what has happened here so\nit displays the first few lines and then\nyou can see what are the columns within\nthat and\nwhat are the values in each of these\ncells and so on and so forth you can\nalso typically you would like to see if\nthere are any null values or are there\nany is the data for whatever reason is\ninvalid or looking dirty for whatever\nreason some unnecessary character so\nthis will give a quick view of that so\nin this case pretty much everything\nlooks okay then the next step is to\nunderstand the data a little bit overall\nfor each of the columns\nwhat is the information so the describe\nfunction will basically give us a\nsummary of the data what else can we do\npandas also allows us to visualize the\ndata and this is more like a part of\nwhat we call it as univariate analysis\nthat means each and every column you can\ntake and do some plots and visualization\nto understand data in each of the\ncolumns so for example here the loan\namount column we can take and then the\nhist basically hist method will create a\nhistogram so you take all the values\nfrom one column which is loan amount and\nyou create a histogram to see how the\ndata is distributed right so that's what\nis happening here and as you can see\nthere are some extreme values so this is\nagain to identify do we have to do some\ndata preparation because if the data is\nin a completely hazard way the analysis\nmay be difficult so we these are the\ninitial or exploratory data analysis is\nprimarily done to understand that and\nsee if we need to do some data\npreparation before we get into the other\nsteps like machine learning and\nstatistical modeling and so on so in\nthis case we will see that here\nby plotting this histogram we see that\nthere are some extreme values so there\nare some values a lot of it is around\n100 range but there is also something of\none or two observations in the 700 range\nso it's pretty scattered in that sense\nor they're not really scattered\ndistributedly scattered but it is\nrandomly scattered so the range is\nreally huge so what can we do about this\nso there are some steps that we need to\ndo normalization and so on so we'll see\nthat in a bit so this is for one of the\ncolumns let's take another column which\nis applicant income similar kind of\nsimilar situation you have most of your\nobservations in this range but there are\nalso some which are far off from where\nmost of the observations are so this is\nalso pretty this also has some extreme\nvalues so we'll have to see what can be\ndone credit history is the binary value\nso some people have a zero value and\nsome will have credit history of one\nthis is just like a flag so this\nbasically is telling us how many people\nhave a one and how many people have zero\nso it looks like majority of them have a\nvalue of 1 and a few about 100 of them\nhave a value of 0. okay what else can we\ndo so we now understood a little bit\nabout the data so we need to do some\ndata wrangling or data munching and see\nif we can some bring in some kind of\nnormalization of all this data and\nwe will kind of try to understand what\nis data wrangling and before we actually\ngo into it okay so data wrangling is\nnothing but a process of cleaning the\ndata if let's say there are there are\nmultiple things that can happen in this\nparticular example there were no missing\nvalues but typically when you get some\ndata very often it will so happen that a\nlot of values are missing either there\nare null values or there are a lot of\nzeros now you cannot use such data as it\nis to perform some let's say predictive\nanalysis or perform some machine\nlearning activities and so on so that is\none part of it so you need to clean the\ndata the other is unifying the data now\nthese ranges of this data are very huge\nsome of them are going from\nsome columns are going from 0 to 100 000\nand some columns are just between 10 to\n20 and so on these will affect the\naccuracy of the analysis so we need to\ndo some kind of unifying the data and so\non so that is what wrangling data\nwrangling is all about so before we\nactually perform any analysis we need to\nbring the data so to some kind of a\nshape so that we can perform additional\nanalysis actual analysis on this and get\nsome insights now how do we deal with\nmissing values is a very common issue\nwhen we take data or when we get data\nfrom the business when a data scientist\ngets the data from the business so we\nshould never assume that all our data\nwill be clean and all the values filled\nup and so on because in real life very\noften there will be the data will be\ndirty so data wrangling is the process\nwhere you kind of clean up the data\nfirst of all identify whether the data\nis dirty and then clean up so how do we\nfind some data is missing so there are a\nfew ways you can write a small piece of\ncode which will identify if for a given\ncolumn or for given row any of the\nobservations are null primarily so this\nline of code for example is doing that\nit is trying to identify how many null\nvalues or missing values are there for\neach of the columns so this is a lambda\nfunction and what we are saying is find\nout if a value is null and then you add\nall of them how many observations are\nthere where this particular column is\nnull so it does that for all the column\nso here you will see that for loan id\nobviously it's an id so there are no\nnull values or missing values gender has\nabout 13 observations where the values\nare missing similarly marital status as\nthree and so on and so forth so we'll\nsee here for example the loan amount has\n21 observations where the values are\nmissing loan amount term has 14\nobservations and so on so we'll see how\nto handle this missing values so there\nare multiple ways in which you can\nhandle missing values if the number of\nobservations are very small compared to\nthe total number of observations then\nsometimes one of the easy ways is to\ncompletely remove that data so or delete\nthat record exclude that record so that\nis one way of doing it so if there are\nlet's say a million records and maybe 10\nrecords are having missing values it may\nnot be\nworth doing something to fill up those\nvalues it may be better off to get rid\nof those observations right so that is\nthe missing values are proportionately\nvery small but if there are relatively\nlarge number of missing values if you\nexclude those observations then your\naccuracy may not be that very good so\nthe other way of doing it is we can take\na mean value or for a particular column\nand fill up wherever there are missing\nvalues fill up those observations or\ncells with the mean value so that way\nwhat happens is you don't give some\nvalue which is too high or too low and\nit somehow fits within the range of the\nobservations that we are seeing so this\nis one technique again there are it can\nbe case to case and you may have to take\na call based on your specific situation\nbut these are some of the common methods\nif you see in the previous case loan\namount had 21 and now we went ahead and\nfilled all of those with the mean value\nso now there are zero with missing\nvalues okay so this is one part of a\ndata wrangling activity what else you\ncan do you can also check what are the\ntypes of the data so df dot d types will\ngive us what are the various data types\nso all right so you can also perform\nsome basic mathematical observations we\nhave already seen that mean we found out\nso similarly if you do call the mean\nmethod for the data frame object it will\nactually perform or display or calculate\nthe mean for pretty much all the\nnumerical columns that are available in\nthis right so for example here applicant\nincome coeplicant income and all these\nare numerical values so it will\ndisplay the main values of all of those\nnow another thing that you can do is you\ncan actually also combine data frames so\nlet's say you import data from one csv\nfile into one data frame and another csv\nfile into another data frame and then\nyou want to merge these because you want\nto do an analysis on the entire data\nokay one example could be that you have\ndata in the form of csv files one csv\nfile for each month of the year january\nfebruary march each of these are in a\ndifferent so you can import them into\nlet's say 12 data frames and then you\ncan merge them together as a single data\nframe and then you perform your analysis\non the entire data frame or the entire\ndata for the year so that is one example\nso how do we do that this is how we do\nagain in this case we are not importing\nany data we are just creating some\nrandom values uh using some random\nvalues so let's assume i have a data\nframe which is by the name one and i\nassign some random values here which is\na five by four format so there are five\nrows and four columns and this is how my\ndata frame one looks and then i create\nanother data frame which is data frame\ntwo again random numbers of the format\nfive by four and i have something like\nthis now i want to combine these two how\ndo i combine these two i can use the\nconcatenate or concat method and i can\ncombine these two so pd dot concat and\nit takes the the data frames one and two\nif you have more of them you can provide\nthem and it will just simply add all of\nthem merge all of them or concatenate\nwhatever you call whichever term you\ncall\nit will so of course we have to make\nsure that the structure remains the same\nlike i said this could be let's say\nsales data coming for 12 different\nmonths but each of the files has the\nsame structure so now you can combine\nall of them merge all of them by using\nthe concat method if we have let's say\nstructure is not identical then what\nwill happen let's say we have these two\ndata frames one has a column by the name\nkey and the second column is lval and a\nsecond data frame which has\na column by the name key but the second\ncolumn by the name are well not l val so\nyou see here the structure is not\nidentical so you can still combine them\nbut then the way they get combined or\nmerged is somewhat like this so it takes\nthe key as a common parameter between\nthem some common column has to be there\notherwise this will not work and then we\nhave to use merge instead of concatenate\nand when we do a merge then we get the\nresult will be in this format what it\ndoes is it uses the key as the common\nthread between them and then it kind of\npopulates the values accordingly so if\nyou see here the first one had four and\nbar for key and then it had l values of\n1 and 2 right so if we go back 4 and bar\nhad 1 and 2 l values so that's what we\nsee here 1 and 2. whereas in the right\ndata frame we had foo bar and bar as a\nsecond time and then our values are\nthree four and five so what it has done\nfor foo it has put for the existing\nright for four is already existing\nbecause it has come from left so it will\njust put the value of r while here which\nis 3 similarly it will put 4 here\nbecause for bar if you go back for bar\nit is the value is 4 and since it has\none more value of bar it will go and add\nthis 5 as well the only thing here is\nthat this one had for example left had\nonly two values and only one value for\nbar but since we are appending or\nmerging and there are two key values\nwith the bar therefore it will kind of\nrepeat the value of l val here so that's\nwhat we are seeing in this case right so\nl value appears twice the number 2\nappears twice but that is because r\nvalue there are two of them okay all\nright so that is how when you don't have\nidentical structure that's how you merge\nnow we will talk a little bit about\nscikit-learn so scikit-learn is a\nlibrary which is used for doing machine\nlearning or work for performing machine\nlearning activities so if you want to do\nlinear regression logistic regression\nand so on there are easily usable apis\nthat you can call and that's\nthe advantage of scikit-learn and it\nprovides a bunch of algorithms so i\nthink that is the good part about this\nlibrary so if you want to use scikit\nlearn obviously you need to import these\nmodules and also there are some sub\nmodules you may have to import based on\nwhat you're trying to use like for\nexample if we know if we want to use\nlogistic regression again people who are\nprobably not very familiar with machine\nlearning there is a separate module for\nmachine learning you may want to take a\nlook at that but we will just touch upon\nthe basics here so machine learning has\nsome algorithms like linear regression\nlogistic regression and random forest\nclassification and so on so that is what\nwe are talking about here so those\nalgorithms are available and when if you\nwant to use some of them you need to\nimport them and from the scikit-learn\nlibrary so scikit-learn is the top-level\nlibrary which is basically sklearn right\nand then it has a kind of subparts in it\nyou need to import those based on what\nexactly you will be or which algorithm\nyou will be using so let's take an\nexample as we move and we will see that\nwhenever we perform some machine\nlearning activity those of you who are\nfamiliar with machine learning will\nalready know this we split our labeled\ndata into two parts training and test\nnow there are multiple ways of splitting\nthis data how do we either some people\ndo it like 50 50 some people do it 80 20\nwhich is training is 80 and test it is\n20 and so on so it is individual\npreference there are no hard and fast\nrules by and large we have seen that\ntraining data set is larger than the\ntest data set and again we will probably\nnot go into details of why do we do this\nat this point but that's one of the\nsteps in machine learning so scikit\nlearn offers a readily available method\nto do this which is strain test split\nall right so in this example let's say\nwe are taking the values x and y are our\nvalues x is the independent variables\nand y is our dependent variable okay and\nwe are using these two and then i want\nto split this into train and test data\nso what do we do we import the train\ntest split sub module from within scikit\nlearn which is sklearn right so within\nthat we import drain test split and then\nyou call the strain test split method or\nfunction or whatever you call it and\npass the data so x is the all the values\nof the independent variables and y is\nour labels so you pass x and y and then\nyou specify what should be your size of\nthe test data so only one you need to\nspecify so if you say test size is 0.25\nit is understood that train size will be\n0.75 so you're telling what should be\nthe ratio of the split so technically it\ndoesn't nothing prevents you from giving\nwhatever you like here so you can give\ntest as 80 and train as 20 so whichever\nway but then this normal practices you\nwill have the training data set would be\nlarger than the test data set and\ntypically it would be 80 20 75 25 or 65\n35 something like that right so that is\nthe second parameter and this is just to\nsay that you know the data has to be\nrandomly split so it shouldn't be like\nyou take the first 75 percent and put it\nin training and then the next 25 percent\nand put it in test so that so such a\nthing shouldn't happen so we first set\nthe state random state so that the the\nsplitting is done in a very random way\nso they randomly picked up the data and\nthen put it into training and test and\nthen this results in these four data\nframes so x train and x test and white\nrain and y test okay so that is\nbasically the result it will\nnow that the splitting is done let's see\nhow to implement or execute logistic\nregression so in logistic regression\nwhat we try to do is try to develop a\nmodel which will classify the data\nlogistic regression is an algorithm for\nsupervised learning for performing\nclassification so logistic regression is\nfor classification and usually it is\nbinary classification so binary\nclassification means there are two\nclasses so either like a yes no or for\nexample customer will buy or will not\nbuy so that is a binary classification\nso that's where we use logistic\nregression so let's take a look at the\ncode how to implement something like\nthat using psychic learn so the first\nthing is to import this logitech\nregression submodule or subclass\nwhatever you call it and then create an\ninstance of that so our object is\nclassifier so we are creating an object\nby the name this is a name by the way\nyou can give any name in our case we are\nsaying classifier we say classifier is\nequal to logistic regression so we are\ncreating an instance of the logistic\nregression variable or class or whatever\nokay and you can pass a variable or a\nparameter rather which is the random\nstate is equal to 0 and once you create\nthe object which in our case is named\nclassifier you can then train the object\nby calling the method fit so this is\nimportant to note we don't call any\nthere is no method like train here but\nwe call what is known as there is a\nmethod called fit so you are basically\nby calling the fit method you are\ntraining this model and\nin order to train the model you need to\npass the training data set so x\nunderscore train is your independent\nvariables the set of independent\nvariables and y underscore train is your\ndependent variable or the label so you\npass both of these and call the fit\nfunction or fit method which will\nactually result in the training of this\nmodel classifier now this is basically\nshowing what are the possible parameters\nthat can be passed or initiated when we\nare calling the logistic or the instance\nof logistic regression so this is but\nyou can also look up the help file if\nyou have installed python so some of\nthese are very intuitive but some you\nmay want to take a look at the details\nof what exactly they do all right so\nmoving on once we train the model by\ncalling fit then the next step is to\ntest our model so this is where we will\nuse the test data you need to pay\nattention here here i am calling so\nthere are two things one is in order to\ntest our data we have to actually call\nwhat is known as the method known as\npredict right so here this is where so\nthe training is done now is the time for\ninference isn't it so we have the model\nnow we want to check whether our model\nis working correctly or not so what do\nyou do you have your test data remember\nwe split it 25 percent of our data was\nstored here right we split it into test\nand training so that 25 of the data we\npass to and call the method predict so\nthat the model will now predict the\nvalues for y right so that's why here we\nare calling it as y underscore predict\nand\nif we display here as i said this is the\nlogistic regression which is basically\nbinary classification so it gives us the\nresults like yes or no in this\nparticular case and then you can so this\nis what the model has predicted our\nmodel has classified now but we also\nknow we already have the labels for this\nso we need to compare with the existing\nlabels with the known labels whether\nthis classification is correct or not so\nthat is where is the next step which is\nbasically calculating the accuracy and\nso on will come into play okay so in\nthis case the first thing most important\nthing to note is we do the prediction\nusing predict and here we are passing x\nunderscore test and not train right in\nthis case we did x and y ten so again\none more point to be noted here in case\nof training we will pass both the\nindependent variables and also the\ndependent variables because the system\nhas to internally it has to verify that\nis what is the training process so what\nit will do it will take the x values it\nwill try to come up with the y value and\ncompare with the actual y value right so\nthat is what is the training method so\nthat's why we have to pass both x as\nwell as y whereas in case of predict we\ndon't pass both we only pass because we\nare pretending as if this is the actual\ndata so in actual data you will not have\nthe labels isn't it so we are just\npassing the independent variables and\nthe system will then come up with the y\nvalues which we will then okay remember\nwe also know the actual value so we will\ncompare this with the actual values and\nwe will find out whether how accurate\nthe model is so how do we do that we use\nwhat is known as a confusion matrix so\nthis is also readily available in the\npython library so we import this\nconfusion matrix and some of you who\nalready know machine learning will find\nthis familiar but those who are new to\nmachine learning this confusion matrix\nis nothing but this matrix this kind of\na matrix which basically tells how many\nof them are correctly predicted and how\nmany of them are incorrectly predicted\nso the some of the characteristics let's\nquickly spend some time on this\nconfusion matrix itself this the total\nnumbers out here these are just the\nnumbers these are like number of\nobservations then the accuracy is\nconsidered to be highest when the the\nnumbers or the sum of the numbers across\nthe diagonals is maximum okay and the\nnumbers outside of the diagonal should\nbe minimum so which means that if this\nmodel was 100 percent accurate then the\nsum of these two there would have been\nonly numbers in these two along the\ndiagonal this would have been zero and\nthis would have been zero okay so that\nis like a hundred percent accurate model\nthat is very rare but just that you are\naware so just to give an idea okay all\nright so once you have the confusion\nmatrix you then try to calculate the\naccuracy which is in a percentage so\nthere are two things that we can do from\na confusion matrix or that we can\ncalculate from a confusion matrix one is\nthe accuracy and the other is the\nprecision what is the accuracy accuracy\nis basically a measure of how many of\nthe observations have been correctly\npredicted okay so let's say this is a\nlittle bit more detailed view of the\nconfusion matrix it looks very similar\nlike as we saw in this case right so\nthis is a two by two matrix that's what\nwe're seeing here 18 27 2 1 0 3 so 18 27\n2 1 0 3. now but what are these values\nthat is what is kind of the labels are\nshown here in this so there are\naltogether 150 observations so as i said\nthe sum of all these 4 right 18 plus 27\nplus 1 0 3 plus 2 is equal to 150 that's\nthe first thing we have to observe the\nsum of all these values will be equal to\nthe sum of test observations number of\ntest observations we have 150 test\nobservations because remember we had\nabout 500 we split that into 2575 so\nthat is why we have 150 here and i think\n350 in the training data set okay so\nthat we get the numbers correct so\nthat's the first thing now this next\nthing is let's take a look at the actual\nvalues this view is the actual view so\nthere are actually right in the actual\ndata we have labels yes and no so as per\nthe actual data there are 45\nobservations tagged as no and similarly\nthere are 105 observations that are\ntagged as yes or labeled as yes okay now\ni know for the first time when you're\nseeing this it may be a little confusing\nbut just stay with me okay so this is\nthe actual part of it and this side\ntells us the predicted part of it so our\nmodel is predicted and it has totally\npredicted 20 of them as no right so that\nis what this is totally 20 of them it\nhas predicted as no and it has predicted\n130 of them as yes okay i hope this part\nis clear so before we go into the middle\npart let us first understand what\nexactly are these numbers so actually\ntagged as no there are 45 total actually\ntagged as yes there are 105 and\npredicted no there are 20 predicted as\nyes there are 130. this is the result\nfrom our model okay this is the result\nfrom our model and this is the actual\nvalue which we already know because this\nis our label data that's the first thing\nnow now let us take a look at each of\nthese individually okay now what are the\noptions we have once again okay so now\nwhat is happening here let us look at\nthese these values so this 18 says that\nthese are actually tagged as no and the\nmodel is also predicted as no which\nmeans this is what is known as a true\npositive right or true negative sorry\nright which means that our model has\npredicted is it correctly it is negative\nbecause it says no so and it is also\npredicted no so it is known as what is\nknown as true negative okay now let's\ncome to this side of it that way we are\ntalking about the diagonal remember i\nsaid most of the values should be in the\ndiagonal okay so that means these 18 are\ncorrectly tagged they are labeled as no\nand our model is predicted as no so\nthese are correctly tagged and these are\nknown as true negative okay similarly if\nwe come diagonally down there are 103\nobservations which are labeled as yes\nactual value is s and our model is also\npredicted as yes and these are known as\ntrue positive values positive because of\nthis yes okay right so what is important\nis this is true this is also true so we\nhave to make sure that the maximum\nnumber of values are in the true section\nokay true positive and true negative\nthat's the reason i said the sum along\nthe diagonal should be maximum now let's\nsee if our model was 100 accurate this\nsum in this case it is only 103 plus 103\nplus 18 which is\n121 but if our model was accurate the\nsum of these two would have been 150\nthat means it's a perfect model okay all\nright now what else since we covered\nthese two let's also cover these two so\nhere this says that 27 of them were\nactually labeled no but our model is\npredicted as yes that means this is\nwrong right similarly these are two of\nthem where the actual value is yes but\nour model is predicted as no that means\nit's a wrong prediction so you get the\npoint so therefore along the diagonals\nare the correct values whereas in other\nplaces it is all wrong values or wrong\npredictions okay now how do we calculate\naccuracy from this information so the\nway to calculate accuracy is so we say\nokay there are total observations are\n150 and what are the correctly predicted\nvalues these are the correctly predicted\nvalues which is 18 plus 103 so this will\ngive us our accuracy so 103 plus 18\nwhich is 121 divided by our total\nobservations which is 150 is our\naccuracy which is 0.8 or we can say it\nis 80 percent okay now there is another\nconcept called precision so precision is\ngiven by the formula true positives\ndivided by the predicted positives\ntotally predicted positives okay what do\nwe mean by that which are the true\npositives here remember which are the\ntrue positives we just recall we just\ntalked in the previous slide which are\nthe true positives you see here so this\n103 are the true positives which means\nthat the value is positive actual value\nis positive predicted value is also\npositive so that's why it's called a\ntrue positive so 103 divided by so that\nis our true positive 103 divided by\ntotally predicted as yes now what is\ntotally predicted is yes remember 130 of\nthem have altogether been predicted as\nyes not that they are correctly\npredicted only 103 have been correctly\npredicted but 130 of them have been\npredicted as yes so precision is\nbasically the ratio of these two out of\nthe totally predicted how many of them\nare actually true that ratio so 103 by\n130 which is again about 80 percent is\nthe precision that's how you calculate\nprecision so this is just a simple\nformula and the term that you need to\nremember so accuracy is you need to take\ntotal of true positive and true negative\ndivided by the total number of\nobservations whereas precision is true\npositives divided by the totally\npredicted positives okay so that is our\naccuracy and precision now what we did\nthe accuracy calculation was manual but\nwe can also use some libraries which are\nalready existing and the functions\nwithin that library so a scikit-learn\nprovides uh one such method so for\nexample accuracy underscore score is one\nsuch method so if you use that and pass\nyour test and predicted values only the\ny you need to pass right the dependent\nvariable values so if you pass that it\nwill calculate it for you so in this\ncase again as you can see it still\ncalculates the same which is 80 which we\nhave seen here as well okay so this can\nbe done using the method great so that's\npretty much what we have done here\nbefore we conclude let me take you into\nthe code and show you how it actually\nlooks okay so\nthis is our code let me run it okay one\nby one we have already seen most of the\nsteps in the slides so i will but i will\nrun this in the actual jupyter notebook\nsome of you if you are not yet familiar\nwith jupiter notebook again there are\nother videos we created on how to\ninstall jupyter notebook and how to set\nup jupyter notebook and so on in this\ntutorial also we there was one slide on\nhow to install python and jupyter\nnotebook if you have not yet done please\ndo that so that then you can actually\nwalk through this code while you're\nwatching this okay so what are we doing\nhere we are importing the libraries\nrequired libraries recall here we have\npandas we have numpy and for\nvisualization we have matplotlib and\nthis line is basically reading the csv\nfile so we have the csv file locally on\nour local drive and this is where i'm\nchecking the data just so i'm starting\nwith my exploratory analysis how the\ndata is looking so it looks good there\nare no major missing values or anything\nlike that so it will display all the\ncolumns and it will show me the first\nfive rows if when i'm using this head\nfunction and then i want to see a kind\nof a summary of all the each of the\nnumerical columns so that's what i'm\ndoing here so these are the numerical\ncolumns and it gives a summary like how\nmany observations are there what is the\nmean standard deviation minimum maximum\nand so on and so forth for each of them\nand then you can\ndo some visualization so this is the\nvisualization for this okay the next\nstep is to view the data data\nvisualization and we will do that using\na histogram for a couple of these\ncolumns so in this case i'm taking a\nlook at the loan amount and if i create\nthe histogram it displays the data here\nin the form of a histogram one thing\nthat we gather from this as i mentioned\nin the slides as well is how the data is\nkind of scattered so while most of the\nvalues are in this range 0 to 300 range\nthere are a few extreme values around\nthe 700 range so that is one information\nwe get from this histogram similarly for\nthe applicant income if we draw a\nhistogram something similar we can see\nthat while most of the values are in\nthis range 0 to 20 000 range there are a\nfew in the range of 80 000 and probably\n65 000 and so on okay so the next step\nis to perform data wrangling where we\nwill check if any data is missing and\nhow to fill those missing values and so\non so in this case we will just check\nfor all the columns how many data or how\nmany entries are there with missing\nvalues so this is the results the loan\nid has all the columns or all the cells\nfilled gender has 13 missing values\nmarital status has three missing values\nand so on and so forth loan amount has\n21 and this is what we are going to show\nyou how to remove these missing values\nso when you have missing values as i\nmentioned in the during the slides there\nare a couple of ways of handling that\none is you can completely remove those\nor you fill in with some meaningful\nvalue so in this case we will fill the\nmissing values with the mean value of\nthe loan amount so let's go ahead and do\nthat and\nnow if we check here now loan amount\nnumber of missing values is 0 because\nwhat we did was for all these 21 cells\nwhere the values were missing we filled\nwith the mean value of the loan amount\nso now there are no more missing values\nfor loan amount we can do this for other\ncolumns as well but this was just one\nexample so we have shown it here okay so\nwe will run this for credit history and\nloan amount term as well and\nthen if we calculate the mean of pretty\nmuch all the numerical columns that's\nthe method call so df.mean will give us\nthe mean of all the numerical values and\nanother thing that we can do is we want\nto find out what are the data types of\neach of these columns so you can call\ndf.d types and get the data types of\ncourse it may not be that very useful\nmost of the cases is an object but for\nexample this one it shows as int 64 and\nthere are float64 and so on and so forth\nnow in addition to doing the\nexploratory data analysis we can do some\nmachine learning activity as well so in\nthis case we are going to do logistic\nregression so this is the example that i\nhave shown you in the slides as well\nthis is the actual code for that all\nright so the first step here is to\nimport the libraries and then the next\nstep is to separate the independent\nvariables and the dependent variables so\nx is our independent variable and y is\nour dependent variable so we separate\nthe data into two parts and this will be\nour target as well right so that's how\nwe separate it now\nwe have to split the data into training\nand test data sets as i mentioned in the\nduring the slides we use the train test\nsplit method and when we call this and\npass the independent variables and the\ndependent variables and we specify the\ntest size to be 0.25 which means the\ntraining size will be 0.75 which is\nnothing but you split the data into\ntraining data set which is 75 percent\nand test data set in which is 25\nokay so once you split that you will\nhave all your independent variables data\nin x strain the training data which is\n75 percent of it similarly independent\nvariables for test will be in x\nunderscore test and dependent variable\nstrain will be in underscore train and\ndependent variable test will be y\nunderscore test once we do this we have\nto do a small exercise for scaling\nremember we had some data which was kind\nof very scattered there were some\nextreme values and so on so this will\ntake care of that so that the data is\nnormalized so that before we pass to our\nalgorithm the data is normalized so that\nthe performance will be much better the\nnext step is to create the instance of\nlogistic regression object so that's\nwhat we are doing here so classifier is\nour logistic regression instance right\nclassifier is equal to logistic\nregression we are saying so one instance\nof logistic regression is created and\nthen we call the training method the\nname of the method actually is fit but\nwhat it is doing is it is taking the\ntraining data x is the training data the\nindependent variables and y is the\ndependent variable so we are taking both\nof these and the model gets trained so\nthe method for calling the training is\nfit okay so it gives us the output and\nthen once we are done with the training\nwe do the testing and once again just to\nrecall in the slides when i was showing\nyou the slides also i mentioned we don't\npass y here while we are testing well\nfor training we do pass y but right so\nfor fit we are passing x and y but for\ntest we are only passing x something you\nneed to observe because y will be\ncalculated by the model and we will then\ncompare that with the known value of y\nto measure the accuracy so that's what\nwe will do here and the method that is\ncalled here is predict so this will\nbasically create or predict the values\nof y now we have in this case a binary\nclassification so the outputs are yes or\nno y indicates yes and n indicates no so\ny or n is the output now how do we\nmeasure the accuracy as we have seen\nearlier i described how confusion matrix\nworks and how we can use confusion\nmatrix for calculating the accuracy\nthat's what we are seeing here so this\nis the confusion matrix and then you\nwant to do the measure the accuracy you\ncan directly use this method and we find\nthat it is 80 so we in the slides we\nhave seen when we calculate manually as\nwell we get an accuracy of 80 okay let's\ngo back to our slides and\ndo a summary so what we have done in the\nsession we talked about what is data\nscience and\n[Music]\nwhy python is being used why it is\nbecoming so popular how to install\npython and we talked about the various\nlibraries in python like panda scipy\nnumpy and so on and then we took a\ncouple of examples\nand wrote the code and demonstrated the\ncode for performing exploratory analysis\nand\nperforming data wrangling or data\nmanipulation\nand then we at the end we did one\nexample of machine learning using\nscikit-learn\nlibrary and perform the logistic\nregression example\nso with that we come to the end of the\nsession if you have any queries comments\nplease put them below\nand you can also give your email id so\nthat we can get back to you if you have\nany questions i hope you enjoyed the\nsession thank you very much\nhi there if you like this video\nsubscribe to the simply learn youtube\nchannel and click here to watch similar\nvideos turn it up and get certified\nclick here\n",
  "words": [
    "hello",
    "welcome",
    "session",
    "data",
    "science",
    "python",
    "going",
    "session",
    "talk",
    "data",
    "science",
    "basics",
    "python",
    "may",
    "aware",
    "data",
    "science",
    "use",
    "either",
    "python",
    "r",
    "tools",
    "programming",
    "languages",
    "session",
    "focus",
    "python",
    "talk",
    "basics",
    "python",
    "learn",
    "python",
    "install",
    "python",
    "talk",
    "important",
    "libraries",
    "required",
    "data",
    "analysis",
    "go",
    "little",
    "bit",
    "details",
    "exploratory",
    "data",
    "analysis",
    "take",
    "example",
    "loan",
    "prediction",
    "see",
    "little",
    "bit",
    "data",
    "wrangling",
    "using",
    "pandas",
    "one",
    "libraries",
    "python",
    "end",
    "small",
    "predictive",
    "model",
    "logistic",
    "regression",
    "model",
    "part",
    "machine",
    "learning",
    "case",
    "need",
    "details",
    "machine",
    "learning",
    "session",
    "probably",
    "go",
    "details",
    "machine",
    "learning",
    "separate",
    "session",
    "might",
    "want",
    "look",
    "separate",
    "video",
    "machine",
    "learning",
    "might",
    "want",
    "take",
    "look",
    "need",
    "details",
    "giving",
    "quick",
    "overview",
    "see",
    "use",
    "library",
    "go",
    "lot",
    "details",
    "basics",
    "machine",
    "learning",
    "right",
    "let",
    "move",
    "forward",
    "data",
    "science",
    "data",
    "science",
    "finding",
    "insights",
    "data",
    "lot",
    "data",
    "sufficient",
    "data",
    "analyze",
    "find",
    "insights",
    "data",
    "science",
    "couple",
    "examples",
    "customer",
    "prediction",
    "let",
    "say",
    "customer",
    "base",
    "want",
    "find",
    "likely",
    "buy",
    "product",
    "use",
    "past",
    "behavior",
    "probably",
    "develop",
    "model",
    "try",
    "predict",
    "people",
    "thousand",
    "leads",
    "potential",
    "customers",
    "actually",
    "buy",
    "may",
    "patterns",
    "use",
    "predict",
    "similarly",
    "service",
    "planning",
    "example",
    "running",
    "restaurant",
    "want",
    "know",
    "many",
    "people",
    "coming",
    "many",
    "customers",
    "visiting",
    "restaurant",
    "given",
    "day",
    "based",
    "historical",
    "data",
    "build",
    "model",
    "predict",
    "well",
    "wastage",
    "food",
    "forth",
    "quick",
    "easy",
    "examples",
    "data",
    "science",
    "used",
    "business",
    "let",
    "talk",
    "python",
    "data",
    "science",
    "need",
    "kind",
    "programming",
    "language",
    "tool",
    "session",
    "python",
    "tools",
    "like",
    "example",
    "r",
    "probably",
    "separate",
    "video",
    "session",
    "python",
    "must",
    "already",
    "heard",
    "python",
    "really",
    "becoming",
    "popular",
    "everybody",
    "talking",
    "python",
    "data",
    "science",
    "iot",
    "ai",
    "many",
    "places",
    "popular",
    "getting",
    "popular",
    "yet",
    "familiar",
    "python",
    "may",
    "good",
    "time",
    "get",
    "started",
    "want",
    "use",
    "python",
    "basically",
    "python",
    "used",
    "programming",
    "language",
    "data",
    "science",
    "rich",
    "tools",
    "mathematics",
    "statistical",
    "perspective",
    "rich",
    "tools",
    "one",
    "reasons",
    "use",
    "python",
    "see",
    "trends",
    "probably",
    "tracking",
    "trends",
    "see",
    "last",
    "years",
    "python",
    "become",
    "programming",
    "language",
    "choice",
    "especially",
    "data",
    "science",
    "sas",
    "earlier",
    "one",
    "popular",
    "tools",
    "increasingly",
    "python",
    "used",
    "data",
    "science",
    "course",
    "well",
    "r",
    "one",
    "reasons",
    "course",
    "python",
    "r",
    "open",
    "source",
    "compared",
    "sas",
    "commercial",
    "product",
    "could",
    "definitely",
    "one",
    "explanation",
    "beyond",
    "think",
    "ease",
    "understanding",
    "language",
    "ease",
    "using",
    "language",
    "also",
    "making",
    "popular",
    "addition",
    "availability",
    "fantastic",
    "libraries",
    "performing",
    "data",
    "science",
    "factors",
    "speed",
    "availability",
    "number",
    "packages",
    "course",
    "design",
    "goal",
    "right",
    "design",
    "goal",
    "primarily",
    "syntax",
    "rules",
    "python",
    "relatively",
    "intuitive",
    "easy",
    "understand",
    "thereby",
    "helps",
    "building",
    "applications",
    "con",
    "size",
    "readable",
    "code",
    "base",
    "lines",
    "code",
    "really",
    "achieve",
    "lot",
    "stuff",
    "lot",
    "packages",
    "available",
    "developed",
    "people",
    "reused",
    "reinvent",
    "wheel",
    "last",
    "least",
    "speed",
    "python",
    "relatively",
    "faster",
    "language",
    "course",
    "fast",
    "let",
    "say",
    "crc",
    "plus",
    "plus",
    "relatively",
    "still",
    "faster",
    "three",
    "factors",
    "make",
    "python",
    "programming",
    "language",
    "choice",
    "want",
    "get",
    "started",
    "python",
    "first",
    "thing",
    "obviously",
    "install",
    "python",
    "documentation",
    "steps",
    "need",
    "follow",
    "try",
    "briefly",
    "touch",
    "upon",
    "otherwise",
    "course",
    "lot",
    "material",
    "available",
    "install",
    "python",
    "always",
    "look",
    "around",
    "one",
    "different",
    "ways",
    "also",
    "install",
    "python",
    "use",
    "anaconda",
    "path",
    "packaging",
    "tool",
    "called",
    "anaconda",
    "use",
    "path",
    "also",
    "directly",
    "install",
    "python",
    "session",
    "use",
    "anaconda",
    "route",
    "first",
    "thing",
    "need",
    "download",
    "anaconda",
    "path",
    "click",
    "come",
    "page",
    "somewhat",
    "like",
    "download",
    "corresponding",
    "download",
    "based",
    "whether",
    "windows",
    "ubuntu",
    "also",
    "downloader",
    "possible",
    "package",
    "available",
    "ubuntu",
    "something",
    "ubuntu",
    "based",
    "operating",
    "system",
    "fact",
    "page",
    "automatically",
    "detect",
    "operating",
    "system",
    "actually",
    "suggest",
    "example",
    "see",
    "running",
    "mac",
    "os",
    "automatically",
    "detect",
    "max",
    "corresponding",
    "installers",
    "displayed",
    "similarly",
    "flavor",
    "linux",
    "like",
    "ubuntu",
    "get",
    "corresponding",
    "download",
    "links",
    "beyond",
    "also",
    "select",
    "version",
    "python",
    "want",
    "install",
    "course",
    "latest",
    "version",
    "three",
    "point",
    "x",
    "range",
    "time",
    "recording",
    "one",
    "latest",
    "versions",
    "may",
    "want",
    "start",
    "earlier",
    "version",
    "python",
    "point",
    "x",
    "download",
    "well",
    "anything",
    "installed",
    "suggestion",
    "start",
    "python",
    "right",
    "able",
    "install",
    "python",
    "able",
    "run",
    "jupyter",
    "notebook",
    "okay",
    "know",
    "install",
    "python",
    "installed",
    "python",
    "let",
    "take",
    "look",
    "various",
    "libraries",
    "available",
    "python",
    "easy",
    "language",
    "learn",
    "basic",
    "stuff",
    "example",
    "adding",
    "printing",
    "hello",
    "world",
    "statement",
    "without",
    "importing",
    "specific",
    "libraries",
    "want",
    "perform",
    "data",
    "analysis",
    "need",
    "include",
    "import",
    "specific",
    "libraries",
    "going",
    "talk",
    "move",
    "forward",
    "pandas",
    "example",
    "used",
    "structured",
    "data",
    "operations",
    "let",
    "say",
    "performing",
    "something",
    "csv",
    "file",
    "import",
    "csv",
    "file",
    "create",
    "data",
    "frame",
    "lot",
    "stuffs",
    "like",
    "data",
    "munching",
    "data",
    "preparation",
    "stuff",
    "like",
    "example",
    "machine",
    "learning",
    "pandas",
    "scipy",
    "name",
    "suggests",
    "kind",
    "provides",
    "scientific",
    "capabilities",
    "like",
    "example",
    "linear",
    "algebra",
    "fourier",
    "transform",
    "forth",
    "numpy",
    "powerful",
    "library",
    "performing",
    "creating",
    "arrays",
    "also",
    "stuff",
    "like",
    "example",
    "linear",
    "algebra",
    "fourier",
    "transform",
    "forth",
    "matplotlib",
    "primarily",
    "visualization",
    "purpose",
    "powerful",
    "features",
    "visualizing",
    "data",
    "initial",
    "known",
    "exploratory",
    "data",
    "analysis",
    "univariate",
    "analysis",
    "bivariate",
    "analysis",
    "extremely",
    "useful",
    "visualizing",
    "data",
    "used",
    "performing",
    "machine",
    "learning",
    "activities",
    "want",
    "anything",
    "like",
    "linear",
    "regression",
    "classification",
    "stuff",
    "library",
    "extremely",
    "helpful",
    "addition",
    "libraries",
    "example",
    "networks",
    "igraph",
    "course",
    "important",
    "one",
    "tensorflow",
    "interested",
    "deep",
    "learning",
    "ai",
    "related",
    "stuff",
    "would",
    "good",
    "idea",
    "learn",
    "tensorflow",
    "tensorflow",
    "one",
    "libraries",
    "separate",
    "video",
    "tensorflow",
    "look",
    "uh",
    "one",
    "libraries",
    "created",
    "google",
    "open",
    "source",
    "library",
    "familiar",
    "machine",
    "learning",
    "data",
    "analysis",
    "machine",
    "learning",
    "may",
    "next",
    "step",
    "go",
    "deep",
    "learning",
    "ai",
    "tensorflow",
    "used",
    "beautiful",
    "soup",
    "primarily",
    "used",
    "web",
    "scraping",
    "take",
    "data",
    "analyze",
    "os",
    "library",
    "common",
    "library",
    "name",
    "suggests",
    "operating",
    "system",
    "want",
    "something",
    "creating",
    "directories",
    "folders",
    "things",
    "like",
    "would",
    "use",
    "os",
    "right",
    "moving",
    "let",
    "talk",
    "little",
    "bit",
    "detail",
    "libraries",
    "scipy",
    "name",
    "suggests",
    "scientific",
    "library",
    "specifically",
    "special",
    "functions",
    "integration",
    "ordinary",
    "differential",
    "equations",
    "see",
    "mathematical",
    "operations",
    "mathematical",
    "functions",
    "readily",
    "available",
    "library",
    "linear",
    "algebra",
    "modules",
    "built",
    "top",
    "numpy",
    "see",
    "numpy",
    "name",
    "suggests",
    "num",
    "comes",
    "numbers",
    "mathematical",
    "library",
    "one",
    "key",
    "features",
    "availability",
    "array",
    "object",
    "powerful",
    "object",
    "see",
    "use",
    "course",
    "create",
    "let",
    "say",
    "objects",
    "tools",
    "integrating",
    "cc",
    "plus",
    "plus",
    "also",
    "tran",
    "code",
    "course",
    "also",
    "linear",
    "algebra",
    "fourier",
    "transformation",
    "scientific",
    "capabilities",
    "okay",
    "else",
    "pandas",
    "another",
    "powerful",
    "library",
    "primarily",
    "data",
    "manipulation",
    "importing",
    "files",
    "want",
    "create",
    "like",
    "table",
    "create",
    "known",
    "data",
    "frames",
    "powerful",
    "data",
    "structures",
    "used",
    "python",
    "programming",
    "pandas",
    "library",
    "provides",
    "uh",
    "capability",
    "import",
    "data",
    "import",
    "data",
    "data",
    "frame",
    "pretty",
    "much",
    "whatever",
    "like",
    "regular",
    "database",
    "people",
    "coming",
    "database",
    "background",
    "sql",
    "background",
    "would",
    "really",
    "like",
    "feel",
    "much",
    "home",
    "feels",
    "like",
    "using",
    "viewing",
    "table",
    "using",
    "table",
    "lot",
    "stuff",
    "using",
    "pandas",
    "library",
    "two",
    "important",
    "terms",
    "components",
    "pandas",
    "series",
    "data",
    "frame",
    "talking",
    "data",
    "frame",
    "let",
    "take",
    "look",
    "series",
    "data",
    "frame",
    "within",
    "pandas",
    "series",
    "data",
    "frames",
    "series",
    "primarily",
    "may",
    "also",
    "knowing",
    "let",
    "say",
    "array",
    "structure",
    "data",
    "structure",
    "languages",
    "may",
    "call",
    "array",
    "maybe",
    "others",
    "probably",
    "equivalent",
    "list",
    "r",
    "perhaps",
    "sure",
    "aspect",
    "yes",
    "like",
    "storage",
    "information",
    "series",
    "whereas",
    "data",
    "frame",
    "like",
    "table",
    "structure",
    "rows",
    "columns",
    "people",
    "said",
    "familiar",
    "sql",
    "databases",
    "able",
    "relate",
    "quickly",
    "like",
    "table",
    "rows",
    "columns",
    "manipulate",
    "data",
    "want",
    "create",
    "series",
    "would",
    "create",
    "code",
    "snippet",
    "see",
    "programming",
    "python",
    "simple",
    "major",
    "overheads",
    "need",
    "import",
    "libraries",
    "whichever",
    "essential",
    "start",
    "creating",
    "objects",
    "additional",
    "declaration",
    "variables",
    "things",
    "like",
    "think",
    "one",
    "key",
    "difference",
    "python",
    "programming",
    "languages",
    "series",
    "contain",
    "contain",
    "numbers",
    "6",
    "3",
    "4",
    "6",
    "x",
    "object",
    "consisting",
    "series",
    "display",
    "say",
    "x",
    "display",
    "contents",
    "x",
    "see",
    "creates",
    "default",
    "index",
    "data",
    "frames",
    "want",
    "create",
    "data",
    "frame",
    "see",
    "series",
    "like",
    "structure",
    "like",
    "row",
    "one",
    "row",
    "items",
    "whereas",
    "data",
    "frame",
    "looks",
    "somewhat",
    "like",
    "structure",
    "columns",
    "one",
    "dimension",
    "rows",
    "dimension",
    "create",
    "data",
    "frame",
    "need",
    "create",
    "need",
    "rather",
    "import",
    "pandas",
    "import",
    "case",
    "basically",
    "creating",
    "data",
    "reason",
    "importing",
    "numpy",
    "one",
    "libraries",
    "refer",
    "little",
    "bit",
    "using",
    "one",
    "functionalities",
    "within",
    "numpy",
    "create",
    "random",
    "numbers",
    "otherwise",
    "really",
    "mandatory",
    "probably",
    "importing",
    "data",
    "outside",
    "maybe",
    "csv",
    "file",
    "import",
    "data",
    "frame",
    "case",
    "creating",
    "test",
    "data",
    "reason",
    "importing",
    "numpy",
    "np",
    "create",
    "data",
    "frame",
    "saying",
    "pd",
    "dot",
    "data",
    "frame",
    "keyword",
    "similarly",
    "case",
    "creating",
    "series",
    "said",
    "pass",
    "values",
    "similarly",
    "using",
    "order",
    "create",
    "data",
    "frame",
    "needs",
    "values",
    "cells",
    "values",
    "rows",
    "values",
    "column",
    "example",
    "providing",
    "using",
    "random",
    "number",
    "generator",
    "np",
    "dot",
    "random",
    "like",
    "class",
    "method",
    "available",
    "numpy",
    "saying",
    "okay",
    "generate",
    "random",
    "numbers",
    "form",
    "four",
    "three",
    "matrix",
    "four",
    "three",
    "data",
    "frame",
    "four",
    "indicates",
    "number",
    "rows",
    "three",
    "indicates",
    "number",
    "columns",
    "columns",
    "0",
    "1",
    "2",
    "columns",
    "rows",
    "0",
    "1",
    "2",
    "3",
    "okay",
    "display",
    "df",
    "give",
    "us",
    "default",
    "index",
    "ways",
    "omit",
    "point",
    "keep",
    "simple",
    "display",
    "default",
    "index",
    "actual",
    "values",
    "rows",
    "columns",
    "way",
    "create",
    "data",
    "frame",
    "learned",
    "basics",
    "pandas",
    "let",
    "take",
    "quick",
    "look",
    "use",
    "real",
    "life",
    "let",
    "assume",
    "situation",
    "customer",
    "data",
    "want",
    "kind",
    "predict",
    "whether",
    "customer",
    "loan",
    "approved",
    "historical",
    "data",
    "loans",
    "customers",
    "using",
    "try",
    "come",
    "way",
    "maybe",
    "predict",
    "whether",
    "loan",
    "approved",
    "let",
    "see",
    "part",
    "exploratory",
    "analysis",
    "first",
    "start",
    "exploratory",
    "analysis",
    "try",
    "see",
    "data",
    "looking",
    "kind",
    "data",
    "course",
    "take",
    "jupiter",
    "notebook",
    "give",
    "quick",
    "live",
    "demo",
    "let",
    "quickly",
    "walk",
    "pieces",
    "program",
    "slides",
    "take",
    "actually",
    "actual",
    "code",
    "demo",
    "python",
    "program",
    "structure",
    "looks",
    "somewhat",
    "like",
    "first",
    "step",
    "import",
    "required",
    "libraries",
    "course",
    "necessary",
    "import",
    "libraries",
    "right",
    "top",
    "code",
    "good",
    "practice",
    "know",
    "going",
    "need",
    "certain",
    "set",
    "libraries",
    "may",
    "good",
    "idea",
    "put",
    "readability",
    "perspective",
    "good",
    "practice",
    "put",
    "libraries",
    "importing",
    "beginning",
    "code",
    "however",
    "mandatory",
    "middle",
    "code",
    "somewhere",
    "feel",
    "need",
    "particular",
    "library",
    "import",
    "library",
    "start",
    "using",
    "middle",
    "code",
    "also",
    "perfectly",
    "fine",
    "give",
    "errors",
    "anything",
    "however",
    "said",
    "good",
    "practice",
    "import",
    "required",
    "libraries",
    "case",
    "importing",
    "pandas",
    "numpy",
    "matplotlib",
    "addition",
    "include",
    "piece",
    "code",
    "percentage",
    "matplotlib",
    "inline",
    "happen",
    "graphs",
    "going",
    "create",
    "visualizations",
    "going",
    "create",
    "displayed",
    "within",
    "notebook",
    "want",
    "kind",
    "provision",
    "need",
    "line",
    "always",
    "good",
    "idea",
    "starting",
    "think",
    "good",
    "idea",
    "include",
    "line",
    "graphs",
    "shown",
    "line",
    "okay",
    "four",
    "start",
    "four",
    "lines",
    "code",
    "next",
    "step",
    "import",
    "data",
    "case",
    "training",
    "data",
    "loans",
    "name",
    "loan",
    "p",
    "underscore",
    "train",
    "dot",
    "csv",
    "reading",
    "data",
    "case",
    "see",
    "unlike",
    "previous",
    "example",
    "created",
    "data",
    "frame",
    "data",
    "created",
    "actually",
    "creating",
    "data",
    "frame",
    "using",
    "external",
    "data",
    "method",
    "straightforward",
    "use",
    "read",
    "underscore",
    "csv",
    "method",
    "intuitive",
    "function",
    "name",
    "say",
    "pd",
    "dot",
    "read",
    "underscore",
    "csv",
    "give",
    "path",
    "file",
    "csv",
    "file",
    "read",
    "data",
    "frame",
    "df",
    "name",
    "calling",
    "df",
    "call",
    "xyz",
    "anything",
    "name",
    "name",
    "object",
    "head",
    "one",
    "methods",
    "within",
    "data",
    "frame",
    "give",
    "us",
    "first",
    "five",
    "take",
    "quick",
    "look",
    "imported",
    "data",
    "want",
    "initially",
    "quick",
    "look",
    "data",
    "looking",
    "values",
    "columns",
    "forth",
    "right",
    "typically",
    "would",
    "head",
    "df",
    "dot",
    "head",
    "get",
    "sample",
    "let",
    "say",
    "first",
    "lines",
    "data",
    "happened",
    "displays",
    "first",
    "lines",
    "see",
    "columns",
    "within",
    "values",
    "cells",
    "forth",
    "also",
    "typically",
    "would",
    "like",
    "see",
    "null",
    "values",
    "data",
    "whatever",
    "reason",
    "invalid",
    "looking",
    "dirty",
    "whatever",
    "reason",
    "unnecessary",
    "character",
    "give",
    "quick",
    "view",
    "case",
    "pretty",
    "much",
    "everything",
    "looks",
    "okay",
    "next",
    "step",
    "understand",
    "data",
    "little",
    "bit",
    "overall",
    "columns",
    "information",
    "describe",
    "function",
    "basically",
    "give",
    "us",
    "summary",
    "data",
    "else",
    "pandas",
    "also",
    "allows",
    "us",
    "visualize",
    "data",
    "like",
    "part",
    "call",
    "univariate",
    "analysis",
    "means",
    "every",
    "column",
    "take",
    "plots",
    "visualization",
    "understand",
    "data",
    "columns",
    "example",
    "loan",
    "amount",
    "column",
    "take",
    "hist",
    "basically",
    "hist",
    "method",
    "create",
    "histogram",
    "take",
    "values",
    "one",
    "column",
    "loan",
    "amount",
    "create",
    "histogram",
    "see",
    "data",
    "distributed",
    "right",
    "happening",
    "see",
    "extreme",
    "values",
    "identify",
    "data",
    "preparation",
    "data",
    "completely",
    "hazard",
    "way",
    "analysis",
    "may",
    "difficult",
    "initial",
    "exploratory",
    "data",
    "analysis",
    "primarily",
    "done",
    "understand",
    "see",
    "need",
    "data",
    "preparation",
    "get",
    "steps",
    "like",
    "machine",
    "learning",
    "statistical",
    "modeling",
    "case",
    "see",
    "plotting",
    "histogram",
    "see",
    "extreme",
    "values",
    "values",
    "lot",
    "around",
    "100",
    "range",
    "also",
    "something",
    "one",
    "two",
    "observations",
    "700",
    "range",
    "pretty",
    "scattered",
    "sense",
    "really",
    "scattered",
    "distributedly",
    "scattered",
    "randomly",
    "scattered",
    "range",
    "really",
    "huge",
    "steps",
    "need",
    "normalization",
    "see",
    "bit",
    "one",
    "columns",
    "let",
    "take",
    "another",
    "column",
    "applicant",
    "income",
    "similar",
    "kind",
    "similar",
    "situation",
    "observations",
    "range",
    "also",
    "far",
    "observations",
    "also",
    "pretty",
    "also",
    "extreme",
    "values",
    "see",
    "done",
    "credit",
    "history",
    "binary",
    "value",
    "people",
    "zero",
    "value",
    "credit",
    "history",
    "one",
    "like",
    "flag",
    "basically",
    "telling",
    "us",
    "many",
    "people",
    "one",
    "many",
    "people",
    "zero",
    "looks",
    "like",
    "majority",
    "value",
    "1",
    "100",
    "value",
    "okay",
    "else",
    "understood",
    "little",
    "bit",
    "data",
    "need",
    "data",
    "wrangling",
    "data",
    "munching",
    "see",
    "bring",
    "kind",
    "normalization",
    "data",
    "kind",
    "try",
    "understand",
    "data",
    "wrangling",
    "actually",
    "go",
    "okay",
    "data",
    "wrangling",
    "nothing",
    "process",
    "cleaning",
    "data",
    "let",
    "say",
    "multiple",
    "things",
    "happen",
    "particular",
    "example",
    "missing",
    "values",
    "typically",
    "get",
    "data",
    "often",
    "happen",
    "lot",
    "values",
    "missing",
    "either",
    "null",
    "values",
    "lot",
    "zeros",
    "use",
    "data",
    "perform",
    "let",
    "say",
    "predictive",
    "analysis",
    "perform",
    "machine",
    "learning",
    "activities",
    "one",
    "part",
    "need",
    "clean",
    "data",
    "unifying",
    "data",
    "ranges",
    "data",
    "huge",
    "going",
    "columns",
    "going",
    "0",
    "100",
    "000",
    "columns",
    "10",
    "20",
    "affect",
    "accuracy",
    "analysis",
    "need",
    "kind",
    "unifying",
    "data",
    "wrangling",
    "data",
    "wrangling",
    "actually",
    "perform",
    "analysis",
    "need",
    "bring",
    "data",
    "kind",
    "shape",
    "perform",
    "additional",
    "analysis",
    "actual",
    "analysis",
    "get",
    "insights",
    "deal",
    "missing",
    "values",
    "common",
    "issue",
    "take",
    "data",
    "get",
    "data",
    "business",
    "data",
    "scientist",
    "gets",
    "data",
    "business",
    "never",
    "assume",
    "data",
    "clean",
    "values",
    "filled",
    "real",
    "life",
    "often",
    "data",
    "dirty",
    "data",
    "wrangling",
    "process",
    "kind",
    "clean",
    "data",
    "first",
    "identify",
    "whether",
    "data",
    "dirty",
    "clean",
    "find",
    "data",
    "missing",
    "ways",
    "write",
    "small",
    "piece",
    "code",
    "identify",
    "given",
    "column",
    "given",
    "row",
    "observations",
    "null",
    "primarily",
    "line",
    "code",
    "example",
    "trying",
    "identify",
    "many",
    "null",
    "values",
    "missing",
    "values",
    "columns",
    "lambda",
    "function",
    "saying",
    "find",
    "value",
    "null",
    "add",
    "many",
    "observations",
    "particular",
    "column",
    "null",
    "column",
    "see",
    "loan",
    "id",
    "obviously",
    "id",
    "null",
    "values",
    "missing",
    "values",
    "gender",
    "13",
    "observations",
    "values",
    "missing",
    "similarly",
    "marital",
    "status",
    "three",
    "forth",
    "see",
    "example",
    "loan",
    "amount",
    "21",
    "observations",
    "values",
    "missing",
    "loan",
    "amount",
    "term",
    "14",
    "observations",
    "see",
    "handle",
    "missing",
    "values",
    "multiple",
    "ways",
    "handle",
    "missing",
    "values",
    "number",
    "observations",
    "small",
    "compared",
    "total",
    "number",
    "observations",
    "sometimes",
    "one",
    "easy",
    "ways",
    "completely",
    "remove",
    "data",
    "delete",
    "record",
    "exclude",
    "record",
    "one",
    "way",
    "let",
    "say",
    "million",
    "records",
    "maybe",
    "10",
    "records",
    "missing",
    "values",
    "may",
    "worth",
    "something",
    "fill",
    "values",
    "may",
    "better",
    "get",
    "rid",
    "observations",
    "right",
    "missing",
    "values",
    "proportionately",
    "small",
    "relatively",
    "large",
    "number",
    "missing",
    "values",
    "exclude",
    "observations",
    "accuracy",
    "may",
    "good",
    "way",
    "take",
    "mean",
    "value",
    "particular",
    "column",
    "fill",
    "wherever",
    "missing",
    "values",
    "fill",
    "observations",
    "cells",
    "mean",
    "value",
    "way",
    "happens",
    "give",
    "value",
    "high",
    "low",
    "somehow",
    "fits",
    "within",
    "range",
    "observations",
    "seeing",
    "one",
    "technique",
    "case",
    "case",
    "may",
    "take",
    "call",
    "based",
    "specific",
    "situation",
    "common",
    "methods",
    "see",
    "previous",
    "case",
    "loan",
    "amount",
    "21",
    "went",
    "ahead",
    "filled",
    "mean",
    "value",
    "zero",
    "missing",
    "values",
    "okay",
    "one",
    "part",
    "data",
    "wrangling",
    "activity",
    "else",
    "also",
    "check",
    "types",
    "data",
    "df",
    "dot",
    "types",
    "give",
    "us",
    "various",
    "data",
    "types",
    "right",
    "also",
    "perform",
    "basic",
    "mathematical",
    "observations",
    "already",
    "seen",
    "mean",
    "found",
    "similarly",
    "call",
    "mean",
    "method",
    "data",
    "frame",
    "object",
    "actually",
    "perform",
    "display",
    "calculate",
    "mean",
    "pretty",
    "much",
    "numerical",
    "columns",
    "available",
    "right",
    "example",
    "applicant",
    "income",
    "coeplicant",
    "income",
    "numerical",
    "values",
    "display",
    "main",
    "values",
    "another",
    "thing",
    "actually",
    "also",
    "combine",
    "data",
    "frames",
    "let",
    "say",
    "import",
    "data",
    "one",
    "csv",
    "file",
    "one",
    "data",
    "frame",
    "another",
    "csv",
    "file",
    "another",
    "data",
    "frame",
    "want",
    "merge",
    "want",
    "analysis",
    "entire",
    "data",
    "okay",
    "one",
    "example",
    "could",
    "data",
    "form",
    "csv",
    "files",
    "one",
    "csv",
    "file",
    "month",
    "year",
    "january",
    "february",
    "march",
    "different",
    "import",
    "let",
    "say",
    "12",
    "data",
    "frames",
    "merge",
    "together",
    "single",
    "data",
    "frame",
    "perform",
    "analysis",
    "entire",
    "data",
    "frame",
    "entire",
    "data",
    "year",
    "one",
    "example",
    "case",
    "importing",
    "data",
    "creating",
    "random",
    "values",
    "uh",
    "using",
    "random",
    "values",
    "let",
    "assume",
    "data",
    "frame",
    "name",
    "one",
    "assign",
    "random",
    "values",
    "five",
    "four",
    "format",
    "five",
    "rows",
    "four",
    "columns",
    "data",
    "frame",
    "one",
    "looks",
    "create",
    "another",
    "data",
    "frame",
    "data",
    "frame",
    "two",
    "random",
    "numbers",
    "format",
    "five",
    "four",
    "something",
    "like",
    "want",
    "combine",
    "two",
    "combine",
    "two",
    "use",
    "concatenate",
    "concat",
    "method",
    "combine",
    "two",
    "pd",
    "dot",
    "concat",
    "takes",
    "data",
    "frames",
    "one",
    "two",
    "provide",
    "simply",
    "add",
    "merge",
    "concatenate",
    "whatever",
    "call",
    "whichever",
    "term",
    "call",
    "course",
    "make",
    "sure",
    "structure",
    "remains",
    "like",
    "said",
    "could",
    "let",
    "say",
    "sales",
    "data",
    "coming",
    "12",
    "different",
    "months",
    "files",
    "structure",
    "combine",
    "merge",
    "using",
    "concat",
    "method",
    "let",
    "say",
    "structure",
    "identical",
    "happen",
    "let",
    "say",
    "two",
    "data",
    "frames",
    "one",
    "column",
    "name",
    "key",
    "second",
    "column",
    "lval",
    "second",
    "data",
    "frame",
    "column",
    "name",
    "key",
    "second",
    "column",
    "name",
    "well",
    "l",
    "val",
    "see",
    "structure",
    "identical",
    "still",
    "combine",
    "way",
    "get",
    "combined",
    "merged",
    "somewhat",
    "like",
    "takes",
    "key",
    "common",
    "parameter",
    "common",
    "column",
    "otherwise",
    "work",
    "use",
    "merge",
    "instead",
    "concatenate",
    "merge",
    "get",
    "result",
    "format",
    "uses",
    "key",
    "common",
    "thread",
    "kind",
    "populates",
    "values",
    "accordingly",
    "see",
    "first",
    "one",
    "four",
    "bar",
    "key",
    "l",
    "values",
    "1",
    "2",
    "right",
    "go",
    "back",
    "4",
    "bar",
    "1",
    "2",
    "l",
    "values",
    "see",
    "1",
    "whereas",
    "right",
    "data",
    "frame",
    "foo",
    "bar",
    "bar",
    "second",
    "time",
    "values",
    "three",
    "four",
    "five",
    "done",
    "foo",
    "put",
    "existing",
    "right",
    "four",
    "already",
    "existing",
    "come",
    "left",
    "put",
    "value",
    "r",
    "3",
    "similarly",
    "put",
    "4",
    "bar",
    "go",
    "back",
    "bar",
    "value",
    "4",
    "since",
    "one",
    "value",
    "bar",
    "go",
    "add",
    "5",
    "well",
    "thing",
    "one",
    "example",
    "left",
    "two",
    "values",
    "one",
    "value",
    "bar",
    "since",
    "appending",
    "merging",
    "two",
    "key",
    "values",
    "bar",
    "therefore",
    "kind",
    "repeat",
    "value",
    "l",
    "val",
    "seeing",
    "case",
    "right",
    "l",
    "value",
    "appears",
    "twice",
    "number",
    "2",
    "appears",
    "twice",
    "r",
    "value",
    "two",
    "okay",
    "right",
    "identical",
    "structure",
    "merge",
    "talk",
    "little",
    "bit",
    "library",
    "used",
    "machine",
    "learning",
    "work",
    "performing",
    "machine",
    "learning",
    "activities",
    "want",
    "linear",
    "regression",
    "logistic",
    "regression",
    "easily",
    "usable",
    "apis",
    "call",
    "advantage",
    "provides",
    "bunch",
    "algorithms",
    "think",
    "good",
    "part",
    "library",
    "want",
    "use",
    "scikit",
    "learn",
    "obviously",
    "need",
    "import",
    "modules",
    "also",
    "sub",
    "modules",
    "may",
    "import",
    "based",
    "trying",
    "use",
    "like",
    "example",
    "know",
    "want",
    "use",
    "logistic",
    "regression",
    "people",
    "probably",
    "familiar",
    "machine",
    "learning",
    "separate",
    "module",
    "machine",
    "learning",
    "may",
    "want",
    "take",
    "look",
    "touch",
    "upon",
    "basics",
    "machine",
    "learning",
    "algorithms",
    "like",
    "linear",
    "regression",
    "logistic",
    "regression",
    "random",
    "forest",
    "classification",
    "talking",
    "algorithms",
    "available",
    "want",
    "use",
    "need",
    "import",
    "library",
    "library",
    "basically",
    "sklearn",
    "right",
    "kind",
    "subparts",
    "need",
    "import",
    "based",
    "exactly",
    "algorithm",
    "using",
    "let",
    "take",
    "example",
    "move",
    "see",
    "whenever",
    "perform",
    "machine",
    "learning",
    "activity",
    "familiar",
    "machine",
    "learning",
    "already",
    "know",
    "split",
    "labeled",
    "data",
    "two",
    "parts",
    "training",
    "test",
    "multiple",
    "ways",
    "splitting",
    "data",
    "either",
    "people",
    "like",
    "50",
    "50",
    "people",
    "80",
    "20",
    "training",
    "80",
    "test",
    "20",
    "individual",
    "preference",
    "hard",
    "fast",
    "rules",
    "large",
    "seen",
    "training",
    "data",
    "set",
    "larger",
    "test",
    "data",
    "set",
    "probably",
    "go",
    "details",
    "point",
    "one",
    "steps",
    "machine",
    "learning",
    "scikit",
    "learn",
    "offers",
    "readily",
    "available",
    "method",
    "strain",
    "test",
    "split",
    "right",
    "example",
    "let",
    "say",
    "taking",
    "values",
    "x",
    "values",
    "x",
    "independent",
    "variables",
    "dependent",
    "variable",
    "okay",
    "using",
    "two",
    "want",
    "split",
    "train",
    "test",
    "data",
    "import",
    "train",
    "test",
    "split",
    "sub",
    "module",
    "within",
    "scikit",
    "learn",
    "sklearn",
    "right",
    "within",
    "import",
    "drain",
    "test",
    "split",
    "call",
    "strain",
    "test",
    "split",
    "method",
    "function",
    "whatever",
    "call",
    "pass",
    "data",
    "x",
    "values",
    "independent",
    "variables",
    "labels",
    "pass",
    "x",
    "specify",
    "size",
    "test",
    "data",
    "one",
    "need",
    "specify",
    "say",
    "test",
    "size",
    "understood",
    "train",
    "size",
    "telling",
    "ratio",
    "split",
    "technically",
    "nothing",
    "prevents",
    "giving",
    "whatever",
    "like",
    "give",
    "test",
    "80",
    "train",
    "20",
    "whichever",
    "way",
    "normal",
    "practices",
    "training",
    "data",
    "set",
    "would",
    "larger",
    "test",
    "data",
    "set",
    "typically",
    "would",
    "80",
    "20",
    "75",
    "25",
    "65",
    "35",
    "something",
    "like",
    "right",
    "second",
    "parameter",
    "say",
    "know",
    "data",
    "randomly",
    "split",
    "like",
    "take",
    "first",
    "75",
    "percent",
    "put",
    "training",
    "next",
    "25",
    "percent",
    "put",
    "test",
    "thing",
    "happen",
    "first",
    "set",
    "state",
    "random",
    "state",
    "splitting",
    "done",
    "random",
    "way",
    "randomly",
    "picked",
    "data",
    "put",
    "training",
    "test",
    "results",
    "four",
    "data",
    "frames",
    "x",
    "train",
    "x",
    "test",
    "white",
    "rain",
    "test",
    "okay",
    "basically",
    "result",
    "splitting",
    "done",
    "let",
    "see",
    "implement",
    "execute",
    "logistic",
    "regression",
    "logistic",
    "regression",
    "try",
    "try",
    "develop",
    "model",
    "classify",
    "data",
    "logistic",
    "regression",
    "algorithm",
    "supervised",
    "learning",
    "performing",
    "classification",
    "logistic",
    "regression",
    "classification",
    "usually",
    "binary",
    "classification",
    "binary",
    "classification",
    "means",
    "two",
    "classes",
    "either",
    "like",
    "yes",
    "example",
    "customer",
    "buy",
    "buy",
    "binary",
    "classification",
    "use",
    "logistic",
    "regression",
    "let",
    "take",
    "look",
    "code",
    "implement",
    "something",
    "like",
    "using",
    "psychic",
    "learn",
    "first",
    "thing",
    "import",
    "logitech",
    "regression",
    "submodule",
    "subclass",
    "whatever",
    "call",
    "create",
    "instance",
    "object",
    "classifier",
    "creating",
    "object",
    "name",
    "name",
    "way",
    "give",
    "name",
    "case",
    "saying",
    "classifier",
    "say",
    "classifier",
    "equal",
    "logistic",
    "regression",
    "creating",
    "instance",
    "logistic",
    "regression",
    "variable",
    "class",
    "whatever",
    "okay",
    "pass",
    "variable",
    "parameter",
    "rather",
    "random",
    "state",
    "equal",
    "0",
    "create",
    "object",
    "case",
    "named",
    "classifier",
    "train",
    "object",
    "calling",
    "method",
    "fit",
    "important",
    "note",
    "call",
    "method",
    "like",
    "train",
    "call",
    "known",
    "method",
    "called",
    "fit",
    "basically",
    "calling",
    "fit",
    "method",
    "training",
    "model",
    "order",
    "train",
    "model",
    "need",
    "pass",
    "training",
    "data",
    "set",
    "x",
    "underscore",
    "train",
    "independent",
    "variables",
    "set",
    "independent",
    "variables",
    "underscore",
    "train",
    "dependent",
    "variable",
    "label",
    "pass",
    "call",
    "fit",
    "function",
    "fit",
    "method",
    "actually",
    "result",
    "training",
    "model",
    "classifier",
    "basically",
    "showing",
    "possible",
    "parameters",
    "passed",
    "initiated",
    "calling",
    "logistic",
    "instance",
    "logistic",
    "regression",
    "also",
    "look",
    "help",
    "file",
    "installed",
    "python",
    "intuitive",
    "may",
    "want",
    "take",
    "look",
    "details",
    "exactly",
    "right",
    "moving",
    "train",
    "model",
    "calling",
    "fit",
    "next",
    "step",
    "test",
    "model",
    "use",
    "test",
    "data",
    "need",
    "pay",
    "attention",
    "calling",
    "two",
    "things",
    "one",
    "order",
    "test",
    "data",
    "actually",
    "call",
    "known",
    "method",
    "known",
    "predict",
    "right",
    "training",
    "done",
    "time",
    "inference",
    "model",
    "want",
    "check",
    "whether",
    "model",
    "working",
    "correctly",
    "test",
    "data",
    "remember",
    "split",
    "25",
    "percent",
    "data",
    "stored",
    "right",
    "split",
    "test",
    "training",
    "25",
    "data",
    "pass",
    "call",
    "method",
    "predict",
    "model",
    "predict",
    "values",
    "right",
    "calling",
    "underscore",
    "predict",
    "display",
    "said",
    "logistic",
    "regression",
    "basically",
    "binary",
    "classification",
    "gives",
    "us",
    "results",
    "like",
    "yes",
    "particular",
    "case",
    "model",
    "predicted",
    "model",
    "classified",
    "also",
    "know",
    "already",
    "labels",
    "need",
    "compare",
    "existing",
    "labels",
    "known",
    "labels",
    "whether",
    "classification",
    "correct",
    "next",
    "step",
    "basically",
    "calculating",
    "accuracy",
    "come",
    "play",
    "okay",
    "case",
    "first",
    "thing",
    "important",
    "thing",
    "note",
    "prediction",
    "using",
    "predict",
    "passing",
    "x",
    "underscore",
    "test",
    "train",
    "right",
    "case",
    "x",
    "ten",
    "one",
    "point",
    "noted",
    "case",
    "training",
    "pass",
    "independent",
    "variables",
    "also",
    "dependent",
    "variables",
    "system",
    "internally",
    "verify",
    "training",
    "process",
    "take",
    "x",
    "values",
    "try",
    "come",
    "value",
    "compare",
    "actual",
    "value",
    "right",
    "training",
    "method",
    "pass",
    "x",
    "well",
    "whereas",
    "case",
    "predict",
    "pass",
    "pass",
    "pretending",
    "actual",
    "data",
    "actual",
    "data",
    "labels",
    "passing",
    "independent",
    "variables",
    "system",
    "come",
    "values",
    "okay",
    "remember",
    "also",
    "know",
    "actual",
    "value",
    "compare",
    "actual",
    "values",
    "find",
    "whether",
    "accurate",
    "model",
    "use",
    "known",
    "confusion",
    "matrix",
    "also",
    "readily",
    "available",
    "python",
    "library",
    "import",
    "confusion",
    "matrix",
    "already",
    "know",
    "machine",
    "learning",
    "find",
    "familiar",
    "new",
    "machine",
    "learning",
    "confusion",
    "matrix",
    "nothing",
    "matrix",
    "kind",
    "matrix",
    "basically",
    "tells",
    "many",
    "correctly",
    "predicted",
    "many",
    "incorrectly",
    "predicted",
    "characteristics",
    "let",
    "quickly",
    "spend",
    "time",
    "confusion",
    "matrix",
    "total",
    "numbers",
    "numbers",
    "like",
    "number",
    "observations",
    "accuracy",
    "considered",
    "highest",
    "numbers",
    "sum",
    "numbers",
    "across",
    "diagonals",
    "maximum",
    "okay",
    "numbers",
    "outside",
    "diagonal",
    "minimum",
    "means",
    "model",
    "100",
    "percent",
    "accurate",
    "sum",
    "two",
    "would",
    "numbers",
    "two",
    "along",
    "diagonal",
    "would",
    "zero",
    "would",
    "zero",
    "okay",
    "like",
    "hundred",
    "percent",
    "accurate",
    "model",
    "rare",
    "aware",
    "give",
    "idea",
    "okay",
    "right",
    "confusion",
    "matrix",
    "try",
    "calculate",
    "accuracy",
    "percentage",
    "two",
    "things",
    "confusion",
    "matrix",
    "calculate",
    "confusion",
    "matrix",
    "one",
    "accuracy",
    "precision",
    "accuracy",
    "accuracy",
    "basically",
    "measure",
    "many",
    "observations",
    "correctly",
    "predicted",
    "okay",
    "let",
    "say",
    "little",
    "bit",
    "detailed",
    "view",
    "confusion",
    "matrix",
    "looks",
    "similar",
    "like",
    "saw",
    "case",
    "right",
    "two",
    "two",
    "matrix",
    "seeing",
    "18",
    "27",
    "2",
    "1",
    "0",
    "3",
    "18",
    "27",
    "2",
    "1",
    "0",
    "values",
    "kind",
    "labels",
    "shown",
    "altogether",
    "150",
    "observations",
    "said",
    "sum",
    "4",
    "right",
    "18",
    "plus",
    "27",
    "plus",
    "1",
    "0",
    "3",
    "plus",
    "2",
    "equal",
    "150",
    "first",
    "thing",
    "observe",
    "sum",
    "values",
    "equal",
    "sum",
    "test",
    "observations",
    "number",
    "test",
    "observations",
    "150",
    "test",
    "observations",
    "remember",
    "500",
    "split",
    "2575",
    "150",
    "think",
    "350",
    "training",
    "data",
    "set",
    "okay",
    "get",
    "numbers",
    "correct",
    "first",
    "thing",
    "next",
    "thing",
    "let",
    "take",
    "look",
    "actual",
    "values",
    "view",
    "actual",
    "view",
    "actually",
    "right",
    "actual",
    "data",
    "labels",
    "yes",
    "per",
    "actual",
    "data",
    "45",
    "observations",
    "tagged",
    "similarly",
    "105",
    "observations",
    "tagged",
    "yes",
    "labeled",
    "yes",
    "okay",
    "know",
    "first",
    "time",
    "seeing",
    "may",
    "little",
    "confusing",
    "stay",
    "okay",
    "actual",
    "part",
    "side",
    "tells",
    "us",
    "predicted",
    "part",
    "model",
    "predicted",
    "totally",
    "predicted",
    "20",
    "right",
    "totally",
    "20",
    "predicted",
    "predicted",
    "130",
    "yes",
    "okay",
    "hope",
    "part",
    "clear",
    "go",
    "middle",
    "part",
    "let",
    "us",
    "first",
    "understand",
    "exactly",
    "numbers",
    "actually",
    "tagged",
    "45",
    "total",
    "actually",
    "tagged",
    "yes",
    "105",
    "predicted",
    "20",
    "predicted",
    "yes",
    "result",
    "model",
    "okay",
    "result",
    "model",
    "actual",
    "value",
    "already",
    "know",
    "label",
    "data",
    "first",
    "thing",
    "let",
    "us",
    "take",
    "look",
    "individually",
    "okay",
    "options",
    "okay",
    "happening",
    "let",
    "us",
    "look",
    "values",
    "18",
    "says",
    "actually",
    "tagged",
    "model",
    "also",
    "predicted",
    "means",
    "known",
    "true",
    "positive",
    "right",
    "true",
    "negative",
    "sorry",
    "right",
    "means",
    "model",
    "predicted",
    "correctly",
    "negative",
    "says",
    "also",
    "predicted",
    "known",
    "known",
    "true",
    "negative",
    "okay",
    "let",
    "come",
    "side",
    "way",
    "talking",
    "diagonal",
    "remember",
    "said",
    "values",
    "diagonal",
    "okay",
    "means",
    "18",
    "correctly",
    "tagged",
    "labeled",
    "model",
    "predicted",
    "correctly",
    "tagged",
    "known",
    "true",
    "negative",
    "okay",
    "similarly",
    "come",
    "diagonally",
    "103",
    "observations",
    "labeled",
    "yes",
    "actual",
    "value",
    "model",
    "also",
    "predicted",
    "yes",
    "known",
    "true",
    "positive",
    "values",
    "positive",
    "yes",
    "okay",
    "right",
    "important",
    "true",
    "also",
    "true",
    "make",
    "sure",
    "maximum",
    "number",
    "values",
    "true",
    "section",
    "okay",
    "true",
    "positive",
    "true",
    "negative",
    "reason",
    "said",
    "sum",
    "along",
    "diagonal",
    "maximum",
    "let",
    "see",
    "model",
    "100",
    "accurate",
    "sum",
    "case",
    "103",
    "plus",
    "103",
    "plus",
    "18",
    "121",
    "model",
    "accurate",
    "sum",
    "two",
    "would",
    "150",
    "means",
    "perfect",
    "model",
    "okay",
    "right",
    "else",
    "since",
    "covered",
    "two",
    "let",
    "also",
    "cover",
    "two",
    "says",
    "27",
    "actually",
    "labeled",
    "model",
    "predicted",
    "yes",
    "means",
    "wrong",
    "right",
    "similarly",
    "two",
    "actual",
    "value",
    "yes",
    "model",
    "predicted",
    "means",
    "wrong",
    "prediction",
    "get",
    "point",
    "therefore",
    "along",
    "diagonals",
    "correct",
    "values",
    "whereas",
    "places",
    "wrong",
    "values",
    "wrong",
    "predictions",
    "okay",
    "calculate",
    "accuracy",
    "information",
    "way",
    "calculate",
    "accuracy",
    "say",
    "okay",
    "total",
    "observations",
    "150",
    "correctly",
    "predicted",
    "values",
    "correctly",
    "predicted",
    "values",
    "18",
    "plus",
    "103",
    "give",
    "us",
    "accuracy",
    "103",
    "plus",
    "18",
    "121",
    "divided",
    "total",
    "observations",
    "150",
    "accuracy",
    "say",
    "80",
    "percent",
    "okay",
    "another",
    "concept",
    "called",
    "precision",
    "precision",
    "given",
    "formula",
    "true",
    "positives",
    "divided",
    "predicted",
    "positives",
    "totally",
    "predicted",
    "positives",
    "okay",
    "mean",
    "true",
    "positives",
    "remember",
    "true",
    "positives",
    "recall",
    "talked",
    "previous",
    "slide",
    "true",
    "positives",
    "see",
    "103",
    "true",
    "positives",
    "means",
    "value",
    "positive",
    "actual",
    "value",
    "positive",
    "predicted",
    "value",
    "also",
    "positive",
    "called",
    "true",
    "positive",
    "103",
    "divided",
    "true",
    "positive",
    "103",
    "divided",
    "totally",
    "predicted",
    "yes",
    "totally",
    "predicted",
    "yes",
    "remember",
    "130",
    "altogether",
    "predicted",
    "yes",
    "correctly",
    "predicted",
    "103",
    "correctly",
    "predicted",
    "130",
    "predicted",
    "yes",
    "precision",
    "basically",
    "ratio",
    "two",
    "totally",
    "predicted",
    "many",
    "actually",
    "true",
    "ratio",
    "103",
    "130",
    "80",
    "percent",
    "precision",
    "calculate",
    "precision",
    "simple",
    "formula",
    "term",
    "need",
    "remember",
    "accuracy",
    "need",
    "take",
    "total",
    "true",
    "positive",
    "true",
    "negative",
    "divided",
    "total",
    "number",
    "observations",
    "whereas",
    "precision",
    "true",
    "positives",
    "divided",
    "totally",
    "predicted",
    "positives",
    "okay",
    "accuracy",
    "precision",
    "accuracy",
    "calculation",
    "manual",
    "also",
    "use",
    "libraries",
    "already",
    "existing",
    "functions",
    "within",
    "library",
    "provides",
    "uh",
    "one",
    "method",
    "example",
    "accuracy",
    "underscore",
    "score",
    "one",
    "method",
    "use",
    "pass",
    "test",
    "predicted",
    "values",
    "need",
    "pass",
    "right",
    "dependent",
    "variable",
    "values",
    "pass",
    "calculate",
    "case",
    "see",
    "still",
    "calculates",
    "80",
    "seen",
    "well",
    "okay",
    "done",
    "using",
    "method",
    "great",
    "pretty",
    "much",
    "done",
    "conclude",
    "let",
    "take",
    "code",
    "show",
    "actually",
    "looks",
    "okay",
    "code",
    "let",
    "run",
    "okay",
    "one",
    "one",
    "already",
    "seen",
    "steps",
    "slides",
    "run",
    "actual",
    "jupyter",
    "notebook",
    "yet",
    "familiar",
    "jupiter",
    "notebook",
    "videos",
    "created",
    "install",
    "jupyter",
    "notebook",
    "set",
    "jupyter",
    "notebook",
    "tutorial",
    "also",
    "one",
    "slide",
    "install",
    "python",
    "jupyter",
    "notebook",
    "yet",
    "done",
    "please",
    "actually",
    "walk",
    "code",
    "watching",
    "okay",
    "importing",
    "libraries",
    "required",
    "libraries",
    "recall",
    "pandas",
    "numpy",
    "visualization",
    "matplotlib",
    "line",
    "basically",
    "reading",
    "csv",
    "file",
    "csv",
    "file",
    "locally",
    "local",
    "drive",
    "checking",
    "data",
    "starting",
    "exploratory",
    "analysis",
    "data",
    "looking",
    "looks",
    "good",
    "major",
    "missing",
    "values",
    "anything",
    "like",
    "display",
    "columns",
    "show",
    "first",
    "five",
    "rows",
    "using",
    "head",
    "function",
    "want",
    "see",
    "kind",
    "summary",
    "numerical",
    "columns",
    "numerical",
    "columns",
    "gives",
    "summary",
    "like",
    "many",
    "observations",
    "mean",
    "standard",
    "deviation",
    "minimum",
    "maximum",
    "forth",
    "visualization",
    "visualization",
    "okay",
    "next",
    "step",
    "view",
    "data",
    "data",
    "visualization",
    "using",
    "histogram",
    "couple",
    "columns",
    "case",
    "taking",
    "look",
    "loan",
    "amount",
    "create",
    "histogram",
    "displays",
    "data",
    "form",
    "histogram",
    "one",
    "thing",
    "gather",
    "mentioned",
    "slides",
    "well",
    "data",
    "kind",
    "scattered",
    "values",
    "range",
    "0",
    "300",
    "range",
    "extreme",
    "values",
    "around",
    "700",
    "range",
    "one",
    "information",
    "get",
    "histogram",
    "similarly",
    "applicant",
    "income",
    "draw",
    "histogram",
    "something",
    "similar",
    "see",
    "values",
    "range",
    "0",
    "20",
    "000",
    "range",
    "range",
    "80",
    "000",
    "probably",
    "65",
    "000",
    "okay",
    "next",
    "step",
    "perform",
    "data",
    "wrangling",
    "check",
    "data",
    "missing",
    "fill",
    "missing",
    "values",
    "case",
    "check",
    "columns",
    "many",
    "data",
    "many",
    "entries",
    "missing",
    "values",
    "results",
    "loan",
    "id",
    "columns",
    "cells",
    "filled",
    "gender",
    "13",
    "missing",
    "values",
    "marital",
    "status",
    "three",
    "missing",
    "values",
    "forth",
    "loan",
    "amount",
    "21",
    "going",
    "show",
    "remove",
    "missing",
    "values",
    "missing",
    "values",
    "mentioned",
    "slides",
    "couple",
    "ways",
    "handling",
    "one",
    "completely",
    "remove",
    "fill",
    "meaningful",
    "value",
    "case",
    "fill",
    "missing",
    "values",
    "mean",
    "value",
    "loan",
    "amount",
    "let",
    "go",
    "ahead",
    "check",
    "loan",
    "amount",
    "number",
    "missing",
    "values",
    "0",
    "21",
    "cells",
    "values",
    "missing",
    "filled",
    "mean",
    "value",
    "loan",
    "amount",
    "missing",
    "values",
    "loan",
    "amount",
    "columns",
    "well",
    "one",
    "example",
    "shown",
    "okay",
    "run",
    "credit",
    "history",
    "loan",
    "amount",
    "term",
    "well",
    "calculate",
    "mean",
    "pretty",
    "much",
    "numerical",
    "columns",
    "method",
    "call",
    "give",
    "us",
    "mean",
    "numerical",
    "values",
    "another",
    "thing",
    "want",
    "find",
    "data",
    "types",
    "columns",
    "call",
    "types",
    "get",
    "data",
    "types",
    "course",
    "may",
    "useful",
    "cases",
    "object",
    "example",
    "one",
    "shows",
    "int",
    "64",
    "float64",
    "forth",
    "addition",
    "exploratory",
    "data",
    "analysis",
    "machine",
    "learning",
    "activity",
    "well",
    "case",
    "going",
    "logistic",
    "regression",
    "example",
    "shown",
    "slides",
    "well",
    "actual",
    "code",
    "right",
    "first",
    "step",
    "import",
    "libraries",
    "next",
    "step",
    "separate",
    "independent",
    "variables",
    "dependent",
    "variables",
    "x",
    "independent",
    "variable",
    "dependent",
    "variable",
    "separate",
    "data",
    "two",
    "parts",
    "target",
    "well",
    "right",
    "separate",
    "split",
    "data",
    "training",
    "test",
    "data",
    "sets",
    "mentioned",
    "slides",
    "use",
    "train",
    "test",
    "split",
    "method",
    "call",
    "pass",
    "independent",
    "variables",
    "dependent",
    "variables",
    "specify",
    "test",
    "size",
    "means",
    "training",
    "size",
    "nothing",
    "split",
    "data",
    "training",
    "data",
    "set",
    "75",
    "percent",
    "test",
    "data",
    "set",
    "25",
    "okay",
    "split",
    "independent",
    "variables",
    "data",
    "x",
    "strain",
    "training",
    "data",
    "75",
    "percent",
    "similarly",
    "independent",
    "variables",
    "test",
    "x",
    "underscore",
    "test",
    "dependent",
    "variable",
    "strain",
    "underscore",
    "train",
    "dependent",
    "variable",
    "test",
    "underscore",
    "test",
    "small",
    "exercise",
    "scaling",
    "remember",
    "data",
    "kind",
    "scattered",
    "extreme",
    "values",
    "take",
    "care",
    "data",
    "normalized",
    "pass",
    "algorithm",
    "data",
    "normalized",
    "performance",
    "much",
    "better",
    "next",
    "step",
    "create",
    "instance",
    "logistic",
    "regression",
    "object",
    "classifier",
    "logistic",
    "regression",
    "instance",
    "right",
    "classifier",
    "equal",
    "logistic",
    "regression",
    "saying",
    "one",
    "instance",
    "logistic",
    "regression",
    "created",
    "call",
    "training",
    "method",
    "name",
    "method",
    "actually",
    "fit",
    "taking",
    "training",
    "data",
    "x",
    "training",
    "data",
    "independent",
    "variables",
    "dependent",
    "variable",
    "taking",
    "model",
    "gets",
    "trained",
    "method",
    "calling",
    "training",
    "fit",
    "okay",
    "gives",
    "us",
    "output",
    "done",
    "training",
    "testing",
    "recall",
    "slides",
    "showing",
    "slides",
    "also",
    "mentioned",
    "pass",
    "testing",
    "well",
    "training",
    "pass",
    "right",
    "fit",
    "passing",
    "x",
    "test",
    "passing",
    "x",
    "something",
    "need",
    "observe",
    "calculated",
    "model",
    "compare",
    "known",
    "value",
    "measure",
    "accuracy",
    "method",
    "called",
    "predict",
    "basically",
    "create",
    "predict",
    "values",
    "case",
    "binary",
    "classification",
    "outputs",
    "yes",
    "indicates",
    "yes",
    "n",
    "indicates",
    "n",
    "output",
    "measure",
    "accuracy",
    "seen",
    "earlier",
    "described",
    "confusion",
    "matrix",
    "works",
    "use",
    "confusion",
    "matrix",
    "calculating",
    "accuracy",
    "seeing",
    "confusion",
    "matrix",
    "want",
    "measure",
    "accuracy",
    "directly",
    "use",
    "method",
    "find",
    "80",
    "slides",
    "seen",
    "calculate",
    "manually",
    "well",
    "get",
    "accuracy",
    "80",
    "okay",
    "let",
    "go",
    "back",
    "slides",
    "summary",
    "done",
    "session",
    "talked",
    "data",
    "science",
    "music",
    "python",
    "used",
    "becoming",
    "popular",
    "install",
    "python",
    "talked",
    "various",
    "libraries",
    "python",
    "like",
    "panda",
    "scipy",
    "numpy",
    "took",
    "couple",
    "examples",
    "wrote",
    "code",
    "demonstrated",
    "code",
    "performing",
    "exploratory",
    "analysis",
    "performing",
    "data",
    "wrangling",
    "data",
    "manipulation",
    "end",
    "one",
    "example",
    "machine",
    "learning",
    "using",
    "library",
    "perform",
    "logistic",
    "regression",
    "example",
    "come",
    "end",
    "session",
    "queries",
    "comments",
    "please",
    "put",
    "also",
    "give",
    "email",
    "id",
    "get",
    "back",
    "questions",
    "hope",
    "enjoyed",
    "session",
    "thank",
    "much",
    "hi",
    "like",
    "video",
    "subscribe",
    "simply",
    "learn",
    "youtube",
    "channel",
    "click",
    "watch",
    "similar",
    "videos",
    "turn",
    "get",
    "certified",
    "click"
  ],
  "keywords": [
    "session",
    "data",
    "science",
    "python",
    "going",
    "talk",
    "basics",
    "may",
    "use",
    "r",
    "tools",
    "programming",
    "learn",
    "install",
    "important",
    "libraries",
    "analysis",
    "go",
    "little",
    "bit",
    "details",
    "exploratory",
    "take",
    "example",
    "loan",
    "see",
    "wrangling",
    "using",
    "pandas",
    "one",
    "small",
    "model",
    "logistic",
    "regression",
    "part",
    "machine",
    "learning",
    "case",
    "need",
    "probably",
    "separate",
    "want",
    "look",
    "quick",
    "library",
    "lot",
    "right",
    "let",
    "find",
    "customer",
    "say",
    "try",
    "predict",
    "people",
    "actually",
    "similarly",
    "know",
    "many",
    "based",
    "well",
    "forth",
    "used",
    "kind",
    "language",
    "like",
    "already",
    "really",
    "popular",
    "familiar",
    "good",
    "time",
    "get",
    "basically",
    "course",
    "think",
    "also",
    "performing",
    "number",
    "primarily",
    "understand",
    "size",
    "code",
    "stuff",
    "available",
    "plus",
    "three",
    "first",
    "thing",
    "steps",
    "ways",
    "called",
    "download",
    "come",
    "whether",
    "something",
    "system",
    "point",
    "x",
    "range",
    "start",
    "anything",
    "jupyter",
    "notebook",
    "okay",
    "importing",
    "perform",
    "import",
    "csv",
    "file",
    "create",
    "frame",
    "name",
    "linear",
    "numpy",
    "powerful",
    "creating",
    "visualization",
    "known",
    "classification",
    "tensorflow",
    "would",
    "idea",
    "created",
    "next",
    "step",
    "common",
    "things",
    "numbers",
    "key",
    "object",
    "else",
    "another",
    "table",
    "frames",
    "pretty",
    "much",
    "whatever",
    "two",
    "series",
    "within",
    "structure",
    "call",
    "yes",
    "whereas",
    "rows",
    "columns",
    "said",
    "variables",
    "3",
    "4",
    "display",
    "looks",
    "reason",
    "random",
    "test",
    "saying",
    "dot",
    "pass",
    "values",
    "cells",
    "column",
    "method",
    "four",
    "matrix",
    "0",
    "1",
    "2",
    "df",
    "give",
    "us",
    "actual",
    "way",
    "slides",
    "set",
    "put",
    "particular",
    "happen",
    "line",
    "training",
    "underscore",
    "train",
    "function",
    "calling",
    "five",
    "null",
    "view",
    "means",
    "amount",
    "histogram",
    "extreme",
    "done",
    "100",
    "observations",
    "scattered",
    "similar",
    "binary",
    "value",
    "zero",
    "missing",
    "20",
    "accuracy",
    "total",
    "fill",
    "mean",
    "seeing",
    "check",
    "types",
    "seen",
    "calculate",
    "numerical",
    "combine",
    "merge",
    "second",
    "l",
    "result",
    "bar",
    "split",
    "labeled",
    "80",
    "independent",
    "dependent",
    "variable",
    "labels",
    "25",
    "percent",
    "instance",
    "classifier",
    "equal",
    "fit",
    "correctly",
    "remember",
    "predicted",
    "accurate",
    "confusion",
    "sum",
    "diagonal",
    "precision",
    "18",
    "150",
    "tagged",
    "totally",
    "true",
    "positive",
    "negative",
    "103",
    "divided",
    "positives"
  ]
}