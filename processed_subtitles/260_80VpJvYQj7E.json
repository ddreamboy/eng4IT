{
  "text": "hi in this video let's look at how to\nuse various programming languages or\nframeworks in Hadoop applications in\nHadoop can be written in a wide range of\nlanguages depending on the use case the\ndeveloper can choose an appropriate\nprocessing engine as well as an\nappropriate programming language some\nproblems may require a procedural\napproach or a functional approach\nscripts in a high-level languages such\nas speak and hi are automatically\ncombined or compiled into a set of\nMapReduce Java classes by the respective\nengines which are then executed on the\nyarn framework across a cluster yarn is\nyet another resource negotiator which\nwe'll look in the next video pig is a\nsimple procedural scripting language in\nwhich the developer defines how data is\ntransformed from one step to the next\nhive uses high query language or in\nshort hql which is similar to the SQL we\nwill talk about more on Pig and hi in a\nvarious different videos as the\ndeveloper can choose an appropriate\nprocessing engine this gives the\ndeveloper a greater flexibility in\ndealing with complex problems tools such\nas storm and spark are often used for\nprocessing data intensive applications\nwhich may involve interactive or\nanalytical approaches these engines\nprovides support for multiple\nprogramming languages now let's quickly\nlook at different types of processing\nframeworks we have in Hadoop starting\nwith batch processing so batch\nprocessing is used to process data in\nbatches and it reads data input\nprocesses it and writes it to the output\nApache Hadoop is a most well-known and\npopular open source implementation of\nbatch processing and a distributed\nsystem\nusing the MapReduce paradigm the data is\nstored in a shared and distributed file\nsystem called her HDFS or Hadoop\ndistributed file system where the day of\ndata is divided into multiple splits\nwhich are the logical data divisions for\nthe MapReduce processing to process\nthese splits using the MapReduce\nparadigm the map task that reads the\nsplits and passes all of its key value\npairs the map function and writes the\nresults to the intermediate files after\nthe map phase is completed the reducer\nreads intermediate files and passes it\nto the reduce function finally the\nreduce task writes results to the final\noutput files after a blink the relevant\nlogical the advantage of the MapReduce\nmodel include making distributed\nprogramming easier non linear speed-up\ngood scalability as well as fault\ntolerance the disadvantage of this batch\nprocessing model is being unable to\nexecute recursive or iterative jobs in\naddition the obvious batch behavior is\nthat all inputs must be ready by map\nbefore the reduced job starts which\nmakes MapReduce unsuitable for online\nand stream processing use cases moving\non to the stream processing so seam\nstream processing is to continuously\nprocess and act on the live stream data\nto get a specific result in stream\nprocessing there are two popular\nframeworks one is the storm which you\ncan find it on storm rat Apache dot\no-r-g it's from Twitter and s4 from\nYahoo which can be found on incubated\nApache dot o-r-g /s for both the\nframeworks run on the Java Virtual\nMachine and process heat streams in\nterms of the programming model s4 is a\nprogram defined as a graph of processing\nelements small sub programs and s for\ninstant jets instantiates a PE\nor a processing element perky in short\nstorm gives the basic tools to build\nthis dream book while s4 gives you a\nbell different framework moving on to\nthe real-time processing real-time\nprocessing is to process data and get\nthe result almost immediately\nthis concept in the area of real-time\nad-hoc queries over Big Data was first\nimplemented in dremel by Google it uses\na novel columnar storage format for\nnested structures with fast index and\nscalable aggregation algorithms for\ncomputing query results in parallel\ninstead of bad sequences these two\ntechniques are the major characteristics\nfor real-time processing and are used by\nsimilar implementations such as cloud\nera Impala Facebook presto Apache drill\nand hye-won tests powered by stinger\nwhose effort is to make a hundred times\nperformance improvement or Apache hype\non the other hand in memory computing no\ndoubt offers other solutions for\nreal-time processing in memory computing\noffers very high bandwidth which is more\nthan 10 gigabytes per second compared to\nhard disks 200 megabytes per second also\nthe latency is comparatively lower\nnanosecond versus milliseconds compared\nto the hard disks with the price of RAM\ngoing lower and lower each day in memory\ncomputing is more affordable as\nreal-time solutions such as Apache spark\nwhich is a popular open source\nimplementation of in-memory computing\nspark can easily be integrated with\nHadoop and the resilient distributed\ndata set or rdd's can be generated from\nthe data sources such as HDFS and HBase\nfor efficient caching in summary\nreal-time frameworks provide near\nreal-time processing for data in the\nHadoop ecosystem they can be built on\ntop of generic frameworks such as spark\nstreaming or spark or as a standalone or\na special-purpose framework such as\napache spark offers unique in memory\ncapabilities and is well suited to a\nbright wide variety of data processing\nworkloads including machine learning and\nmicro batch processing moving on to the\ngrabb frameworks so here we have giraffe\ngraphics and graphlab which are popular\ngraph processing frameworks Apache\ngiraffe is a library that runs on top of\nMap Reduce giraffe originated as\nopen-source counterpart to briegel the\ngraph processing architecture developed\nat Google and which was described in\n2010 graphics is a library for graph\nprocessing on SPARC whereas graph lab\nwas standalone special-purpose graph\nprocessing framework that can now also\nhandle tabular data moving on to the\nmachine learning frameworks we have\nmahute ml Lib Oryx and h2o which are\ncommonly used machine learning\nframeworks at a high level mahute is a\nlibrary on top of MapReduce although\nthere are plans to make mewho to work on\nSPARC ml lib is a machine learning\nlibrary for SPARC\nsimilarly Oryx and h2o are standalone\nspecial purpose machine learning engines\nthe way in which these different\nframeworks or languages are integrated\ninto Hadoop is shown in this picture big\nhive scripts are compiled into MapReduce\njobs behind the scenes in the latest\nversions these can be compiled into test\njob then these MapReduce are tests jobs\nwill run on yarn framework of the Hadoop\ncluster we will have a deep\nunderstanding of Veon in a separate\nvideo applications can be written in\nscala storm spark and these engines can\nplug straight into yarn framework to\nprovide greater flexibility to the\ndeveloper or to the analyst to provide\ndifferent ways of crossing for different\napplications as we've seen already many\napplications can run at the same time in\nthe same cluster even if they are\nwritten in different line engines we\nhave seen how to use different languages\nor frameworks in the Hadoop because\nin the next video we'll discuss\nprimarily more on the Hadoop\narchitecture and the most important\ndemons are processed that form part of\nthe architecture if you enjoy this video\nplease subscribe to the channel for more\nupcoming videos\n",
  "words": [
    "hi",
    "video",
    "let",
    "look",
    "use",
    "various",
    "programming",
    "languages",
    "frameworks",
    "hadoop",
    "applications",
    "hadoop",
    "written",
    "wide",
    "range",
    "languages",
    "depending",
    "use",
    "case",
    "developer",
    "choose",
    "appropriate",
    "processing",
    "engine",
    "well",
    "appropriate",
    "programming",
    "language",
    "problems",
    "may",
    "require",
    "procedural",
    "approach",
    "functional",
    "approach",
    "scripts",
    "languages",
    "speak",
    "hi",
    "automatically",
    "combined",
    "compiled",
    "set",
    "mapreduce",
    "java",
    "classes",
    "respective",
    "engines",
    "executed",
    "yarn",
    "framework",
    "across",
    "cluster",
    "yarn",
    "yet",
    "another",
    "resource",
    "negotiator",
    "look",
    "next",
    "video",
    "pig",
    "simple",
    "procedural",
    "scripting",
    "language",
    "developer",
    "defines",
    "data",
    "transformed",
    "one",
    "step",
    "next",
    "hive",
    "uses",
    "high",
    "query",
    "language",
    "short",
    "hql",
    "similar",
    "sql",
    "talk",
    "pig",
    "hi",
    "various",
    "different",
    "videos",
    "developer",
    "choose",
    "appropriate",
    "processing",
    "engine",
    "gives",
    "developer",
    "greater",
    "flexibility",
    "dealing",
    "complex",
    "problems",
    "tools",
    "storm",
    "spark",
    "often",
    "used",
    "processing",
    "data",
    "intensive",
    "applications",
    "may",
    "involve",
    "interactive",
    "analytical",
    "approaches",
    "engines",
    "provides",
    "support",
    "multiple",
    "programming",
    "languages",
    "let",
    "quickly",
    "look",
    "different",
    "types",
    "processing",
    "frameworks",
    "hadoop",
    "starting",
    "batch",
    "processing",
    "batch",
    "processing",
    "used",
    "process",
    "data",
    "batches",
    "reads",
    "data",
    "input",
    "processes",
    "writes",
    "output",
    "apache",
    "hadoop",
    "popular",
    "open",
    "source",
    "implementation",
    "batch",
    "processing",
    "distributed",
    "system",
    "using",
    "mapreduce",
    "paradigm",
    "data",
    "stored",
    "shared",
    "distributed",
    "file",
    "system",
    "called",
    "hdfs",
    "hadoop",
    "distributed",
    "file",
    "system",
    "day",
    "data",
    "divided",
    "multiple",
    "splits",
    "logical",
    "data",
    "divisions",
    "mapreduce",
    "processing",
    "process",
    "splits",
    "using",
    "mapreduce",
    "paradigm",
    "map",
    "task",
    "reads",
    "splits",
    "passes",
    "key",
    "value",
    "pairs",
    "map",
    "function",
    "writes",
    "results",
    "intermediate",
    "files",
    "map",
    "phase",
    "completed",
    "reducer",
    "reads",
    "intermediate",
    "files",
    "passes",
    "reduce",
    "function",
    "finally",
    "reduce",
    "task",
    "writes",
    "results",
    "final",
    "output",
    "files",
    "blink",
    "relevant",
    "logical",
    "advantage",
    "mapreduce",
    "model",
    "include",
    "making",
    "distributed",
    "programming",
    "easier",
    "non",
    "linear",
    "good",
    "scalability",
    "well",
    "fault",
    "tolerance",
    "disadvantage",
    "batch",
    "processing",
    "model",
    "unable",
    "execute",
    "recursive",
    "iterative",
    "jobs",
    "addition",
    "obvious",
    "batch",
    "behavior",
    "inputs",
    "must",
    "ready",
    "map",
    "reduced",
    "job",
    "starts",
    "makes",
    "mapreduce",
    "unsuitable",
    "online",
    "stream",
    "processing",
    "use",
    "cases",
    "moving",
    "stream",
    "processing",
    "seam",
    "stream",
    "processing",
    "continuously",
    "process",
    "act",
    "live",
    "stream",
    "data",
    "get",
    "specific",
    "result",
    "stream",
    "processing",
    "two",
    "popular",
    "frameworks",
    "one",
    "storm",
    "find",
    "storm",
    "rat",
    "apache",
    "dot",
    "twitter",
    "s4",
    "yahoo",
    "found",
    "incubated",
    "apache",
    "dot",
    "frameworks",
    "run",
    "java",
    "virtual",
    "machine",
    "process",
    "heat",
    "streams",
    "terms",
    "programming",
    "model",
    "s4",
    "program",
    "defined",
    "graph",
    "processing",
    "elements",
    "small",
    "sub",
    "programs",
    "instant",
    "jets",
    "instantiates",
    "pe",
    "processing",
    "element",
    "perky",
    "short",
    "storm",
    "gives",
    "basic",
    "tools",
    "build",
    "dream",
    "book",
    "s4",
    "gives",
    "bell",
    "different",
    "framework",
    "moving",
    "processing",
    "processing",
    "process",
    "data",
    "get",
    "result",
    "almost",
    "immediately",
    "concept",
    "area",
    "queries",
    "big",
    "data",
    "first",
    "implemented",
    "dremel",
    "google",
    "uses",
    "novel",
    "columnar",
    "storage",
    "format",
    "nested",
    "structures",
    "fast",
    "index",
    "scalable",
    "aggregation",
    "algorithms",
    "computing",
    "query",
    "results",
    "parallel",
    "instead",
    "bad",
    "sequences",
    "two",
    "techniques",
    "major",
    "characteristics",
    "processing",
    "used",
    "similar",
    "implementations",
    "cloud",
    "era",
    "impala",
    "facebook",
    "presto",
    "apache",
    "drill",
    "tests",
    "powered",
    "stinger",
    "whose",
    "effort",
    "make",
    "hundred",
    "times",
    "performance",
    "improvement",
    "apache",
    "hype",
    "hand",
    "memory",
    "computing",
    "doubt",
    "offers",
    "solutions",
    "processing",
    "memory",
    "computing",
    "offers",
    "high",
    "bandwidth",
    "10",
    "gigabytes",
    "per",
    "second",
    "compared",
    "hard",
    "disks",
    "200",
    "megabytes",
    "per",
    "second",
    "also",
    "latency",
    "comparatively",
    "lower",
    "nanosecond",
    "versus",
    "milliseconds",
    "compared",
    "hard",
    "disks",
    "price",
    "ram",
    "going",
    "lower",
    "lower",
    "day",
    "memory",
    "computing",
    "affordable",
    "solutions",
    "apache",
    "spark",
    "popular",
    "open",
    "source",
    "implementation",
    "computing",
    "spark",
    "easily",
    "integrated",
    "hadoop",
    "resilient",
    "distributed",
    "data",
    "set",
    "rdd",
    "generated",
    "data",
    "sources",
    "hdfs",
    "hbase",
    "efficient",
    "caching",
    "summary",
    "frameworks",
    "provide",
    "near",
    "processing",
    "data",
    "hadoop",
    "ecosystem",
    "built",
    "top",
    "generic",
    "frameworks",
    "spark",
    "streaming",
    "spark",
    "standalone",
    "framework",
    "apache",
    "spark",
    "offers",
    "unique",
    "memory",
    "capabilities",
    "well",
    "suited",
    "bright",
    "wide",
    "variety",
    "data",
    "processing",
    "workloads",
    "including",
    "machine",
    "learning",
    "micro",
    "batch",
    "processing",
    "moving",
    "grabb",
    "frameworks",
    "giraffe",
    "graphics",
    "graphlab",
    "popular",
    "graph",
    "processing",
    "frameworks",
    "apache",
    "giraffe",
    "library",
    "runs",
    "top",
    "map",
    "reduce",
    "giraffe",
    "originated",
    "counterpart",
    "briegel",
    "graph",
    "processing",
    "architecture",
    "developed",
    "google",
    "described",
    "2010",
    "graphics",
    "library",
    "graph",
    "processing",
    "sparc",
    "whereas",
    "graph",
    "lab",
    "standalone",
    "graph",
    "processing",
    "framework",
    "also",
    "handle",
    "tabular",
    "data",
    "moving",
    "machine",
    "learning",
    "frameworks",
    "mahute",
    "ml",
    "lib",
    "oryx",
    "h2o",
    "commonly",
    "used",
    "machine",
    "learning",
    "frameworks",
    "high",
    "level",
    "mahute",
    "library",
    "top",
    "mapreduce",
    "although",
    "plans",
    "make",
    "mewho",
    "work",
    "sparc",
    "ml",
    "lib",
    "machine",
    "learning",
    "library",
    "sparc",
    "similarly",
    "oryx",
    "h2o",
    "standalone",
    "special",
    "purpose",
    "machine",
    "learning",
    "engines",
    "way",
    "different",
    "frameworks",
    "languages",
    "integrated",
    "hadoop",
    "shown",
    "picture",
    "big",
    "hive",
    "scripts",
    "compiled",
    "mapreduce",
    "jobs",
    "behind",
    "scenes",
    "latest",
    "versions",
    "compiled",
    "test",
    "job",
    "mapreduce",
    "tests",
    "jobs",
    "run",
    "yarn",
    "framework",
    "hadoop",
    "cluster",
    "deep",
    "understanding",
    "veon",
    "separate",
    "video",
    "applications",
    "written",
    "scala",
    "storm",
    "spark",
    "engines",
    "plug",
    "straight",
    "yarn",
    "framework",
    "provide",
    "greater",
    "flexibility",
    "developer",
    "analyst",
    "provide",
    "different",
    "ways",
    "crossing",
    "different",
    "applications",
    "seen",
    "already",
    "many",
    "applications",
    "run",
    "time",
    "cluster",
    "even",
    "written",
    "different",
    "line",
    "engines",
    "seen",
    "use",
    "different",
    "languages",
    "frameworks",
    "hadoop",
    "next",
    "video",
    "discuss",
    "primarily",
    "hadoop",
    "architecture",
    "important",
    "demons",
    "processed",
    "form",
    "part",
    "architecture",
    "enjoy",
    "video",
    "please",
    "subscribe",
    "channel",
    "upcoming",
    "videos"
  ],
  "keywords": [
    "hi",
    "video",
    "let",
    "look",
    "use",
    "various",
    "programming",
    "languages",
    "frameworks",
    "hadoop",
    "applications",
    "written",
    "wide",
    "developer",
    "choose",
    "appropriate",
    "processing",
    "engine",
    "well",
    "language",
    "problems",
    "may",
    "procedural",
    "approach",
    "scripts",
    "compiled",
    "set",
    "mapreduce",
    "java",
    "engines",
    "yarn",
    "framework",
    "cluster",
    "next",
    "pig",
    "data",
    "one",
    "hive",
    "uses",
    "high",
    "query",
    "short",
    "similar",
    "different",
    "videos",
    "gives",
    "greater",
    "flexibility",
    "tools",
    "storm",
    "spark",
    "used",
    "multiple",
    "batch",
    "process",
    "reads",
    "writes",
    "output",
    "apache",
    "popular",
    "open",
    "source",
    "implementation",
    "distributed",
    "system",
    "using",
    "paradigm",
    "file",
    "hdfs",
    "day",
    "splits",
    "logical",
    "map",
    "task",
    "passes",
    "function",
    "results",
    "intermediate",
    "files",
    "reduce",
    "model",
    "jobs",
    "job",
    "stream",
    "moving",
    "get",
    "result",
    "two",
    "dot",
    "s4",
    "run",
    "machine",
    "graph",
    "big",
    "google",
    "computing",
    "tests",
    "make",
    "memory",
    "offers",
    "solutions",
    "per",
    "second",
    "compared",
    "hard",
    "disks",
    "also",
    "lower",
    "integrated",
    "provide",
    "top",
    "standalone",
    "learning",
    "giraffe",
    "graphics",
    "library",
    "architecture",
    "sparc",
    "mahute",
    "ml",
    "lib",
    "oryx",
    "h2o",
    "seen"
  ]
}