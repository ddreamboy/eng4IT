{
  "text": "have you ever wanted to build your very\nown deep image classifier well in this\ntutorial we're going to do exactly that\nlet's do it\n[Music]\n[Music]\nwhat's happening guys my name is\nnicholas tronat and in this tutorial as\ni mentioned we're going to be building a\ncustom deep image classifier using your\nown data now the nice thing about this\ntutorial is that you can literally pull\ndown any bunch of images from the web\nand load it into this pipeline and\nyou'll be able to use it to classify\nimages as a zero or one binary\nclassification type problem now in this\ntutorial we are going to be very much\nfocused on going through the end to end\npipeline so first up what we're going to\ndo is focus on getting some data and\nloading it into our pipeline we're then\ngoing to take a look at some\npre-processing steps that we need to\nperform in order to improve how well our\nmodel performs then we're going to build\na deep image classifier using keras and\ntensorflow so we'll build a sequential\ndeep neural network then we'll evaluate\nit test it and last but not least we'll\nsave down this model so that you can\ntake it elsewhere and use it where you\nneed it ready to do it let's get to it\nhey nick i was hoping to build a deep\nlearning model to classify some pictures\nis that something that's possible what\nare you trying to classify uh it's part\nof my stealth tech startup we're looking\nto build a cutting edge mobile app to\nclassify youtuber thumbnails as\nwait for\nit shocked face\nor duck face\ni'm gonna need you to sign an nda now\nthat you know that\nso you like the idea\nright\nwell my other idea is to use ai to\nclassify images of people as happy or\nsad okay that that we can do we can use\nimage classification to do it nice how\ndo you get started well the first thing\nwe probably need is to get some images\nof happy and sad people then we can use\nsome of the helpers inside of keras and\ntensorflow to load it up so we doing\nthis or what yeah let's go alrighty guys\nso we are going to be going through an\nend to end image classification deep\nlearning pipeline thing\nwow that got really long really quick no\nso we are going to be able to build our\nvery own deep image classifier using\npretty much whatever data you want in\nthis particular tutorial this is sort of\nwhy i wanted to show you this\nso\nfirst things first what we're going to\nneed to go on ahead and do and this is\nwhat we discussed with our client is we\nneed to go and set up and load some data\nand then in order to do that we are\ngoing to do a couple of key things first\nup we're going to install our\ndependencies and set them up we're also\ngoing to we are also going to remove any\ndodgy images so i found that sometimes\nwhen you download images from the web\ni.e images the versus images that you\nhaven't captured yourself you can tend\nto get some dodgy images or images that\nare corrupt so i'm going to show you how\nto remove those we are then going to\nload that data so those are the first\ncouple of things that we need to do so\nfirst up installing dependencies in\nsetup and as per usual all the code that\nyou see inside of this including the\nentire jupyter notebook is going to be\navailable inside of github just check\nthe link in the description below\nso\nfirst things first we need to install\ndependencies and setup so what we can do\nin order to do that is run this\nparticular line here so the first line\nis exclamation mark pip install\ntensorflow tensorflow gpu opencv python\nand matplotlib so tensorflow and\ntensorflow gpu are going to be used as\npart of the deep learning pipeline\nitself so we are going to use the keras\nsequential api in a second to be able to\ngo ahead and do that\nopencv is going to be used when we go\nand remove our dodgy images and\nmatplotlib is going to be used to\nvisualize our images so if we go and run\nthat that is going to go ahead and\ninstall our dependencies so we we scroll\non down\nlooks like we just got a warning and\nthis is just telling us that we should\nprobably update our pip version that in\nthis particular case it's fine we don't\nneed to\ncool then we can go and validate whether\nor not we've got the right dependencies\ninstalled so if we go and run pip list\nlet's go and take a look\nso do we have tense flow so we've got\ntensorflow and tensorflow gpu so we've\ngot 2.8.0 and 2.8.0 if you haven't\nwatched the beginner setup tutorial\nwhich i just released make sure you go\nand visit that particularly if you've\ngot a gpu and you need to set up\ntensorflow with gpu acceleration i go\nthrough it step by step so it's going to\nmake your life a ton easier\nokay so the next thing that we need to\ngo ahead and do is import some\ndependencies so in order to do that\nwe're going to import two key\ndependencies the first one is tensorflow\nso import tensorflow as tf and the\nsecond one is os so we've written import\nos so os is namely used let me minimize\nthat so os is mainly used to navigate\nthrough file structures so typically\nwhen i'm using os i'm using it for\nos.path dot join so let's say for\nexample we need to go into our data\ndirectory and we needed to go into a\nfolder called happy right\nso what this is going to do is return\nback a file structure which is\nuh what is it homogeneous regardless of\nwhat type of operating system you're\nusing so this is if you're using it on a\nwindows machine it's going to be\nperfectly fine if you're using it on a\nmac or a linux machine it's going to\nreturn the folder structure in a format\nwhich is appropriate for that particular\ntype of operating system now the other\nmain type of function that i use inside\nof os is os.listia so let's say for\nexample i wanted to show all of the um\nall of the files or all of the images\ninside of a particular directory i could\nactually type in os.listia and let's say\ni've got a folder called data it's going\nto list everything that is inside of\nthat particular folder now i don't have\nanything in there but later on you'll\nactually see that in use just a couple\nof key tips on what i use os for\nall right next line we are going to go\non ahead\nand limit the\nlimit tense flow using up all of the\nvram on our gpu so by default when you\nload in tensorflow or you load in data\nit's going to expand and use all of the\npotential vram that's available on your\nmachine which tends to become a bit of a\nnightmare particularly if you're getting\ninto really big models so these two\nparticular lines of code actually help\nprevent that and it helps prevent\nsomething called an oom error or an out\nof memory error\nso first thing that we're doing is we're\nactually grabbing all of the gpus\navailable on our machine so the first\nline is gpus equals\ntf.config.experimental.list underscore\nphysical underscore devices and to that\nwe've passed through gpu right so if i\nactually go and write that line so\ngpustf.config.experimental\ndot list\nphysical oh gosh my typing is the\nshocker\ndevices and then if i type in gpu\nthis is going to give us all of the gpus\nthat we've got available right so you\ncan see i've got one there if i had a\ngiant machine that had multiple gpus\nyou'd actually see multiple there so if\ni type take a look at the length\nof that particular line you can see\nwe've only got one gpu available there\nwe typed in cpu\nyou can see again i've only got one cpu\navailable\nright so this particular case returning\nmy cpu so if you wanted to see all the\ndevices you've got available you can\nfilter through on that\nso that is what that line is doing there\nthen the next line is actually limiting\nthe memory growth so we're looping\nthrough every potential gpu that we've\ngot inside of this line here so four gpu\nin gpu so for each of the gpus inside of\nthis we are going to run\ntf.config.experiment\nunderscore memory growth so this is\ntelling tensorflow hey don't use up all\nof our memory keep it to a minimum or\nkeep it to whatever you absolutely need\nso by limiting this it ensures that\nwe're going to avoid any of those out of\nmemory errors you might still get some\nif you've got batch sizes that are too\nlarge but that is a solvable error\ncool\nso we have now gone and installed some\ndependencies imported a couple and we've\nalso gone and limited our memory growth\nthis next line is just showing you\nexactly what i showed there so you don't\nneed to run that but if we go and run\nthat that is going to limit our memory\ngrowth so you saw that it wasn't run\nthere i'm just going to run it so we are\nnow good so that is step 1.1 now done so\nwe've gone and installed our\ndependencies we've got an importer\nwhatever we need and we've also gone and\nlimited our memory growth over here now\nthe next bit is removing dodgy images\nnow before we actually do that we\nactually need to get some images so\nthe nice thing about this tutorial is\nthat i wanted to build it so that you\ncould actually go and build an image\nclassifier for just about anything you\nwanted now the nice thing about this is\nthat we can actually go and get a bunch\nof images from the world wide web so\nwe're going to be building an image\nclassifier an image sentiment classifier\nin that particular sense\nso\nwhat do we need to do we need to get\nsome images of happy people so let's get\nimages of happy people\nso i'm just going to go to google go to\nimages and type in happy people and you\ncan see we've got a bunch of overly\necstatic people over here\nthey're so happy who knows what about\nwe're gonna go ahead and download these\nnow i've actually got this extension\ninside of google chrome which makes my\nlife a ton easier when it comes to this\ni don't actually know let's what's it\ncalled uh more tools extensions\nit's this one over here download all\nimages so if you go and get that\nparticular extension\nthis is going to be a game changer when\nit comes to building deep learning stuff\nright\nbecause what we can do is from here i\ncan open up this extension so you can\nsee it says download all images there\nyeah i can click that and that is going\nto start downloading all of the images\nfrom this page so you saw it just\nliterally when it did that so inside of\nthis zip folder we got all those images\nso if i go to downloads open this up\ntake a look at that images are happy\npeople how cool is that\npretty awesome right so now we're now\nable to build up a deep learning image\ndata set really really quickly so we're\ngoing to grab that particular zip file\nso i'm just going to cut that and i'm\ngoing to take it into my image\nclassification repository so i haven't\nactually shown you this\nlet's do that so this particular\nnotebook is here and inside of this same\nfolder i've got a directory called data\na directory called image classification\nwhich is just my virtual environment\nagain if you haven't seen the beginner\ntutorial go and jump back on over to\nthat because i'll show you how to set\nthis up i've got a folder called logs\nbecause that's where we're going to log\nstuff out we've got a folder called\nmodels as well\nnow\nwe are going to grab this data that we\njust downloaded and put it into our data\nfolder and i'm just going to rename it\nand call it happy\njust double check that is the right\nthing\nyeah that's cool happy people so happy\nall right so we are going to go\nwhat have we gone and done so we've got\na set of image data which is for happy\npeople we now need a set of data which\nis for sad people kind of like when i\ndon't get to order pizza or beer on\nfriday night so we've got a bunch of\npeople that are sad so again we're going\nto go to our extensions download those\nimages\nso you can see it's downloading\nwe're good we're great that is now\ndownloaded over there so again we're\ngoing to go to our downloads we're going\nto grab that repository paste it over\nhere and we're going to call this one\nassad\nso we've now got inside of our data\nfolder we've got a 2-zip so we've got a\nhappy zip we've got a sad zip so we're\ngoing to extract these now so if we go\nand extract these and we're just gonna\ncreate or extract them to a separate\nfolder so we're gonna extract too happy\nlet me zoom in because that's way too\nsmall\nhappy we're gonna extract a happy i know\nsometimes my code is pretty small guys\ni'm i work to improve it i promise so\nwe're going to extract a happy\nyou can see we've now got a folder\ncalled happy with all of our overly\nhappy people\nright cool we're going to go and do the\nsame facade\nand this has gone what's that pop up\nthis is saying the following imp file\nalready exists let's just say yes to all\nokay so we've now got two folders we've\ngot a whole bunch of happy people\nyeah cool\ngreat now inside of our sad folder we've\ngot a whole bunch of sad people this\nguy's clearly had a big day at work\nthis guy has as well\nall right\nso what we're going to go ahead and do\nis uh what are we doing\nso we're going to take these zip folders\nand we're actually going to move them\nback into this root folder so that way\nthey don't sort of mess around because\nwhen we go and load in our data where\nthe keras utility is just going to look\nat the subfolders that it needs in here\ncool so i'm going to close that i'm\ngoing to close that i'm going to close\nit well i've opened up a ton of images\nwe don't need that one open either all\nright cool so what have we gone down so\nwe're going to download a bunch of\nimages out people a bunch of images\nhappy people and we've now gone and put\nit inside of our data folder if you\nwanted more classes you literally just\ngo and download those classes paste them\nin here you do need to change the neural\nnetwork a little bit if you want a\ntutorial on that hit me up in the\ncomments below and maybe we'll make one\nokay so we've gone and got our image\ndata sets we've got one of happy one of\nsad\nnow we are kind of good-ish to go so the\nnext thing that we're going to do is\nwe're going to go and remove dodgy\nimages now let me explain why we're\ndoing this so sometimes when you go and\nget images from the world wide web even\nthough they have the appropriate file\nextensions they might not open up in\npython because they might be corrupted\nthey might be mislabeled they might be\nmis-extended or have the incorrect\nextension applied this particular block\nis going to help us get rid of that so\nfirst thing that we need to do is import\ntwo dependencies so we are importing\nopencv so this is uh what allows us let\nme actually show you so if we type in\nopencv\nit's a huge open c or open computer\nvision\nmodule that allows you to do a ton of\ncomputer vision and good stuff so this\nis super awesome if you've never checked\nout opencv by all means do\nthe next thing that we are importing is\nimage hdr so this allows us to check the\nfile extensions for our particular\nimages so two lines there so import\nopencv and import image hdr\nthe next thing that we're going to do is\ncreate a variable to hold the path to\nour data directory so remember inside of\nhere\nwe've got a data directory which is\ncalled data and inside of our data\ndirectory we've got two folders one\ncalled happy\nand one called sad right\nso we're going to go and create a\nvariable which points to that so data\nunderscore dr equals data\nthen we are going to go and create a\nlist of extensions let me minimize that\nwe're not talking about that yet too\nearly so image extensions are jpeg jpg\nbmp and png so this is just a standard\nlist so if we go and navigate through\nthis\nuh let's actually run that first so\nimage underscore exts right\ni haven't typed that in image\nright it's literally just a list so if\nwe actually go and grab the first one\nthat's jpeg the second one that's jpg\nthe third one is going to be png that's\nactually the fourth one\ncool\nso the reason that we're setting up this\nis we are now going to loop into it so\nremember how i told you about import os\nso now what we can actually go ahead and\ndo let's check this out so if i type in\nos dot list dr and type pass through\ndata deal\nthis should return happy and sad it\nreturns the folders which are inside of\nthis data directory if i go and run that\nhappy and sad pretty cool right now what\nwould happen if i wanted to go and check\nevery single image inside of the happy\nfolder well i could go os.path.join\npass through my data directory and then\npass through let's say for example a\nhappy folder\nnow i'm going to return every single\nimage inside of that subfolder\npretty cool right so this allows us to\nloop through every single image that\nwe've got inside of that folder which is\nexactly what our dodgy image script is\ngoing to do in a second but i just\nremember there's one additional thing\nthat we need to go on ahead and do so\nbefore we actually go and run that image\nscript normally what i'll do when i'm\ngetting images from the interwebs is\ni'll actually go into that data set\nand just anything that is small or weird\ni'm going to remove that so anything\nwhich is under 10 kilobytes which is\nprobably going to be a really small\nimage and all of these weird microsoft\nedge vectors we're going to get rid of\nthose so\nfrom nine kilobytes onwards so you can\nsee let me zoom in so you can see these\nare nine kilobytes eight four three so\npretty small we're gonna get rid of\nthose so from\nhere\nto here delete those and if you wanted\nto add in additional images so go and do\nlike go to another page download more go\nto another page download more you could\ndefinitely do that\nokay so we've gone and removed the small\nand weird images from happy let's go and\ndo the same from sad let's go to our\ndetails tab\nso again we're going to find 10 kb and\nthen we're going to delete everything\nbelow that you can see 9 we're going to\ngo all the way down we're going to\nremove anything smaller than that\ngot to get rid of that quick assist it's\ndriving me insane all right so down here\nlet's take a look nine kilobytes one\nkilobyte remove those boom done all\nright cool so that leaves what\neffectively should work but we're still\ngonna run our dodgy image script as well\njust to make sure that we don't have any\nweird stuff there so\nremember how i said i talked about\nos.listia that's exactly what we're\ndoing so first up we're looping through\nevery\nfolder that we've got inside of our data\ndirectory so for image class inside of\nos.list dr so this is just going to go\ninside of our data directory and it\nshould effectively just print out happy\ninside so but let's actually show you\nthis or let me actually show you this so\nprint image class\nimage image underscore class\nso we're going to print out happy and\nwe're going to print out sad then what\nwe're going to go ahead and do is we're\ngoing to print out every single image\ninside of those subdirectories so if we\ngo and print that\nso if i go and print image\nwe are printing out or looping through\nevery single image and then we're just\ngoing to do a bunch of checks right so\nif you wanted to do a specific check you\ncould go and do that i'm just double\nchecking that one we can load the image\ninto opencv and two that our image\nmatches one of these paths over here so\nif we've loaded it up and it's still\nweird we're actually going to remove it\nfrom that particular folder\nright so what we're doing is for looping\nthrough every single one of our data\ndirectory folders so happy and sad we're\nthen looping through every single image\nthat we've got inside of those sub\ndirectories\nso in order to do that we're in four\nimage underscore class in os.listia four\nimage.os or for image in os.listia and\nthen we're going into those subfolders\nso we're joining the path so\nos.path.join our data directory and then\nour image class so this would\neffectively be um happy and then well no\nthis would be data and then it will be\nhappy and then it will be data and then\nit will be sad and then we're going into\nthat and we're grabbing every single\nimage explicitly so we're going os or\npath.join the data directory the image\nclassification folder and then the image\nitself and we're storing that inside of\na variable called image path and then\nwe're passing that through to\nopencv.imread so this actually opens up\nan image or it allows you to open up an\nimage using opencv so let's actually\ntest that out right\nso if i type in cv2 dot i'm read\nand then we need to pass through the\nfull file path so we're going to pass in\nos.path.join\nbecause it just makes it easier\nwe're then going to pass through our\ndata folder and then let's say for\nexample happy and then let's go and get\na file from happy so go to uh image\nclassification and then\ndata happy let's grab this one\nlooks pretty big\nand we're going to pass through the\nstring so there's a jpg so we need the\nextension as well\nthe image classification data happy\njpg cool\ndot jpg\nwe need to close\nthat so you can see we've just gone and\nread in our image as a numpy array so if\ni type in let's just store it inside of\nvariable so i can show you type image\nit's a numpy array\nnow what does actu this actually mean so\nbasically let's take a look at the shape\nso we have an image of the shape what is\nthat three so this guy should be rows\nfirst so it's going to be\n3744 pixels high\n5616 pixels wide and it's got three\nchannels that means it's a colored image\nso if we actually go and open up that\nimage for d well let's actually use our\npython capability so we can type in\nplot.i am show\nand then pass through our image\nand we have we not imported matplotlib\nwe have not let's import matplotlib\nwe\nlet's just import up here so let's just\nadd in another line so um\nfrom we're probably going to visualize\nit later but i want to show you now so\nfrom matplotlib\nimport pie plot as plt\nlet's go and run this\nso that is our image there so you can\nsee 3 000 what is it 744 pixels high\n5616 pixels wide and we it is a colored\nimage and you're probably wondering nick\nwhy is it a weird color this is because\nopencv reads in an image as bgr\nmatplotlib expects it to be rgb so if we\nwanted to fix this we can type in cv2\ndot cvt color\npass through the image and then pass\nthrough a color conversion code so this\nis just going to reorder the channels so\nwe can type in cv2.color underscore\nbgr2rgb\nboom\nyep that should work\nand there you go so you can see the\ncolor is now fixed and we can if we\nwanted to get rid of this weird line\nhere you can just type in plot.show\nwith that so pretty so again so this\nparticular line effectively shows you\none how you can read an image using\nopencv how you can join paths using\nos.path.join and how we can go and\nrender those okay but this is just sort\nof explaining so we don't need this we\ndon't need this we don't need this we\ndon't need this and we don't need that\nwhat we want to do is actually go and\nrun through our dodgy image script so\nagain if it's not a valid image not a\nvalid image extension we're going to go\nand get rid of it using os.remove so\nos.remove allows you to delete a file so\nlet's go and run this\nand you can see that this is inside of a\ntry accept block so effectively if it\nthrows up any errors then we're going to\nfail out of that particular block\nso let's go and run that\nsee we've got some weird images it's\nremoving them\nand that is done so now let's just\ndouble check we still have a bunch of\nimages inside of our data folders so if\nwe go into data happy still got a bunch\nof images there so 131 to be exact and\ninside of sad we've got 74. so it looks\nlike it's a bit of an unbalanced data\nset so we could definitely fix this up\nor resample if we needed to but for now\nwe'll be okay\ncool so we've got a bunch of images\nwe've gone and cleaned them up we're\nlooking good\nso let's take a look at what we've done\nso far so we've now installed our\ndependencies successfully we've also\nremoved any dodgy images the next thing\nthat we want to go on ahead and do is\nload our data now how are we going to do\nthis well tensorflow actually has a data\nset api and\ni originally didn't use this a ton when\ni was just getting started on my deep\nlearning journey but now i probably use\nit every single time i'm building a deep\nlearning model why well it actually\nallows you to build data pipeline so\nrather than loading everything into\nmemory to begin with it actually allows\nyou to build a data pipeline which one\nallows you to scale out to much larger\ndata sets but it also gives you a\nrepeatable set of steps that you're\ngoing to apply to your data\nto be honest just makes up a lot cleaner\num there's a whole bunch of\ndocumentation on this now if you wanted\nto actually access it you can type in\ntf.data.dataset\nand it actually allows you to access\nthis tf.dataset api now we're actually\ngoing to use it slightly differently so\nrather than using the data set api\ndirectly we're actually going to use a\nkeras utility which actually allows you\nto do it but for example if you've in\nsome of the two trials that i've\nactually got coming up namely iris\ntracking and\nwhich one other one did i use it in i\nthink for the toxic comment detection i\nactually use it so typically you can\nload in a data set using um tf.data\ndataset from\nwhat is it from tensors from generator\nfrom tensor slices but you can also use\nit and load in data from a directory by\ntyping in list files so this actually\nallows you to do a wild card search i\njust wanted to give you a little bit of\nbackground on this but um we're not\ngoing to be using it directly in this\nparticular tutorial but there is a ton\nof capability in this uh tf data set api\nokay that is the data set api talked\nabout now we've also taken a look at its\nuh documentation so also pro tip if\nyou've never haven't used jupiter too\nmuch if you type in question mark\nquestion mark gives you the\ndocumentation for that particular line\nof code or that method which you can see\nthere\nso next thing there are so we're\nimporting matplotlib there so i imported\nre-imported it up here but i wanted to\nshow you that image visualization so we\nare now importing numpy so import numpy\nas np and then from matplotlib import pi\nplot as plt\nso if we go and run that now that's two\nnew dependencies imported\nand then this is where we're going to\nload our data so remember how i told you\nthat we've got this data set api here\nwell keras actually has a data pipeline\ndirect function or helper built into it\nas well\nand this is how we access it so in order\nto use it you can type in tf.keras.utils\ndot image underscore data set underscore\nfrom underscore directory and this\nactually builds an image data set for\nyou on the fly so you don't need to\nbuild the labels you don't need to\nactually build the classes it's going to\ndo it for you and it's actually going to\ndo a bunch of pre-processing out of the\nbox so it'll resize your images as well\nnow let's actually take a look at the\ndoco for that nope we don't want to take\na look at that yet so if we go to\ntf.keras.utils\nutils dot image\nso it is actually going to batch your\nimages into this batch of 32 it's going\nto resize your images into 256 by 256\nit's going to shuffle them you can also\ncreate a validation split so on and so\nforth but it's pretty cool right so it\nactually allows you to do a ton of stuff\nright off the bat so this is a super\nuseful helper if you're building image\nclassification models so we're going to\nget rid of that\nso we're actually going to create this\ndata set now\nso i've just gone and run this line here\nso we are then going to store our data\nset into a folder called or into a\nvariable called data\nso this means that we can now take a\nlook at the data itself\nnow\nthe nice thing about the data part or\nwell actually\nit's nice but it's also a little bit\npainful so if i let's say for example i\nwanted to go and take a look at this\ndata i can't just go and grab the first\ninstance\nbecause this isn't a\ndata set which is pre-loaded into memory\nalready it is actually a generator so on\nthe fly we actually need to go and grab\nthe data that we want now the easiest\nway to do that is to convert it into a\nnumpy iterator first which is what this\nnext line is doing\nso\nwe are going to go and create a data\niterator so data underscore iterator\nequals data dot as numpy iterator so you\nprobably would have seen me do this\nbefore in the face verification tutorial\ni actually did it there so this is going\nto convert or allow us to access the\ngenerator from our data pipeline so data\nunderscore iterator equals data as numpy\niterator then we can actually get\nconsecutive batches using the dot next\nmethod so i'll show you this in a sec so\nif we go and run that now then our next\nline of code is actually going to run\ndot next so this is actually going to\nget us a batch back but first up let's\ntake a look at our data iterator so you\ncan actually see it is an iterator so\nalso like a generator so you can loop\nthrough and continuously pull data\nbatches back right and again this is\nprobably not hyper useful right now but\nwhen you get to significantly more\nsophisticated deep learning models where\nyou've got massive amounts of data gonna\nmake your life a ton easier\nbut\nfor now let's actually take a look so we\nare then going to grab one batch so if\nyou think about it this way so this is\nbuilding our data pipeline\nthis is actually allowing us to access\nour data pipeline and then this is\nactually accessing the data pipeline\nitself so this is allowing us to loop\nthrough it this is grabbing one batch\nback so if i go and run this line\nthis batch let's actually take a little\nbatch before we visualize it so if i\ntype in batch\nso this is actually a batch of data so\nthis should have a shape of two or it\nshould have two variables on two parts\nof the tuple\nnow you're probably thinking nick what\nthe hell is this number two well there's\ntwo parts to this data set there is the\nimages and then there's the labels so\nthe first part is actually the image\nrepresentation so it's our images from\nour directory loaded into memory as a\nset of numpy arrays so if i go and grab\nthat first value\nwe've got a whole bunch of arrays here\nyeah can you see that\nnow if we take a look at the shape\nwe should have all of our images loaded\nso if i type in dot shape\nso we've got a batch size of 32 and\nremember this is based on the image\nunderscore data set underscore from\nunderscore directory helper method we\ncan configure that if we wanted\nmore images per batch if we actually\nwanted different image shapes but this\nis the nice thing about that particular\nutility it automatically reshapes our\nimages to ensure that they are of a\nconsistent size and it also batches them\nup into a batch size of 32 but again you\ncan configure all of this so let's say\nfor example um i go let's actually go\nand grab it so tf.keras.utils.image\ndataset from directory\nso if i wanted more images per batch i\ncan increase that let's say for example\nyou don't have as much vram on your gpu\nyou could actually drop that batch size\nand the way that you would do this is\nlet's say that that's your data\ndirectory you would type in batch\nunderscore size\nequals i don't know 16 for example yeah\nor you'd go batch size equals eight\nso you can change that if you wanted\nyour image size to be different you\ncould actually pass through that keyword\nargument so image and the score size\nequals i don't know let's say 128 by 128\nso it would actually allow you to\nconfigure what you want your data set to\nlook like\nfor now the defaults are going to work\ncool all right so we're taking a look at\nour batch um so we took a look so these\nare the images right so this is the\nimages\nimages represented\nas numpy arrays\nnow\nlet's say what about the labels so if we\ngo to batch z one\nthis should be the labels there you go\nso in this particular case we've got a\nflag of one we've got a flag of zero\nzero zero zero one one one now these\nactually represent the labels so one is\ngoing to represent either happy or sad\nand zero is going to represent either\nhappy or sat i couldn't quite work out\nwhether or not there's a way to dictate\nwhich\nclass belongs to which number now i know\nthere is a way i think there is a way\nthat you can actually configure this i\nknow for sure that you can do it using\nthe\ntf.data.dataset api because i do it a\nton um with this default helper i'm not\ntoo sure actually how you actually go\nabout configuring that but there's one\neasy way around that you just double\ncheck which class is assigned to which\ntype of image and this is what this plot\nis going to allow you to do here\nso over here we can see that the one\nflag is actually assigned to sad images\nand the zero flag is assigned to happy\nimages so you can see one there\none sad person zero happy people\nzero happy people zero happy people now\nlet's say for example we wanted to\nvisualize another batch of data well we\ncan actually go and run this line over\nhere again because we are going to get\nanother batch get another\nbatch from the iterator\nit's director if we go and run this\nagain our batch size is not going to\nchange\nbut our classes so you should see these\nnumbers change over here right so if we\ngo and run this again you can see that\nwe've now got a new batch of data from\nour data pipeline and just for our own\npurposes let's write a note so class one\nequals sad people\npeople\nand then class\nzero\nequals\nhappy\npeople\nand if we go and run our visualization\nagain you're gonna see that so zero\nhappy people one sad people one sad\npeople one sad people\nwho is that is that timberland kid cardi\ni don't know um but over here what we're\ndoing is we're actually using matplotlib\nand matplotlib's subplots function to be\nable to plot out four images at a\nparticular time\ncool but that is our data set now\nbrought in so we've actually got that\nnow read in let's uh let's quickly\nreview what we've done so we have\nsuccessfully\ninstalled a bunch of dependencies and\nset them up we've removed any dodgy\nimages we might have and we've also gone\nand loaded up our data using the keras\nimage data set from directory helper\nlet's jump back on over and have a chat\nto our client and see what's next\nall right so now that we've got some\ndata loaded what's next we've got to get\npre-processing what pre-processing for\nimage data we tend to pre-process by\nscaling the image values to between 0\nand 1 instead of zero to 255 this helps\nour deep learning model generalize\nfaster and produces better results cool\nanything else we've got to do yep we're\nalso going to split up our data into\ntraining testing and validation\npartitions to ensure that we don't\noverfit let's get to it and we are back\nso now what we're on to doing is\npre-processing our data so we've got our\ndata loaded but now we've got to do some\npre-processing and this is where step\ntwo comes in so there's two things that\nwe're going to do here we are going to\nscale our data and by that what i mean\nis that when we loaded in our data over\nhere actually let me tell you so if we\nactually go to our data so if i type in\nbatch and remember our batch is composed\nof two parts our images and our labels\nso our images are going to be in key 0\nand our labels are going to be in key\none\nif we go to or index one whatever you\nwant to call it uh if we go to the first\nthing then this is going to be our\nimages so if we type in dot shape all of\nour images all right so we've got 32\nimages of shape 256 by 256 by three\nchannels\nnow\nwhen you load in an images of\nrepresentation of a number of channels\nwhich are going to be rgb for opencv\nit's going to be bgr when you use\ntensorflow i think it's rgb\nbut it's going to be of the values 0 to\n255.\nso if i type in dot min does that work\nyep\nso this means our lowest value is 0.0\nand dot max should return 255.\nnow when you're building deep learning\nmodels ideally you want the values to be\nas small as possible this is going to\nhelp you optimize a ton faster so what\nwe can do is really quickly is all we\nreally need to do is divide these values\nby 255\nand that is going to give us values\nbetween zero and one now so if i type in\nuh certain let's say um scaled\nso if i type in scaled\nand then we type in dot min\nso the last value is still zero the\nmaximum value\nnow one so this means that we've\nsuccessfully scaled our data but\nremember that we are using a data\npipeline so we can't necessarily go and\ndo this every single time we load up a\nbatch what we want to do in order to do\nit most efficiently is just do it as\nwe're loading in the data through the\ndata pipeline using the data pipeline\ncapability\nso let's actually go and take a look at\nhow we might do this\ninside of the data pipeline we've\nactually got a function called map and\nthis allows us to apply a particular\ntype of transformation\nas our data is being pre-processed\nthrough the data pipeline now this means\nthat when we go on pre-fetch data it's\ngoing to do that transformation as well\nso this means that it speeds up how\nquickly we can access our data from our\ndisk\nso what we've got in written is data\nequals data dot map this is really\nreally important guys pay attention the\ndata.map actually allows you to perform\nthat transformation in pipeline so\ndata.map and then we're using a lambda\nfunction to be able to go and do that\ntransformation so when we go and access\nour batch remember we're going to get\nour images and our labels so x is going\nto represent our images because those\nare our what is it our independent\nfeatures so we are going to be passing\nthose in y is going to be our target\nvariable so that is what you can see\nthere or effectively our labels\nwhat we're going to do is that as we\nload in a batch we are going to go and\nget our data over here so you can see\nwe've got x and we're going to divide it\nby 255 that is our scaling\nand we are going to form no\ntransformation on our y so if we go and\nrun that\nwe've now effectively applied that\ntransformation step on our data pipeline\nnow there are a ton of additional um\ntransformations you can do inside of a\ndata pipeline or a tensorflow data set\npipeline right and if you just go to\ntens flow\ndata set\napi i know tensorflow data api\nyeah tf.data\nright there are a ton of functions so if\ni go to tf.data where is it here\nover here\nso tf.data.dataset\nthere are a ton of functions so over\nhere you can see that there are an\nabsolute ton so we are using the map\nfunction which you can see there\nand again this allows you to do a whole\nbunch of stuff across elements within a\ndata set exactly what it's saying there\nthere's a whole bunch of other ways that\nyou can use it we're using it in this\nparticular manner over here\ncool cool\nthe other ones that i tend to use a ton\nare zip so let's say for example i\nwanted to combine a\nset of features and labels zip oh sorry\njust slap the mic zip is a way to\ncombine those um skip you'll probably\nsee that in a second\nwhat's another one\nfrom generator tensor slices from\ntensors these are pretty common as well\nbut i'll include a link to this inside\nof the description below so you can see\nit as well but that is effectively our\ndata scaled right\nso now\nif we go and take a look at a next batch\nyou can see that we are doing that\ninside of our data pipeline so this is\nno different to what we did from up here\nso rather than going and creating\nseparate variables from our iterator we\ncan actually access our data that like\nthat as well so data dot and then dot as\nnumpy iterator so that gives us access\nto our iterator and then dot next is\ngoing to grab our next batch now keep in\nmind this is going to if we're not\napplying shuffling it's going to return\nback the exact same values each and\nevery time in this case we've got\nshuffling so you can see that our data\nis changing\nlet's just grab our first set of at\nimages so again we can grab our images\nby grabbing the first index if we type\nin dot max\nyou can see them wait hold on that is a\nvery low max dot min\nzero dot max\n0.03 that seems very low\nlet's grab another batch\nuh so we can let's call this scaled\nequals\nscaled iterator\ndata.as numpyre\nand then if we go scale to iterator\ndot next\nthese all look awfully low\nmaybe we've just got uh images which\naren't all that bright or aren't that\ncolorful\nlet's go dot max\nwe need to grab our first value again\ngrab the next batch\nseems awfully low\nlet's actually take a look at it using\nour\nusing our plotting function over here so\nif we grab that\nso let's grab a batch so that's our data\nthen we can grab the iterator and then\nlet's just grab create a batch here\nkind of weird that they're so low batch\nequal scale data.next\nall right so data equals that this is\ngoing to be our scale iterator grab a\nnext batch\nwhat does this look like they're all\nblack\nsomething has gone wrong there\nlet's go and reload our data so\ngrab our data set\nand skip that bit let's go and run\nthrough that pipeline\nwait hold up so because we've gone and\ndivided our images by\n255 they're no longer going to be\nintegers but right over here inside of\nour visualization function we are\nconverting them to integers but in this\nparticular case they'd all be 0 because\nthey're between 0 and 1. so if i divide\nthis\nthis is now on a set of our scale data\nright so data's now got a lambda\nfunction let's just go and reload our\ndata over here\nthis is reestablishing our data pipeline\nwe're then going and running it through\nour lambda then if we go and take our\nnext batch let's go through our scale\ndata set\nthis is going to be our scale data\nperfect so if we go and type dot as type\ninto\nright that's going to turn them all\nblack no go\ncolored let's just double check so batch\nokay so that looks a little bit better\nnow hold on so if we go batch zero\ndot max\nokay one\ndot min i don't know what's happening\nthere but that looks like it's okay\ngood good thing that we're double\nchecking that this data is appropriately\nfunction maybe we went around that data\npipeline twice so we're going and\ndividing by 255 twice that's the only\nthing that i can think of there but if\nwe go and reload or re-establish our\ndata set by going and running this line\nover here\nand then if we go and apply a lambda\nagain\ngo and test this out\nright so max is one i'm in\nis zero now if we go and visualize\nperfect all right cool so that is our\ndata now scaled so we know that our\nimages are now between zero and one the\nnext thing that we want to go on ahead\nand do is split our data into a training\nand testing partition this means that\nwhen it comes to actually going and\nvalidating our data and ensuring that\nour model hasn't overfit we've actually\ngot specific partitions\nso in order to do this we are first up\ngoing to establish what our training\ndata sizes should be so let's just\nquickly take a look at the length of our\ndata in its entirety\nso we have seven batches and remember\neach batch is going to have 32 images so\nthere's probably one that's going to be\ntruncated if it's not equal batches but\nthat is the number of batches that we've\ngot so our training set is going to be\n70 of that data so that should be what\nuh 50 what is it 49 so it would be like\nwhat five batches or seven times point\nseven\nright so we'll have roughly five batches\nthere then we're going to have\n20 assigned to validation so that'll\nprobably be one and then this will\nprobably be one as well let's just see\nwhat this comes out as\nso how big is our training size four so\nit's rounded down how big is our\nvalidation size\none and how big is our test size\nzero so all right so we should probably\nadd one to that so that means we'll have\nfour plus one plus one that's only going\nto give us six so let's add an\nadditional one to our validation\npartition so\ntrain is going to now be\nfour batches validation is now going to\nbe\ntwo batches and test is now going to be\none batch so train\nplus or train size plus vowel size\nplus test size\nequals seven which equals this right so\nwe're good to go now let me quickly\nexplain what we're doing here so our\ntraining data is going to be what is\nused to actually train our deep learning\nmodel our validation data is going to be\nwhat we use to evaluate our model while\nwe're training so this means that our\nmodel hasn't necessarily seen our\nvalidation partition but we're using it\nto fine tune how we actually build this\ndeep learning model and it's good\npractice to have a training and\nvalidation partition as you're building\nup these models your test partition your\nmodel is not going to have seen until we\nget to the final evaluation state so we\nhold that out all the way until the end\nso these two are using are used during\ntraining this one is used post training\nto do the evaluation and right now all\nwe're establishing is how much data\nwe're going to allocate to each one of\nthese partitions so we are going to have\n7 multiplied by 32 image or wait hold on\nwe're going to have four multiplied by\n32 images allocated to our training\npartition we're going to have two\nmultiplied by 32 images allocated to our\nvalidation partition and we're going to\nhave one batch assigned to our test size\nnow\nuh we don't need to take a look at that\nin order to do this we actually can use\nthe take and skip methods available\ninside of the tensorflow dataset\npipeline so if i actually show you this\nso over here you can see\nwe've got take and skip so take defines\nhow much data we are going to take in\nthat particular partition so if we go\nand run this line here\nso our training size\nso uh len\nis for batches aval\ndata is two batches and our test data\nis one batch\nso in order to do this first up what\nwe're doing is we're saying train\nequals data dot take and then we're\nsaying how many batches we want to\nallocate to our training data now keep\nin mind our data is already shuffled if\nyour data hadn't been shuffled you want\nto shuffle it before you do this so\ntrain is going to equal four batches so\ntrain equals data dot take and then to\nthat we're passing through train size\nval is gonna equal data dot skip so\nfirst up what we're gonna do is we're\ngonna skip the batches that we've\nalready allocated to our training\npartition and then we're gonna take the\nlast two into our valve data so data dot\nskip and we're going to skip the first\nfour which we've allocated to train and\nthen we're going to take two based on\nthe vowel size so take two and then we\nare going to take two batches and that\nis what our validation partition is\ngoing to look like then our test is\ngoing to be everything left over right\nso test equals data dot skip and we're\ngoing to skip the training data and the\nvalidation data and then we're going to\ntake the rest which should be our test\npartition\nand that is how you establish your train\ntest and validation partitions and that\nis the last step in our pre-processing\nstage as well so we've now gone\nand scaled our data and i sort of showed\nyou how to actually go and apply that\nlambda layer or the map layer and we\nalso saw that we had a bit of an issue\nthere right so we saw that our data\nwasn't necessarily scaled and this is\npotentially because we went and applied\nthis twice\nnow in order to fix that all you need to\ndo is go and re-run this line over here\nand go and re-run this particular line\nhere and again we're overwriting\nvariables so again that can be a little\nbit sketchy in terms of how we can\nactually trace that back so you might\nactually go and choose to call this um\nscale data\nso that way you can't override it twice\nbut in this case we are good so our data\nis scaled our data is now between 0 and\n255 we've gone and taken a look and\nvisualized it and we have also gone and\ncreated our train validation and testing\npartitions let's jump back on over to\nour client\nall righty onto the good bit now that\nour data's pre-processed we can begin\nmodeling i've always told my mom i was\ndestined for the catwalk what uh yeah\nwhat we're going to do now is build our\ndeep learning model using the keras\nsequential api nice so this is the ai\nbit right right come on gisele let's do\nthis all right so we are now on to the\ngood bit actually doing the deep\nlearning so in terms of doing this there\nare going to be three components so\nfirst up we are going to build a deep\nneural network and in order to do that\nwe're probably going to need to import a\nbunch of stuff then we're actually going\nto go on ahead and train the specific\ndeep learning model\nin order to do this we can actually use\nthe dot fit method and then we're also\ngoing to plot our performance using\nmatplotlib as well okay so first things\nfirst let's go and import some\ndependencies using tensorflow so\nfirst up what we're going to be doing is\nwe are going to be importing the\nsequential api so in order to do that\nwithin from tensorflow.keras.models\nimport sequential now the reason that i\nmake this distinction is that there are\ntwo really specific models or two\nspecific\nlike model building apis available\ninside of tensorflow and keras the first\none is called sequential and that's what\nwe're going to be using this is great if\nyou've got one data input and one data\noutput and the model sort of just flows\nfrom top to bottom there is another type\nof api and that is the functional api\nand that is really really powerful if\nyou've got like multiple inputs multiple\noutputs multiple connections you need to\ndo a whole bunch of fancy stuff with\ndeep learning models so um i've\ndefinitely got one of those coming up\nfor you a little bit more advanced but\nwe do have that coming up so sequential\nis great if you need something quick and\neasy and that's what we're going to be\ndoing in this case for deep learning\nclassification\nthen the next thing that we're bringing\nin are a whole bunch of layers so the\nlayers that we've brought in are\navailable through from\ntensorflow.keras.layers import conf 2d\nso this is a convolutional neural\nnetwork layer so if we actually type in\nconf 2d into google and we don't want\nthe pi torch equivalent we want the\ntensorflow equivalent\nso this is a 2d convolutional layer eg\nspatial convolution over images which is\nexactly what we're doing\nso we're bringing in a convolutional 2d\nor conv 2d layer a max pooling layer\nwhich effectively\nacts as a like think of it like a\ncondensing layer so it actually goes\nthrough your images and actually\ncondenses it down so it goes what's the\nmax value in this region only return\nthat region so rather than returning all\nof the data from our convolution we\nactually condense it down then we're\nbringing in dents so this is a fully\nconnected layer available through keras\nwe'll also bring in the flattened layer\nso this is what allows us to go for a\nconvolutional layer which has\nchannels or kernels\nnamely channels and it actually reduces\nit back into a format which our dense\nlayer will be able to take so that we\ncan only get one output at the end and\nthen we've got dropout which is\ntypically used for regularization but i\ndon't think we actually use that in this\nbut anyway we've got a whole bunch of\nlayers so typically when you're building\nneural networks you're going to form an\narchitecture and an architecture is a\nwhole bunch of different layers or\nhidden layers which form a deep neural\nnetwork so\nin order to do that first up we are\ngoing to create or let's actually go and\nimport that first up we are going to\ncreate a model and we are establishing\nthat as so so model equals sequential\nnow i'm going to show you the way that i\ntypically do this but you can always um\npass through the layers inside of the\nsequential class so i could actually do\nconv 2d here\nand then add in all the stuff and then\njust sort of stack these as so but i\ntypically use the add method and\nactually sort of chain them on when i'm\nusing the sequential api but you'll see\npeople do it like that as well so um\nthat's just the thing to call out if you\nsee people doing using the sequential\napi like that perfectly fine this is\njust a matter of choice so we are\nestablishing our sequential class or an\ninstance of our sequential class so\nwritten model equals sequential and a\nset of parentheses now we're going to\nadd in our layers this is where the\nmagic happens so we have let me break\nthis out\nwe're not actually using dropout we\ncould actually get rid of that would\nstill work over here so we've got three\nconvolution blocks we have a flattened\nlayer and we've got two dense layers so\nlet's break this up so this first\nsection over here is performing or\nadding a convolutional layer and a max\npooling layer so model dot add and\nremember how i said that you can either\nstack them or pass them direct to the\nsequential class or you can use\nmodel.add to add layers now i'm adding\nthis sequentially so this means that the\nfirst layer in my deep neural network is\nfirst up going to be an input so we\nwhenever you're passing through a first\nlayer that first layer needs to have an\ninput or either needs to be an input\nlayer now again i'll talk about that\nmore when we do functional models later\non but\nknow that our first layer is a\nconvolution here so model.add and we're\nadding a convolution and this\nconvolution is going to have 16 filters\nthat is what a convolution has so it's\ngot a whole bunch of filters and it\nbasically scans over an image and tries\nto condense or extract the relevant\ninformation inside of that image to make\nan output classification\nso we've got 16 filters and our filter\nis going to be three pixels by three\npixels in size and we are going to\nstrike have a stride of one this means\nthat it's going to move one pixel each\ntime so it's gonna go bang bang bang so\non and so forth now you can increase\nthat stride you can increase the number\nof filters you can increase um the size\nof the filters these are all what we\ncall architectural decisions now you\nmight have actual like state-of-the-art\nmodels which actually prescribe how you\ndo this so if you actually go and take a\nlook at how imagenet does classification\nthere is a specific architecture that is\nused there\nhow we actually go and change these\nparticular hyper parameters or these\nparticular model parameters influences\nwhat our model performs like\nbut typically when you're doing a\nconvolution you have the number of\nfilters the size of the filter and the\nstride another really important function\nor another aspect of it is the\nactivation that gets applied so here we\nare applying a relu activation so let me\nshow you this a relu\nactivation really all we're saying is\nthat we're taking the output from this\nconvolutional layer and we're going to\npass it through a function that looks\nlike this so that means that any output\nthat was pre previously below zero\nis now going to be converted to zero and\nwe are going to preserve the positive\nvalues so this effectively means that we\nare\nconverting any negative values to zero\nand anything that's positive remains\nunchanged this allows us to take into\naccount a non-linear patterns right so\nif you've just got or if you've got no\nactivations and really all you're\nbuilding is a deep neural network which\nis linear in nature so it's not\nnecessarily that powerful this is where\nthe power comes from applying all these\nactivations there are a ton of them\nright so another popular one that we'll\nuse as well is a sigmoid activation\nand that looks like this now these can\nsound really complex but just think\nabout it as that we're taking all of our\ndata or all of the output from a layer\nand we're passing it through this\nfunction to modify what the output looks\nlike right so we might have a whole\nbunch of numbers between um i don't know\nnegative infinity and positive infinity\nor like really really small or really\nreally big values\nbut by going and actually changing it\ni'm passing it through one of these\nactivations we're reshaping what that\noutput looks like right and we're\nreshaping what the function looks like\nas a result of that as well\ncool so\nwhat's the full line i've gone through\nand talked about this a ton but so we're\ngoing to read a model model.addconf2d so\nwe're going to have 16 filters of shape\n3x3 and then we are going to have a\nstride of 1 and a pass through a relu\nactivation we are also going to specify\nwhat our input shape looks like now\nremember that i said that the keras\ntense what is that image data set from\ndirectory function actually reshapes our\nimages well our images are going to be\nin the shape 256 pixels by 256 pixels by\nthree channels so they're going to be\n256 pixels higher by 256 pixels wired by\nthree channels deep and again we pass\nthis through into our initial we just\npassed it through in our first layer\nhere\nthen we're applying a max pooling layer\nso this is just gonna take the maximum\nvalue after the relu activation and it's\ngoing to return back that value so it's\ngoing to scan across and go it's\neffectively going to condense the\ninformation it's not just going to take\none number it's actually going to do it\nover a set region so\nwhat is this let's actually take a look\nwhat's the default max pooling 2d\nquestion mark question mark so it's\ngoing to go over a two by two region so\nyou can see two by two two by two\nand it's going to take the max value out\nof that two by two region so it's\neffectively going to reduce our image\ndata i think by half in that particular\ncase so rather than having well yeah\nhalf\nbased on the rows or half based on the\nrows half based on the width as well so\nit's going to condense that information\ndown\nand then we've effectively got another\none of those blocks over here so again\nthe next set of laser we're adding so\nmodel.addconf2d\nso we've now got 32 filters of shape 3x3\nof stride 1 and again we've got relu\nactivation now the max pooling rate so\nthen we've got another convolution block\nthen we've got exactly the same over\nhere this time we've just got 16 filters\nand then what we're doing is we're\nactually flattening this data down so\nwhen we actually apply a convolutional\nlayer\nthe filters are going to be the last\nchannel so we're going to condense the\nrows and the width and then the number\nof filters will form the channel value\nnow\nwhen we actually go and pass this to our\ndense layer we don't want that channel\nvalue right because we want to condense\nit down to a single value so by\nflattening it that's what we're\neffectively doing so then we're now\ngoing to have 256 values as our output\nand then finally one value as our output\nhere so if we actually go and run this\noh well let's actually talk about this\nin a little bit more detail so we've\ngone and flattened it then the last two\nlayers that we apply are dense layers so\nthese are fully connected layers so if\nyou've ever seen a neural network you\nsee a lot of little dots and they're all\nconnected and they form go down to a\npoint these are referred to as fully\nconnected layers\nso inside of keras we call them dense\nlayers so we've got dents we have 256\nneurons and again we're applying relu\nactivations here and then our final\nlayer is a single dense layer this means\nthat we're going to get a single output\nand that output is effectively going to\nrepresent 0 or 1 because we have a\nsigmoid activation\nso if we take a look at what our sigmoid\nactivation does let's zoom in\nour sigmoid activation takes any output\nand converts it into effectively a range\nbetween 0\nand 1. now as 0 and one map to our happy\nand sad classes so if it is zero that is\ni think what i can't even remember what\nit is now so if it's zero it's going to\nbe a happy person and if it's one it's\ngoing to be a sad person that is what\nour final layer is going to output there\nso you can see that there cool right\nand that is our deep neural network so\nif we go and run that layer\nthat is successfully run\nthe next thing that we need to do is\ncompile that so this is the next most\nimportant bit in your neural network so\nwe type in model.compile and remember\nour model was initially initialized up\nhere\nand then to that we pass through a few\nthings we pass through the optimizer\nthat we want to use and in this case\nwe're going to be using the atom\noptimizer there are a ton of optimizers\nso if we type in tf.keras\nactually is it tf.optimizers dot there\nare a ton\nso we've got ada delta adagrad adam adam\nmax uh ftrl i haven't seen that one too\nmuch uh n atom rms propped sgd so again\nthere's a ton of optimizers that are\nactually available so\nin this case we're going to be using the\natom optimizer then we're specifying\nwhat our loss is and our loss in this\nparticular case because we are\nperforming effectively a binary\nclassification problem it's going to be\ntf.losses.binarycrossentropy\nand the metric that we want to track is\naccuracy you can pass through a bunch\nmore in this particular case but our\naccuracy is going to tell us how well\nour model is classifying as either 0 or\n1.\nso if we go and compile it\nthis is my favorite bit so by typing in\nmodel.summary you can actually see how\nour model transforms our data\nso remember our model takes in an input\nof shape 256 by 256 by 3 right 256 by\n256 by 3.\nour first convolution layer converts it\nto be 254 by 254\nby the number of filters so that 16 is\ncoming from up here then we apply a max\npooling layer so it converts it from 254\nto 54 by 16 to 127 by 127 by 16. that\n127 remember how i said because it is\nshape 2-2 it's taking 254 divided by 2\nwhich gives us 127. so it effectively\nhalves the output that we're getting out\nof this convolutional layer there\nbut it is not a trainable layer right so\nyou can see that there's no parameters\nassigned to it so it shouldn't\neffectively increase the size of our\nmodel too much it just condenses stuff\ndown\nthen we're going and applying another\nconvolution layer so again this one's\ngoing to 125 by 125 by 32\nnow we could actually preserve the size\nfrom over here by applying some padding\nbut i'm not going to delve into that for\nnow so we're going 125 by 125 by 2 and\nagain we've got 32 filters that is\ncoming from over here\nand then we are applying max pooling\nagain so it's going to be halving our\ndata\nthen we've got our last convolution\nblock 60 by 60 by 16 we're playing\nconvolutions 30 by 30 by 16 and then\nwe're getting our flattened layer right\nso we've got 14\n400 values\nlet me enable scrolling so i can show\nyou this so what we're doing is we're\ntaking the outputs from this max pooling\nlayer and we're converting it into a\nsingle dimension so if we type in what\nis that 30 by 30 by 16\nthat is the number of outputs which are\npassed to our flattened layer so you can\nsee that we're getting all of these\ndimensions or all of these elements here\nthat multiply by that multiplied by that\ngives us the number of inputs that are\ngoing into our flattened layer so we're\ncondensing them down into a single\ndimension so rather than having a\nmulti-dimension or multi-rank tensor\nwe're converting it down to that\nthen we pass it to our dense layer which\nis 256 uh what is it neurons which is\nover here\nand then we finally go down to a single\nlayer over here a single output layer\ncool\nnow if you're probably wondering why\nthis is 257 parameters keep in mind\nthere's a bias term as well right so\nit's it's going to be the value of the\nweights from your neurons plus the bias\nterm\nthat gives us our total number of\nparameters so three million six hundred\nninety six thousand six hundred and\ntwenty five values so it's pretty uh\nit's not\nmonstrous right you've probably seen\nlike bert or big bert like those are\nmassive models gpt3 huge as is 3.7\nmillion now we could probably condense\nthat down as well if we really wanted to\nbut that particular case that is our\ndeep neural network now modeled so\nwe can get rid of this get rid of that\nthat is our neural network\nthat is step 3.1 and now done so we've\nnow gone and built our deep learning\nmodel right and so we've taken a look at\nour imports we've taken a look at some\nof the different types of layers that\nwe'll use and we've also seen how we can\nstack these layers up now the next thing\nthat we want to do is actually go on\nahead and train so first thing we're\ngoing to create a log directory and\nwe've already got this created so you\ncan see over here\ni've got a folder called logs\nso we are just going to create a\nvariable which points to that and then\nwe're going to create a callback so\nthese callbacks are really really useful\nif you wanted to\nsave your model at a particular\ncheckpoint if you wanted to do some\nspecific logging which is what we're\ngoing to do\nnow\nin order to do this we're creating a\ncallback so tensorboard underscore\ncallback and we're setting that equal to\ntf.keras.callbacks.tensorboard\nand we're specifying the log directory\nequal to this logs folder over here so\nwhen you go and do this you're going to\nhave your tensorboard logs logged out\ni'm going to talk about this more in a\nfuture tutorial but we're setting it up\nnow so tensorboard underscore callback\nand we're passing through this parameter\nhere so this is going to log out\nyour model training as its training so\nif you wanted to come back and see how\nyour model performed did it vary at a\nparticular point in time do we need to\ndrop our learning rate you're actually\ngoing to see that inside of these boards\nbut we can actually just plot them using\nthe history that you collect from your\ntraining step which i'll show you in a\nsec\ncool\nso that's our callback established\nnow we're going to go on ahead and fit\nour model so there's two really really\nimportant methods when it comes to\nbuilding a neural network model.fit and\nmodel.predict so fit is the training\ncomport component predict is when we\nactually go and make predictions so\nmodel.fit is going to take in our\ntraining data and remember our training\ndata was four batches of 32 images each\nour epochs is how long we're actually\ngoing to go ahead and train for and one\nepoch is one run over our entire\ntraining set of data\nwe're also going to pass through our\nvalidation data so this means that after\nwe've gone and performed a or gone and\ntrained on all of our training data or\ntraining batches we're then going to run\nevaluation on our validation data so we\ncan actually see how well our model is\nperforming in real time\nthen we're also going to pass through\nour callbacks so if we wanted to go and\napply additional callbacks or let me\nknow if you want a tutorial on callbacks\nguys i'm more than happy to do it so\nhere we're actually specifying that we\nwant to log out all of the information\nfrom our model to tensorboard so we\ncould open it up inside a tensorboard\nlater on\num and by storing it inside of a\nvariable called hist or history we're\ngoing to be able to take out all of the\ntraining information from our training\ndata and our validation data and plot\nthem out inside of step 3.3 so if we\nactually go and run this now this is\ngoing to kick off our training run so\nlet's run it\nand you'll actually see our deep\nlearning model start training\nso it might take a little while to start\nbut eventually you'll start to see it\ntraining so it's going really really\nfast because we've obviously got a gpu\nbut that is now training\nyou can see it's taking what 377\nmilliseconds per step our loss is going\ndown so ideally you want to see your\nloss go down and your accuracy go up\nand so what you've got over here so this\nis the loss on your training data this\nis your training let me zoom in because\nyou probably can't see that this is the\nloss on your training data this is the\naccuracy for your training data this is\nyour validation loss\nand this is your validation accuracy so\nideally you want to see them or you want\nto see your losses decrease both pretty\nconsistently and pretty steadily and you\nwant to see your accuracies go up pretty\nsteadily as well\nover here so you can see it's definitely\nperforming way better so look our losses\ndrop down significantly and our accuracy\nhas got up to a hundred percent so again\nit's performing really really well by\nthe end\nand that was it so it went really really\nquickly\nthat's how deep neural network trained\nguys that's how quick it goes so um this\nis obviously with a gpu so it's a lot\nfaster with out a gpu i think we saw\nroughly a\ndouble increase in the training time so\nagain you'll still be able to do this\nwithout a gpu but\nthat is our deep neural network now\ntrained the magic is done now\ncool thing is because we've gone and\nsaved it inside of or saved our training\nhistory inside of a variable called\nhistory we can actually get a whole\nbunch of information from this so if i\nshow you hist\nthere is this shows us that callback so\nif i type in history history\nthere is a whole bunch of information\navailable in here let me scroll so you\ncan see that we've got our loss\ninformation we've got our accuracy\ninformation so that's on our training\ndata also got our validation loss\ninformation and we should also have our\nvalidation accuracy information which\nyou can see there pretty cool right but\nwe can actually plot this performance\nout\nwhich is what i've got here so here i'm\njust using matplotlib so plot.plot and\nwe're grabbing our training loss and\nwe're grabbing our validation loss and\nwe're plotting those so here what you're\ngoing to see is that our training loss\nhas the color teal and our validation\nloss has the\nhas the color orange\nlet's go and plot it out\nso you can see that our loss has sort of\ndecreased pretty steadily over time we\nhave we've had one bit of a spike there\nbut it's sort of come back\nif you start to see your loss going down\nand your validation loss sort of rising\nup that that is an indication that your\nmodel may be overfitting so it might be\ntime to look at applying some\nregularization might also mean that we\nneed to apply some data\nor change some data if you don't see\nthese decreasing at all or if you see\nyour green line like not decreasing or\ngoing weird this might mean that you\nneed to take a look at your training\ndata again maybe potentially consider a\nlarger neural network or a more\nsophisticated neural network because\nthat means that it's not able to learn\nor reduce the loss for that particular\ndata or that training data overall\nso it might mean we have a bit of a bias\nproblem\nokay so um if you the validation law\nstarts tearing off that might mean you\nhave a variance problem so again\nregularization is your friend in that\nparticular case\nokay so we've got our loss metrics so\nvisualize those uh\nnow we can also take a look at our\naccuracy metrics so again this sort of\nlittle block here is pretty useful\nbecause you can actually visualize just\nabout anything that you want\nand it's really really useful when\nyou're doing deep learning as well\nbecause if you added more metrics\nso let me go scroll up\nif we added in more metrics when we're\ncompiling our model you'd actually be\nable to visualize all of them so in the\niris tracking video that i'm working on\nas well i actually show how to do that\nfor a whole bunch of metrics\nokay so that is our last visualize now\nwe can also visualize our accuracy so\nagain we're using matplotlib to\nvisualize these so if we go and run this\none\nyou can see our accuracy steadily\nincreased over time we had a little bit\nof a pop out there but again we've come\nback\nand it has resolved back up to 100\naccuracy which is very very good right\nobviously this model is performing well\nthere's not a ton of data so ideally\nyou'd want to flesh this out with a ton\nmore data but in that particular case\nthat is our model now trained so we've\nactually gone and completed our modeling\nstep so we've gone and built our deep\nlearning model and we've used this\nsequential api we've gone and trained\nour model using the model.fit function\nand i've also shown you how to pass\nthrough your training data your\nvalidation data as well as setting up a\ncallback and we've also gone and taken a\nlook at our training performance so\nwe've visualized our loss and we've also\nvisualized our accuracy let's jump back\non over to our client and we might be on\nto our evaluation step\nso we've finished training our model now\nit's time to test it out of course wait\nwhat does that mean well think of how\nyou might test an athlete you put the\nathlete through its paces and review\ncertain metrics so you might measure a\nsprinter by their 100 meter dash time\nfor our classification model we'll do\nthe same ah got it so we're going to\ncheck how fast our model is\nnot quite we've got a few different\nmetrics we'll use for classification\nthese include precision recall and\naccuracy let's jump to it so we're in\nthe end game now evaluating performance\nso we've gone and trained our model the\nnext thing that we want to do is\nactually go and evaluate performance on\nour testing data because remember we\nheld out that partition that our model\nhas never seen before so there's two\nthings we want to do first up evaluate\nit and then we'll also grab some random\nimages and test that out\nso\nin order to evaluate we're going to\nimport a couple of key metrics so from\ntensorflow.keras.metrics import\nprecision recall and binary accuracy\nthese are different measures that you\ntypically use for classification\nproblems so i'm going to import those\nand then what we can do or in order to\nuse them we need to establish instances\nof them\nand then what we can do is update our\nstate as we actually go and make\npredictions so we can go and instantiate\nthose i've written pre and these are\npretty crappy variable names i think i\nwas running out of energy so pre equals\nprecision and again we're grabbing this\nclass over here creating it\nre equals recall\nand then accuracy equals binary accuracy\nthen in order to go and test them out\nwe're going to loop through each batch\nin our testing data which i think we\nonly had one\nbatch anyway right\nthe len test nope lower case\none batch anyway so four batch in test\ndot as numpy iterator so that's going to\nbring back our batch and then we can\nunpack it so x comma y equals batch so\nthis is going to be our set of images\nthis is effectively our y true value\nthen we're passing through our image\ndata to our model so model.predict is\nhow we make predictions and that is\ngoing to return back a set of values\nbetween zero and one because remember\nwe've gone and passed it through a\nsigmoid activation\nso in order to update our metrics we can\nthen type in or use the update state\nmethod so\nprecision.updatestate and we pass\nthrough our y true value and our\npredicted value of i've gone and screwed\nthat up so pass through our y true value\nand our y hat value so you can see those\nthere\nand we've gone and done that for\nprecision a recall and for accuracy so\nwe'll then be able to see how it's\nactually performed on our test data so\nif i go and run that it should run for a\nlittle sec and then we can actually\nprint out those results so to actually\nmake\nthis a little bit easier to read so uh f\nequals uh precision result\nso this is precision\nor ecr\nand i think we can write dot numpy as\nwell\nand uh what is this this is recall\ndot numpy\nand this is accuracy\nmy head blocking that off nope okay\ngot num hi\nuh what have we done we haven't finished\nit gotta close that\nboom okay\ni should close that over there all right\nso there we go so we've now gone and\nprinted out our performance on each of\nthose different metrics our precision is\none so a higher precision means your\nmodel is performing better a recall is\none again high value on recall means\nyou're performing better and that\naccuracy is one so again higher value\nmeans you're performing better now the\neach of these metrics are between zero\nand one so this is the highest possible\nvalue it can take um now again if you\nwant to deep dive on how these metrics\nare calculated or let's say for example\nwanted to do a confusion matrix let me\nknow and i can delve into those but just\nknow that this model is performing\npretty much as well as it can on a\nsingle batch of data and considering how\nlittle data we've actually given it to\nperform\nso we've got a precision of 100 a recall\nof 100 and an accuracy of a hundred\npercent as well now normally i don't\nlike to leave it there i like to\nactually go and test it out on data\nthat's outside of that batch so\nlet's actually go on ahead and do this\nnow the first import that we're going to\nimport is cv2 but i thought we've\nalready imported opencv\nwe have we should have\nwe imported it when we're doing the ht\nyeah we've already got that so we can\nactually skip that\nwe don't need to import opencv but for\nnow let's just import it anyway i'm\nwasting time\nwhat we're going to do is we're going to\nread in an image that our model has\nnever seen before so what we're going to\ndo is let's go and grab a random image\nso let's actually go to page 2 or scroll\nfurther down\nlet's grab this dude\nso i'm going to save this image and i'm\ngoing to save it into our image\nclassification folder we're going to\ncall this sad test\nand let's saved it as jfif i don't know\nwhy google does that so frustrating sad\ntest dot jpg\nis it yes okay cool then we're gonna get\nan image of a happy person\nhappy peoples\nfind a happy dude\nso this is completely out of sample\nright our model's never seen this before\nlet's go\nthis one's great all right let's save\nthis image\nso happy um that's webp that's not gonna\nwork\nso again it needs to be jpg it's just\ngonna make your life a whole bunch\neasier let's grab this one\nhappy test dot jpg\nokay cool so i've got two test images so\nif i open up my folders so you can see\nwhy they're not there there we go so\nwe've got happytest.jpg so this is that\ngirl that's super happy and we've got a\nsad test but this dude dark and stormy\nis red ready to drop a beat all right\nnow what we're going to do\nis we are going to read in that image\nusing cv2.iamread\nand so first up let's read in a happy\nimage so we can type in\nhappy test dot jpg so that should read\nin our image and we should plot it out\nright now remember this opencv is going\nto read it in as bgr rather than rgb do\nwe fix that here no we don't let me show\nyou how to do it cv2 cvt color\nand then we're going to go and pass\nthrough the color conversion code\ncv2.color underscore bgr2rgb\nand that should visualize it in its\ncorrect color so there you go so we've\ngone and fixed up the color there it's\ngone and successfully loaded it\nnow remember when we pass through our\ndata to our neural network and need to\nbe in the shape 256 by 256x3\nso 256 pixels high 256 pixels wide and\nit needs to be three channels so what we\ncan actually do is use\ntf.image.resize to resize our image\nbefore we pass it through to our neural\nnetwork so if we actually go and run\nthis\nthat is what our image looks like now\nresized now again we could go and apply\nthe\ncv2cv2.cvt color method over here\nand grab this\npaste it here\nand we are throwing an error that is\nbecause it is an integer\nfrom that doesn't look like it's playing\nnicely anyway we've gone and transformed\nit now so\nwith uh tensorflow so you can see that\nwe've definitely gone and resized it\njust because we've read it in using\nopencv we're getting that weird coloring\nbut\nlet's actually go and test this out now\nso if we actually go and pass this\nthrough to our model so model.predict\nand then we're passing it through to our\nneural network so now quick word on what\nhow we're actually doing this prediction\nour neural network expects us to pass\nthrough a batch of images not a single\nimage so what we actually need to do is\nwe need to encapsulate it inside of\nanother set of parentheses or arrays or\nput it inside of a list so in order to\ndo this and you'll see this done quite a\nfair bit is we can type in np.expanddims\npass through our image which is right\nnow called resize because we've gone and\nresize it using tf.image.resize\npass that into there and if i type in\nwhat axis i want to apply the extra\ndimension\nyou can see that right now it's just\nstored inside of an extra dimension so\nlet me show you that the first value\nyou can see that we've got a whole bunch\nof extra dimensions there this is the\nfirst value\nuh let's scroll it so you can see that\nwe don't have an extra set of\nparentheses there by throwing it in\nthere literally all we're doing is we're\nencapsulating it in another set of\narrays or putting it in inside of\nanother list so if i actually show you\nthe shape now dot shape\nit's 1 by 256 by 256 by 3. if we take a\nlook at the shape for this\nit's 256 by 256 by 3. so we're literally\njust wrapping it in another set of\narrays now what we're also doing at the\nsame time is we're dividing about 255 to\nscale it so if we go and run this\ntake a look at y hat so 0.28 so remember\nwhat was a sad or happy person happy\nperson was zero\nwhich you can see there so happy is zero\nsad is one\nso in this particular case our model has\nsuccessfully predicted that this\nparticular person is happy\nnow the reason that we're making this\nassumption is if a particular in our\nbinary classification problem\nwhat we're saying is that 50 is our\ncutoff point so if it's below 50 we\nround down to zero then this particular\ncase we're saying that our person is\ngoing to be happy so it's successfully\nclassified that particular person we've\ngot y hat twice there we don't need that\nnow\nthe way that you can extrapolate this or\nactually explain this in in regular\nterms is that\nour predicted class is happy if it is\nless than 0.5 so if y hat is greater\nthan 0.5 the predicted class is going to\nbe sad otherwise the predicted class is\ngoing to be happy which is exactly what\nwe've said over there so because it's\n0.28 it is less than 0.5 which means\nthat our model has successfully\npredicted it as happy pretty nuts right\nlike we didn't have a ton of data we\ndidn't even train for that long and\nwe've successfully gone and built a deep\nneural network that performs\nclassification but let's actually go and\ntest it out on our sad person as well so\nin order to do that we just need to pass\nthrough a different image so this one's\ngoing to be sad test\nand if we go and run this\nso our model has gone and given us a\nprobability of 86.8\nwhich means it's going to be above 50\nwhich means we have predicted sad\nsuccessfully take a look at that\npredicted class is sad\nso really quickly we've gone and been\nable to perform or build a deep neural\nnetwork that is able to perform\nsentiment classification using nothing\nbut a couple of images we've collected\nfrom the web\nlet's go jump back on over to our client\nand give him one last final update\nalright home run baby you know it the\nlast thing we need to do is save our\nmodel so we can reload it at a future\ndate so this means another developer or\nengineer could use the model right right\nthis could also be deployed as an api or\nto an edge device let's finish this\nalrighty we're at the final step so\nsaving the model so this is a really\nimportant step so you've gone through\nall to this and this amount of effort\nthe last thing that you want to do is\nsave this model so you can go and use it\nagain if you did want to now this is\nrelatively straightforward we can import\nor bring in the dependency from\ntensorflow called load model so from\ntensorflow.kerastop models import load\nmodel\nso then what we can do is actually use\nthis load model function to be able to\nload up our model now first of all we\nactually need to do save the model and\nto do that we can just use model.save\nnow we're going to save it inside of the\nfolder models and we can name it just\nabout whatever we want so we could call\nit um\nhappy sad model\nand because we're saving it as a h5\nmodel what we're actually doing is\nsomething called serialization so we're\ntaking a model and we're serializing it\nonto something that we can store as a\ndisk so this is similar to what you\nmight do when you zip a data set um when\nyou go and wire a data set h5 is a\nserialization file format so it\nbasically means that you're going to\nhave a file called happysadmodel.h5\nand then we can reload that using the\nload model function up here so the full\nline is model.save and then to that\nwe're passing os.path.join\nand we're going to be saving it inside\nof our models folder which i've already\ngot created over here nothing in there\nat the moment\nand we're going to be saving it as happy\nsad model.h5 it could be whatever you\nwant it to save it as right if i go and\nrun that inside of our models folder you\ncan see we've now got our happy sad\nmodel.h5 file over there\nso we're looking good now the next thing\nthat we want to do is actually go and\nreload this model so let's actually go\nand rename it so we're going to call it\nnew underscore model and we can use load\nunderscore model to load that model back\nup now we need to pass through the full\nfile path to our saved model in order to\nreload it so we can actually grab this\nh5 file name here pass it over to here\nso we are basically saying it's going to\nbe inside of\nthe models folder\nso models and then happysav model.h5 so\nwe're basically going to give it this\nfile path to be to the load model\nfunction to be able to load it back up\nso if we go and run this now\nthis is our new model it's a new model\nis our sequential keras model\nand if we go and pass data to it so\nagain we're going to pass through our\nresize image so np dot expand dims\npassing through our resize image which\nwe're scaling\nand we should get a prediction again you\ncan see we're getting a sad prediction\nif we go and run this again so let's\ncall this y hat\nnew\ngrab this block over here\nso what we're going to say if y hat nu\ngreater than 0.5 you can see still\npredicting sad\nthat in a nutshell is how to build a\ndeep neural network for image\nclassification so we've gone through a\nton of stuff in this tutorial let's\nquickly recap so we first up went up and\nset up our image or our environment to\nbe able to set up and load our data so\nwe're going to import a bunch of\ndependencies we went and removed some\ndodgy images and we went and downloaded\nthem originally from google now remember\nyou can get that image extension which\nmakes your life a whole bunch easier so\nwhat was it called um\ndownload all images it's just a google\nchrome extension nothing fancy there it\njust makes your life ton easier when\ngetting images we then went and loaded\nour data set using the image data set\nfrom directory method we went and\npre-processed our data so we scaled it\nand we split it we then went and built\nour deep neural network and went into a\nbit of detail as to how we've actually\nconstructed this architecture we then\nwent and trained it using model.fit\ntook a look at our performance over time\nwe went and then finally evaluated it\nover some new images that we've got off\nthe web and last but not least we've\ngone and saved our model down to our\ndisk so we can bring it back when we\nneed to that in a nutshell is this\ntutorial done thanks again for tuning in\nguys peace thanks so much for tuning in\nguys hopefully you enjoyed this video if\nyou did be sure to give it a big thumbs\nup hit subscribe and tick that bell and\nlet me know what deep neural network\ntype tutorials we should be doing next\ndid you enjoy this one did you build it\nyourself and what do you go on about and\nclassify thanks again for tuning in\npeace\n",
  "words": [
    "ever",
    "wanted",
    "build",
    "deep",
    "image",
    "classifier",
    "well",
    "tutorial",
    "going",
    "exactly",
    "let",
    "music",
    "music",
    "happening",
    "guys",
    "name",
    "nicholas",
    "tronat",
    "tutorial",
    "mentioned",
    "going",
    "building",
    "custom",
    "deep",
    "image",
    "classifier",
    "using",
    "data",
    "nice",
    "thing",
    "tutorial",
    "literally",
    "pull",
    "bunch",
    "images",
    "web",
    "load",
    "pipeline",
    "able",
    "use",
    "classify",
    "images",
    "zero",
    "one",
    "binary",
    "classification",
    "type",
    "problem",
    "tutorial",
    "going",
    "much",
    "focused",
    "going",
    "end",
    "end",
    "pipeline",
    "first",
    "going",
    "focus",
    "getting",
    "data",
    "loading",
    "pipeline",
    "going",
    "take",
    "look",
    "steps",
    "need",
    "perform",
    "order",
    "improve",
    "well",
    "model",
    "performs",
    "going",
    "build",
    "deep",
    "image",
    "classifier",
    "using",
    "keras",
    "tensorflow",
    "build",
    "sequential",
    "deep",
    "neural",
    "network",
    "evaluate",
    "test",
    "last",
    "least",
    "save",
    "model",
    "take",
    "elsewhere",
    "use",
    "need",
    "ready",
    "let",
    "get",
    "hey",
    "nick",
    "hoping",
    "build",
    "deep",
    "learning",
    "model",
    "classify",
    "pictures",
    "something",
    "possible",
    "trying",
    "classify",
    "uh",
    "part",
    "stealth",
    "tech",
    "startup",
    "looking",
    "build",
    "cutting",
    "edge",
    "mobile",
    "app",
    "classify",
    "youtuber",
    "thumbnails",
    "wait",
    "shocked",
    "face",
    "duck",
    "face",
    "gon",
    "na",
    "need",
    "sign",
    "nda",
    "know",
    "like",
    "idea",
    "right",
    "well",
    "idea",
    "use",
    "ai",
    "classify",
    "images",
    "people",
    "happy",
    "sad",
    "okay",
    "use",
    "image",
    "classification",
    "nice",
    "get",
    "started",
    "well",
    "first",
    "thing",
    "probably",
    "need",
    "get",
    "images",
    "happy",
    "sad",
    "people",
    "use",
    "helpers",
    "inside",
    "keras",
    "tensorflow",
    "load",
    "yeah",
    "let",
    "go",
    "alrighty",
    "guys",
    "going",
    "going",
    "end",
    "end",
    "image",
    "classification",
    "deep",
    "learning",
    "pipeline",
    "thing",
    "wow",
    "got",
    "really",
    "long",
    "really",
    "quick",
    "going",
    "able",
    "build",
    "deep",
    "image",
    "classifier",
    "using",
    "pretty",
    "much",
    "whatever",
    "data",
    "want",
    "particular",
    "tutorial",
    "sort",
    "wanted",
    "show",
    "first",
    "things",
    "first",
    "going",
    "need",
    "go",
    "ahead",
    "discussed",
    "client",
    "need",
    "go",
    "set",
    "load",
    "data",
    "order",
    "going",
    "couple",
    "key",
    "things",
    "first",
    "going",
    "install",
    "dependencies",
    "set",
    "also",
    "going",
    "also",
    "going",
    "remove",
    "dodgy",
    "images",
    "found",
    "sometimes",
    "download",
    "images",
    "web",
    "images",
    "versus",
    "images",
    "captured",
    "tend",
    "get",
    "dodgy",
    "images",
    "images",
    "corrupt",
    "going",
    "show",
    "remove",
    "going",
    "load",
    "data",
    "first",
    "couple",
    "things",
    "need",
    "first",
    "installing",
    "dependencies",
    "setup",
    "per",
    "usual",
    "code",
    "see",
    "inside",
    "including",
    "entire",
    "jupyter",
    "notebook",
    "going",
    "available",
    "inside",
    "github",
    "check",
    "link",
    "description",
    "first",
    "things",
    "first",
    "need",
    "install",
    "dependencies",
    "setup",
    "order",
    "run",
    "particular",
    "line",
    "first",
    "line",
    "exclamation",
    "mark",
    "pip",
    "install",
    "tensorflow",
    "tensorflow",
    "gpu",
    "opencv",
    "python",
    "matplotlib",
    "tensorflow",
    "tensorflow",
    "gpu",
    "going",
    "used",
    "part",
    "deep",
    "learning",
    "pipeline",
    "going",
    "use",
    "keras",
    "sequential",
    "api",
    "second",
    "able",
    "go",
    "ahead",
    "opencv",
    "going",
    "used",
    "go",
    "remove",
    "dodgy",
    "images",
    "matplotlib",
    "going",
    "used",
    "visualize",
    "images",
    "go",
    "run",
    "going",
    "go",
    "ahead",
    "install",
    "dependencies",
    "scroll",
    "looks",
    "like",
    "got",
    "warning",
    "telling",
    "us",
    "probably",
    "update",
    "pip",
    "version",
    "particular",
    "case",
    "fine",
    "need",
    "cool",
    "go",
    "validate",
    "whether",
    "got",
    "right",
    "dependencies",
    "installed",
    "go",
    "run",
    "pip",
    "list",
    "let",
    "go",
    "take",
    "look",
    "tense",
    "flow",
    "got",
    "tensorflow",
    "tensorflow",
    "gpu",
    "got",
    "watched",
    "beginner",
    "setup",
    "tutorial",
    "released",
    "make",
    "sure",
    "go",
    "visit",
    "particularly",
    "got",
    "gpu",
    "need",
    "set",
    "tensorflow",
    "gpu",
    "acceleration",
    "go",
    "step",
    "step",
    "going",
    "make",
    "life",
    "ton",
    "easier",
    "okay",
    "next",
    "thing",
    "need",
    "go",
    "ahead",
    "import",
    "dependencies",
    "order",
    "going",
    "import",
    "two",
    "key",
    "dependencies",
    "first",
    "one",
    "tensorflow",
    "import",
    "tensorflow",
    "tf",
    "second",
    "one",
    "os",
    "written",
    "import",
    "os",
    "os",
    "namely",
    "used",
    "let",
    "minimize",
    "os",
    "mainly",
    "used",
    "navigate",
    "file",
    "structures",
    "typically",
    "using",
    "os",
    "using",
    "dot",
    "join",
    "let",
    "say",
    "example",
    "need",
    "go",
    "data",
    "directory",
    "needed",
    "go",
    "folder",
    "called",
    "happy",
    "right",
    "going",
    "return",
    "back",
    "file",
    "structure",
    "uh",
    "homogeneous",
    "regardless",
    "type",
    "operating",
    "system",
    "using",
    "using",
    "windows",
    "machine",
    "going",
    "perfectly",
    "fine",
    "using",
    "mac",
    "linux",
    "machine",
    "going",
    "return",
    "folder",
    "structure",
    "format",
    "appropriate",
    "particular",
    "type",
    "operating",
    "system",
    "main",
    "type",
    "function",
    "use",
    "inside",
    "os",
    "let",
    "say",
    "example",
    "wanted",
    "show",
    "um",
    "files",
    "images",
    "inside",
    "particular",
    "directory",
    "could",
    "actually",
    "type",
    "let",
    "say",
    "got",
    "folder",
    "called",
    "data",
    "going",
    "list",
    "everything",
    "inside",
    "particular",
    "folder",
    "anything",
    "later",
    "actually",
    "see",
    "use",
    "couple",
    "key",
    "tips",
    "use",
    "os",
    "right",
    "next",
    "line",
    "going",
    "go",
    "ahead",
    "limit",
    "limit",
    "tense",
    "flow",
    "using",
    "vram",
    "gpu",
    "default",
    "load",
    "tensorflow",
    "load",
    "data",
    "going",
    "expand",
    "use",
    "potential",
    "vram",
    "available",
    "machine",
    "tends",
    "become",
    "bit",
    "nightmare",
    "particularly",
    "getting",
    "really",
    "big",
    "models",
    "two",
    "particular",
    "lines",
    "code",
    "actually",
    "help",
    "prevent",
    "helps",
    "prevent",
    "something",
    "called",
    "oom",
    "error",
    "memory",
    "error",
    "first",
    "thing",
    "actually",
    "grabbing",
    "gpus",
    "available",
    "machine",
    "first",
    "line",
    "gpus",
    "equals",
    "underscore",
    "physical",
    "underscore",
    "devices",
    "passed",
    "gpu",
    "right",
    "actually",
    "go",
    "write",
    "line",
    "dot",
    "list",
    "physical",
    "oh",
    "gosh",
    "typing",
    "shocker",
    "devices",
    "type",
    "gpu",
    "going",
    "give",
    "us",
    "gpus",
    "got",
    "available",
    "right",
    "see",
    "got",
    "one",
    "giant",
    "machine",
    "multiple",
    "gpus",
    "actually",
    "see",
    "multiple",
    "type",
    "take",
    "look",
    "length",
    "particular",
    "line",
    "see",
    "got",
    "one",
    "gpu",
    "available",
    "typed",
    "cpu",
    "see",
    "got",
    "one",
    "cpu",
    "available",
    "right",
    "particular",
    "case",
    "returning",
    "cpu",
    "wanted",
    "see",
    "devices",
    "got",
    "available",
    "filter",
    "line",
    "next",
    "line",
    "actually",
    "limiting",
    "memory",
    "growth",
    "looping",
    "every",
    "potential",
    "gpu",
    "got",
    "inside",
    "line",
    "four",
    "gpu",
    "gpu",
    "gpus",
    "inside",
    "going",
    "run",
    "underscore",
    "memory",
    "growth",
    "telling",
    "tensorflow",
    "hey",
    "use",
    "memory",
    "keep",
    "minimum",
    "keep",
    "whatever",
    "absolutely",
    "need",
    "limiting",
    "ensures",
    "going",
    "avoid",
    "memory",
    "errors",
    "might",
    "still",
    "get",
    "got",
    "batch",
    "sizes",
    "large",
    "solvable",
    "error",
    "cool",
    "gone",
    "installed",
    "dependencies",
    "imported",
    "couple",
    "also",
    "gone",
    "limited",
    "memory",
    "growth",
    "next",
    "line",
    "showing",
    "exactly",
    "showed",
    "need",
    "run",
    "go",
    "run",
    "going",
    "limit",
    "memory",
    "growth",
    "saw",
    "run",
    "going",
    "run",
    "good",
    "step",
    "done",
    "gone",
    "installed",
    "dependencies",
    "got",
    "importer",
    "whatever",
    "need",
    "also",
    "gone",
    "limited",
    "memory",
    "growth",
    "next",
    "bit",
    "removing",
    "dodgy",
    "images",
    "actually",
    "actually",
    "need",
    "get",
    "images",
    "nice",
    "thing",
    "tutorial",
    "wanted",
    "build",
    "could",
    "actually",
    "go",
    "build",
    "image",
    "classifier",
    "anything",
    "wanted",
    "nice",
    "thing",
    "actually",
    "go",
    "get",
    "bunch",
    "images",
    "world",
    "wide",
    "web",
    "going",
    "building",
    "image",
    "classifier",
    "image",
    "sentiment",
    "classifier",
    "particular",
    "sense",
    "need",
    "need",
    "get",
    "images",
    "happy",
    "people",
    "let",
    "get",
    "images",
    "happy",
    "people",
    "going",
    "go",
    "google",
    "go",
    "images",
    "type",
    "happy",
    "people",
    "see",
    "got",
    "bunch",
    "overly",
    "ecstatic",
    "people",
    "happy",
    "knows",
    "gon",
    "na",
    "go",
    "ahead",
    "download",
    "actually",
    "got",
    "extension",
    "inside",
    "google",
    "chrome",
    "makes",
    "life",
    "ton",
    "easier",
    "comes",
    "actually",
    "know",
    "let",
    "called",
    "uh",
    "tools",
    "extensions",
    "one",
    "download",
    "images",
    "go",
    "get",
    "particular",
    "extension",
    "going",
    "game",
    "changer",
    "comes",
    "building",
    "deep",
    "learning",
    "stuff",
    "right",
    "open",
    "extension",
    "see",
    "says",
    "download",
    "images",
    "yeah",
    "click",
    "going",
    "start",
    "downloading",
    "images",
    "page",
    "saw",
    "literally",
    "inside",
    "zip",
    "folder",
    "got",
    "images",
    "go",
    "downloads",
    "open",
    "take",
    "look",
    "images",
    "happy",
    "people",
    "cool",
    "pretty",
    "awesome",
    "right",
    "able",
    "build",
    "deep",
    "learning",
    "image",
    "data",
    "set",
    "really",
    "really",
    "quickly",
    "going",
    "grab",
    "particular",
    "zip",
    "file",
    "going",
    "cut",
    "going",
    "take",
    "image",
    "classification",
    "repository",
    "actually",
    "shown",
    "let",
    "particular",
    "notebook",
    "inside",
    "folder",
    "got",
    "directory",
    "called",
    "data",
    "directory",
    "called",
    "image",
    "classification",
    "virtual",
    "environment",
    "seen",
    "beginner",
    "tutorial",
    "go",
    "jump",
    "back",
    "show",
    "set",
    "got",
    "folder",
    "called",
    "logs",
    "going",
    "log",
    "stuff",
    "got",
    "folder",
    "called",
    "models",
    "well",
    "going",
    "grab",
    "data",
    "downloaded",
    "put",
    "data",
    "folder",
    "going",
    "rename",
    "call",
    "happy",
    "double",
    "check",
    "right",
    "thing",
    "yeah",
    "cool",
    "happy",
    "people",
    "happy",
    "right",
    "going",
    "go",
    "gone",
    "done",
    "got",
    "set",
    "image",
    "data",
    "happy",
    "people",
    "need",
    "set",
    "data",
    "sad",
    "people",
    "kind",
    "like",
    "get",
    "order",
    "pizza",
    "beer",
    "friday",
    "night",
    "got",
    "bunch",
    "people",
    "sad",
    "going",
    "go",
    "extensions",
    "download",
    "images",
    "see",
    "downloading",
    "good",
    "great",
    "downloaded",
    "going",
    "go",
    "downloads",
    "going",
    "grab",
    "repository",
    "paste",
    "going",
    "call",
    "one",
    "assad",
    "got",
    "inside",
    "data",
    "folder",
    "got",
    "got",
    "happy",
    "zip",
    "got",
    "sad",
    "zip",
    "going",
    "extract",
    "go",
    "extract",
    "gon",
    "na",
    "create",
    "extract",
    "separate",
    "folder",
    "gon",
    "na",
    "extract",
    "happy",
    "let",
    "zoom",
    "way",
    "small",
    "happy",
    "gon",
    "na",
    "extract",
    "happy",
    "know",
    "sometimes",
    "code",
    "pretty",
    "small",
    "guys",
    "work",
    "improve",
    "promise",
    "going",
    "extract",
    "happy",
    "see",
    "got",
    "folder",
    "called",
    "happy",
    "overly",
    "happy",
    "people",
    "right",
    "cool",
    "going",
    "go",
    "facade",
    "gone",
    "pop",
    "saying",
    "following",
    "imp",
    "file",
    "already",
    "exists",
    "let",
    "say",
    "yes",
    "okay",
    "got",
    "two",
    "folders",
    "got",
    "whole",
    "bunch",
    "happy",
    "people",
    "yeah",
    "cool",
    "great",
    "inside",
    "sad",
    "folder",
    "got",
    "whole",
    "bunch",
    "sad",
    "people",
    "guy",
    "clearly",
    "big",
    "day",
    "work",
    "guy",
    "well",
    "right",
    "going",
    "go",
    "ahead",
    "uh",
    "going",
    "take",
    "zip",
    "folders",
    "actually",
    "going",
    "move",
    "back",
    "root",
    "folder",
    "way",
    "sort",
    "mess",
    "around",
    "go",
    "load",
    "data",
    "keras",
    "utility",
    "going",
    "look",
    "subfolders",
    "needs",
    "cool",
    "going",
    "close",
    "going",
    "close",
    "going",
    "close",
    "well",
    "opened",
    "ton",
    "images",
    "need",
    "one",
    "open",
    "either",
    "right",
    "cool",
    "gone",
    "going",
    "download",
    "bunch",
    "images",
    "people",
    "bunch",
    "images",
    "happy",
    "people",
    "gone",
    "put",
    "inside",
    "data",
    "folder",
    "wanted",
    "classes",
    "literally",
    "go",
    "download",
    "classes",
    "paste",
    "need",
    "change",
    "neural",
    "network",
    "little",
    "bit",
    "want",
    "tutorial",
    "hit",
    "comments",
    "maybe",
    "make",
    "one",
    "okay",
    "gone",
    "got",
    "image",
    "data",
    "sets",
    "got",
    "one",
    "happy",
    "one",
    "sad",
    "kind",
    "go",
    "next",
    "thing",
    "going",
    "going",
    "go",
    "remove",
    "dodgy",
    "images",
    "let",
    "explain",
    "sometimes",
    "go",
    "get",
    "images",
    "world",
    "wide",
    "web",
    "even",
    "though",
    "appropriate",
    "file",
    "extensions",
    "might",
    "open",
    "python",
    "might",
    "corrupted",
    "might",
    "mislabeled",
    "might",
    "incorrect",
    "extension",
    "applied",
    "particular",
    "block",
    "going",
    "help",
    "us",
    "get",
    "rid",
    "first",
    "thing",
    "need",
    "import",
    "two",
    "dependencies",
    "importing",
    "opencv",
    "uh",
    "allows",
    "us",
    "let",
    "actually",
    "show",
    "type",
    "opencv",
    "huge",
    "open",
    "c",
    "open",
    "computer",
    "vision",
    "module",
    "allows",
    "ton",
    "computer",
    "vision",
    "good",
    "stuff",
    "super",
    "awesome",
    "never",
    "checked",
    "opencv",
    "means",
    "next",
    "thing",
    "importing",
    "image",
    "hdr",
    "allows",
    "us",
    "check",
    "file",
    "extensions",
    "particular",
    "images",
    "two",
    "lines",
    "import",
    "opencv",
    "import",
    "image",
    "hdr",
    "next",
    "thing",
    "going",
    "create",
    "variable",
    "hold",
    "path",
    "data",
    "directory",
    "remember",
    "inside",
    "got",
    "data",
    "directory",
    "called",
    "data",
    "inside",
    "data",
    "directory",
    "got",
    "two",
    "folders",
    "one",
    "called",
    "happy",
    "one",
    "called",
    "sad",
    "right",
    "going",
    "go",
    "create",
    "variable",
    "points",
    "data",
    "underscore",
    "dr",
    "equals",
    "data",
    "going",
    "go",
    "create",
    "list",
    "extensions",
    "let",
    "minimize",
    "talking",
    "yet",
    "early",
    "image",
    "extensions",
    "jpeg",
    "jpg",
    "bmp",
    "png",
    "standard",
    "list",
    "go",
    "navigate",
    "uh",
    "let",
    "actually",
    "run",
    "first",
    "image",
    "underscore",
    "exts",
    "right",
    "typed",
    "image",
    "right",
    "literally",
    "list",
    "actually",
    "go",
    "grab",
    "first",
    "one",
    "jpeg",
    "second",
    "one",
    "jpg",
    "third",
    "one",
    "going",
    "png",
    "actually",
    "fourth",
    "one",
    "cool",
    "reason",
    "setting",
    "going",
    "loop",
    "remember",
    "told",
    "import",
    "os",
    "actually",
    "go",
    "ahead",
    "let",
    "check",
    "type",
    "os",
    "dot",
    "list",
    "dr",
    "type",
    "pass",
    "data",
    "deal",
    "return",
    "happy",
    "sad",
    "returns",
    "folders",
    "inside",
    "data",
    "directory",
    "go",
    "run",
    "happy",
    "sad",
    "pretty",
    "cool",
    "right",
    "would",
    "happen",
    "wanted",
    "go",
    "check",
    "every",
    "single",
    "image",
    "inside",
    "happy",
    "folder",
    "well",
    "could",
    "go",
    "pass",
    "data",
    "directory",
    "pass",
    "let",
    "say",
    "example",
    "happy",
    "folder",
    "going",
    "return",
    "every",
    "single",
    "image",
    "inside",
    "subfolder",
    "pretty",
    "cool",
    "right",
    "allows",
    "us",
    "loop",
    "every",
    "single",
    "image",
    "got",
    "inside",
    "folder",
    "exactly",
    "dodgy",
    "image",
    "script",
    "going",
    "second",
    "remember",
    "one",
    "additional",
    "thing",
    "need",
    "go",
    "ahead",
    "actually",
    "go",
    "run",
    "image",
    "script",
    "normally",
    "getting",
    "images",
    "interwebs",
    "actually",
    "go",
    "data",
    "set",
    "anything",
    "small",
    "weird",
    "going",
    "remove",
    "anything",
    "10",
    "kilobytes",
    "probably",
    "going",
    "really",
    "small",
    "image",
    "weird",
    "microsoft",
    "edge",
    "vectors",
    "going",
    "get",
    "rid",
    "nine",
    "kilobytes",
    "onwards",
    "see",
    "let",
    "zoom",
    "see",
    "nine",
    "kilobytes",
    "eight",
    "four",
    "three",
    "pretty",
    "small",
    "gon",
    "na",
    "get",
    "rid",
    "delete",
    "wanted",
    "add",
    "additional",
    "images",
    "go",
    "like",
    "go",
    "another",
    "page",
    "download",
    "go",
    "another",
    "page",
    "download",
    "could",
    "definitely",
    "okay",
    "gone",
    "removed",
    "small",
    "weird",
    "images",
    "happy",
    "let",
    "go",
    "sad",
    "let",
    "go",
    "details",
    "tab",
    "going",
    "find",
    "10",
    "kb",
    "going",
    "delete",
    "everything",
    "see",
    "9",
    "going",
    "go",
    "way",
    "going",
    "remove",
    "anything",
    "smaller",
    "got",
    "get",
    "rid",
    "quick",
    "assist",
    "driving",
    "insane",
    "right",
    "let",
    "take",
    "look",
    "nine",
    "kilobytes",
    "one",
    "kilobyte",
    "remove",
    "boom",
    "done",
    "right",
    "cool",
    "leaves",
    "effectively",
    "work",
    "still",
    "gon",
    "na",
    "run",
    "dodgy",
    "image",
    "script",
    "well",
    "make",
    "sure",
    "weird",
    "stuff",
    "remember",
    "said",
    "talked",
    "exactly",
    "first",
    "looping",
    "every",
    "folder",
    "got",
    "inside",
    "data",
    "directory",
    "image",
    "class",
    "inside",
    "dr",
    "going",
    "go",
    "inside",
    "data",
    "directory",
    "effectively",
    "print",
    "happy",
    "inside",
    "let",
    "actually",
    "show",
    "let",
    "actually",
    "show",
    "print",
    "image",
    "class",
    "image",
    "image",
    "underscore",
    "class",
    "going",
    "print",
    "happy",
    "going",
    "print",
    "sad",
    "going",
    "go",
    "ahead",
    "going",
    "print",
    "every",
    "single",
    "image",
    "inside",
    "subdirectories",
    "go",
    "print",
    "go",
    "print",
    "image",
    "printing",
    "looping",
    "every",
    "single",
    "image",
    "going",
    "bunch",
    "checks",
    "right",
    "wanted",
    "specific",
    "check",
    "could",
    "go",
    "double",
    "checking",
    "one",
    "load",
    "image",
    "opencv",
    "two",
    "image",
    "matches",
    "one",
    "paths",
    "loaded",
    "still",
    "weird",
    "actually",
    "going",
    "remove",
    "particular",
    "folder",
    "right",
    "looping",
    "every",
    "single",
    "one",
    "data",
    "directory",
    "folders",
    "happy",
    "sad",
    "looping",
    "every",
    "single",
    "image",
    "got",
    "inside",
    "sub",
    "directories",
    "order",
    "four",
    "image",
    "underscore",
    "class",
    "four",
    "image",
    "going",
    "subfolders",
    "joining",
    "path",
    "data",
    "directory",
    "image",
    "class",
    "would",
    "effectively",
    "um",
    "happy",
    "well",
    "would",
    "data",
    "happy",
    "data",
    "sad",
    "going",
    "grabbing",
    "every",
    "single",
    "image",
    "explicitly",
    "going",
    "os",
    "data",
    "directory",
    "image",
    "classification",
    "folder",
    "image",
    "storing",
    "inside",
    "variable",
    "called",
    "image",
    "path",
    "passing",
    "actually",
    "opens",
    "image",
    "allows",
    "open",
    "image",
    "using",
    "opencv",
    "let",
    "actually",
    "test",
    "right",
    "type",
    "cv2",
    "dot",
    "read",
    "need",
    "pass",
    "full",
    "file",
    "path",
    "going",
    "pass",
    "makes",
    "easier",
    "going",
    "pass",
    "data",
    "folder",
    "let",
    "say",
    "example",
    "happy",
    "let",
    "go",
    "get",
    "file",
    "happy",
    "go",
    "uh",
    "image",
    "classification",
    "data",
    "happy",
    "let",
    "grab",
    "one",
    "looks",
    "pretty",
    "big",
    "going",
    "pass",
    "string",
    "jpg",
    "need",
    "extension",
    "well",
    "image",
    "classification",
    "data",
    "happy",
    "jpg",
    "cool",
    "dot",
    "jpg",
    "need",
    "close",
    "see",
    "gone",
    "read",
    "image",
    "numpy",
    "array",
    "type",
    "let",
    "store",
    "inside",
    "variable",
    "show",
    "type",
    "image",
    "numpy",
    "array",
    "actu",
    "actually",
    "mean",
    "basically",
    "let",
    "take",
    "look",
    "shape",
    "image",
    "shape",
    "three",
    "guy",
    "rows",
    "first",
    "going",
    "3744",
    "pixels",
    "high",
    "5616",
    "pixels",
    "wide",
    "got",
    "three",
    "channels",
    "means",
    "colored",
    "image",
    "actually",
    "go",
    "open",
    "image",
    "well",
    "let",
    "actually",
    "use",
    "python",
    "capability",
    "type",
    "show",
    "pass",
    "image",
    "imported",
    "matplotlib",
    "let",
    "import",
    "matplotlib",
    "let",
    "import",
    "let",
    "add",
    "another",
    "line",
    "um",
    "probably",
    "going",
    "visualize",
    "later",
    "want",
    "show",
    "matplotlib",
    "import",
    "pie",
    "plot",
    "plt",
    "let",
    "go",
    "run",
    "image",
    "see",
    "3",
    "000",
    "744",
    "pixels",
    "high",
    "5616",
    "pixels",
    "wide",
    "colored",
    "image",
    "probably",
    "wondering",
    "nick",
    "weird",
    "color",
    "opencv",
    "reads",
    "image",
    "bgr",
    "matplotlib",
    "expects",
    "rgb",
    "wanted",
    "fix",
    "type",
    "cv2",
    "dot",
    "cvt",
    "color",
    "pass",
    "image",
    "pass",
    "color",
    "conversion",
    "code",
    "going",
    "reorder",
    "channels",
    "type",
    "underscore",
    "bgr2rgb",
    "boom",
    "yep",
    "work",
    "go",
    "see",
    "color",
    "fixed",
    "wanted",
    "get",
    "rid",
    "weird",
    "line",
    "type",
    "pretty",
    "particular",
    "line",
    "effectively",
    "shows",
    "one",
    "read",
    "image",
    "using",
    "opencv",
    "join",
    "paths",
    "using",
    "go",
    "render",
    "okay",
    "sort",
    "explaining",
    "need",
    "need",
    "need",
    "need",
    "need",
    "want",
    "actually",
    "go",
    "run",
    "dodgy",
    "image",
    "script",
    "valid",
    "image",
    "valid",
    "image",
    "extension",
    "going",
    "go",
    "get",
    "rid",
    "using",
    "allows",
    "delete",
    "file",
    "let",
    "go",
    "run",
    "see",
    "inside",
    "try",
    "accept",
    "block",
    "effectively",
    "throws",
    "errors",
    "going",
    "fail",
    "particular",
    "block",
    "let",
    "go",
    "run",
    "see",
    "got",
    "weird",
    "images",
    "removing",
    "done",
    "let",
    "double",
    "check",
    "still",
    "bunch",
    "images",
    "inside",
    "data",
    "folders",
    "go",
    "data",
    "happy",
    "still",
    "got",
    "bunch",
    "images",
    "131",
    "exact",
    "inside",
    "sad",
    "got",
    "looks",
    "like",
    "bit",
    "unbalanced",
    "data",
    "set",
    "could",
    "definitely",
    "fix",
    "resample",
    "needed",
    "okay",
    "cool",
    "got",
    "bunch",
    "images",
    "gone",
    "cleaned",
    "looking",
    "good",
    "let",
    "take",
    "look",
    "done",
    "far",
    "installed",
    "dependencies",
    "successfully",
    "also",
    "removed",
    "dodgy",
    "images",
    "next",
    "thing",
    "want",
    "go",
    "ahead",
    "load",
    "data",
    "going",
    "well",
    "tensorflow",
    "actually",
    "data",
    "set",
    "api",
    "originally",
    "use",
    "ton",
    "getting",
    "started",
    "deep",
    "learning",
    "journey",
    "probably",
    "use",
    "every",
    "single",
    "time",
    "building",
    "deep",
    "learning",
    "model",
    "well",
    "actually",
    "allows",
    "build",
    "data",
    "pipeline",
    "rather",
    "loading",
    "everything",
    "memory",
    "begin",
    "actually",
    "allows",
    "build",
    "data",
    "pipeline",
    "one",
    "allows",
    "scale",
    "much",
    "larger",
    "data",
    "sets",
    "also",
    "gives",
    "repeatable",
    "set",
    "steps",
    "going",
    "apply",
    "data",
    "honest",
    "makes",
    "lot",
    "cleaner",
    "um",
    "whole",
    "bunch",
    "documentation",
    "wanted",
    "actually",
    "access",
    "type",
    "actually",
    "allows",
    "access",
    "api",
    "actually",
    "going",
    "use",
    "slightly",
    "differently",
    "rather",
    "using",
    "data",
    "set",
    "api",
    "directly",
    "actually",
    "going",
    "use",
    "keras",
    "utility",
    "actually",
    "allows",
    "example",
    "two",
    "trials",
    "actually",
    "got",
    "coming",
    "namely",
    "iris",
    "tracking",
    "one",
    "one",
    "use",
    "think",
    "toxic",
    "comment",
    "detection",
    "actually",
    "use",
    "typically",
    "load",
    "data",
    "set",
    "using",
    "um",
    "dataset",
    "tensors",
    "generator",
    "tensor",
    "slices",
    "also",
    "use",
    "load",
    "data",
    "directory",
    "typing",
    "list",
    "files",
    "actually",
    "allows",
    "wild",
    "card",
    "search",
    "wanted",
    "give",
    "little",
    "bit",
    "background",
    "um",
    "going",
    "using",
    "directly",
    "particular",
    "tutorial",
    "ton",
    "capability",
    "uh",
    "tf",
    "data",
    "set",
    "api",
    "okay",
    "data",
    "set",
    "api",
    "talked",
    "also",
    "taken",
    "look",
    "uh",
    "documentation",
    "also",
    "pro",
    "tip",
    "never",
    "used",
    "jupiter",
    "much",
    "type",
    "question",
    "mark",
    "question",
    "mark",
    "gives",
    "documentation",
    "particular",
    "line",
    "code",
    "method",
    "see",
    "next",
    "thing",
    "importing",
    "matplotlib",
    "imported",
    "wanted",
    "show",
    "image",
    "visualization",
    "importing",
    "numpy",
    "import",
    "numpy",
    "np",
    "matplotlib",
    "import",
    "pi",
    "plot",
    "plt",
    "go",
    "run",
    "two",
    "new",
    "dependencies",
    "imported",
    "going",
    "load",
    "data",
    "remember",
    "told",
    "got",
    "data",
    "set",
    "api",
    "well",
    "keras",
    "actually",
    "data",
    "pipeline",
    "direct",
    "function",
    "helper",
    "built",
    "well",
    "access",
    "order",
    "use",
    "type",
    "dot",
    "image",
    "underscore",
    "data",
    "set",
    "underscore",
    "underscore",
    "directory",
    "actually",
    "builds",
    "image",
    "data",
    "set",
    "fly",
    "need",
    "build",
    "labels",
    "need",
    "actually",
    "build",
    "classes",
    "going",
    "actually",
    "going",
    "bunch",
    "box",
    "resize",
    "images",
    "well",
    "let",
    "actually",
    "take",
    "look",
    "doco",
    "nope",
    "want",
    "take",
    "look",
    "yet",
    "go",
    "utils",
    "dot",
    "image",
    "actually",
    "going",
    "batch",
    "images",
    "batch",
    "32",
    "going",
    "resize",
    "images",
    "256",
    "256",
    "going",
    "shuffle",
    "also",
    "create",
    "validation",
    "split",
    "forth",
    "pretty",
    "cool",
    "right",
    "actually",
    "allows",
    "ton",
    "stuff",
    "right",
    "bat",
    "super",
    "useful",
    "helper",
    "building",
    "image",
    "classification",
    "models",
    "going",
    "get",
    "rid",
    "actually",
    "going",
    "create",
    "data",
    "set",
    "gone",
    "run",
    "line",
    "going",
    "store",
    "data",
    "set",
    "folder",
    "called",
    "variable",
    "called",
    "data",
    "means",
    "take",
    "look",
    "data",
    "nice",
    "thing",
    "data",
    "part",
    "well",
    "actually",
    "nice",
    "also",
    "little",
    "bit",
    "painful",
    "let",
    "say",
    "example",
    "wanted",
    "go",
    "take",
    "look",
    "data",
    "ca",
    "go",
    "grab",
    "first",
    "instance",
    "data",
    "set",
    "memory",
    "already",
    "actually",
    "generator",
    "fly",
    "actually",
    "need",
    "go",
    "grab",
    "data",
    "want",
    "easiest",
    "way",
    "convert",
    "numpy",
    "iterator",
    "first",
    "next",
    "line",
    "going",
    "go",
    "create",
    "data",
    "iterator",
    "data",
    "underscore",
    "iterator",
    "equals",
    "data",
    "dot",
    "numpy",
    "iterator",
    "probably",
    "would",
    "seen",
    "face",
    "verification",
    "tutorial",
    "actually",
    "going",
    "convert",
    "allow",
    "us",
    "access",
    "generator",
    "data",
    "pipeline",
    "data",
    "underscore",
    "iterator",
    "equals",
    "data",
    "numpy",
    "iterator",
    "actually",
    "get",
    "consecutive",
    "batches",
    "using",
    "dot",
    "next",
    "method",
    "show",
    "sec",
    "go",
    "run",
    "next",
    "line",
    "code",
    "actually",
    "going",
    "run",
    "dot",
    "next",
    "actually",
    "going",
    "get",
    "us",
    "batch",
    "back",
    "first",
    "let",
    "take",
    "look",
    "data",
    "iterator",
    "actually",
    "see",
    "iterator",
    "also",
    "like",
    "generator",
    "loop",
    "continuously",
    "pull",
    "data",
    "batches",
    "back",
    "right",
    "probably",
    "hyper",
    "useful",
    "right",
    "get",
    "significantly",
    "sophisticated",
    "deep",
    "learning",
    "models",
    "got",
    "massive",
    "amounts",
    "data",
    "gon",
    "na",
    "make",
    "life",
    "ton",
    "easier",
    "let",
    "actually",
    "take",
    "look",
    "going",
    "grab",
    "one",
    "batch",
    "think",
    "way",
    "building",
    "data",
    "pipeline",
    "actually",
    "allowing",
    "us",
    "access",
    "data",
    "pipeline",
    "actually",
    "accessing",
    "data",
    "pipeline",
    "allowing",
    "us",
    "loop",
    "grabbing",
    "one",
    "batch",
    "back",
    "go",
    "run",
    "line",
    "batch",
    "let",
    "actually",
    "take",
    "little",
    "batch",
    "visualize",
    "type",
    "batch",
    "actually",
    "batch",
    "data",
    "shape",
    "two",
    "two",
    "variables",
    "two",
    "parts",
    "tuple",
    "probably",
    "thinking",
    "nick",
    "hell",
    "number",
    "two",
    "well",
    "two",
    "parts",
    "data",
    "set",
    "images",
    "labels",
    "first",
    "part",
    "actually",
    "image",
    "representation",
    "images",
    "directory",
    "loaded",
    "memory",
    "set",
    "numpy",
    "arrays",
    "go",
    "grab",
    "first",
    "value",
    "got",
    "whole",
    "bunch",
    "arrays",
    "yeah",
    "see",
    "take",
    "look",
    "shape",
    "images",
    "loaded",
    "type",
    "dot",
    "shape",
    "got",
    "batch",
    "size",
    "32",
    "remember",
    "based",
    "image",
    "underscore",
    "data",
    "set",
    "underscore",
    "underscore",
    "directory",
    "helper",
    "method",
    "configure",
    "wanted",
    "images",
    "per",
    "batch",
    "actually",
    "wanted",
    "different",
    "image",
    "shapes",
    "nice",
    "thing",
    "particular",
    "utility",
    "automatically",
    "reshapes",
    "images",
    "ensure",
    "consistent",
    "size",
    "also",
    "batches",
    "batch",
    "size",
    "32",
    "configure",
    "let",
    "say",
    "example",
    "um",
    "go",
    "let",
    "actually",
    "go",
    "grab",
    "dataset",
    "directory",
    "wanted",
    "images",
    "per",
    "batch",
    "increase",
    "let",
    "say",
    "example",
    "much",
    "vram",
    "gpu",
    "could",
    "actually",
    "drop",
    "batch",
    "size",
    "way",
    "would",
    "let",
    "say",
    "data",
    "directory",
    "would",
    "type",
    "batch",
    "underscore",
    "size",
    "equals",
    "know",
    "16",
    "example",
    "yeah",
    "go",
    "batch",
    "size",
    "equals",
    "eight",
    "change",
    "wanted",
    "image",
    "size",
    "different",
    "could",
    "actually",
    "pass",
    "keyword",
    "argument",
    "image",
    "score",
    "size",
    "equals",
    "know",
    "let",
    "say",
    "128",
    "128",
    "would",
    "actually",
    "allow",
    "configure",
    "want",
    "data",
    "set",
    "look",
    "like",
    "defaults",
    "going",
    "work",
    "cool",
    "right",
    "taking",
    "look",
    "batch",
    "um",
    "took",
    "look",
    "images",
    "right",
    "images",
    "images",
    "represented",
    "numpy",
    "arrays",
    "let",
    "say",
    "labels",
    "go",
    "batch",
    "z",
    "one",
    "labels",
    "go",
    "particular",
    "case",
    "got",
    "flag",
    "one",
    "got",
    "flag",
    "zero",
    "zero",
    "zero",
    "zero",
    "one",
    "one",
    "one",
    "actually",
    "represent",
    "labels",
    "one",
    "going",
    "represent",
    "either",
    "happy",
    "sad",
    "zero",
    "going",
    "represent",
    "either",
    "happy",
    "sat",
    "could",
    "quite",
    "work",
    "whether",
    "way",
    "dictate",
    "class",
    "belongs",
    "number",
    "know",
    "way",
    "think",
    "way",
    "actually",
    "configure",
    "know",
    "sure",
    "using",
    "api",
    "ton",
    "um",
    "default",
    "helper",
    "sure",
    "actually",
    "actually",
    "go",
    "configuring",
    "one",
    "easy",
    "way",
    "around",
    "double",
    "check",
    "class",
    "assigned",
    "type",
    "image",
    "plot",
    "going",
    "allow",
    "see",
    "one",
    "flag",
    "actually",
    "assigned",
    "sad",
    "images",
    "zero",
    "flag",
    "assigned",
    "happy",
    "images",
    "see",
    "one",
    "one",
    "sad",
    "person",
    "zero",
    "happy",
    "people",
    "zero",
    "happy",
    "people",
    "zero",
    "happy",
    "people",
    "let",
    "say",
    "example",
    "wanted",
    "visualize",
    "another",
    "batch",
    "data",
    "well",
    "actually",
    "go",
    "run",
    "line",
    "going",
    "get",
    "another",
    "batch",
    "get",
    "another",
    "batch",
    "iterator",
    "director",
    "go",
    "run",
    "batch",
    "size",
    "going",
    "change",
    "classes",
    "see",
    "numbers",
    "change",
    "right",
    "go",
    "run",
    "see",
    "got",
    "new",
    "batch",
    "data",
    "data",
    "pipeline",
    "purposes",
    "let",
    "write",
    "note",
    "class",
    "one",
    "equals",
    "sad",
    "people",
    "people",
    "class",
    "zero",
    "equals",
    "happy",
    "people",
    "go",
    "run",
    "visualization",
    "gon",
    "na",
    "see",
    "zero",
    "happy",
    "people",
    "one",
    "sad",
    "people",
    "one",
    "sad",
    "people",
    "one",
    "sad",
    "people",
    "timberland",
    "kid",
    "cardi",
    "know",
    "um",
    "actually",
    "using",
    "matplotlib",
    "matplotlib",
    "subplots",
    "function",
    "able",
    "plot",
    "four",
    "images",
    "particular",
    "time",
    "cool",
    "data",
    "set",
    "brought",
    "actually",
    "got",
    "read",
    "let",
    "uh",
    "let",
    "quickly",
    "review",
    "done",
    "successfully",
    "installed",
    "bunch",
    "dependencies",
    "set",
    "removed",
    "dodgy",
    "images",
    "might",
    "also",
    "gone",
    "loaded",
    "data",
    "using",
    "keras",
    "image",
    "data",
    "set",
    "directory",
    "helper",
    "let",
    "jump",
    "back",
    "chat",
    "client",
    "see",
    "next",
    "right",
    "got",
    "data",
    "loaded",
    "next",
    "got",
    "get",
    "image",
    "data",
    "tend",
    "scaling",
    "image",
    "values",
    "0",
    "1",
    "instead",
    "zero",
    "255",
    "helps",
    "deep",
    "learning",
    "model",
    "generalize",
    "faster",
    "produces",
    "better",
    "results",
    "cool",
    "anything",
    "else",
    "got",
    "yep",
    "also",
    "going",
    "split",
    "data",
    "training",
    "testing",
    "validation",
    "partitions",
    "ensure",
    "overfit",
    "let",
    "get",
    "back",
    "data",
    "got",
    "data",
    "loaded",
    "got",
    "step",
    "two",
    "comes",
    "two",
    "things",
    "going",
    "going",
    "scale",
    "data",
    "mean",
    "loaded",
    "data",
    "actually",
    "let",
    "tell",
    "actually",
    "go",
    "data",
    "type",
    "batch",
    "remember",
    "batch",
    "composed",
    "two",
    "parts",
    "images",
    "labels",
    "images",
    "going",
    "key",
    "0",
    "labels",
    "going",
    "key",
    "one",
    "go",
    "index",
    "one",
    "whatever",
    "want",
    "call",
    "uh",
    "go",
    "first",
    "thing",
    "going",
    "images",
    "type",
    "dot",
    "shape",
    "images",
    "right",
    "got",
    "32",
    "images",
    "shape",
    "256",
    "256",
    "three",
    "channels",
    "load",
    "images",
    "representation",
    "number",
    "channels",
    "going",
    "rgb",
    "opencv",
    "going",
    "bgr",
    "use",
    "tensorflow",
    "think",
    "rgb",
    "going",
    "values",
    "0",
    "type",
    "dot",
    "min",
    "work",
    "yep",
    "means",
    "lowest",
    "value",
    "dot",
    "max",
    "return",
    "building",
    "deep",
    "learning",
    "models",
    "ideally",
    "want",
    "values",
    "small",
    "possible",
    "going",
    "help",
    "optimize",
    "ton",
    "faster",
    "really",
    "quickly",
    "really",
    "need",
    "divide",
    "values",
    "255",
    "going",
    "give",
    "us",
    "values",
    "zero",
    "one",
    "type",
    "uh",
    "certain",
    "let",
    "say",
    "um",
    "scaled",
    "type",
    "scaled",
    "type",
    "dot",
    "min",
    "last",
    "value",
    "still",
    "zero",
    "maximum",
    "value",
    "one",
    "means",
    "successfully",
    "scaled",
    "data",
    "remember",
    "using",
    "data",
    "pipeline",
    "ca",
    "necessarily",
    "go",
    "every",
    "single",
    "time",
    "load",
    "batch",
    "want",
    "order",
    "efficiently",
    "loading",
    "data",
    "data",
    "pipeline",
    "using",
    "data",
    "pipeline",
    "capability",
    "let",
    "actually",
    "go",
    "take",
    "look",
    "might",
    "inside",
    "data",
    "pipeline",
    "actually",
    "got",
    "function",
    "called",
    "map",
    "allows",
    "us",
    "apply",
    "particular",
    "type",
    "transformation",
    "data",
    "data",
    "pipeline",
    "means",
    "go",
    "data",
    "going",
    "transformation",
    "well",
    "means",
    "speeds",
    "quickly",
    "access",
    "data",
    "disk",
    "got",
    "written",
    "data",
    "equals",
    "data",
    "dot",
    "map",
    "really",
    "really",
    "important",
    "guys",
    "pay",
    "attention",
    "actually",
    "allows",
    "perform",
    "transformation",
    "pipeline",
    "using",
    "lambda",
    "function",
    "able",
    "go",
    "transformation",
    "go",
    "access",
    "batch",
    "remember",
    "going",
    "get",
    "images",
    "labels",
    "x",
    "going",
    "represent",
    "images",
    "independent",
    "features",
    "going",
    "passing",
    "going",
    "target",
    "variable",
    "see",
    "effectively",
    "labels",
    "going",
    "load",
    "batch",
    "going",
    "go",
    "get",
    "data",
    "see",
    "got",
    "x",
    "going",
    "divide",
    "255",
    "scaling",
    "going",
    "form",
    "transformation",
    "go",
    "run",
    "effectively",
    "applied",
    "transformation",
    "step",
    "data",
    "pipeline",
    "ton",
    "additional",
    "um",
    "transformations",
    "inside",
    "data",
    "pipeline",
    "tensorflow",
    "data",
    "set",
    "pipeline",
    "right",
    "go",
    "tens",
    "flow",
    "data",
    "set",
    "api",
    "know",
    "tensorflow",
    "data",
    "api",
    "yeah",
    "right",
    "ton",
    "functions",
    "go",
    "ton",
    "functions",
    "see",
    "absolute",
    "ton",
    "using",
    "map",
    "function",
    "see",
    "allows",
    "whole",
    "bunch",
    "stuff",
    "across",
    "elements",
    "within",
    "data",
    "set",
    "exactly",
    "saying",
    "whole",
    "bunch",
    "ways",
    "use",
    "using",
    "particular",
    "manner",
    "cool",
    "cool",
    "ones",
    "tend",
    "use",
    "ton",
    "zip",
    "let",
    "say",
    "example",
    "wanted",
    "combine",
    "set",
    "features",
    "labels",
    "zip",
    "oh",
    "sorry",
    "slap",
    "mic",
    "zip",
    "way",
    "combine",
    "um",
    "skip",
    "probably",
    "see",
    "second",
    "another",
    "one",
    "generator",
    "tensor",
    "slices",
    "tensors",
    "pretty",
    "common",
    "well",
    "include",
    "link",
    "inside",
    "description",
    "see",
    "well",
    "effectively",
    "data",
    "scaled",
    "right",
    "go",
    "take",
    "look",
    "next",
    "batch",
    "see",
    "inside",
    "data",
    "pipeline",
    "different",
    "rather",
    "going",
    "creating",
    "separate",
    "variables",
    "iterator",
    "actually",
    "access",
    "data",
    "like",
    "well",
    "data",
    "dot",
    "dot",
    "numpy",
    "iterator",
    "gives",
    "us",
    "access",
    "iterator",
    "dot",
    "next",
    "going",
    "grab",
    "next",
    "batch",
    "keep",
    "mind",
    "going",
    "applying",
    "shuffling",
    "going",
    "return",
    "back",
    "exact",
    "values",
    "every",
    "time",
    "case",
    "got",
    "shuffling",
    "see",
    "data",
    "changing",
    "let",
    "grab",
    "first",
    "set",
    "images",
    "grab",
    "images",
    "grabbing",
    "first",
    "index",
    "type",
    "dot",
    "max",
    "see",
    "wait",
    "hold",
    "low",
    "max",
    "dot",
    "min",
    "zero",
    "dot",
    "max",
    "seems",
    "low",
    "let",
    "grab",
    "another",
    "batch",
    "uh",
    "let",
    "call",
    "scaled",
    "equals",
    "scaled",
    "iterator",
    "numpyre",
    "go",
    "scale",
    "iterator",
    "dot",
    "next",
    "look",
    "awfully",
    "low",
    "maybe",
    "got",
    "uh",
    "images",
    "bright",
    "colorful",
    "let",
    "go",
    "dot",
    "max",
    "need",
    "grab",
    "first",
    "value",
    "grab",
    "next",
    "batch",
    "seems",
    "awfully",
    "low",
    "let",
    "actually",
    "take",
    "look",
    "using",
    "using",
    "plotting",
    "function",
    "grab",
    "let",
    "grab",
    "batch",
    "data",
    "grab",
    "iterator",
    "let",
    "grab",
    "create",
    "batch",
    "kind",
    "weird",
    "low",
    "batch",
    "equal",
    "scale",
    "right",
    "data",
    "equals",
    "going",
    "scale",
    "iterator",
    "grab",
    "next",
    "batch",
    "look",
    "like",
    "black",
    "something",
    "gone",
    "wrong",
    "let",
    "go",
    "reload",
    "data",
    "grab",
    "data",
    "set",
    "skip",
    "bit",
    "let",
    "go",
    "run",
    "pipeline",
    "wait",
    "hold",
    "gone",
    "divided",
    "images",
    "255",
    "longer",
    "going",
    "integers",
    "right",
    "inside",
    "visualization",
    "function",
    "converting",
    "integers",
    "particular",
    "case",
    "0",
    "0",
    "divide",
    "set",
    "scale",
    "data",
    "right",
    "data",
    "got",
    "lambda",
    "function",
    "let",
    "go",
    "reload",
    "data",
    "reestablishing",
    "data",
    "pipeline",
    "going",
    "running",
    "lambda",
    "go",
    "take",
    "next",
    "batch",
    "let",
    "go",
    "scale",
    "data",
    "set",
    "going",
    "scale",
    "data",
    "perfect",
    "go",
    "type",
    "dot",
    "type",
    "right",
    "going",
    "turn",
    "black",
    "go",
    "colored",
    "let",
    "double",
    "check",
    "batch",
    "okay",
    "looks",
    "little",
    "bit",
    "better",
    "hold",
    "go",
    "batch",
    "zero",
    "dot",
    "max",
    "okay",
    "one",
    "dot",
    "min",
    "know",
    "happening",
    "looks",
    "like",
    "okay",
    "good",
    "good",
    "thing",
    "double",
    "checking",
    "data",
    "appropriately",
    "function",
    "maybe",
    "went",
    "around",
    "data",
    "pipeline",
    "twice",
    "going",
    "dividing",
    "255",
    "twice",
    "thing",
    "think",
    "go",
    "reload",
    "data",
    "set",
    "going",
    "running",
    "line",
    "go",
    "apply",
    "lambda",
    "go",
    "test",
    "right",
    "max",
    "one",
    "zero",
    "go",
    "visualize",
    "perfect",
    "right",
    "cool",
    "data",
    "scaled",
    "know",
    "images",
    "zero",
    "one",
    "next",
    "thing",
    "want",
    "go",
    "ahead",
    "split",
    "data",
    "training",
    "testing",
    "partition",
    "means",
    "comes",
    "actually",
    "going",
    "validating",
    "data",
    "ensuring",
    "model",
    "overfit",
    "actually",
    "got",
    "specific",
    "partitions",
    "order",
    "first",
    "going",
    "establish",
    "training",
    "data",
    "sizes",
    "let",
    "quickly",
    "take",
    "look",
    "length",
    "data",
    "entirety",
    "seven",
    "batches",
    "remember",
    "batch",
    "going",
    "32",
    "images",
    "probably",
    "one",
    "going",
    "truncated",
    "equal",
    "batches",
    "number",
    "batches",
    "got",
    "training",
    "set",
    "going",
    "70",
    "data",
    "uh",
    "50",
    "49",
    "would",
    "like",
    "five",
    "batches",
    "seven",
    "times",
    "point",
    "seven",
    "right",
    "roughly",
    "five",
    "batches",
    "going",
    "20",
    "assigned",
    "validation",
    "probably",
    "one",
    "probably",
    "one",
    "well",
    "let",
    "see",
    "comes",
    "big",
    "training",
    "size",
    "four",
    "rounded",
    "big",
    "validation",
    "size",
    "one",
    "big",
    "test",
    "size",
    "zero",
    "right",
    "probably",
    "add",
    "one",
    "means",
    "four",
    "plus",
    "one",
    "plus",
    "one",
    "going",
    "give",
    "us",
    "six",
    "let",
    "add",
    "additional",
    "one",
    "validation",
    "partition",
    "train",
    "going",
    "four",
    "batches",
    "validation",
    "going",
    "two",
    "batches",
    "test",
    "going",
    "one",
    "batch",
    "train",
    "plus",
    "train",
    "size",
    "plus",
    "vowel",
    "size",
    "plus",
    "test",
    "size",
    "equals",
    "seven",
    "equals",
    "right",
    "good",
    "go",
    "let",
    "quickly",
    "explain",
    "training",
    "data",
    "going",
    "used",
    "actually",
    "train",
    "deep",
    "learning",
    "model",
    "validation",
    "data",
    "going",
    "use",
    "evaluate",
    "model",
    "training",
    "means",
    "model",
    "necessarily",
    "seen",
    "validation",
    "partition",
    "using",
    "fine",
    "tune",
    "actually",
    "build",
    "deep",
    "learning",
    "model",
    "good",
    "practice",
    "training",
    "validation",
    "partition",
    "building",
    "models",
    "test",
    "partition",
    "model",
    "going",
    "seen",
    "get",
    "final",
    "evaluation",
    "state",
    "hold",
    "way",
    "end",
    "two",
    "using",
    "used",
    "training",
    "one",
    "used",
    "post",
    "training",
    "evaluation",
    "right",
    "establishing",
    "much",
    "data",
    "going",
    "allocate",
    "one",
    "partitions",
    "going",
    "7",
    "multiplied",
    "32",
    "image",
    "wait",
    "hold",
    "going",
    "four",
    "multiplied",
    "32",
    "images",
    "allocated",
    "training",
    "partition",
    "going",
    "two",
    "multiplied",
    "32",
    "images",
    "allocated",
    "validation",
    "partition",
    "going",
    "one",
    "batch",
    "assigned",
    "test",
    "size",
    "uh",
    "need",
    "take",
    "look",
    "order",
    "actually",
    "use",
    "take",
    "skip",
    "methods",
    "available",
    "inside",
    "tensorflow",
    "dataset",
    "pipeline",
    "actually",
    "show",
    "see",
    "got",
    "take",
    "skip",
    "take",
    "defines",
    "much",
    "data",
    "going",
    "take",
    "particular",
    "partition",
    "go",
    "run",
    "line",
    "training",
    "size",
    "uh",
    "len",
    "batches",
    "aval",
    "data",
    "two",
    "batches",
    "test",
    "data",
    "one",
    "batch",
    "order",
    "first",
    "saying",
    "train",
    "equals",
    "data",
    "dot",
    "take",
    "saying",
    "many",
    "batches",
    "want",
    "allocate",
    "training",
    "data",
    "keep",
    "mind",
    "data",
    "already",
    "shuffled",
    "data",
    "shuffled",
    "want",
    "shuffle",
    "train",
    "going",
    "equal",
    "four",
    "batches",
    "train",
    "equals",
    "data",
    "dot",
    "take",
    "passing",
    "train",
    "size",
    "val",
    "gon",
    "na",
    "equal",
    "data",
    "dot",
    "skip",
    "first",
    "gon",
    "na",
    "gon",
    "na",
    "skip",
    "batches",
    "already",
    "allocated",
    "training",
    "partition",
    "gon",
    "na",
    "take",
    "last",
    "two",
    "valve",
    "data",
    "data",
    "dot",
    "skip",
    "going",
    "skip",
    "first",
    "four",
    "allocated",
    "train",
    "going",
    "take",
    "two",
    "based",
    "vowel",
    "size",
    "take",
    "two",
    "going",
    "take",
    "two",
    "batches",
    "validation",
    "partition",
    "going",
    "look",
    "like",
    "test",
    "going",
    "everything",
    "left",
    "right",
    "test",
    "equals",
    "data",
    "dot",
    "skip",
    "going",
    "skip",
    "training",
    "data",
    "validation",
    "data",
    "going",
    "take",
    "rest",
    "test",
    "partition",
    "establish",
    "train",
    "test",
    "validation",
    "partitions",
    "last",
    "step",
    "stage",
    "well",
    "gone",
    "scaled",
    "data",
    "sort",
    "showed",
    "actually",
    "go",
    "apply",
    "lambda",
    "layer",
    "map",
    "layer",
    "also",
    "saw",
    "bit",
    "issue",
    "right",
    "saw",
    "data",
    "necessarily",
    "scaled",
    "potentially",
    "went",
    "applied",
    "twice",
    "order",
    "fix",
    "need",
    "go",
    "line",
    "go",
    "particular",
    "line",
    "overwriting",
    "variables",
    "little",
    "bit",
    "sketchy",
    "terms",
    "actually",
    "trace",
    "back",
    "might",
    "actually",
    "go",
    "choose",
    "call",
    "um",
    "scale",
    "data",
    "way",
    "ca",
    "override",
    "twice",
    "case",
    "good",
    "data",
    "scaled",
    "data",
    "0",
    "255",
    "gone",
    "taken",
    "look",
    "visualized",
    "also",
    "gone",
    "created",
    "train",
    "validation",
    "testing",
    "partitions",
    "let",
    "jump",
    "back",
    "client",
    "righty",
    "onto",
    "good",
    "bit",
    "data",
    "begin",
    "modeling",
    "always",
    "told",
    "mom",
    "destined",
    "catwalk",
    "uh",
    "yeah",
    "going",
    "build",
    "deep",
    "learning",
    "model",
    "using",
    "keras",
    "sequential",
    "api",
    "nice",
    "ai",
    "bit",
    "right",
    "right",
    "come",
    "gisele",
    "let",
    "right",
    "good",
    "bit",
    "actually",
    "deep",
    "learning",
    "terms",
    "going",
    "three",
    "components",
    "first",
    "going",
    "build",
    "deep",
    "neural",
    "network",
    "order",
    "probably",
    "going",
    "need",
    "import",
    "bunch",
    "stuff",
    "actually",
    "going",
    "go",
    "ahead",
    "train",
    "specific",
    "deep",
    "learning",
    "model",
    "order",
    "actually",
    "use",
    "dot",
    "fit",
    "method",
    "also",
    "going",
    "plot",
    "performance",
    "using",
    "matplotlib",
    "well",
    "okay",
    "first",
    "things",
    "first",
    "let",
    "go",
    "import",
    "dependencies",
    "using",
    "tensorflow",
    "first",
    "going",
    "going",
    "importing",
    "sequential",
    "api",
    "order",
    "within",
    "import",
    "sequential",
    "reason",
    "make",
    "distinction",
    "two",
    "really",
    "specific",
    "models",
    "two",
    "specific",
    "like",
    "model",
    "building",
    "apis",
    "available",
    "inside",
    "tensorflow",
    "keras",
    "first",
    "one",
    "called",
    "sequential",
    "going",
    "using",
    "great",
    "got",
    "one",
    "data",
    "input",
    "one",
    "data",
    "output",
    "model",
    "sort",
    "flows",
    "top",
    "bottom",
    "another",
    "type",
    "api",
    "functional",
    "api",
    "really",
    "really",
    "powerful",
    "got",
    "like",
    "multiple",
    "inputs",
    "multiple",
    "outputs",
    "multiple",
    "connections",
    "need",
    "whole",
    "bunch",
    "fancy",
    "stuff",
    "deep",
    "learning",
    "models",
    "um",
    "definitely",
    "got",
    "one",
    "coming",
    "little",
    "bit",
    "advanced",
    "coming",
    "sequential",
    "great",
    "need",
    "something",
    "quick",
    "easy",
    "going",
    "case",
    "deep",
    "learning",
    "classification",
    "next",
    "thing",
    "bringing",
    "whole",
    "bunch",
    "layers",
    "layers",
    "brought",
    "available",
    "import",
    "conf",
    "2d",
    "convolutional",
    "neural",
    "network",
    "layer",
    "actually",
    "type",
    "conf",
    "2d",
    "google",
    "want",
    "pi",
    "torch",
    "equivalent",
    "want",
    "tensorflow",
    "equivalent",
    "2d",
    "convolutional",
    "layer",
    "eg",
    "spatial",
    "convolution",
    "images",
    "exactly",
    "bringing",
    "convolutional",
    "2d",
    "conv",
    "2d",
    "layer",
    "max",
    "pooling",
    "layer",
    "effectively",
    "acts",
    "like",
    "think",
    "like",
    "condensing",
    "layer",
    "actually",
    "goes",
    "images",
    "actually",
    "condenses",
    "goes",
    "max",
    "value",
    "region",
    "return",
    "region",
    "rather",
    "returning",
    "data",
    "convolution",
    "actually",
    "condense",
    "bringing",
    "dents",
    "fully",
    "connected",
    "layer",
    "available",
    "keras",
    "also",
    "bring",
    "flattened",
    "layer",
    "allows",
    "us",
    "go",
    "convolutional",
    "layer",
    "channels",
    "kernels",
    "namely",
    "channels",
    "actually",
    "reduces",
    "back",
    "format",
    "dense",
    "layer",
    "able",
    "take",
    "get",
    "one",
    "output",
    "end",
    "got",
    "dropout",
    "typically",
    "used",
    "regularization",
    "think",
    "actually",
    "use",
    "anyway",
    "got",
    "whole",
    "bunch",
    "layers",
    "typically",
    "building",
    "neural",
    "networks",
    "going",
    "form",
    "architecture",
    "architecture",
    "whole",
    "bunch",
    "different",
    "layers",
    "hidden",
    "layers",
    "form",
    "deep",
    "neural",
    "network",
    "order",
    "first",
    "going",
    "create",
    "let",
    "actually",
    "go",
    "import",
    "first",
    "going",
    "create",
    "model",
    "establishing",
    "model",
    "equals",
    "sequential",
    "going",
    "show",
    "way",
    "typically",
    "always",
    "um",
    "pass",
    "layers",
    "inside",
    "sequential",
    "class",
    "could",
    "actually",
    "conv",
    "2d",
    "add",
    "stuff",
    "sort",
    "stack",
    "typically",
    "use",
    "add",
    "method",
    "actually",
    "sort",
    "chain",
    "using",
    "sequential",
    "api",
    "see",
    "people",
    "like",
    "well",
    "um",
    "thing",
    "call",
    "see",
    "people",
    "using",
    "sequential",
    "api",
    "like",
    "perfectly",
    "fine",
    "matter",
    "choice",
    "establishing",
    "sequential",
    "class",
    "instance",
    "sequential",
    "class",
    "written",
    "model",
    "equals",
    "sequential",
    "set",
    "parentheses",
    "going",
    "add",
    "layers",
    "magic",
    "happens",
    "let",
    "break",
    "actually",
    "using",
    "dropout",
    "could",
    "actually",
    "get",
    "rid",
    "would",
    "still",
    "work",
    "got",
    "three",
    "convolution",
    "blocks",
    "flattened",
    "layer",
    "got",
    "two",
    "dense",
    "layers",
    "let",
    "break",
    "first",
    "section",
    "performing",
    "adding",
    "convolutional",
    "layer",
    "max",
    "pooling",
    "layer",
    "model",
    "dot",
    "add",
    "remember",
    "said",
    "either",
    "stack",
    "pass",
    "direct",
    "sequential",
    "class",
    "use",
    "add",
    "layers",
    "adding",
    "sequentially",
    "means",
    "first",
    "layer",
    "deep",
    "neural",
    "network",
    "first",
    "going",
    "input",
    "whenever",
    "passing",
    "first",
    "layer",
    "first",
    "layer",
    "needs",
    "input",
    "either",
    "needs",
    "input",
    "layer",
    "talk",
    "functional",
    "models",
    "later",
    "know",
    "first",
    "layer",
    "convolution",
    "adding",
    "convolution",
    "convolution",
    "going",
    "16",
    "filters",
    "convolution",
    "got",
    "whole",
    "bunch",
    "filters",
    "basically",
    "scans",
    "image",
    "tries",
    "condense",
    "extract",
    "relevant",
    "information",
    "inside",
    "image",
    "make",
    "output",
    "classification",
    "got",
    "16",
    "filters",
    "filter",
    "going",
    "three",
    "pixels",
    "three",
    "pixels",
    "size",
    "going",
    "strike",
    "stride",
    "one",
    "means",
    "going",
    "move",
    "one",
    "pixel",
    "time",
    "gon",
    "na",
    "go",
    "bang",
    "bang",
    "bang",
    "forth",
    "increase",
    "stride",
    "increase",
    "number",
    "filters",
    "increase",
    "um",
    "size",
    "filters",
    "call",
    "architectural",
    "decisions",
    "might",
    "actual",
    "like",
    "models",
    "actually",
    "prescribe",
    "actually",
    "go",
    "take",
    "look",
    "imagenet",
    "classification",
    "specific",
    "architecture",
    "used",
    "actually",
    "go",
    "change",
    "particular",
    "hyper",
    "parameters",
    "particular",
    "model",
    "parameters",
    "influences",
    "model",
    "performs",
    "like",
    "typically",
    "convolution",
    "number",
    "filters",
    "size",
    "filter",
    "stride",
    "another",
    "really",
    "important",
    "function",
    "another",
    "aspect",
    "activation",
    "gets",
    "applied",
    "applying",
    "relu",
    "activation",
    "let",
    "show",
    "relu",
    "activation",
    "really",
    "saying",
    "taking",
    "output",
    "convolutional",
    "layer",
    "going",
    "pass",
    "function",
    "looks",
    "like",
    "means",
    "output",
    "pre",
    "previously",
    "zero",
    "going",
    "converted",
    "zero",
    "going",
    "preserve",
    "positive",
    "values",
    "effectively",
    "means",
    "converting",
    "negative",
    "values",
    "zero",
    "anything",
    "positive",
    "remains",
    "unchanged",
    "allows",
    "us",
    "take",
    "account",
    "patterns",
    "right",
    "got",
    "got",
    "activations",
    "really",
    "building",
    "deep",
    "neural",
    "network",
    "linear",
    "nature",
    "necessarily",
    "powerful",
    "power",
    "comes",
    "applying",
    "activations",
    "ton",
    "right",
    "another",
    "popular",
    "one",
    "use",
    "well",
    "sigmoid",
    "activation",
    "looks",
    "like",
    "sound",
    "really",
    "complex",
    "think",
    "taking",
    "data",
    "output",
    "layer",
    "passing",
    "function",
    "modify",
    "output",
    "looks",
    "like",
    "right",
    "might",
    "whole",
    "bunch",
    "numbers",
    "um",
    "know",
    "negative",
    "infinity",
    "positive",
    "infinity",
    "like",
    "really",
    "really",
    "small",
    "really",
    "really",
    "big",
    "values",
    "going",
    "actually",
    "changing",
    "passing",
    "one",
    "activations",
    "reshaping",
    "output",
    "looks",
    "like",
    "right",
    "reshaping",
    "function",
    "looks",
    "like",
    "result",
    "well",
    "cool",
    "full",
    "line",
    "gone",
    "talked",
    "ton",
    "going",
    "read",
    "model",
    "going",
    "16",
    "filters",
    "shape",
    "3x3",
    "going",
    "stride",
    "1",
    "pass",
    "relu",
    "activation",
    "also",
    "going",
    "specify",
    "input",
    "shape",
    "looks",
    "like",
    "remember",
    "said",
    "keras",
    "tense",
    "image",
    "data",
    "set",
    "directory",
    "function",
    "actually",
    "reshapes",
    "images",
    "well",
    "images",
    "going",
    "shape",
    "256",
    "pixels",
    "256",
    "pixels",
    "three",
    "channels",
    "going",
    "256",
    "pixels",
    "higher",
    "256",
    "pixels",
    "wired",
    "three",
    "channels",
    "deep",
    "pass",
    "initial",
    "passed",
    "first",
    "layer",
    "applying",
    "max",
    "pooling",
    "layer",
    "gon",
    "na",
    "take",
    "maximum",
    "value",
    "relu",
    "activation",
    "going",
    "return",
    "back",
    "value",
    "going",
    "scan",
    "across",
    "go",
    "effectively",
    "going",
    "condense",
    "information",
    "going",
    "take",
    "one",
    "number",
    "actually",
    "going",
    "set",
    "region",
    "let",
    "actually",
    "take",
    "look",
    "default",
    "max",
    "pooling",
    "2d",
    "question",
    "mark",
    "question",
    "mark",
    "going",
    "go",
    "two",
    "two",
    "region",
    "see",
    "two",
    "two",
    "two",
    "two",
    "going",
    "take",
    "max",
    "value",
    "two",
    "two",
    "region",
    "effectively",
    "going",
    "reduce",
    "image",
    "data",
    "think",
    "half",
    "particular",
    "case",
    "rather",
    "well",
    "yeah",
    "half",
    "based",
    "rows",
    "half",
    "based",
    "rows",
    "half",
    "based",
    "width",
    "well",
    "going",
    "condense",
    "information",
    "effectively",
    "got",
    "another",
    "one",
    "blocks",
    "next",
    "set",
    "laser",
    "adding",
    "got",
    "32",
    "filters",
    "shape",
    "3x3",
    "stride",
    "1",
    "got",
    "relu",
    "activation",
    "max",
    "pooling",
    "rate",
    "got",
    "another",
    "convolution",
    "block",
    "got",
    "exactly",
    "time",
    "got",
    "16",
    "filters",
    "actually",
    "flattening",
    "data",
    "actually",
    "apply",
    "convolutional",
    "layer",
    "filters",
    "going",
    "last",
    "channel",
    "going",
    "condense",
    "rows",
    "width",
    "number",
    "filters",
    "form",
    "channel",
    "value",
    "actually",
    "go",
    "pass",
    "dense",
    "layer",
    "want",
    "channel",
    "value",
    "right",
    "want",
    "condense",
    "single",
    "value",
    "flattening",
    "effectively",
    "going",
    "256",
    "values",
    "output",
    "finally",
    "one",
    "value",
    "output",
    "actually",
    "go",
    "run",
    "oh",
    "well",
    "let",
    "actually",
    "talk",
    "little",
    "bit",
    "detail",
    "gone",
    "flattened",
    "last",
    "two",
    "layers",
    "apply",
    "dense",
    "layers",
    "fully",
    "connected",
    "layers",
    "ever",
    "seen",
    "neural",
    "network",
    "see",
    "lot",
    "little",
    "dots",
    "connected",
    "form",
    "go",
    "point",
    "referred",
    "fully",
    "connected",
    "layers",
    "inside",
    "keras",
    "call",
    "dense",
    "layers",
    "got",
    "dents",
    "256",
    "neurons",
    "applying",
    "relu",
    "activations",
    "final",
    "layer",
    "single",
    "dense",
    "layer",
    "means",
    "going",
    "get",
    "single",
    "output",
    "output",
    "effectively",
    "going",
    "represent",
    "0",
    "1",
    "sigmoid",
    "activation",
    "take",
    "look",
    "sigmoid",
    "activation",
    "let",
    "zoom",
    "sigmoid",
    "activation",
    "takes",
    "output",
    "converts",
    "effectively",
    "range",
    "0",
    "0",
    "one",
    "map",
    "happy",
    "sad",
    "classes",
    "zero",
    "think",
    "ca",
    "even",
    "remember",
    "zero",
    "going",
    "happy",
    "person",
    "one",
    "going",
    "sad",
    "person",
    "final",
    "layer",
    "going",
    "output",
    "see",
    "cool",
    "right",
    "deep",
    "neural",
    "network",
    "go",
    "run",
    "layer",
    "successfully",
    "run",
    "next",
    "thing",
    "need",
    "compile",
    "next",
    "important",
    "bit",
    "neural",
    "network",
    "type",
    "remember",
    "model",
    "initially",
    "initialized",
    "pass",
    "things",
    "pass",
    "optimizer",
    "want",
    "use",
    "case",
    "going",
    "using",
    "atom",
    "optimizer",
    "ton",
    "optimizers",
    "type",
    "actually",
    "dot",
    "ton",
    "got",
    "ada",
    "delta",
    "adagrad",
    "adam",
    "adam",
    "max",
    "uh",
    "ftrl",
    "seen",
    "one",
    "much",
    "uh",
    "n",
    "atom",
    "rms",
    "propped",
    "sgd",
    "ton",
    "optimizers",
    "actually",
    "available",
    "case",
    "going",
    "using",
    "atom",
    "optimizer",
    "specifying",
    "loss",
    "loss",
    "particular",
    "case",
    "performing",
    "effectively",
    "binary",
    "classification",
    "problem",
    "going",
    "metric",
    "want",
    "track",
    "accuracy",
    "pass",
    "bunch",
    "particular",
    "case",
    "accuracy",
    "going",
    "tell",
    "us",
    "well",
    "model",
    "classifying",
    "either",
    "0",
    "go",
    "compile",
    "favorite",
    "bit",
    "typing",
    "actually",
    "see",
    "model",
    "transforms",
    "data",
    "remember",
    "model",
    "takes",
    "input",
    "shape",
    "256",
    "256",
    "3",
    "right",
    "256",
    "256",
    "first",
    "convolution",
    "layer",
    "converts",
    "254",
    "254",
    "number",
    "filters",
    "16",
    "coming",
    "apply",
    "max",
    "pooling",
    "layer",
    "converts",
    "254",
    "54",
    "16",
    "127",
    "127",
    "127",
    "remember",
    "said",
    "shape",
    "taking",
    "254",
    "divided",
    "2",
    "gives",
    "us",
    "effectively",
    "halves",
    "output",
    "getting",
    "convolutional",
    "layer",
    "trainable",
    "layer",
    "right",
    "see",
    "parameters",
    "assigned",
    "effectively",
    "increase",
    "size",
    "model",
    "much",
    "condenses",
    "stuff",
    "going",
    "applying",
    "another",
    "convolution",
    "layer",
    "one",
    "going",
    "125",
    "125",
    "32",
    "could",
    "actually",
    "preserve",
    "size",
    "applying",
    "padding",
    "going",
    "delve",
    "going",
    "125",
    "125",
    "2",
    "got",
    "32",
    "filters",
    "coming",
    "applying",
    "max",
    "pooling",
    "going",
    "halving",
    "data",
    "got",
    "last",
    "convolution",
    "block",
    "60",
    "60",
    "16",
    "playing",
    "convolutions",
    "30",
    "30",
    "16",
    "getting",
    "flattened",
    "layer",
    "right",
    "got",
    "14",
    "400",
    "values",
    "let",
    "enable",
    "scrolling",
    "show",
    "taking",
    "outputs",
    "max",
    "pooling",
    "layer",
    "converting",
    "single",
    "dimension",
    "type",
    "30",
    "30",
    "16",
    "number",
    "outputs",
    "passed",
    "flattened",
    "layer",
    "see",
    "getting",
    "dimensions",
    "elements",
    "multiply",
    "multiplied",
    "gives",
    "us",
    "number",
    "inputs",
    "going",
    "flattened",
    "layer",
    "condensing",
    "single",
    "dimension",
    "rather",
    "tensor",
    "converting",
    "pass",
    "dense",
    "layer",
    "256",
    "uh",
    "neurons",
    "finally",
    "go",
    "single",
    "layer",
    "single",
    "output",
    "layer",
    "cool",
    "probably",
    "wondering",
    "257",
    "parameters",
    "keep",
    "mind",
    "bias",
    "term",
    "well",
    "right",
    "going",
    "value",
    "weights",
    "neurons",
    "plus",
    "bias",
    "term",
    "gives",
    "us",
    "total",
    "number",
    "parameters",
    "three",
    "million",
    "six",
    "hundred",
    "ninety",
    "six",
    "thousand",
    "six",
    "hundred",
    "twenty",
    "five",
    "values",
    "pretty",
    "uh",
    "monstrous",
    "right",
    "probably",
    "seen",
    "like",
    "bert",
    "big",
    "bert",
    "like",
    "massive",
    "models",
    "gpt3",
    "huge",
    "million",
    "could",
    "probably",
    "condense",
    "well",
    "really",
    "wanted",
    "particular",
    "case",
    "deep",
    "neural",
    "network",
    "modeled",
    "get",
    "rid",
    "get",
    "rid",
    "neural",
    "network",
    "step",
    "done",
    "gone",
    "built",
    "deep",
    "learning",
    "model",
    "right",
    "taken",
    "look",
    "imports",
    "taken",
    "look",
    "different",
    "types",
    "layers",
    "use",
    "also",
    "seen",
    "stack",
    "layers",
    "next",
    "thing",
    "want",
    "actually",
    "go",
    "ahead",
    "train",
    "first",
    "thing",
    "going",
    "create",
    "log",
    "directory",
    "already",
    "got",
    "created",
    "see",
    "got",
    "folder",
    "called",
    "logs",
    "going",
    "create",
    "variable",
    "points",
    "going",
    "create",
    "callback",
    "callbacks",
    "really",
    "really",
    "useful",
    "wanted",
    "save",
    "model",
    "particular",
    "checkpoint",
    "wanted",
    "specific",
    "logging",
    "going",
    "order",
    "creating",
    "callback",
    "tensorboard",
    "underscore",
    "callback",
    "setting",
    "equal",
    "specifying",
    "log",
    "directory",
    "equal",
    "logs",
    "folder",
    "go",
    "going",
    "tensorboard",
    "logs",
    "logged",
    "going",
    "talk",
    "future",
    "tutorial",
    "setting",
    "tensorboard",
    "underscore",
    "callback",
    "passing",
    "parameter",
    "going",
    "log",
    "model",
    "training",
    "training",
    "wanted",
    "come",
    "back",
    "see",
    "model",
    "performed",
    "vary",
    "particular",
    "point",
    "time",
    "need",
    "drop",
    "learning",
    "rate",
    "actually",
    "going",
    "see",
    "inside",
    "boards",
    "actually",
    "plot",
    "using",
    "history",
    "collect",
    "training",
    "step",
    "show",
    "sec",
    "cool",
    "callback",
    "established",
    "going",
    "go",
    "ahead",
    "fit",
    "model",
    "two",
    "really",
    "really",
    "important",
    "methods",
    "comes",
    "building",
    "neural",
    "network",
    "fit",
    "training",
    "comport",
    "component",
    "predict",
    "actually",
    "go",
    "make",
    "predictions",
    "going",
    "take",
    "training",
    "data",
    "remember",
    "training",
    "data",
    "four",
    "batches",
    "32",
    "images",
    "epochs",
    "long",
    "actually",
    "going",
    "go",
    "ahead",
    "train",
    "one",
    "epoch",
    "one",
    "run",
    "entire",
    "training",
    "set",
    "data",
    "also",
    "going",
    "pass",
    "validation",
    "data",
    "means",
    "gone",
    "performed",
    "gone",
    "trained",
    "training",
    "data",
    "training",
    "batches",
    "going",
    "run",
    "evaluation",
    "validation",
    "data",
    "actually",
    "see",
    "well",
    "model",
    "performing",
    "real",
    "time",
    "also",
    "going",
    "pass",
    "callbacks",
    "wanted",
    "go",
    "apply",
    "additional",
    "callbacks",
    "let",
    "know",
    "want",
    "tutorial",
    "callbacks",
    "guys",
    "happy",
    "actually",
    "specifying",
    "want",
    "log",
    "information",
    "model",
    "tensorboard",
    "could",
    "open",
    "inside",
    "tensorboard",
    "later",
    "um",
    "storing",
    "inside",
    "variable",
    "called",
    "hist",
    "history",
    "going",
    "able",
    "take",
    "training",
    "information",
    "training",
    "data",
    "validation",
    "data",
    "plot",
    "inside",
    "step",
    "actually",
    "go",
    "run",
    "going",
    "kick",
    "training",
    "run",
    "let",
    "run",
    "actually",
    "see",
    "deep",
    "learning",
    "model",
    "start",
    "training",
    "might",
    "take",
    "little",
    "start",
    "eventually",
    "start",
    "see",
    "training",
    "going",
    "really",
    "really",
    "fast",
    "obviously",
    "got",
    "gpu",
    "training",
    "see",
    "taking",
    "377",
    "milliseconds",
    "per",
    "step",
    "loss",
    "going",
    "ideally",
    "want",
    "see",
    "loss",
    "go",
    "accuracy",
    "go",
    "got",
    "loss",
    "training",
    "data",
    "training",
    "let",
    "zoom",
    "probably",
    "ca",
    "see",
    "loss",
    "training",
    "data",
    "accuracy",
    "training",
    "data",
    "validation",
    "loss",
    "validation",
    "accuracy",
    "ideally",
    "want",
    "see",
    "want",
    "see",
    "losses",
    "decrease",
    "pretty",
    "consistently",
    "pretty",
    "steadily",
    "want",
    "see",
    "accuracies",
    "go",
    "pretty",
    "steadily",
    "well",
    "see",
    "definitely",
    "performing",
    "way",
    "better",
    "look",
    "losses",
    "drop",
    "significantly",
    "accuracy",
    "got",
    "hundred",
    "percent",
    "performing",
    "really",
    "really",
    "well",
    "end",
    "went",
    "really",
    "really",
    "quickly",
    "deep",
    "neural",
    "network",
    "trained",
    "guys",
    "quick",
    "goes",
    "um",
    "obviously",
    "gpu",
    "lot",
    "faster",
    "gpu",
    "think",
    "saw",
    "roughly",
    "double",
    "increase",
    "training",
    "time",
    "still",
    "able",
    "without",
    "gpu",
    "deep",
    "neural",
    "network",
    "trained",
    "magic",
    "done",
    "cool",
    "thing",
    "gone",
    "saved",
    "inside",
    "saved",
    "training",
    "history",
    "inside",
    "variable",
    "called",
    "history",
    "actually",
    "get",
    "whole",
    "bunch",
    "information",
    "show",
    "hist",
    "shows",
    "us",
    "callback",
    "type",
    "history",
    "history",
    "whole",
    "bunch",
    "information",
    "available",
    "let",
    "scroll",
    "see",
    "got",
    "loss",
    "information",
    "got",
    "accuracy",
    "information",
    "training",
    "data",
    "also",
    "got",
    "validation",
    "loss",
    "information",
    "also",
    "validation",
    "accuracy",
    "information",
    "see",
    "pretty",
    "cool",
    "right",
    "actually",
    "plot",
    "performance",
    "got",
    "using",
    "matplotlib",
    "grabbing",
    "training",
    "loss",
    "grabbing",
    "validation",
    "loss",
    "plotting",
    "going",
    "see",
    "training",
    "loss",
    "color",
    "teal",
    "validation",
    "loss",
    "color",
    "orange",
    "let",
    "go",
    "plot",
    "see",
    "loss",
    "sort",
    "decreased",
    "pretty",
    "steadily",
    "time",
    "one",
    "bit",
    "spike",
    "sort",
    "come",
    "back",
    "start",
    "see",
    "loss",
    "going",
    "validation",
    "loss",
    "sort",
    "rising",
    "indication",
    "model",
    "may",
    "overfitting",
    "might",
    "time",
    "look",
    "applying",
    "regularization",
    "might",
    "also",
    "mean",
    "need",
    "apply",
    "data",
    "change",
    "data",
    "see",
    "decreasing",
    "see",
    "green",
    "line",
    "like",
    "decreasing",
    "going",
    "weird",
    "might",
    "mean",
    "need",
    "take",
    "look",
    "training",
    "data",
    "maybe",
    "potentially",
    "consider",
    "larger",
    "neural",
    "network",
    "sophisticated",
    "neural",
    "network",
    "means",
    "able",
    "learn",
    "reduce",
    "loss",
    "particular",
    "data",
    "training",
    "data",
    "overall",
    "might",
    "mean",
    "bit",
    "bias",
    "problem",
    "okay",
    "um",
    "validation",
    "law",
    "starts",
    "tearing",
    "might",
    "mean",
    "variance",
    "problem",
    "regularization",
    "friend",
    "particular",
    "case",
    "okay",
    "got",
    "loss",
    "metrics",
    "visualize",
    "uh",
    "also",
    "take",
    "look",
    "accuracy",
    "metrics",
    "sort",
    "little",
    "block",
    "pretty",
    "useful",
    "actually",
    "visualize",
    "anything",
    "want",
    "really",
    "really",
    "useful",
    "deep",
    "learning",
    "well",
    "added",
    "metrics",
    "let",
    "go",
    "scroll",
    "added",
    "metrics",
    "compiling",
    "model",
    "actually",
    "able",
    "visualize",
    "iris",
    "tracking",
    "video",
    "working",
    "well",
    "actually",
    "show",
    "whole",
    "bunch",
    "metrics",
    "okay",
    "last",
    "visualize",
    "also",
    "visualize",
    "accuracy",
    "using",
    "matplotlib",
    "visualize",
    "go",
    "run",
    "one",
    "see",
    "accuracy",
    "steadily",
    "increased",
    "time",
    "little",
    "bit",
    "pop",
    "come",
    "back",
    "resolved",
    "back",
    "100",
    "accuracy",
    "good",
    "right",
    "obviously",
    "model",
    "performing",
    "well",
    "ton",
    "data",
    "ideally",
    "want",
    "flesh",
    "ton",
    "data",
    "particular",
    "case",
    "model",
    "trained",
    "actually",
    "gone",
    "completed",
    "modeling",
    "step",
    "gone",
    "built",
    "deep",
    "learning",
    "model",
    "used",
    "sequential",
    "api",
    "gone",
    "trained",
    "model",
    "using",
    "function",
    "also",
    "shown",
    "pass",
    "training",
    "data",
    "validation",
    "data",
    "well",
    "setting",
    "callback",
    "also",
    "gone",
    "taken",
    "look",
    "training",
    "performance",
    "visualized",
    "loss",
    "also",
    "visualized",
    "accuracy",
    "let",
    "jump",
    "back",
    "client",
    "might",
    "evaluation",
    "step",
    "finished",
    "training",
    "model",
    "time",
    "test",
    "course",
    "wait",
    "mean",
    "well",
    "think",
    "might",
    "test",
    "athlete",
    "put",
    "athlete",
    "paces",
    "review",
    "certain",
    "metrics",
    "might",
    "measure",
    "sprinter",
    "100",
    "meter",
    "dash",
    "time",
    "classification",
    "model",
    "ah",
    "got",
    "going",
    "check",
    "fast",
    "model",
    "quite",
    "got",
    "different",
    "metrics",
    "use",
    "classification",
    "include",
    "precision",
    "recall",
    "accuracy",
    "let",
    "jump",
    "end",
    "game",
    "evaluating",
    "performance",
    "gone",
    "trained",
    "model",
    "next",
    "thing",
    "want",
    "actually",
    "go",
    "evaluate",
    "performance",
    "testing",
    "data",
    "remember",
    "held",
    "partition",
    "model",
    "never",
    "seen",
    "two",
    "things",
    "want",
    "first",
    "evaluate",
    "also",
    "grab",
    "random",
    "images",
    "test",
    "order",
    "evaluate",
    "going",
    "import",
    "couple",
    "key",
    "metrics",
    "import",
    "precision",
    "recall",
    "binary",
    "accuracy",
    "different",
    "measures",
    "typically",
    "use",
    "classification",
    "problems",
    "going",
    "import",
    "order",
    "use",
    "need",
    "establish",
    "instances",
    "update",
    "state",
    "actually",
    "go",
    "make",
    "predictions",
    "go",
    "instantiate",
    "written",
    "pre",
    "pretty",
    "crappy",
    "variable",
    "names",
    "think",
    "running",
    "energy",
    "pre",
    "equals",
    "precision",
    "grabbing",
    "class",
    "creating",
    "equals",
    "recall",
    "accuracy",
    "equals",
    "binary",
    "accuracy",
    "order",
    "go",
    "test",
    "going",
    "loop",
    "batch",
    "testing",
    "data",
    "think",
    "one",
    "batch",
    "anyway",
    "right",
    "len",
    "test",
    "nope",
    "lower",
    "case",
    "one",
    "batch",
    "anyway",
    "four",
    "batch",
    "test",
    "dot",
    "numpy",
    "iterator",
    "going",
    "bring",
    "back",
    "batch",
    "unpack",
    "x",
    "comma",
    "equals",
    "batch",
    "going",
    "set",
    "images",
    "effectively",
    "true",
    "value",
    "passing",
    "image",
    "data",
    "model",
    "make",
    "predictions",
    "going",
    "return",
    "back",
    "set",
    "values",
    "zero",
    "one",
    "remember",
    "gone",
    "passed",
    "sigmoid",
    "activation",
    "order",
    "update",
    "metrics",
    "type",
    "use",
    "update",
    "state",
    "method",
    "pass",
    "true",
    "value",
    "predicted",
    "value",
    "gone",
    "screwed",
    "pass",
    "true",
    "value",
    "hat",
    "value",
    "see",
    "gone",
    "done",
    "precision",
    "recall",
    "accuracy",
    "able",
    "see",
    "actually",
    "performed",
    "test",
    "data",
    "go",
    "run",
    "run",
    "little",
    "sec",
    "actually",
    "print",
    "results",
    "actually",
    "make",
    "little",
    "bit",
    "easier",
    "read",
    "uh",
    "f",
    "equals",
    "uh",
    "precision",
    "result",
    "precision",
    "ecr",
    "think",
    "write",
    "dot",
    "numpy",
    "well",
    "uh",
    "recall",
    "dot",
    "numpy",
    "accuracy",
    "head",
    "blocking",
    "nope",
    "okay",
    "got",
    "num",
    "hi",
    "uh",
    "done",
    "finished",
    "got",
    "ta",
    "close",
    "boom",
    "okay",
    "close",
    "right",
    "go",
    "gone",
    "printed",
    "performance",
    "different",
    "metrics",
    "precision",
    "one",
    "higher",
    "precision",
    "means",
    "model",
    "performing",
    "better",
    "recall",
    "one",
    "high",
    "value",
    "recall",
    "means",
    "performing",
    "better",
    "accuracy",
    "one",
    "higher",
    "value",
    "means",
    "performing",
    "better",
    "metrics",
    "zero",
    "one",
    "highest",
    "possible",
    "value",
    "take",
    "um",
    "want",
    "deep",
    "dive",
    "metrics",
    "calculated",
    "let",
    "say",
    "example",
    "wanted",
    "confusion",
    "matrix",
    "let",
    "know",
    "delve",
    "know",
    "model",
    "performing",
    "pretty",
    "much",
    "well",
    "single",
    "batch",
    "data",
    "considering",
    "little",
    "data",
    "actually",
    "given",
    "perform",
    "got",
    "precision",
    "100",
    "recall",
    "100",
    "accuracy",
    "hundred",
    "percent",
    "well",
    "normally",
    "like",
    "leave",
    "like",
    "actually",
    "go",
    "test",
    "data",
    "outside",
    "batch",
    "let",
    "actually",
    "go",
    "ahead",
    "first",
    "import",
    "going",
    "import",
    "cv2",
    "thought",
    "already",
    "imported",
    "opencv",
    "imported",
    "ht",
    "yeah",
    "already",
    "got",
    "actually",
    "skip",
    "need",
    "import",
    "opencv",
    "let",
    "import",
    "anyway",
    "wasting",
    "time",
    "going",
    "going",
    "read",
    "image",
    "model",
    "never",
    "seen",
    "going",
    "let",
    "go",
    "grab",
    "random",
    "image",
    "let",
    "actually",
    "go",
    "page",
    "2",
    "scroll",
    "let",
    "grab",
    "dude",
    "going",
    "save",
    "image",
    "going",
    "save",
    "image",
    "classification",
    "folder",
    "going",
    "call",
    "sad",
    "test",
    "let",
    "saved",
    "jfif",
    "know",
    "google",
    "frustrating",
    "sad",
    "test",
    "dot",
    "jpg",
    "yes",
    "okay",
    "cool",
    "gon",
    "na",
    "get",
    "image",
    "happy",
    "person",
    "happy",
    "peoples",
    "find",
    "happy",
    "dude",
    "completely",
    "sample",
    "right",
    "model",
    "never",
    "seen",
    "let",
    "go",
    "one",
    "great",
    "right",
    "let",
    "save",
    "image",
    "happy",
    "um",
    "webp",
    "gon",
    "na",
    "work",
    "needs",
    "jpg",
    "gon",
    "na",
    "make",
    "life",
    "whole",
    "bunch",
    "easier",
    "let",
    "grab",
    "one",
    "happy",
    "test",
    "dot",
    "jpg",
    "okay",
    "cool",
    "got",
    "two",
    "test",
    "images",
    "open",
    "folders",
    "see",
    "go",
    "got",
    "girl",
    "super",
    "happy",
    "got",
    "sad",
    "test",
    "dude",
    "dark",
    "stormy",
    "red",
    "ready",
    "drop",
    "beat",
    "right",
    "going",
    "going",
    "read",
    "image",
    "using",
    "first",
    "let",
    "read",
    "happy",
    "image",
    "type",
    "happy",
    "test",
    "dot",
    "jpg",
    "read",
    "image",
    "plot",
    "right",
    "remember",
    "opencv",
    "going",
    "read",
    "bgr",
    "rather",
    "rgb",
    "fix",
    "let",
    "show",
    "cv2",
    "cvt",
    "color",
    "going",
    "go",
    "pass",
    "color",
    "conversion",
    "code",
    "underscore",
    "bgr2rgb",
    "visualize",
    "correct",
    "color",
    "go",
    "gone",
    "fixed",
    "color",
    "gone",
    "successfully",
    "loaded",
    "remember",
    "pass",
    "data",
    "neural",
    "network",
    "need",
    "shape",
    "256",
    "256x3",
    "256",
    "pixels",
    "high",
    "256",
    "pixels",
    "wide",
    "needs",
    "three",
    "channels",
    "actually",
    "use",
    "resize",
    "image",
    "pass",
    "neural",
    "network",
    "actually",
    "go",
    "run",
    "image",
    "looks",
    "like",
    "resized",
    "could",
    "go",
    "apply",
    "color",
    "method",
    "grab",
    "paste",
    "throwing",
    "error",
    "integer",
    "look",
    "like",
    "playing",
    "nicely",
    "anyway",
    "gone",
    "transformed",
    "uh",
    "tensorflow",
    "see",
    "definitely",
    "gone",
    "resized",
    "read",
    "using",
    "opencv",
    "getting",
    "weird",
    "coloring",
    "let",
    "actually",
    "go",
    "test",
    "actually",
    "go",
    "pass",
    "model",
    "passing",
    "neural",
    "network",
    "quick",
    "word",
    "actually",
    "prediction",
    "neural",
    "network",
    "expects",
    "us",
    "pass",
    "batch",
    "images",
    "single",
    "image",
    "actually",
    "need",
    "need",
    "encapsulate",
    "inside",
    "another",
    "set",
    "parentheses",
    "arrays",
    "put",
    "inside",
    "list",
    "order",
    "see",
    "done",
    "quite",
    "fair",
    "bit",
    "type",
    "pass",
    "image",
    "right",
    "called",
    "resize",
    "gone",
    "resize",
    "using",
    "pass",
    "type",
    "axis",
    "want",
    "apply",
    "extra",
    "dimension",
    "see",
    "right",
    "stored",
    "inside",
    "extra",
    "dimension",
    "let",
    "show",
    "first",
    "value",
    "see",
    "got",
    "whole",
    "bunch",
    "extra",
    "dimensions",
    "first",
    "value",
    "uh",
    "let",
    "scroll",
    "see",
    "extra",
    "set",
    "parentheses",
    "throwing",
    "literally",
    "encapsulating",
    "another",
    "set",
    "arrays",
    "putting",
    "inside",
    "another",
    "list",
    "actually",
    "show",
    "shape",
    "dot",
    "shape",
    "1",
    "256",
    "256",
    "take",
    "look",
    "shape",
    "256",
    "256",
    "literally",
    "wrapping",
    "another",
    "set",
    "arrays",
    "also",
    "time",
    "dividing",
    "255",
    "scale",
    "go",
    "run",
    "take",
    "look",
    "hat",
    "remember",
    "sad",
    "happy",
    "person",
    "happy",
    "person",
    "zero",
    "see",
    "happy",
    "zero",
    "sad",
    "one",
    "particular",
    "case",
    "model",
    "successfully",
    "predicted",
    "particular",
    "person",
    "happy",
    "reason",
    "making",
    "assumption",
    "particular",
    "binary",
    "classification",
    "problem",
    "saying",
    "50",
    "cutoff",
    "point",
    "50",
    "round",
    "zero",
    "particular",
    "case",
    "saying",
    "person",
    "going",
    "happy",
    "successfully",
    "classified",
    "particular",
    "person",
    "got",
    "hat",
    "twice",
    "need",
    "way",
    "extrapolate",
    "actually",
    "explain",
    "regular",
    "terms",
    "predicted",
    "class",
    "happy",
    "less",
    "hat",
    "greater",
    "predicted",
    "class",
    "going",
    "sad",
    "otherwise",
    "predicted",
    "class",
    "going",
    "happy",
    "exactly",
    "said",
    "less",
    "means",
    "model",
    "successfully",
    "predicted",
    "happy",
    "pretty",
    "nuts",
    "right",
    "like",
    "ton",
    "data",
    "even",
    "train",
    "long",
    "successfully",
    "gone",
    "built",
    "deep",
    "neural",
    "network",
    "performs",
    "classification",
    "let",
    "actually",
    "go",
    "test",
    "sad",
    "person",
    "well",
    "order",
    "need",
    "pass",
    "different",
    "image",
    "one",
    "going",
    "sad",
    "test",
    "go",
    "run",
    "model",
    "gone",
    "given",
    "us",
    "probability",
    "means",
    "going",
    "50",
    "means",
    "predicted",
    "sad",
    "successfully",
    "take",
    "look",
    "predicted",
    "class",
    "sad",
    "really",
    "quickly",
    "gone",
    "able",
    "perform",
    "build",
    "deep",
    "neural",
    "network",
    "able",
    "perform",
    "sentiment",
    "classification",
    "using",
    "nothing",
    "couple",
    "images",
    "collected",
    "web",
    "let",
    "go",
    "jump",
    "back",
    "client",
    "give",
    "one",
    "last",
    "final",
    "update",
    "alright",
    "home",
    "run",
    "baby",
    "know",
    "last",
    "thing",
    "need",
    "save",
    "model",
    "reload",
    "future",
    "date",
    "means",
    "another",
    "developer",
    "engineer",
    "could",
    "use",
    "model",
    "right",
    "right",
    "could",
    "also",
    "deployed",
    "api",
    "edge",
    "device",
    "let",
    "finish",
    "alrighty",
    "final",
    "step",
    "saving",
    "model",
    "really",
    "important",
    "step",
    "gone",
    "amount",
    "effort",
    "last",
    "thing",
    "want",
    "save",
    "model",
    "go",
    "use",
    "want",
    "relatively",
    "straightforward",
    "import",
    "bring",
    "dependency",
    "tensorflow",
    "called",
    "load",
    "model",
    "models",
    "import",
    "load",
    "model",
    "actually",
    "use",
    "load",
    "model",
    "function",
    "able",
    "load",
    "model",
    "first",
    "actually",
    "need",
    "save",
    "model",
    "use",
    "going",
    "save",
    "inside",
    "folder",
    "models",
    "name",
    "whatever",
    "want",
    "could",
    "call",
    "um",
    "happy",
    "sad",
    "model",
    "saving",
    "h5",
    "model",
    "actually",
    "something",
    "called",
    "serialization",
    "taking",
    "model",
    "serializing",
    "onto",
    "something",
    "store",
    "disk",
    "similar",
    "might",
    "zip",
    "data",
    "set",
    "um",
    "go",
    "wire",
    "data",
    "set",
    "h5",
    "serialization",
    "file",
    "format",
    "basically",
    "means",
    "going",
    "file",
    "called",
    "reload",
    "using",
    "load",
    "model",
    "function",
    "full",
    "line",
    "passing",
    "going",
    "saving",
    "inside",
    "models",
    "folder",
    "already",
    "got",
    "created",
    "nothing",
    "moment",
    "going",
    "saving",
    "happy",
    "sad",
    "could",
    "whatever",
    "want",
    "save",
    "right",
    "go",
    "run",
    "inside",
    "models",
    "folder",
    "see",
    "got",
    "happy",
    "sad",
    "file",
    "looking",
    "good",
    "next",
    "thing",
    "want",
    "actually",
    "go",
    "reload",
    "model",
    "let",
    "actually",
    "go",
    "rename",
    "going",
    "call",
    "new",
    "underscore",
    "model",
    "use",
    "load",
    "underscore",
    "model",
    "load",
    "model",
    "back",
    "need",
    "pass",
    "full",
    "file",
    "path",
    "saved",
    "model",
    "order",
    "reload",
    "actually",
    "grab",
    "h5",
    "file",
    "name",
    "pass",
    "basically",
    "saying",
    "going",
    "inside",
    "models",
    "folder",
    "models",
    "happysav",
    "basically",
    "going",
    "give",
    "file",
    "path",
    "load",
    "model",
    "function",
    "able",
    "load",
    "back",
    "go",
    "run",
    "new",
    "model",
    "new",
    "model",
    "sequential",
    "keras",
    "model",
    "go",
    "pass",
    "data",
    "going",
    "pass",
    "resize",
    "image",
    "np",
    "dot",
    "expand",
    "dims",
    "passing",
    "resize",
    "image",
    "scaling",
    "get",
    "prediction",
    "see",
    "getting",
    "sad",
    "prediction",
    "go",
    "run",
    "let",
    "call",
    "hat",
    "new",
    "grab",
    "block",
    "going",
    "say",
    "hat",
    "nu",
    "greater",
    "see",
    "still",
    "predicting",
    "sad",
    "nutshell",
    "build",
    "deep",
    "neural",
    "network",
    "image",
    "classification",
    "gone",
    "ton",
    "stuff",
    "tutorial",
    "let",
    "quickly",
    "recap",
    "first",
    "went",
    "set",
    "image",
    "environment",
    "able",
    "set",
    "load",
    "data",
    "going",
    "import",
    "bunch",
    "dependencies",
    "went",
    "removed",
    "dodgy",
    "images",
    "went",
    "downloaded",
    "originally",
    "google",
    "remember",
    "get",
    "image",
    "extension",
    "makes",
    "life",
    "whole",
    "bunch",
    "easier",
    "called",
    "um",
    "download",
    "images",
    "google",
    "chrome",
    "extension",
    "nothing",
    "fancy",
    "makes",
    "life",
    "ton",
    "easier",
    "getting",
    "images",
    "went",
    "loaded",
    "data",
    "set",
    "using",
    "image",
    "data",
    "set",
    "directory",
    "method",
    "went",
    "data",
    "scaled",
    "split",
    "went",
    "built",
    "deep",
    "neural",
    "network",
    "went",
    "bit",
    "detail",
    "actually",
    "constructed",
    "architecture",
    "went",
    "trained",
    "using",
    "took",
    "look",
    "performance",
    "time",
    "went",
    "finally",
    "evaluated",
    "new",
    "images",
    "got",
    "web",
    "last",
    "least",
    "gone",
    "saved",
    "model",
    "disk",
    "bring",
    "back",
    "need",
    "nutshell",
    "tutorial",
    "done",
    "thanks",
    "tuning",
    "guys",
    "peace",
    "thanks",
    "much",
    "tuning",
    "guys",
    "hopefully",
    "enjoyed",
    "video",
    "sure",
    "give",
    "big",
    "thumbs",
    "hit",
    "subscribe",
    "tick",
    "bell",
    "let",
    "know",
    "deep",
    "neural",
    "network",
    "type",
    "tutorials",
    "next",
    "enjoy",
    "one",
    "build",
    "go",
    "classify",
    "thanks",
    "tuning",
    "peace"
  ],
  "keywords": [
    "wanted",
    "build",
    "deep",
    "image",
    "classifier",
    "well",
    "tutorial",
    "going",
    "exactly",
    "let",
    "guys",
    "building",
    "using",
    "data",
    "nice",
    "thing",
    "bunch",
    "images",
    "load",
    "pipeline",
    "able",
    "use",
    "zero",
    "one",
    "classification",
    "type",
    "much",
    "end",
    "first",
    "getting",
    "take",
    "look",
    "need",
    "order",
    "model",
    "keras",
    "tensorflow",
    "sequential",
    "neural",
    "network",
    "test",
    "last",
    "save",
    "get",
    "learning",
    "uh",
    "gon",
    "na",
    "know",
    "like",
    "right",
    "people",
    "happy",
    "sad",
    "okay",
    "probably",
    "inside",
    "yeah",
    "go",
    "got",
    "really",
    "pretty",
    "want",
    "particular",
    "sort",
    "show",
    "things",
    "ahead",
    "set",
    "dependencies",
    "also",
    "remove",
    "dodgy",
    "download",
    "code",
    "see",
    "available",
    "check",
    "run",
    "line",
    "gpu",
    "opencv",
    "matplotlib",
    "used",
    "api",
    "visualize",
    "looks",
    "us",
    "case",
    "cool",
    "list",
    "make",
    "step",
    "ton",
    "easier",
    "next",
    "import",
    "two",
    "os",
    "file",
    "typically",
    "dot",
    "say",
    "example",
    "directory",
    "folder",
    "called",
    "return",
    "back",
    "function",
    "um",
    "could",
    "actually",
    "anything",
    "bit",
    "big",
    "models",
    "memory",
    "grabbing",
    "equals",
    "underscore",
    "give",
    "every",
    "four",
    "might",
    "still",
    "batch",
    "gone",
    "good",
    "done",
    "extension",
    "comes",
    "stuff",
    "open",
    "zip",
    "quickly",
    "grab",
    "seen",
    "call",
    "double",
    "extract",
    "create",
    "way",
    "small",
    "work",
    "saying",
    "already",
    "folders",
    "whole",
    "little",
    "block",
    "rid",
    "allows",
    "means",
    "variable",
    "remember",
    "jpg",
    "pass",
    "would",
    "single",
    "weird",
    "three",
    "add",
    "another",
    "effectively",
    "class",
    "print",
    "specific",
    "loaded",
    "passing",
    "read",
    "numpy",
    "mean",
    "shape",
    "pixels",
    "channels",
    "plot",
    "color",
    "successfully",
    "time",
    "rather",
    "scale",
    "apply",
    "access",
    "think",
    "method",
    "new",
    "labels",
    "resize",
    "32",
    "256",
    "validation",
    "iterator",
    "batches",
    "number",
    "value",
    "size",
    "different",
    "16",
    "taking",
    "person",
    "values",
    "0",
    "255",
    "training",
    "max",
    "scaled",
    "skip",
    "applying",
    "reload",
    "went",
    "partition",
    "train",
    "layer",
    "performance",
    "output",
    "layers",
    "2d",
    "convolutional",
    "convolution",
    "pooling",
    "condense",
    "dense",
    "performing",
    "filters",
    "information",
    "activation",
    "loss",
    "accuracy",
    "callback",
    "trained",
    "metrics",
    "precision",
    "recall",
    "predicted"
  ]
}