{
  "text": "So today, I thought we talk about generative adversarial networks because they're really cool, and they've\nThey can do a lot of really cool things people have used them for all kinds of things\nThings like you know you draw a sketch of a shoe\nAnd it will render you an actual picture of a shoe or a handbag\nThey're fairly low-resolution right now, but it's very impressive the way that they can produce\nreal quite good-looking images\nYou could make a neural network\nThat's a classifier right you give it lots and lots of pictures of cats and lots and lots of pictures of dogs\nand you say you know you present it with a picture of a cat and\nIt says it outputs a number. Let's say between zero and one\nand\nZero represents cats and one represents dogs and so you give it a cat and it puts out one and you say no\nThat's not right should be zero and you keep training it until eventually it can tell the difference right?\nso\nsomewhere inside that\nNetwork\nIt's... it must have formed some model of what cats are and what dogs are, at least as far as images of\nimages of them are concerned\nBut\nThat model really... you can only really use it to classify things\nYou can't say \"ok draw me a new cat picture\", \"draw me a cat picture I haven't seen before\"\nIt doesn't know how to do that so quite often you want a model that can generate new\nSamples you have so you give it a bunch of samples from a particular distribution, and you want it to\nGive you more samples which are also from that same distribution, so it has to learn the underlying\nStructure of what you've given it. And that's kind of tricky, actually.\nThere's a lot of...\nWell there's a lot of challenges involved in that.\nWell, let's be honest\nI don't think as a human you can find that tricky\nYou know if... if I know what a cat looks like but, uh, being not the greatest artist in the world\nI'm not sure that I could draw you a decent cat. So, you know, that this is not confined to just\nComputing is it? This...\nYeah, that's true. That's really true.\nbut if you take\nLet's do like a really simple example of a generative model\nsay you you give your network one thing\nIt looks like this.\nAnd then you give it another one you're like these are your training samples looks like this\nYou give it another one that looks like this, and then...\nWhat are those dots in the systems?\nInstances of something on two dimensions?\nYeah, I mean right now, it's literally just data. We just... it doesn't matter what it is\nJust some... yeah, these are these are data points\nAnd so these are the things you're giving it, and then it will learn\nYou can train it. It will learn a model, and the model it might learn is something like this, right?\nIt's figured out that these dots all lie along a path, and if its model was always to draw a line\nThen it could learn by adjusting the parameters of that line\nIt would move the line around until it found a line that was a good fit, and generally gave you a good prediction.\nBut then if you were to ask this model:\n\"Okay, now make me a new one\"\nunless you did something clever, what you get is probably this, because that is on average\nThe closest to any of these, because any of these dots you don't know if they're going to be above or below\nor, you know, to the left or the right. There's no pattern there. It's kind of random.\nSo the best place you can go that will minimize your error, is to go just right on the line every time.\nBut anybody looking at this will say: \"well, that's fake\"\nThat's not a plausible example of something from this distribution, even though for a lot of the\nlike, error functions, that people use when training networks this would perform best, so it's this interesting situation where\nThere's not just one right answer.\nyou know, generally speaking the way that neuron networks work is:\nyou're training them towards a specific you have a label or you have a\nyou have an output a target output and\nYou get penalty the further away you are from that output, whereas in in a in an application like this\nThere's effect... there's basically an infinite number of perfectly valid\nOutputs here\nBut, so, to generate this what you actually need is to take this model and then apply some randomness, you say: \"they're all\nWithin, you know,\nThey occur randomly and they're normally distributed around this line with this standard deviation\" or whatever.\nBut a lot of models would have a hard time actually\npicking one of all of the possibilities\nAnd they would have this tendency to kind of smooth things out and go for the average, whereas we actually just want\n\"Just pick me one doesn't matter\". So that's part of the problem of generating.\nAdversarial training is is help is a way of\ntraining\nNot just networks, actually, a way of training machine learning systems.\nWhich\ninvolves focusing on\nthe system's weaknesses.\nSo, if you are learning... let's say you're teaching your\nNetwork to recognize handwritten digits.\nThe normal way you would do that you have your big training sample of labeled samples\nYou've got an array of pixels that looks like a three and then it's labeled with three and so on.\nAnd the normal way\nthat you would train a network with this is you would just\nPresent all of them pretty much at random. You'd present as many ones as two as threes and just keep throwing examples at it\n\"What's this?\", you know, \"Yes, you got that right\", \"no. You've got that wrong, It should really be this\".\nAnd keep doing that and the system will eventually learn\nbut\nIf you were actually teaching a person to recognize the numbers, if you were teaching a child\nyou wouldn't do that, like, if you'd been teaching them for a while, presenting them and\nYou know, getting the response and correcting them and so on, and you noticed that they can do...\nyou know... with 2 3 4 5 6 8 & 9 they're getting like 70 80 percent\nYou know, accuracy recognition rate.\nBut 1 & 7 it's like 50/50, because any time they get a 1 or a 7 they just guess because they can't\nTell the difference between them.\nIf you noticed that you wouldn't keep training those other numbers, right? You would stop and say:\n\"Well, You know what? we're just gonna focus on 1 & 7 because this is an issue for you\".\n\"I'm gonna keep showing you Ones and 7s and correcting you until\nThe error rate on ones and 7s comes down to the error rate that you're getting on your other numbers\".\nYou're focusing the training on the area where the student is failing and\nthere's kinda of a balance there when you're teaching humans\nbecause if you keep relentlessly focusing on their weaknesses and making them do stuff they can't do all the time\nThey will just become super discouraged and give up. But neural networks don't have feelings yet, so that's really not an issue.\nYou can just\ncontinually hammer on the weak points\nFind whatever they're having trouble with and focus on that. And so, that behavior,\nand I think some people have had teachers where it feels like this,\nIt feels like an adversary, right? it feels like they want you to fail.\nSo in fact\nyou can make them an actual adversary. If you have some process which is genuinely\nDoing its best to make the network give as high an error as possible\nthat will produce this effect where if it spots any weakness it will focus on that and\nThereby force the learner\nTo learn to not have that weakness anymore. Like one form of adversarial training people sometimes\nDo is if you have a game playing program you make it play itself a lot of times\nBecause all the time. They are trying to look for weaknesses in their opponent and exploit those weaknesses and when they do that\nThey're forced to then improve or fix those weaknesses in themselves because their opponent is exploiting those weaknesses, so\nEvery time\nthe\nEvery time the system finds a strategy that is extremely good against this opponent\nThe the opponent, who's also them, has to learn a way of dealing with that strategy. And so on and so on.\nSo, as the system gets better it forces itself to get better\nBecause it's continuously having to learn how to play a better and better opponent\nIt's quite elegant, you know.\nThis is where we get to generative adversarial. Networks. Let's say\nYou've got a network you want to...\nLet's say you want cat pictures\nYou know, you want to be able to give it a bunch of pictures of cats and have it\nSpit out a new picture of a cat that you've never seen before that looks exactly like a cat\nthe way that the generative\nadversarial network works is it's this architecture where you actually have two networks one of the networks is the discriminator\nHow's my spelling?\nYeah, like that\nThe discriminator Network is a classifier right it's a straightforward classifier\nYou give it an image\nAnd it outputs a number between 0 & 1 and your training that in standard supervised learning way\nThen you have a generator and the generator\nIs...\nUsually a convolutional neural network, although actually both of these can be other processes\nBut people tend to use in your networks for this.\nAnd the generator, you\ngive it some random noise, and that's the random,\nthat's where it gets its source of randomness, so\nThat it can give multiple answers to the same question effectively.\nYou give it some random noise and it generates an image\nFrom that noise and the idea is it's supposed to look like a cat\nSo the way that we do this with a generative adversarial Network is it's this architecture whereby you have two networks\nPlaying a game\nEffectively it's a competitive game. It's adversarial between them and in fact\nIt's a very similar to the games we talked about in the  Alpha go video.\nit's a min/max game\nBecause these two networks are fighting over one number\none of them wants the number to be high one of them wants the number to be low.\nAnd what that number actually is is the error rate of the discriminator?\nso\nThe discriminator\nWants a low error rate the generator wants a high error rate the discriminators job is to look at an image\nwhich could have come from the original data set or\nIt could have come from the generator and its job is to say yes. This is a real image or no. This is a fake\nany outputs a number between 0 & 1 like 1 for its real and 0 for its fake for example and\nthe generator\nGets fed as its input. Just some random noise and it then generates an image from that and\nit's\nReward you know it's training is\nPretty much the inverse of what the discriminator says\nfor that image so if it produces an image\nWhich the discriminator can immediately tell this fake? It gets a negative reward you know it's a\nThat's it's trained not to do that if it manages to produce an image that the discriminator\nCan't tell is fake\nThen that's really good so you train them in a inner cycle effectively you you give the discriminator a real image\nget its output, then you generate a fake image and get the discriminator that and\nThen you give it a real so the discriminator gets alternating real image fake image real image fake image\nusually I mean there are things you can do where you\nTrain them at different rates and whatever but by default they're generally to get any help with this at all, or is it purely\nYes, so if you this is this is like part of what makes this especially clever actually\nthe generator does get help because\nif\nYou set up the networks right you can use the gradient of the discriminator\nto train the generator\nso when I\nKnow you done back propagation before about how neural networks are trained its gradient descent right and in fact we talked about this in like\n2014 sure if you were a\nYou're a blind person climbing a mountain or you're it's really foggy, and you're climbing a mountain you can only see directly\nWhat's underneath your own feet?\nYou can still climb that mountain if you just follow the gradient you just look directly under me which way is the\nYou know which way is the ground sloping? This is what we did the hill climb algorithm exactly\nYeah, sometimes people call it hill climbing sometimes people call it gradient descent\nIt's the same\nmetaphor\nUpside down effectively if we're climbing up or we're climbing down you're training them by gradient descent, which means that\nYou're not just you're not just able to say\nYes, that's good. No. That's bad\nYou're actually able to say and you should adjust yours you should adjust your weights in this direction so that you'll move down the gradient\nright\nSo generally you're trying to move down the gradient of error for the network\nIf you're like if you're training if your training the thing to just recognize cats and dogs you're just moving it\nYou're moving it down the gradient towards the correct label whereas in this case\nThe generator is being moved\nsort of up the gradient for the discriminators error\nSo it can find out not just you did well you did badly\nBut here's how to tweak your weights so that you will so that the discriminator would have been more wrong\nSo so that you can confuse the discriminator more so you can think of this whole thing?\nAn analogy people sometimes use is like a a forger and\nAn expert investigator person right at the beginning, you know let's assume\nThere's one forger in there's one investigator and all of the art\nbuyers of the world are idiots at the beginning the the\nLevel of the the quality of the forgeries is going to be quite low right the guy\nJust go get some paint, and he he then he just writes you know Picasso on it\nAnd he can sell it for a lot of money and the investigator comes along and says yeah\nI do I don't know that's right or maybe it is. I'm not sure I haven't really figured it out\nAnd then as time goes on the investigator who's the discriminator will?\nStart to spot certain things that are different between the things that the forger produces and real paintings\nAnd then they'll start to be able to reliably spot. Oh, this is a fake\nYou know this uses the wrong type of paint or whatever\nSo it's fake and once that happens the forger is forced to get better right you can't sell his fakes anymore\nHe has to find that kind of paint\nSo he goes and you know\nDigs up Egyptian mummies or whatever to get the legit paint and now he can forge again\nand now of the discriminator the investigator is fooled and\nThey have to find a new thing\nThat distinguishes the real from the fakes and so on and so on in a cycle they force each other to improve\nAnd it's the same thing here\nSo at the beginning the generator is making just random noise basically because it's it's it's getting random noisy\nAnd it's doing something to it who knows what and it spits out an image and the discriminator goes that looks nothing like a cat\nyou know\nand\nthen\neventually because the discriminator is also not very smart at the beginning right and\nAnd they just they both get better and better\nThe generator gets better at producing cat looking things and the discriminator gets better and better at identifying them\nuntil eventually in principle if you run this for long enough theoretically you end up with a situation where the\nGenerator is creating images that look exactly\nIndistinguishable from\nImages from the real data set and the discriminator if it's given a real image, or a fake image always outputs 0.5\n5050 I\nDon't know could be either these things are literally indistinguishable, then you pretty much can throw away the discriminator\nAnd you've got a generator, which you give random noise to and it outputs\nbrand-new\nIndistinguishable images of cats there's another cool thing about this\nWhich is every every time we ask the generator to generate new image\nWe're giving it some random data, right we give it just this vector of random numbers\nWhich you can think of as being a randomly selected point in a space because you know if you give it\nIf you give it ten random numbers you know between zero and one or whatever that is effectively a point in a 10 dimensional space\nand\nthe thing that's cool is that as\nthe generator learns\nIt's forced to\nYou if the generator is effectively making a mapping from that space into cat pictures\nThis is called the lateness base by the way generally\nAny two nearby points in that latent space will when you put them through the generator produce similar\ncabbages you know similar pictures in general\nWhich means sort of as you move\nAround if you sort of take that point and smoothly move it around the latent space you get a smooth léa varying\npicture of a cat and so the directions you can move in the space\nActually end up\ncorresponding to\nSomething that we as humans might consider meaningful about cats\nso there's one you know there's one direction, and it's not necessarily one dimension of the space or whatever but\nAnd it's not necessarily linear or a straight line or anything\nBut there will be a direction in that space which corresponds to\nHow big the cat is in the frame for example or another dimension will be the color of the cat or?\nwhatever\nso\nThat's really cool, because it means that\nby\nIntuitively you think\nThe fact that the generator can reliably produce a very large number of images of cats\nmeans it must have some like understanding understanding of\nWhat cats are right or at least what images of cats are\nAnd it's nice to see that it has actually\nStructured its latent space in this way that it's by looking at a huge number of pictures of cats it has actually extracted\nsome of the structure of\ncat pictures in general\nIn a way, which is meaningful when you look at it?\nSo and that means you can do some really cool things, so one example was they trained Annette one of these systems\non a really large\nDatabase of just face photographs and so it could generate\narbitrarily large number of well as largest the input space a number of different faces and\nSo they found that actually by doing\nbasic\narithmetic like just adding and subtracting vectors on the\nLatent space would actually produce meaningful changes in the image if you took a bunch of latent\nvectors, which when you give them to the generator produce pictures of men and\na bunch of them that produce pictures of women and average those you get a point in your\nlatent space which\ncorresponds to\na picture of a man or a picture of a woman which is not one of your input points, but it's sort of representative and\nThen you could do the same thing and say oh, I only want\nGive me the average point of all of the things that correspond to pictures of men wearing sunglasses\nright and\nThen if you take your sunglass vector, you're you're men wearing sunglasses vector\nSubtract the man vector and add the woman vector you get a point in your space\nAnd if you run that through the generator you get a woman wearing sunglasses\nright\nSo doing doing basic vector arithmetic in your input space actually is?\nMeaningful in terms of images in a way that humans would recognize, which means that?\nThere's there's a sense in which the generator really does\nHave an understanding of wearing sunglasses or not or being a man or being a woman\nWhich is kind of an impressive result\nAll the way along\nBut it's not a truly random thing because if I know the key and I can start want to generate the same\nYeah\nI'm so I mean that's about\nUnfortunate is the problem with cryptography is that we couldn't ever use truly random because we wouldn't be able to decrypt it again\nWe have our message bits, which are you know naught 1 1 naught something different?\nAnd we XOR these together one bit at a time, and that's how we encrypt\n",
  "words": [
    "today",
    "thought",
    "talk",
    "generative",
    "adversarial",
    "networks",
    "really",
    "cool",
    "lot",
    "really",
    "cool",
    "things",
    "people",
    "used",
    "kinds",
    "things",
    "things",
    "like",
    "know",
    "draw",
    "sketch",
    "shoe",
    "render",
    "actual",
    "picture",
    "shoe",
    "handbag",
    "fairly",
    "right",
    "impressive",
    "way",
    "produce",
    "real",
    "quite",
    "images",
    "could",
    "make",
    "neural",
    "network",
    "classifier",
    "right",
    "give",
    "lots",
    "lots",
    "pictures",
    "cats",
    "lots",
    "lots",
    "pictures",
    "dogs",
    "say",
    "know",
    "present",
    "picture",
    "cat",
    "says",
    "outputs",
    "number",
    "let",
    "say",
    "zero",
    "one",
    "zero",
    "represents",
    "cats",
    "one",
    "represents",
    "dogs",
    "give",
    "cat",
    "puts",
    "one",
    "say",
    "right",
    "zero",
    "keep",
    "training",
    "eventually",
    "tell",
    "difference",
    "right",
    "somewhere",
    "inside",
    "network",
    "must",
    "formed",
    "model",
    "cats",
    "dogs",
    "least",
    "far",
    "images",
    "images",
    "concerned",
    "model",
    "really",
    "really",
    "use",
    "classify",
    "things",
    "ca",
    "say",
    "ok",
    "draw",
    "new",
    "cat",
    "picture",
    "draw",
    "cat",
    "picture",
    "seen",
    "know",
    "quite",
    "often",
    "want",
    "model",
    "generate",
    "new",
    "samples",
    "give",
    "bunch",
    "samples",
    "particular",
    "distribution",
    "want",
    "give",
    "samples",
    "also",
    "distribution",
    "learn",
    "underlying",
    "structure",
    "given",
    "kind",
    "tricky",
    "actually",
    "lot",
    "well",
    "lot",
    "challenges",
    "involved",
    "well",
    "let",
    "honest",
    "think",
    "human",
    "find",
    "tricky",
    "know",
    "know",
    "cat",
    "looks",
    "like",
    "uh",
    "greatest",
    "artist",
    "world",
    "sure",
    "could",
    "draw",
    "decent",
    "cat",
    "know",
    "confined",
    "computing",
    "yeah",
    "true",
    "really",
    "true",
    "take",
    "let",
    "like",
    "really",
    "simple",
    "example",
    "generative",
    "model",
    "say",
    "give",
    "network",
    "one",
    "thing",
    "looks",
    "like",
    "give",
    "another",
    "one",
    "like",
    "training",
    "samples",
    "looks",
    "like",
    "give",
    "another",
    "one",
    "looks",
    "like",
    "dots",
    "systems",
    "instances",
    "something",
    "two",
    "dimensions",
    "yeah",
    "mean",
    "right",
    "literally",
    "data",
    "matter",
    "yeah",
    "data",
    "points",
    "things",
    "giving",
    "learn",
    "train",
    "learn",
    "model",
    "model",
    "might",
    "learn",
    "something",
    "like",
    "right",
    "figured",
    "dots",
    "lie",
    "along",
    "path",
    "model",
    "always",
    "draw",
    "line",
    "could",
    "learn",
    "adjusting",
    "parameters",
    "line",
    "would",
    "move",
    "line",
    "around",
    "found",
    "line",
    "good",
    "fit",
    "generally",
    "gave",
    "good",
    "prediction",
    "ask",
    "model",
    "okay",
    "make",
    "new",
    "one",
    "unless",
    "something",
    "clever",
    "get",
    "probably",
    "average",
    "closest",
    "dots",
    "know",
    "going",
    "know",
    "left",
    "right",
    "pattern",
    "kind",
    "random",
    "best",
    "place",
    "go",
    "minimize",
    "error",
    "go",
    "right",
    "line",
    "every",
    "time",
    "anybody",
    "looking",
    "say",
    "well",
    "fake",
    "plausible",
    "example",
    "something",
    "distribution",
    "even",
    "though",
    "lot",
    "like",
    "error",
    "functions",
    "people",
    "use",
    "training",
    "networks",
    "would",
    "perform",
    "best",
    "interesting",
    "situation",
    "one",
    "right",
    "answer",
    "know",
    "generally",
    "speaking",
    "way",
    "neuron",
    "networks",
    "work",
    "training",
    "towards",
    "specific",
    "label",
    "output",
    "target",
    "output",
    "get",
    "penalty",
    "away",
    "output",
    "whereas",
    "application",
    "like",
    "effect",
    "basically",
    "infinite",
    "number",
    "perfectly",
    "valid",
    "outputs",
    "generate",
    "actually",
    "need",
    "take",
    "model",
    "apply",
    "randomness",
    "say",
    "within",
    "know",
    "occur",
    "randomly",
    "normally",
    "distributed",
    "around",
    "line",
    "standard",
    "deviation",
    "whatever",
    "lot",
    "models",
    "would",
    "hard",
    "time",
    "actually",
    "picking",
    "one",
    "possibilities",
    "would",
    "tendency",
    "kind",
    "smooth",
    "things",
    "go",
    "average",
    "whereas",
    "actually",
    "want",
    "pick",
    "one",
    "matter",
    "part",
    "problem",
    "generating",
    "adversarial",
    "training",
    "help",
    "way",
    "training",
    "networks",
    "actually",
    "way",
    "training",
    "machine",
    "learning",
    "systems",
    "involves",
    "focusing",
    "system",
    "weaknesses",
    "learning",
    "let",
    "say",
    "teaching",
    "network",
    "recognize",
    "handwritten",
    "digits",
    "normal",
    "way",
    "would",
    "big",
    "training",
    "sample",
    "labeled",
    "samples",
    "got",
    "array",
    "pixels",
    "looks",
    "like",
    "three",
    "labeled",
    "three",
    "normal",
    "way",
    "would",
    "train",
    "network",
    "would",
    "present",
    "pretty",
    "much",
    "random",
    "present",
    "many",
    "ones",
    "two",
    "threes",
    "keep",
    "throwing",
    "examples",
    "know",
    "yes",
    "got",
    "right",
    "got",
    "wrong",
    "really",
    "keep",
    "system",
    "eventually",
    "learn",
    "actually",
    "teaching",
    "person",
    "recognize",
    "numbers",
    "teaching",
    "child",
    "would",
    "like",
    "teaching",
    "presenting",
    "know",
    "getting",
    "response",
    "correcting",
    "noticed",
    "know",
    "2",
    "3",
    "4",
    "5",
    "6",
    "8",
    "9",
    "getting",
    "like",
    "70",
    "80",
    "percent",
    "know",
    "accuracy",
    "recognition",
    "rate",
    "1",
    "7",
    "like",
    "time",
    "get",
    "1",
    "7",
    "guess",
    "ca",
    "tell",
    "difference",
    "noticed",
    "would",
    "keep",
    "training",
    "numbers",
    "right",
    "would",
    "stop",
    "say",
    "well",
    "know",
    "gon",
    "na",
    "focus",
    "1",
    "7",
    "issue",
    "gon",
    "na",
    "keep",
    "showing",
    "ones",
    "7s",
    "correcting",
    "error",
    "rate",
    "ones",
    "7s",
    "comes",
    "error",
    "rate",
    "getting",
    "numbers",
    "focusing",
    "training",
    "area",
    "student",
    "failing",
    "kinda",
    "balance",
    "teaching",
    "humans",
    "keep",
    "relentlessly",
    "focusing",
    "weaknesses",
    "making",
    "stuff",
    "ca",
    "time",
    "become",
    "super",
    "discouraged",
    "give",
    "neural",
    "networks",
    "feelings",
    "yet",
    "really",
    "issue",
    "continually",
    "hammer",
    "weak",
    "points",
    "find",
    "whatever",
    "trouble",
    "focus",
    "behavior",
    "think",
    "people",
    "teachers",
    "feels",
    "like",
    "feels",
    "like",
    "adversary",
    "right",
    "feels",
    "like",
    "want",
    "fail",
    "fact",
    "make",
    "actual",
    "adversary",
    "process",
    "genuinely",
    "best",
    "make",
    "network",
    "give",
    "high",
    "error",
    "possible",
    "produce",
    "effect",
    "spots",
    "weakness",
    "focus",
    "thereby",
    "force",
    "learner",
    "learn",
    "weakness",
    "anymore",
    "like",
    "one",
    "form",
    "adversarial",
    "training",
    "people",
    "sometimes",
    "game",
    "playing",
    "program",
    "make",
    "play",
    "lot",
    "times",
    "time",
    "trying",
    "look",
    "weaknesses",
    "opponent",
    "exploit",
    "weaknesses",
    "forced",
    "improve",
    "fix",
    "weaknesses",
    "opponent",
    "exploiting",
    "weaknesses",
    "every",
    "time",
    "every",
    "time",
    "system",
    "finds",
    "strategy",
    "extremely",
    "good",
    "opponent",
    "opponent",
    "also",
    "learn",
    "way",
    "dealing",
    "strategy",
    "system",
    "gets",
    "better",
    "forces",
    "get",
    "better",
    "continuously",
    "learn",
    "play",
    "better",
    "better",
    "opponent",
    "quite",
    "elegant",
    "know",
    "get",
    "generative",
    "adversarial",
    "networks",
    "let",
    "say",
    "got",
    "network",
    "want",
    "let",
    "say",
    "want",
    "cat",
    "pictures",
    "know",
    "want",
    "able",
    "give",
    "bunch",
    "pictures",
    "cats",
    "spit",
    "new",
    "picture",
    "cat",
    "never",
    "seen",
    "looks",
    "exactly",
    "like",
    "cat",
    "way",
    "generative",
    "adversarial",
    "network",
    "works",
    "architecture",
    "actually",
    "two",
    "networks",
    "one",
    "networks",
    "discriminator",
    "spelling",
    "yeah",
    "like",
    "discriminator",
    "network",
    "classifier",
    "right",
    "straightforward",
    "classifier",
    "give",
    "image",
    "outputs",
    "number",
    "0",
    "1",
    "training",
    "standard",
    "supervised",
    "learning",
    "way",
    "generator",
    "generator",
    "usually",
    "convolutional",
    "neural",
    "network",
    "although",
    "actually",
    "processes",
    "people",
    "tend",
    "use",
    "networks",
    "generator",
    "give",
    "random",
    "noise",
    "random",
    "gets",
    "source",
    "randomness",
    "give",
    "multiple",
    "answers",
    "question",
    "effectively",
    "give",
    "random",
    "noise",
    "generates",
    "image",
    "noise",
    "idea",
    "supposed",
    "look",
    "like",
    "cat",
    "way",
    "generative",
    "adversarial",
    "network",
    "architecture",
    "whereby",
    "two",
    "networks",
    "playing",
    "game",
    "effectively",
    "competitive",
    "game",
    "adversarial",
    "fact",
    "similar",
    "games",
    "talked",
    "alpha",
    "go",
    "video",
    "game",
    "two",
    "networks",
    "fighting",
    "one",
    "number",
    "one",
    "wants",
    "number",
    "high",
    "one",
    "wants",
    "number",
    "low",
    "number",
    "actually",
    "error",
    "rate",
    "discriminator",
    "discriminator",
    "wants",
    "low",
    "error",
    "rate",
    "generator",
    "wants",
    "high",
    "error",
    "rate",
    "discriminators",
    "job",
    "look",
    "image",
    "could",
    "come",
    "original",
    "data",
    "set",
    "could",
    "come",
    "generator",
    "job",
    "say",
    "yes",
    "real",
    "image",
    "fake",
    "outputs",
    "number",
    "0",
    "1",
    "like",
    "1",
    "real",
    "0",
    "fake",
    "example",
    "generator",
    "gets",
    "fed",
    "input",
    "random",
    "noise",
    "generates",
    "image",
    "reward",
    "know",
    "training",
    "pretty",
    "much",
    "inverse",
    "discriminator",
    "says",
    "image",
    "produces",
    "image",
    "discriminator",
    "immediately",
    "tell",
    "fake",
    "gets",
    "negative",
    "reward",
    "know",
    "trained",
    "manages",
    "produce",
    "image",
    "discriminator",
    "ca",
    "tell",
    "fake",
    "really",
    "good",
    "train",
    "inner",
    "cycle",
    "effectively",
    "give",
    "discriminator",
    "real",
    "image",
    "get",
    "output",
    "generate",
    "fake",
    "image",
    "get",
    "discriminator",
    "give",
    "real",
    "discriminator",
    "gets",
    "alternating",
    "real",
    "image",
    "fake",
    "image",
    "real",
    "image",
    "fake",
    "image",
    "usually",
    "mean",
    "things",
    "train",
    "different",
    "rates",
    "whatever",
    "default",
    "generally",
    "get",
    "help",
    "purely",
    "yes",
    "like",
    "part",
    "makes",
    "especially",
    "clever",
    "actually",
    "generator",
    "get",
    "help",
    "set",
    "networks",
    "right",
    "use",
    "gradient",
    "discriminator",
    "train",
    "generator",
    "know",
    "done",
    "back",
    "propagation",
    "neural",
    "networks",
    "trained",
    "gradient",
    "descent",
    "right",
    "fact",
    "talked",
    "like",
    "2014",
    "sure",
    "blind",
    "person",
    "climbing",
    "mountain",
    "really",
    "foggy",
    "climbing",
    "mountain",
    "see",
    "directly",
    "underneath",
    "feet",
    "still",
    "climb",
    "mountain",
    "follow",
    "gradient",
    "look",
    "directly",
    "way",
    "know",
    "way",
    "ground",
    "sloping",
    "hill",
    "climb",
    "algorithm",
    "exactly",
    "yeah",
    "sometimes",
    "people",
    "call",
    "hill",
    "climbing",
    "sometimes",
    "people",
    "call",
    "gradient",
    "descent",
    "metaphor",
    "upside",
    "effectively",
    "climbing",
    "climbing",
    "training",
    "gradient",
    "descent",
    "means",
    "able",
    "say",
    "yes",
    "good",
    "bad",
    "actually",
    "able",
    "say",
    "adjust",
    "adjust",
    "weights",
    "direction",
    "move",
    "gradient",
    "right",
    "generally",
    "trying",
    "move",
    "gradient",
    "error",
    "network",
    "like",
    "training",
    "training",
    "thing",
    "recognize",
    "cats",
    "dogs",
    "moving",
    "moving",
    "gradient",
    "towards",
    "correct",
    "label",
    "whereas",
    "case",
    "generator",
    "moved",
    "sort",
    "gradient",
    "discriminators",
    "error",
    "find",
    "well",
    "badly",
    "tweak",
    "weights",
    "discriminator",
    "would",
    "wrong",
    "confuse",
    "discriminator",
    "think",
    "whole",
    "thing",
    "analogy",
    "people",
    "sometimes",
    "use",
    "like",
    "forger",
    "expert",
    "investigator",
    "person",
    "right",
    "beginning",
    "know",
    "let",
    "assume",
    "one",
    "forger",
    "one",
    "investigator",
    "art",
    "buyers",
    "world",
    "idiots",
    "beginning",
    "level",
    "quality",
    "forgeries",
    "going",
    "quite",
    "low",
    "right",
    "guy",
    "go",
    "get",
    "paint",
    "writes",
    "know",
    "picasso",
    "sell",
    "lot",
    "money",
    "investigator",
    "comes",
    "along",
    "says",
    "yeah",
    "know",
    "right",
    "maybe",
    "sure",
    "really",
    "figured",
    "time",
    "goes",
    "investigator",
    "discriminator",
    "start",
    "spot",
    "certain",
    "things",
    "different",
    "things",
    "forger",
    "produces",
    "real",
    "paintings",
    "start",
    "able",
    "reliably",
    "spot",
    "oh",
    "fake",
    "know",
    "uses",
    "wrong",
    "type",
    "paint",
    "whatever",
    "fake",
    "happens",
    "forger",
    "forced",
    "get",
    "better",
    "right",
    "ca",
    "sell",
    "fakes",
    "anymore",
    "find",
    "kind",
    "paint",
    "goes",
    "know",
    "digs",
    "egyptian",
    "mummies",
    "whatever",
    "get",
    "legit",
    "paint",
    "forge",
    "discriminator",
    "investigator",
    "fooled",
    "find",
    "new",
    "thing",
    "distinguishes",
    "real",
    "fakes",
    "cycle",
    "force",
    "improve",
    "thing",
    "beginning",
    "generator",
    "making",
    "random",
    "noise",
    "basically",
    "getting",
    "random",
    "noisy",
    "something",
    "knows",
    "spits",
    "image",
    "discriminator",
    "goes",
    "looks",
    "nothing",
    "like",
    "cat",
    "know",
    "eventually",
    "discriminator",
    "also",
    "smart",
    "beginning",
    "right",
    "get",
    "better",
    "better",
    "generator",
    "gets",
    "better",
    "producing",
    "cat",
    "looking",
    "things",
    "discriminator",
    "gets",
    "better",
    "better",
    "identifying",
    "eventually",
    "principle",
    "run",
    "long",
    "enough",
    "theoretically",
    "end",
    "situation",
    "generator",
    "creating",
    "images",
    "look",
    "exactly",
    "indistinguishable",
    "images",
    "real",
    "data",
    "set",
    "discriminator",
    "given",
    "real",
    "image",
    "fake",
    "image",
    "always",
    "outputs",
    "5050",
    "know",
    "could",
    "either",
    "things",
    "literally",
    "indistinguishable",
    "pretty",
    "much",
    "throw",
    "away",
    "discriminator",
    "got",
    "generator",
    "give",
    "random",
    "noise",
    "outputs",
    "indistinguishable",
    "images",
    "cats",
    "another",
    "cool",
    "thing",
    "every",
    "every",
    "time",
    "ask",
    "generator",
    "generate",
    "new",
    "image",
    "giving",
    "random",
    "data",
    "right",
    "give",
    "vector",
    "random",
    "numbers",
    "think",
    "randomly",
    "selected",
    "point",
    "space",
    "know",
    "give",
    "give",
    "ten",
    "random",
    "numbers",
    "know",
    "zero",
    "one",
    "whatever",
    "effectively",
    "point",
    "10",
    "dimensional",
    "space",
    "thing",
    "cool",
    "generator",
    "learns",
    "forced",
    "generator",
    "effectively",
    "making",
    "mapping",
    "space",
    "cat",
    "pictures",
    "called",
    "lateness",
    "base",
    "way",
    "generally",
    "two",
    "nearby",
    "points",
    "latent",
    "space",
    "put",
    "generator",
    "produce",
    "similar",
    "cabbages",
    "know",
    "similar",
    "pictures",
    "general",
    "means",
    "sort",
    "move",
    "around",
    "sort",
    "take",
    "point",
    "smoothly",
    "move",
    "around",
    "latent",
    "space",
    "get",
    "smooth",
    "léa",
    "varying",
    "picture",
    "cat",
    "directions",
    "move",
    "space",
    "actually",
    "end",
    "corresponding",
    "something",
    "humans",
    "might",
    "consider",
    "meaningful",
    "cats",
    "one",
    "know",
    "one",
    "direction",
    "necessarily",
    "one",
    "dimension",
    "space",
    "whatever",
    "necessarily",
    "linear",
    "straight",
    "line",
    "anything",
    "direction",
    "space",
    "corresponds",
    "big",
    "cat",
    "frame",
    "example",
    "another",
    "dimension",
    "color",
    "cat",
    "whatever",
    "really",
    "cool",
    "means",
    "intuitively",
    "think",
    "fact",
    "generator",
    "reliably",
    "produce",
    "large",
    "number",
    "images",
    "cats",
    "means",
    "must",
    "like",
    "understanding",
    "understanding",
    "cats",
    "right",
    "least",
    "images",
    "cats",
    "nice",
    "see",
    "actually",
    "structured",
    "latent",
    "space",
    "way",
    "looking",
    "huge",
    "number",
    "pictures",
    "cats",
    "actually",
    "extracted",
    "structure",
    "cat",
    "pictures",
    "general",
    "way",
    "meaningful",
    "look",
    "means",
    "really",
    "cool",
    "things",
    "one",
    "example",
    "trained",
    "annette",
    "one",
    "systems",
    "really",
    "large",
    "database",
    "face",
    "photographs",
    "could",
    "generate",
    "arbitrarily",
    "large",
    "number",
    "well",
    "largest",
    "input",
    "space",
    "number",
    "different",
    "faces",
    "found",
    "actually",
    "basic",
    "arithmetic",
    "like",
    "adding",
    "subtracting",
    "vectors",
    "latent",
    "space",
    "would",
    "actually",
    "produce",
    "meaningful",
    "changes",
    "image",
    "took",
    "bunch",
    "latent",
    "vectors",
    "give",
    "generator",
    "produce",
    "pictures",
    "men",
    "bunch",
    "produce",
    "pictures",
    "women",
    "average",
    "get",
    "point",
    "latent",
    "space",
    "corresponds",
    "picture",
    "man",
    "picture",
    "woman",
    "one",
    "input",
    "points",
    "sort",
    "representative",
    "could",
    "thing",
    "say",
    "oh",
    "want",
    "give",
    "average",
    "point",
    "things",
    "correspond",
    "pictures",
    "men",
    "wearing",
    "sunglasses",
    "right",
    "take",
    "sunglass",
    "vector",
    "men",
    "wearing",
    "sunglasses",
    "vector",
    "subtract",
    "man",
    "vector",
    "add",
    "woman",
    "vector",
    "get",
    "point",
    "space",
    "run",
    "generator",
    "get",
    "woman",
    "wearing",
    "sunglasses",
    "right",
    "basic",
    "vector",
    "arithmetic",
    "input",
    "space",
    "actually",
    "meaningful",
    "terms",
    "images",
    "way",
    "humans",
    "would",
    "recognize",
    "means",
    "sense",
    "generator",
    "really",
    "understanding",
    "wearing",
    "sunglasses",
    "man",
    "woman",
    "kind",
    "impressive",
    "result",
    "way",
    "along",
    "truly",
    "random",
    "thing",
    "know",
    "key",
    "start",
    "want",
    "generate",
    "yeah",
    "mean",
    "unfortunate",
    "problem",
    "cryptography",
    "could",
    "ever",
    "use",
    "truly",
    "random",
    "would",
    "able",
    "decrypt",
    "message",
    "bits",
    "know",
    "naught",
    "1",
    "1",
    "naught",
    "something",
    "different",
    "xor",
    "together",
    "one",
    "bit",
    "time",
    "encrypt"
  ],
  "keywords": [
    "generative",
    "adversarial",
    "networks",
    "really",
    "cool",
    "lot",
    "things",
    "people",
    "like",
    "know",
    "draw",
    "picture",
    "right",
    "way",
    "produce",
    "real",
    "quite",
    "images",
    "could",
    "make",
    "neural",
    "network",
    "classifier",
    "give",
    "lots",
    "pictures",
    "cats",
    "dogs",
    "say",
    "present",
    "cat",
    "says",
    "outputs",
    "number",
    "let",
    "zero",
    "one",
    "keep",
    "training",
    "eventually",
    "tell",
    "model",
    "use",
    "ca",
    "new",
    "want",
    "generate",
    "samples",
    "bunch",
    "distribution",
    "also",
    "learn",
    "kind",
    "actually",
    "well",
    "think",
    "find",
    "looks",
    "sure",
    "yeah",
    "take",
    "example",
    "thing",
    "another",
    "dots",
    "systems",
    "something",
    "two",
    "mean",
    "data",
    "points",
    "train",
    "along",
    "line",
    "would",
    "move",
    "around",
    "good",
    "generally",
    "get",
    "average",
    "random",
    "best",
    "go",
    "error",
    "every",
    "time",
    "looking",
    "fake",
    "output",
    "whereas",
    "whatever",
    "help",
    "learning",
    "focusing",
    "system",
    "weaknesses",
    "teaching",
    "recognize",
    "got",
    "pretty",
    "much",
    "ones",
    "yes",
    "wrong",
    "person",
    "numbers",
    "getting",
    "rate",
    "1",
    "7",
    "focus",
    "humans",
    "making",
    "feels",
    "fact",
    "high",
    "sometimes",
    "game",
    "look",
    "opponent",
    "forced",
    "gets",
    "better",
    "able",
    "exactly",
    "discriminator",
    "image",
    "0",
    "generator",
    "noise",
    "effectively",
    "similar",
    "wants",
    "low",
    "set",
    "input",
    "trained",
    "different",
    "gradient",
    "descent",
    "climbing",
    "mountain",
    "means",
    "direction",
    "sort",
    "forger",
    "investigator",
    "beginning",
    "paint",
    "goes",
    "start",
    "indistinguishable",
    "vector",
    "point",
    "space",
    "latent",
    "meaningful",
    "large",
    "understanding",
    "men",
    "man",
    "woman",
    "wearing",
    "sunglasses"
  ]
}