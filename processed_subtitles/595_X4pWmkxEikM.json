{
  "text": "feature engineering it is one of those\nblack art ninja data science tricks that\nthe masters use to\nraise the accuracy of their model\nwhether it's a neural network support\nvector machine\nxg boost whatever and get better\naccuracy\nnow feature engineering i've definitely\nused this particular black magic and\nkaggles of my own you can see here in\nthe core of question pairs\ni got to a top seven percent ranking\nand i did this not by throwing crazy\namounts of compute power at it but just\nlooking at the data using my human\nintuition\nand understanding how i can take the\ndata that i already have recombine it\nand create additional features that give\nadditional lift\nto the model now feature engineering is\nnothing more than taking\nthat input vector of your data set that\nyou're given\nhere you see cars and picking out a\ncouple of these that you want to\nrecombine in a different way\nfor example let's just pick horsepower\nand displacement of the engine\nwe can then combine those into a ratio\nwhere you're dividing one by another a\nratio is one of the most\noften touted ways of doing feature\nengineering\nand that gives you a new number that you\nthen augment onto\nthe data set and use that to then train\nyour model\nnow we don't want to just randomly throw\nratios and all these things around we\nneed to think about this\nif we're doing this using data science\nintuition\nlet me show you how you can take these\nformulas\nand build them like legos and know what\nto combine to\nengineer your features\n [Music]\nlook at this cartoon it's great it's by\nphd comics and i feel like it really\ncaptures feature engineering i don't\nthink that's what it's even attempting\nto do\nmaybe produce a very small model but\nthis\nshows you how you would assess whether\nyou wanted to go\nto a particular seminar or a conference\nif you're in the corporate world\nmaybe another team wants to show you\nsomething cool they've been working on\nand to get you there they lure you with\nfood so these are the three inputs\nand to make it more simple for your\nmodel the human mind in this case to\ngrasp\nwe use that formula to combine\nthese relevance of the information\nfood quality and how far away it is all\nthree very important things to decide if\nyou're going to go to a meeting or not\nand reduce those kind of like feature\nreduction it is feature reduction\nto one particular value that's now going\nto go into the model and you'll probably\nstill send those other three\nand it'll be correlated so you have to\ndeal with that in\nin models that need that dealt with but\nthat is how we've been using feature\nengineering for a long long time to\nmake things multiple variables work\nbetter for the model\nin this case our mind so that we can\nthink of them better\nsquare feet square meters if you're\nlooking at a property\na flat area of ground you're going to\nmultiply the width times\nthe length that tells you rather than\nthinking\n it's this it's this\nlong\nyou just have square meters and you're\ndone\nbut maybe taxing authorities always\nthrow\n[Music]\ncurve balls into this maybe taxes are\nmore\nif you have more street front so the\nwidth becomes much more important\nthan the length so you\nsquare the the width or multiply it by\nsomething\nit doesn't really matter that you're\nsquaring a cubing it or\nmultiplying it by a ratio that's for the\nmodel to figure out you're just giving\nit a hint you're pushing it in the right\ndirection\nanother example of simplifying things\nsort of for the human mind\nis medical if you're looking at how much\ndoes somebody weigh their mass\nyou're looking at how high they are\ntheir\ntheir height height those are two values\nmass alone is not enough to tell you the\nperson's\nreal health that's what bmi body mass\nindex is for so you need a way to\ncombine those we have this formula here\nand that is showing how you can put\nthose two in relation\nnow height that's not saying that height\nis necessarily so much more important\nthan the mass those two\nvalues are in different\nranges mass can be much higher\ncompared to the height of an individual\n so that's just kind of bringing that\nnumber you don't want this\nif the numbers for human consumption you\ndon't want it necessarily\nexploding into very very large numbers\nyou don't want to have to talk about you\nhave a\nbmi of 32 100 and whatever\nso this is just looking at some\nbasic examples of how feature\nengineering is used not just for our\nminds in these cases\nbut could be used for a model now let's\nlook at how to build these\nso here are your lego blocks to work\nwith i divide these into really four\nquadrants\nfirst you have your normalizer which is\ndivision\nthat is used often i mean think of\naverages here\nyou don't know really how well somebody\ndid on a test based on how many points\nthey got\nit is points divided by the amount\nthat is on the test so now you get this\npercent\nyou know what 90 means you don't know\nwhat i got 90\npoints are 90 points out of what 900\npoints\nthe next quadrant is combine combine\nis when you have two values and\nreally they're they're working\nvery much together so you would add them\ntogether you would multiply them\nlike the length and with looking at\ntotal value of a property\nlike in the seminar appeal\nthe relevance and food pretty similar\nkind of additive to\neach other you can combine things with\naddition\nwith multiplication if you want to go\ncompletely crazy with powers\nif you're raising something to the power\nthough make sure i mean you're going to\nvery large numbers that you're going to\nprobably have to\nback back down some other way then\nthe third quadrant is scaling\nmaybe you want to take individual values\nas you're building this lego block\nequation together and you want to\nincrease or decrease its importance\nnow you can use a division here just\ndivide something by\na value and that decreases it but more\ncommonly you'll probably use a power to\nincrease it so square something cubit\nyou might use a constant to multiply it\nwhich is sort of the same as dividing it\nyou would use say a logarithm\nor really like the the big o\nnotation in computer science there's all\nkinds of modifiers\nto control how much you want to\nsignify the importance of something heck\nif you want to make it really important\ntake the factorial of it it'll grow\nquite rapidly\nand you can use radicals which are\nreally powers\nbut like the square root and other\nthings as well because that also\ncontrols how fast something is going to\ngrow\nnow the fourth quadrant you're\ncontrasting\n so if two things are working sort of\nin opposition to each other you could\npotentially be dividing them but\nif you're subtracting them then you're\nyou're you're dealing with one thing\nsort of as the baseline\nof another and you might want to\nlook at only the magnitude maybe\nnegative numbers don't\nmatter because which side do you put\nthe two values on on the negative\nthe subtraction so if you put an\nabsolute value around it now\nit's only the magnitude that is going to\nbe important you can also just\nsquare the quantity and that's another\nway that\ncommonly these equations are set up so\nthat you're taking effectively an\nabsolute value and then often you'll put\na radical around the thing later to\nsort of back that out some of the root\nmean square\nand other error calculations are good\nexamples of these\nso now using those building blocks let's\nlook at this comic again\nyou've got relevance times food quality\n so those two things they're both\nimportant to you you're looking\nat the relevance and you're looking at\nthe food quantity now maybe food quality\nwould be more important to you so you\nmight square that one\nor you might have another value in here\nwhich they allude to\nin the final frame how hungry am i when\nhave i last eaten\nyou may actually then do food minus\nthe time that you've last eaten\nsomething such as that but relevance\nand food quality is trumped\nsorta by distance because you're lazy\nand you just don't want to walk very far\nfor this free food or\nthis information the relevance\nso you divide the whole thing by\ndistance\n okay you're really lazy let's square\ndistance or maybe you're worried about\nthose\ndistance units overwhelming the\nunits that relevance and food quality\nare in you don't have to worry so much\nabout that overwhelming\nfactor always with the models sometimes\nthey can figure it out but\ni have done adjustments when i'm\ncreating these and combining these\ntogether\nthat helps it be able to figure out\nhow to build that feature so here's one\nthat i put together\nthese are the values that i had i had\nthe value of somebody's house\nthe average value of houses in that zip\ncode and their age\n and i was feeding all three of these\ninto the model separately and i was\ntrying to predict\nkind of a score on affluence or there's\ninterest in buying a particular\nproduct a propensity model is what these\nare usually called\nso these values i was looking at a way\nhow can i\nextract something out of these three\nbecause i think they work\ntogether and then put it in with all the\nother and i had\nquite a few other features that were\nalso going into this model\n so what i thought about is okay the\nhouse\nvalue what zip code are they in\nit might be a very expensive house but\nthey're in beverly hills\nso that's really imp impressive or\nit might be not as expensive of a house\nbut they're in the midwest where i live\nand then a lower house value might be\nimpressive\n so i did a contrast i took the\naverage house value and the house valley\ncombined them\nby taking house value minus average\nhouse value\n so if you're below the average that's\ngoing to be a negative number if you're\nabove it's going to be a positive number\n and we're\nreally looking at just how much you\ndiffer\nby the average house value in your area\n i don't want to put absolute values\naround that because\nit's important whether you're above or\nbelow\nthat average that's part of what i'm\ntracking\nbut then another thing you'll tend to\nnotice in data is as\npeople age they trade up they buy\ndifferent houses\nnot always but on average you'll have a\nbigger house\nas you are older maybe not bigger size\nwise but it'll cost more\n so that's why i then took the whole\nthing\ndivided by age i'm now doing sort of a\nnormalizer\nand the units are different here the\nhouses i mean if i'm dealing in u.s\ndollars the houses will be i don't know\n100 200 300\nin that order of magnitude whereas the\nage is going to be\n100 and below or slightly above\nso that i squared the age\nto give it some size against\nthe the house values that i were\nsubtracting\nand this became a feature that i was\nthen able to calculate\ni don't really care what this value is\nit's not like i'm looking at it like\nbmi's\nit's just another piece of information\nthat i am giving the model along with\nall the other socioeconomic\ninformation and it lets the model\nthen have less to otherwise the model\nhas to figure out how to synthesize\nand create these formulas on its own\nit's\ninformation in a more pure form that the\nmodel can deal with\nmodels are inherently mathematical so do\nthey really need\nus we humans to be doing this feature\nengineering\nfor them well what i continue to read\nabout in kaggle competitions they they\ntend to\n but this was something that interested\nme so i wanted\nto take a look at really what types of\nformulas would be better to be\nengineering for these models so i did a\nresearch paper a few years ago\nthat i published it's also gotten a\nnumber of citations so it's\nbeen useful at least to somebody and\nwhat this\nwhat this paper looks at i'll probably\ndo a video about it in the future\nis i took a bunch of different formula\ntypes\ntook those 16 or so i believe\nand created data sets that\nhad just random data and i looked at how\nwell\ncan these various models interpolate\nvalues so synthesize these equations i'm\njust\nasking them to pick values that are\nright in the range\nof the values that i gave these types of\nmodels don't typically extrapolate well\n so i didn't give them anything outside\nof those ranges\nand i looked at for neural networks\nrandom forest support vector machine\nand gradient boosting how well\nhow low of errors did they really get\nsynthesizing all these various equations\nand you can see the results here\nthere are some real differences so the\ndifferent model types\nare not always creating the best\nof models when\nthis math is not performed for them\nthank you for watching this video i hope\nthis was\na good crash course in feature\nengineering at least the approach that i\ndo when i'm doing it completely\nfrom hand i typically just look at my\ndata see where\nmy model is predicting very accurately\nand not so accurately and i just\nlook at how can i engineer additional\nvalues that will really\nsegregate those\nconfusing rows that it's just not\npredicting that well on\nand maybe give it something that will\ngive it a bit more lift it certainly has\nworked in a couple of the kaggles that\ni have worked on particularly for\ntabular data this doesn't work so well\nfor\nimage data because it's not like you're\ndividing one pixel by another pixel\nall right if you find this kind of thing\ninteresting please subscribe to my\nyoutube channel\ni'll be definitely talking about more\nthings feature engineering because i\nfind it to be a very fascinating topic\n\n",
  "sentences": [
    "feature engineering it is one of those\nblack art ninja data science tricks that\nthe masters use to\nraise the accuracy of their model\nwhether it's a neural network support\nvector machine\nxg boost whatever and get better\naccuracy\nnow feature engineering i've definitely\nused this particular black magic and\nkaggles of my own you can see here in\nthe core of question pairs\ni got to a top seven percent ranking\nand i did this not by throwing crazy\namounts of compute power at it but just\nlooking at the data using my human\nintuition\nand understanding how i can take the\ndata that i already have recombine it\nand create additional features that give\nadditional lift\nto the model now feature engineering is\nnothing more than taking\nthat input vector of your data set that\nyou're given\nhere you see cars and picking out a\ncouple of these that you want to\nrecombine in a different way\nfor example let's just pick horsepower\nand displacement of the engine\nwe can then combine those into a ratio\nwhere you're dividing one by another a\nratio is one of the most\noften touted ways of doing feature\nengineering\nand that gives you a new number that you\nthen augment onto\nthe data set and use that to then train\nyour model\nnow we don't want to just randomly throw\nratios and all these things around we\nneed to think about this\nif we're doing this using data science\nintuition\nlet me show you how you can take these\nformulas\nand build them like legos and know what\nto combine to\nengineer your features\n [Music]\nlook at this cartoon it's great it's by\nphd comics and i feel like it really\ncaptures feature engineering i don't\nthink that's what it's even attempting\nto do\nmaybe produce a very small model but\nthis\nshows you how you would assess whether\nyou wanted to go\nto a particular seminar or a conference\nif you're in the corporate world\nmaybe another team wants to show you\nsomething cool they've been working on\nand to get you there they lure you with\nfood so these are the three inputs\nand to make it more simple for your\nmodel the human mind in this case to\ngrasp\nwe use that formula to combine\nthese relevance of the information\nfood quality and how far away it is all\nthree very important things to decide if\nyou're going to go to a meeting or not\nand reduce those kind of like feature\nreduction it is feature reduction\nto one particular value that's now going\nto go into the model and you'll probably\nstill send those other three\nand it'll be correlated so you have to\ndeal with that in\nin models that need that dealt with but\nthat is how we've been using feature\nengineering for a long long time to\nmake things multiple variables work\nbetter for the model\nin this case our mind so that we can\nthink of them better\nsquare feet square meters if you're\nlooking at a property\na flat area of ground you're going to\nmultiply the width times\nthe length that tells you rather than\nthinking\n it's this it's this\nlong\nyou just have square meters and you're\ndone\nbut maybe taxing authorities always\nthrow\n[Music]\ncurve balls into this maybe taxes are\nmore\nif you have more street front so the\nwidth becomes much more important\nthan the length so you\nsquare the the width or multiply it by\nsomething\nit doesn't really matter that you're\nsquaring a cubing it or\nmultiplying it by a ratio that's for the\nmodel to figure out you're just giving\nit a hint you're pushing it in the right\ndirection\nanother example of simplifying things\nsort of for the human mind\nis medical if you're looking at how much\ndoes somebody weigh their mass\nyou're looking at how high they are\ntheir\ntheir height height those are two values\nmass alone is not enough to tell you the\nperson's\nreal health that's what bmi body mass\nindex is for so you need a way to\ncombine those we have this formula here\nand that is showing how you can put\nthose two in relation\nnow height that's not saying that height\nis necessarily so much more important\nthan the mass those two\nvalues are in different\nranges mass can be much higher\ncompared to the height of an individual\n so that's just kind of bringing that\nnumber you don't want this\nif the numbers for human consumption you\ndon't want it necessarily\nexploding into very very large numbers\nyou don't want to have to talk about you\nhave a\nbmi of 32 100 and whatever\nso this is just looking at some\nbasic examples of how feature\nengineering is used not just for our\nminds in these cases\nbut could be used for a model now let's\nlook at how to build these\nso here are your lego blocks to work\nwith i divide these into really four\nquadrants\nfirst you have your normalizer which is\ndivision\nthat is used often i mean think of\naverages here\nyou don't know really how well somebody\ndid on a test based on how many points\nthey got\nit is points divided by the amount\nthat is on the test so now you get this\npercent\nyou know what 90 means you don't know\nwhat i got 90\npoints are 90 points out of what 900\npoints\nthe next quadrant is combine combine\nis when you have two values and\nreally they're they're working\nvery much together so you would add them\ntogether you would multiply them\nlike the length and with looking at\ntotal value of a property\nlike in the seminar appeal\nthe relevance and food pretty similar\nkind of additive to\neach other you can combine things with\naddition\nwith multiplication if you want to go\ncompletely crazy with powers\nif you're raising something to the power\nthough make sure i mean you're going to\nvery large numbers that you're going to\nprobably have to\nback back down some other way then\nthe third quadrant is scaling\nmaybe you want to take individual values\nas you're building this lego block\nequation together and you want to\nincrease or decrease its importance\nnow you can use a division here just\ndivide something by\na value and that decreases it but more\ncommonly you'll probably use a power to\nincrease it so square something cubit\nyou might use a constant to multiply it\nwhich is sort of the same as dividing it\nyou would use say a logarithm\nor really like the the big o\nnotation in computer science there's all\nkinds of modifiers\nto control how much you want to\nsignify the importance of something heck\nif you want to make it really important\ntake the factorial of it it'll grow\nquite rapidly\nand you can use radicals which are\nreally powers\nbut like the square root and other\nthings as well because that also\ncontrols how fast something is going to\ngrow\nnow the fourth quadrant you're\ncontrasting\n so if two things are working sort of\nin opposition to each other you could\npotentially be dividing them but\nif you're subtracting them then you're\nyou're you're dealing with one thing\nsort of as the baseline\nof another and you might want to\nlook at only the magnitude maybe\nnegative numbers don't\nmatter because which side do you put\nthe two values on on the negative\nthe subtraction so if you put an\nabsolute value around it now\nit's only the magnitude that is going to\nbe important you can also just\nsquare the quantity and that's another\nway that\ncommonly these equations are set up so\nthat you're taking effectively an\nabsolute value and then often you'll put\na radical around the thing later to\nsort of back that out some of the root\nmean square\nand other error calculations are good\nexamples of these\nso now using those building blocks let's\nlook at this comic again\nyou've got relevance times food quality\n so those two things they're both\nimportant to you you're looking\nat the relevance and you're looking at\nthe food quantity now maybe food quality\nwould be more important to you so you\nmight square that one\nor you might have another value in here\nwhich they allude to\nin the final frame how hungry am i when\nhave i last eaten\nyou may actually then do food minus\nthe time that you've last eaten\nsomething such as that but relevance\nand food quality is trumped\nsorta by distance because you're lazy\nand you just don't want to walk very far\nfor this free food or\nthis information the relevance\nso you divide the whole thing by\ndistance\n okay you're really lazy let's square\ndistance or maybe you're worried about\nthose\ndistance units overwhelming the\nunits that relevance and food quality\nare in you don't have to worry so much\nabout that overwhelming\nfactor always with the models sometimes\nthey can figure it out but\ni have done adjustments when i'm\ncreating these and combining these\ntogether\nthat helps it be able to figure out\nhow to build that feature so here's one\nthat i put together\nthese are the values that i had i had\nthe value of somebody's house\nthe average value of houses in that zip\ncode and their age\n and i was feeding all three of these\ninto the model separately and i was\ntrying to predict\nkind of a score on affluence or there's\ninterest in buying a particular\nproduct a propensity model is what these\nare usually called\nso these values i was looking at a way\nhow can i\nextract something out of these three\nbecause i think they work\ntogether and then put it in with all the\nother and i had\nquite a few other features that were\nalso going into this model\n so what i thought about is okay the\nhouse\nvalue what zip code are they in\nit might be a very expensive house but\nthey're in beverly hills\nso that's really imp impressive or\nit might be not as expensive of a house\nbut they're in the midwest where i live\nand then a lower house value might be\nimpressive\n so i did a contrast i took the\naverage house value and the house valley\ncombined them\nby taking house value minus average\nhouse value\n so if you're below the average that's\ngoing to be a negative number if you're\nabove it's going to be a positive number\n and we're\nreally looking at just how much you\ndiffer\nby the average house value in your area\n i don't want to put absolute values\naround that because\nit's important whether you're above or\nbelow\nthat average that's part of what i'm\ntracking\nbut then another thing you'll tend to\nnotice in data is as\npeople age they trade up they buy\ndifferent houses\nnot always but on average you'll have a\nbigger house\nas you are older maybe not bigger size\nwise but it'll cost more\n so that's why i then took the whole\nthing\ndivided by age i'm now doing sort of a\nnormalizer\nand the units are different here the\nhouses i mean if i'm dealing in u.s\ndollars the houses will be i don't know\n100 200 300\nin that order of magnitude whereas the\nage is going to be\n100 and below or slightly above\nso that i squared the age\nto give it some size against\nthe the house values that i were\nsubtracting\nand this became a feature that i was\nthen able to calculate\ni don't really care what this value is\nit's not like i'm looking at it like\nbmi's\nit's just another piece of information\nthat i am giving the model along with\nall the other socioeconomic\ninformation and it lets the model\nthen have less to otherwise the model\nhas to figure out how to synthesize\nand create these formulas on its own\nit's\ninformation in a more pure form that the\nmodel can deal with\nmodels are inherently mathematical so do\nthey really need\nus we humans to be doing this feature\nengineering\nfor them well what i continue to read\nabout in kaggle competitions they they\ntend to\n but this was something that interested\nme so i wanted\nto take a look at really what types of\nformulas would be better to be\nengineering for these models so i did a\nresearch paper a few years ago\nthat i published it's also gotten a\nnumber of citations so it's\nbeen useful at least to somebody and\nwhat this\nwhat this paper looks at i'll probably\ndo a video about it in the future\nis i took a bunch of different formula\ntypes\ntook those 16 or so i believe\nand created data sets that\nhad just random data and i looked at how\nwell\ncan these various models interpolate\nvalues so synthesize these equations i'm\njust\nasking them to pick values that are\nright in the range\nof the values that i gave these types of\nmodels don't typically extrapolate well\n so i didn't give them anything outside\nof those ranges\nand i looked at for neural networks\nrandom forest support vector machine\nand gradient boosting how well\nhow low of errors did they really get\nsynthesizing all these various equations\nand you can see the results here\nthere are some real differences so the\ndifferent model types\nare not always creating the best\nof models when\nthis math is not performed for them\nthank you for watching this video i hope\nthis was\na good crash course in feature\nengineering at least the approach that i\ndo when i'm doing it completely\nfrom hand i typically just look at my\ndata see where\nmy model is predicting very accurately\nand not so accurately and i just\nlook at how can i engineer additional\nvalues that will really\nsegregate those\nconfusing rows that it's just not\npredicting that well on\nand maybe give it something that will\ngive it a bit more lift it certainly has\nworked in a couple of the kaggles that\ni have worked on particularly for\ntabular data this doesn't work so well\nfor\nimage data because it's not like you're\ndividing one pixel by another pixel\nall right if you find this kind of thing\ninteresting please subscribe to my\nyoutube channel\ni'll be definitely talking about more\nthings feature engineering because i\nfind it to be a very fascinating topic"
  ],
  "paragraphs": [
    "feature engineering it is one of those",
    "black art ninja data science tricks that",
    "the masters use to",
    "raise the accuracy of their model",
    "whether it's a neural network support",
    "vector machine",
    "xg boost whatever and get better",
    "accuracy",
    "now feature engineering i've definitely",
    "used this particular black magic and",
    "kaggles of my own you can see here in",
    "the core of question pairs",
    "i got to a top seven percent ranking",
    "and i did this not by throwing crazy",
    "amounts of compute power at it but just",
    "looking at the data using my human",
    "intuition",
    "and understanding how i can take the",
    "data that i already have recombine it",
    "and create additional features that give",
    "additional lift",
    "to the model now feature engineering is",
    "nothing more than taking",
    "that input vector of your data set that",
    "you're given",
    "here you see cars and picking out a",
    "couple of these that you want to",
    "recombine in a different way",
    "for example let's just pick horsepower",
    "and displacement of the engine",
    "we can then combine those into a ratio",
    "where you're dividing one by another a",
    "ratio is one of the most",
    "often touted ways of doing feature",
    "engineering",
    "and that gives you a new number that you",
    "then augment onto",
    "the data set and use that to then train",
    "your model",
    "now we don't want to just randomly throw",
    "ratios and all these things around we",
    "need to think about this",
    "if we're doing this using data science",
    "intuition",
    "let me show you how you can take these",
    "formulas",
    "and build them like legos and know what",
    "to combine to",
    "engineer your features",
    "[Music]",
    "look at this cartoon it's great it's by",
    "phd comics and i feel like it really",
    "captures feature engineering i don't",
    "think that's what it's even attempting",
    "to do",
    "maybe produce a very small model but",
    "this",
    "shows you how you would assess whether",
    "you wanted to go",
    "to a particular seminar or a conference",
    "if you're in the corporate world",
    "maybe another team wants to show you",
    "something cool they've been working on",
    "and to get you there they lure you with",
    "food so these are the three inputs",
    "and to make it more simple for your",
    "model the human mind in this case to",
    "grasp",
    "we use that formula to combine",
    "these relevance of the information",
    "food quality and how far away it is all",
    "three very important things to decide if",
    "you're going to go to a meeting or not",
    "and reduce those kind of like feature",
    "reduction it is feature reduction",
    "to one particular value that's now going",
    "to go into the model and you'll probably",
    "still send those other three",
    "and it'll be correlated so you have to",
    "deal with that in",
    "in models that need that dealt with but",
    "that is how we've been using feature",
    "engineering for a long long time to",
    "make things multiple variables work",
    "better for the model",
    "in this case our mind so that we can",
    "think of them better",
    "square feet square meters if you're",
    "looking at a property",
    "a flat area of ground you're going to",
    "multiply the width times",
    "the length that tells you rather than",
    "thinking",
    "it's this it's this",
    "long",
    "you just have square meters and you're",
    "done",
    "but maybe taxing authorities always",
    "throw",
    "[Music]",
    "curve balls into this maybe taxes are",
    "more",
    "if you have more street front so the",
    "width becomes much more important",
    "than the length so you",
    "square the the width or multiply it by",
    "something",
    "it doesn't really matter that you're",
    "squaring a cubing it or",
    "multiplying it by a ratio that's for the",
    "model to figure out you're just giving",
    "it a hint you're pushing it in the right",
    "direction",
    "another example of simplifying things",
    "sort of for the human mind",
    "is medical if you're looking at how much",
    "does somebody weigh their mass",
    "you're looking at how high they are",
    "their",
    "their height height those are two values",
    "mass alone is not enough to tell you the",
    "person's",
    "real health that's what bmi body mass",
    "index is for so you need a way to",
    "combine those we have this formula here",
    "and that is showing how you can put",
    "those two in relation",
    "now height that's not saying that height",
    "is necessarily so much more important",
    "than the mass those two",
    "values are in different",
    "ranges mass can be much higher",
    "compared to the height of an individual",
    "so that's just kind of bringing that",
    "number you don't want this",
    "if the numbers for human consumption you",
    "don't want it necessarily",
    "exploding into very very large numbers",
    "you don't want to have to talk about you",
    "have a",
    "bmi of 32 100 and whatever",
    "so this is just looking at some",
    "basic examples of how feature",
    "engineering is used not just for our",
    "minds in these cases",
    "but could be used for a model now let's",
    "look at how to build these",
    "so here are your lego blocks to work",
    "with i divide these into really four",
    "quadrants",
    "first you have your normalizer which is",
    "division",
    "that is used often i mean think of",
    "averages here",
    "you don't know really how well somebody",
    "did on a test based on how many points",
    "they got",
    "it is points divided by the amount",
    "that is on the test so now you get this",
    "percent",
    "you know what 90 means you don't know",
    "what i got 90",
    "points are 90 points out of what 900",
    "points",
    "the next quadrant is combine combine",
    "is when you have two values and",
    "really they're they're working",
    "very much together so you would add them",
    "together you would multiply them",
    "like the length and with looking at",
    "total value of a property",
    "like in the seminar appeal",
    "the relevance and food pretty similar",
    "kind of additive to",
    "each other you can combine things with",
    "addition",
    "with multiplication if you want to go",
    "completely crazy with powers",
    "if you're raising something to the power",
    "though make sure i mean you're going to",
    "very large numbers that you're going to",
    "probably have to",
    "back back down some other way then",
    "the third quadrant is scaling",
    "maybe you want to take individual values",
    "as you're building this lego block",
    "equation together and you want to",
    "increase or decrease its importance",
    "now you can use a division here just",
    "divide something by",
    "a value and that decreases it but more",
    "commonly you'll probably use a power to",
    "increase it so square something cubit",
    "you might use a constant to multiply it",
    "which is sort of the same as dividing it",
    "you would use say a logarithm",
    "or really like the the big o",
    "notation in computer science there's all",
    "kinds of modifiers",
    "to control how much you want to",
    "signify the importance of something heck",
    "if you want to make it really important",
    "take the factorial of it it'll grow",
    "quite rapidly",
    "and you can use radicals which are",
    "really powers",
    "but like the square root and other",
    "things as well because that also",
    "controls how fast something is going to",
    "grow",
    "now the fourth quadrant you're",
    "contrasting",
    "so if two things are working sort of",
    "in opposition to each other you could",
    "potentially be dividing them but",
    "if you're subtracting them then you're",
    "you're you're dealing with one thing",
    "sort of as the baseline",
    "of another and you might want to",
    "look at only the magnitude maybe",
    "negative numbers don't",
    "matter because which side do you put",
    "the two values on on the negative",
    "the subtraction so if you put an",
    "absolute value around it now",
    "it's only the magnitude that is going to",
    "be important you can also just",
    "square the quantity and that's another",
    "way that",
    "commonly these equations are set up so",
    "that you're taking effectively an",
    "absolute value and then often you'll put",
    "a radical around the thing later to",
    "sort of back that out some of the root",
    "mean square",
    "and other error calculations are good",
    "examples of these",
    "so now using those building blocks let's",
    "look at this comic again",
    "you've got relevance times food quality",
    "so those two things they're both",
    "important to you you're looking",
    "at the relevance and you're looking at",
    "the food quantity now maybe food quality",
    "would be more important to you so you",
    "might square that one",
    "or you might have another value in here",
    "which they allude to",
    "in the final frame how hungry am i when",
    "have i last eaten",
    "you may actually then do food minus",
    "the time that you've last eaten",
    "something such as that but relevance",
    "and food quality is trumped",
    "sorta by distance because you're lazy",
    "and you just don't want to walk very far",
    "for this free food or",
    "this information the relevance",
    "so you divide the whole thing by",
    "distance",
    "okay you're really lazy let's square",
    "distance or maybe you're worried about",
    "those",
    "distance units overwhelming the",
    "units that relevance and food quality",
    "are in you don't have to worry so much",
    "about that overwhelming",
    "factor always with the models sometimes",
    "they can figure it out but",
    "i have done adjustments when i'm",
    "creating these and combining these",
    "together",
    "that helps it be able to figure out",
    "how to build that feature so here's one",
    "that i put together",
    "these are the values that i had i had",
    "the value of somebody's house",
    "the average value of houses in that zip",
    "code and their age",
    "and i was feeding all three of these",
    "into the model separately and i was",
    "trying to predict",
    "kind of a score on affluence or there's",
    "interest in buying a particular",
    "product a propensity model is what these",
    "are usually called",
    "so these values i was looking at a way",
    "how can i",
    "extract something out of these three",
    "because i think they work",
    "together and then put it in with all the",
    "other and i had",
    "quite a few other features that were",
    "also going into this model",
    "so what i thought about is okay the",
    "house",
    "value what zip code are they in",
    "it might be a very expensive house but",
    "they're in beverly hills",
    "so that's really imp impressive or",
    "it might be not as expensive of a house",
    "but they're in the midwest where i live",
    "and then a lower house value might be",
    "impressive",
    "so i did a contrast i took the",
    "average house value and the house valley",
    "combined them",
    "by taking house value minus average",
    "house value",
    "so if you're below the average that's",
    "going to be a negative number if you're",
    "above it's going to be a positive number",
    "and we're",
    "really looking at just how much you",
    "differ",
    "by the average house value in your area",
    "i don't want to put absolute values",
    "around that because",
    "it's important whether you're above or",
    "below",
    "that average that's part of what i'm",
    "tracking",
    "but then another thing you'll tend to",
    "notice in data is as",
    "people age they trade up they buy",
    "different houses",
    "not always but on average you'll have a",
    "bigger house",
    "as you are older maybe not bigger size",
    "wise but it'll cost more",
    "so that's why i then took the whole",
    "thing",
    "divided by age i'm now doing sort of a",
    "normalizer",
    "and the units are different here the",
    "houses i mean if i'm dealing in u.s",
    "dollars the houses will be i don't know",
    "100 200 300",
    "in that order of magnitude whereas the",
    "age is going to be",
    "100 and below or slightly above",
    "so that i squared the age",
    "to give it some size against",
    "the the house values that i were",
    "subtracting",
    "and this became a feature that i was",
    "then able to calculate",
    "i don't really care what this value is",
    "it's not like i'm looking at it like",
    "bmi's",
    "it's just another piece of information",
    "that i am giving the model along with",
    "all the other socioeconomic",
    "information and it lets the model",
    "then have less to otherwise the model",
    "has to figure out how to synthesize",
    "and create these formulas on its own",
    "it's",
    "information in a more pure form that the",
    "model can deal with",
    "models are inherently mathematical so do",
    "they really need",
    "us we humans to be doing this feature",
    "engineering",
    "for them well what i continue to read",
    "about in kaggle competitions they they",
    "tend to",
    "but this was something that interested",
    "me so i wanted",
    "to take a look at really what types of",
    "formulas would be better to be",
    "engineering for these models so i did a",
    "research paper a few years ago",
    "that i published it's also gotten a",
    "number of citations so it's",
    "been useful at least to somebody and",
    "what this",
    "what this paper looks at i'll probably",
    "do a video about it in the future",
    "is i took a bunch of different formula",
    "types",
    "took those 16 or so i believe",
    "and created data sets that",
    "had just random data and i looked at how",
    "well",
    "can these various models interpolate",
    "values so synthesize these equations i'm",
    "just",
    "asking them to pick values that are",
    "right in the range",
    "of the values that i gave these types of",
    "models don't typically extrapolate well",
    "so i didn't give them anything outside",
    "of those ranges",
    "and i looked at for neural networks",
    "random forest support vector machine",
    "and gradient boosting how well",
    "how low of errors did they really get",
    "synthesizing all these various equations",
    "and you can see the results here",
    "there are some real differences so the",
    "different model types",
    "are not always creating the best",
    "of models when",
    "this math is not performed for them",
    "thank you for watching this video i hope",
    "this was",
    "a good crash course in feature",
    "engineering at least the approach that i",
    "do when i'm doing it completely",
    "from hand i typically just look at my",
    "data see where",
    "my model is predicting very accurately",
    "and not so accurately and i just",
    "look at how can i engineer additional",
    "values that will really",
    "segregate those",
    "confusing rows that it's just not",
    "predicting that well on",
    "and maybe give it something that will",
    "give it a bit more lift it certainly has",
    "worked in a couple of the kaggles that",
    "i have worked on particularly for",
    "tabular data this doesn't work so well",
    "for",
    "image data because it's not like you're",
    "dividing one pixel by another pixel",
    "all right if you find this kind of thing",
    "interesting please subscribe to my",
    "youtube channel",
    "i'll be definitely talking about more",
    "things feature engineering because i",
    "find it to be a very fascinating topic"
  ],
  "keywords": [
    "eaten",
    "multiplying",
    "anything",
    "height",
    "assess",
    "magnitude",
    "even",
    "nothing",
    "variables",
    "calculations",
    "build",
    "captures",
    "hungry",
    "commonly",
    "best",
    "subscribe",
    "alone",
    "lego",
    "total",
    "model",
    "affluence",
    "multiply",
    "combined",
    "fast",
    "research",
    "differences",
    "machine",
    "distance",
    "forest",
    "augment",
    "compared",
    "thinking",
    "quite",
    "tend",
    "meeting",
    "divide",
    "find",
    "years",
    "along",
    "confusing",
    "hills",
    "kaggles",
    "ratios",
    "mass",
    "contrast",
    "ago",
    "absolute",
    "boost",
    "humans",
    "squaring",
    "midwest",
    "neural",
    "deal",
    "gradient",
    "houses",
    "bigger",
    "seven",
    "positive",
    "already",
    "cubing",
    "picking",
    "errors",
    "computer",
    "area",
    "powers",
    "side",
    "features",
    "multiple",
    "give",
    "extract",
    "worried",
    "multiplication",
    "meters",
    "examples",
    "minds",
    "simple",
    "given",
    "combine",
    "random",
    "need",
    "youtube",
    "intuition",
    "touted",
    "beverly",
    "negative",
    "value",
    "gives",
    "throw",
    "two",
    "thing",
    "recombine",
    "four",
    "data",
    "wanted",
    "lift",
    "couple",
    "bunch",
    "error",
    "street",
    "think",
    "world",
    "mathematical",
    "got",
    "comic",
    "modifiers",
    "one",
    "decreases",
    "person",
    "flat",
    "crazy",
    "results",
    "example",
    "course",
    "dividing",
    "age",
    "displacement",
    "feature",
    "whether",
    "talking",
    "well",
    "necessarily",
    "free",
    "walk",
    "wants",
    "engine",
    "many",
    "fourth",
    "radicals",
    "read",
    "understanding",
    "division",
    "block",
    "usually",
    "lets",
    "predict",
    "whereas",
    "test",
    "equation",
    "show",
    "cars",
    "tracking",
    "slightly",
    "decrease",
    "least",
    "something",
    "health",
    "big",
    "though",
    "video",
    "allude",
    "create",
    "trade",
    "take",
    "let",
    "using",
    "time",
    "quadrants",
    "relevance",
    "trumped",
    "really",
    "great",
    "add",
    "code",
    "corporate",
    "talk",
    "science",
    "types",
    "asking",
    "citations",
    "consumption",
    "throwing",
    "blocks",
    "product",
    "right",
    "equations",
    "legos",
    "inherently",
    "future",
    "older",
    "interested",
    "otherwise",
    "three",
    "property",
    "weigh",
    "number",
    "black",
    "index",
    "hand",
    "square",
    "amounts",
    "may",
    "look",
    "comics",
    "grasp",
    "width",
    "things",
    "models",
    "mind",
    "horsepower",
    "please",
    "sorta",
    "helps",
    "creating",
    "definitely",
    "range",
    "factorial",
    "also",
    "crash",
    "opposition",
    "cool",
    "dollars",
    "importance",
    "pretty",
    "part",
    "ground",
    "subtracting",
    "authorities",
    "watching",
    "reduce",
    "published",
    "go",
    "see",
    "bmi",
    "next",
    "simplifying",
    "want",
    "tells",
    "math",
    "good",
    "small",
    "hint",
    "hope",
    "took",
    "shows",
    "becomes",
    "put",
    "front",
    "enough",
    "additive",
    "continue",
    "thought",
    "values",
    "sure",
    "200",
    "seminar",
    "averages",
    "dealt",
    "channel",
    "gotten",
    "segregate",
    "phd",
    "always",
    "predicting",
    "quality",
    "cost",
    "tabular",
    "contrasting",
    "zip",
    "frame",
    "way",
    "get",
    "conference",
    "ninja",
    "back",
    "cases",
    "interpolate",
    "image",
    "feel",
    "relation",
    "adjustments",
    "dealing",
    "important",
    "ways",
    "thank",
    "still",
    "mean",
    "logarithm",
    "much",
    "300",
    "power",
    "bringing",
    "expensive",
    "case",
    "calculate",
    "factor",
    "pushing",
    "cubit",
    "root",
    "became",
    "people",
    "direction",
    "randomly",
    "addition",
    "subtraction",
    "network",
    "art",
    "third",
    "giving",
    "accurately",
    "100",
    "curve",
    "outside",
    "created",
    "say",
    "formulas",
    "team",
    "inputs",
    "another",
    "gave",
    "imp",
    "looked",
    "could",
    "effectively",
    "reduction",
    "performed",
    "figure",
    "90",
    "together",
    "train",
    "food",
    "house",
    "kaggle",
    "average",
    "able",
    "certainly",
    "sometimes",
    "appeal",
    "correlated",
    "pixel",
    "believe",
    "various",
    "lure",
    "actually",
    "size",
    "percent",
    "increase",
    "human",
    "better",
    "impressive",
    "new",
    "called",
    "masters",
    "core",
    "additional",
    "pure",
    "valley",
    "units",
    "less",
    "music",
    "networks",
    "use",
    "feet",
    "know",
    "basic",
    "baseline",
    "competitions",
    "typically",
    "potentially",
    "live",
    "matter",
    "away",
    "controls",
    "real",
    "us",
    "okay",
    "input",
    "tell",
    "make",
    "constant",
    "buying",
    "socioeconomic",
    "exploding",
    "grow",
    "interest",
    "ratio",
    "ranking",
    "interesting",
    "whole",
    "numbers",
    "top",
    "done",
    "around",
    "raise",
    "saying",
    "quantity",
    "final",
    "control",
    "combining",
    "used",
    "raising",
    "probably",
    "last",
    "like",
    "high",
    "medical",
    "formula",
    "length",
    "care",
    "particular",
    "would",
    "work",
    "sort",
    "looks",
    "far",
    "support",
    "propensity",
    "worked",
    "topic",
    "balls",
    "worry",
    "differ",
    "accuracy",
    "later",
    "tricks",
    "long",
    "taxing",
    "means",
    "engineer",
    "points",
    "set",
    "magic",
    "first",
    "minus",
    "synthesizing",
    "decide",
    "ranges",
    "based",
    "score",
    "pairs",
    "particularly",
    "lower",
    "send",
    "lazy",
    "higher",
    "order",
    "whatever",
    "going",
    "piece",
    "body",
    "heck",
    "attempting",
    "showing",
    "working",
    "radical",
    "pick",
    "taking",
    "might",
    "maybe",
    "divided",
    "fascinating",
    "wise",
    "vector",
    "trying",
    "similar",
    "feeding",
    "building",
    "notation",
    "large",
    "engineering",
    "boosting",
    "signify",
    "taxes",
    "rapidly",
    "kinds",
    "individual",
    "cartoon",
    "question",
    "synthesize",
    "times",
    "normalizer",
    "approach",
    "produce",
    "notice",
    "onto",
    "sets",
    "kind",
    "completely",
    "rather",
    "different",
    "often",
    "form",
    "low",
    "32",
    "information",
    "bit",
    "separately",
    "rows",
    "quadrant",
    "paper",
    "looking",
    "overwhelming",
    "useful",
    "16",
    "900",
    "amount",
    "compute",
    "scaling",
    "squared",
    "buy",
    "extrapolate",
    "somebody",
    "xg"
  ]
}