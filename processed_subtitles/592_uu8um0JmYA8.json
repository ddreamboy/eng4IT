{
  "text": "welcome to the module on feature\nengineering it is one of the most\nfascinating modules and aspects of the\nmachine learning Paradigm but before we\ndive into it and move ahead let's\nquickly take a look at what we've\ncovered so\nfar we used some data to build a machine\nlearning model where the model is\nbasically a function that tries to learn\nthe Rel relationship between the\ndependent variable and independent\nvariables for instance we covered the\nfollowing basic algorithms like K&N\nlinear regression logistic regression\nand decision tree and if you recall\nlinear regression is a function y is\nequal to Beta not + beta 1 X1 + beta 2\nX2 and so on where betas here are\nessentially the coefficients of variable\nsimilarly a decision tree is a\ncombination of multiple F statements\nwhere we've tried to find pure\nnodes here you might have noticed that\nI'm not talking about any coefficients\nbecause decision tree is a nonparametric\nalgorithm whereas linear regression is\nparametric note that all the methods\nwe've looked at so far were around\noptimizing the ml algorithms of finding\nthe optimum model but we have not\nmajorly worked on the data that we've\ngiven to the modu we've just used the\nexisting data and just train the model\non that we can add more data to the\nmodel so that it is able to make better\npredictions we can do this broadly in\ntwo ways first we can add new features\nor more information to the existing data\nfor example if you're trying to predict\nthe daily sales of a product let's say a\ncold drink in a college campus or our\noffice complex we've been given data for\npast sales and using that we need to\nestimate the sales for the next step 10\ndays in this case introducing a feature\nlike the list of holidays for the next\n10 days might help to estimate the sales\nmore correctly or how about having a\nvariable like the daily average\ntemperature because the sales of a cold\nring might vary from Winters to Summers\nEtc it will add more value to our model\nand will help us in estimating the sales\neffectively here you can see that the\naddition of these two variables is\nactually helping us to estimate the\nsales for the next 10 days another way\nto improve our models performance is by\nusing the existing data more effectively\nhere I'm saying that we can generate\nmore information or signal using the\nexisting features to predict the\nrelationship between independent\nvariables and the dependent variable\nsuppose you want to predict whether a\ncustomer will be able to pay a loan or\nnot and we have the details of the\ncustomer like the birth year gender\nsalary income Etc so let's take\napplication date and birth year these\nthese two features can help us generate\nthe age of the customer this new\nvariable age might impact the\nperformance of the model and we'll be\nable to estimate the default ratio of\ncustomer\nright we can also use the income\nvariable to generate a brand new\nvariable currently income is a\ncontinuous variable and we can divide\nthe income into categories or you can\nsay different bands for example low\nincome band High income average and so\non so in this case we've seen that we\ncan use existing variables to generate\nnew variables like age and income band\nthis technique of generating new\nfeatures using existing features is\ncalled feature engineering let's now put\na formal definition to feature\nengineering feature engineering is the\nscience of extracting more information\nfrom existing data we not adding any new\ndata here but we're actually making the\ndata we already have more useful with\nrespect to the problem at\nhand I've said that with respect to\nproblem at hand so having a fair\nknowledge of the domain will always help\nus to build better features so I'll\nrecommend understanding the problem\nstatement and the domain well enough as\nthis will help us to build better and\nrelevant features in this module we will\nlook at various feature engineering\nmethods for different type of data sets\nlike date time continuous categorical\ntext and others\nhere is a small but very interesting\nexercise for you on this slide we have a\nsubset of the two data sets that we've\nbeen using so far Titanic survival\nprediction and bigm sales now I want you\nto take a while and think about what new\nfeatures you can create from the given\nset of features for respective problem\nstatements in the next section we've\nshared the problem statement and data\ndictionary again for both these problems\nso please go through it and share the\nlist of features on the discussion\nportal it's a very interesting exercise\nand will help you understand what\nfeature engineering is and how it\nworks I hope you have a good\nunderstanding of the term feature\nengineering at this point now before we\nlook at the different techniques we can\nuse for feature engineering let's\nquickly look at some basic features we\ncan create with the examples you saw\nbefore here is the bigm sales data set\nyou can see that we have a feature item\nidentifier it's the First Column here it\nhas a large number of unique categories\nif you look at the original data set\nthis data set is a few sample records\nbut even here you can see that all the\ncategories or all the rows are\nunique but if we explore the entire data\nset the first two characters in all\nthese categories seem to have three\nunique categories it's either FD Dr FD\nagain NC and after this it's all FD now\nlook at the item type against them NC is\nagainst household Dr is against soft\ndrinks and FD seems to be against food\nitems like Dairy meat snack foods frozen\nfoods Etc so we can conclude that FD Dr\nand NC represent food drink and\nnon-consumable respectively using this\ninformation we can have a new column\nhaving values like FD Dr and NC only and\nthis might help us to build better\nmodels let's look at another data set\nlet me pull up the Titanic\none this data set also has a lot of\nvariables again as I mentioned before\nyou should read the problem statement\nand the data dictionary well before\nstarting the model building process this\nwill help you to think of new features\nyou can generate so if you've gone\nthrough the feature description of this\nTitanic data set you would know that the\ntwo variables sib SP and Par represent\nthe count of siblings or spouse and\nparents or child on board using this\ninformation we can generate the total\nnumber of family members on board we can\nadd these two values sib SP plus p + 1\nwhere one is for that observation or\nperson there's another feature I want to\ndiscuss the name it's a text field if\nyou look closely at the name column\nyou'll see a title with each name like\nMr Mrs Miss there's a master as well\nthese titles can be useful features in\nmaking predictions because these titles\nin a way represent the age bracket of\npassengers this might help us to impute\nmissing values in the age column as well\nsimilarly we can create many more\nfeatures using the given data now let's\nlook at what we'll be covering in this\nmodule you've seen a few examples of the\nproblem statements in the data set like\nthe Titanic and the bigm sales here we\nhad some numerical features categorical\nfeatures and some text or string based\nfeatures as well these are the most\ncommon variable types we usually find\nourselves working with another type of\nfeature that we might encounter is the\ndate time column we learn how to deal\nwith all these features in this module\nor in other words how can we generate\nmore signal from a given data set for\nnow we'll turn our Focus to numerical\nand categorical\nvariables in this video we'll discuss\nabout the different methods of feature\nengineering we can broadly divide\nfeature engineering into two categories\nfeature pre-processing and feature\ngeneration let me briefly Define these\ntwo\nsubcategories feature processing refers\nto changing updating or transforming the\nexisting features in this case we not\ncreating any new features but making the\nsame features more informative we'll\ntalk about different feature\npre-processing methods in the later part\nof this\nvideo the other category is feature\ngeneration this is where we generate new\nfeatures from the existing\nfeatures but then how is feature\npre-processing different from feature\nGeneration Well feature generation\nrefers to creating new features from the\nexisting data and not simply transform\nforming the values of existing features\nfor example in the Titanic data set that\nwe saw we've created family size and\nextracted title from the name these are\nexamples of feature generation let's\nlook at each of these categories in more\ndetails specific to numerical and\ncategorical\nvariables let's start with feature\npre-processing there are various methods\nto perform feature pre-processing and we\nlook at them one by one the first method\nwe look at is called feature\ntransformation feature transformation as\nthe name suggests is a method used to\ntransform the\nfeatures using mathematical operations\nfor example for a given feature value\nyou can take the log of the value square\nit or take a square root take reciprocal\nand so on but I'm sure you're wondering\nwhy is this important and how can we\ndecide when to use which technique well\nit varies from case to case for example\nlook at this plot it shows a\nrelationship between a Target variable\nand a feature this shows that the\nrelationship is\nnonlinear and we know that for some\nmodels like linear regression it's good\nto have a linear relationship between\nthe dependent and the independent\nvariables so in this case we should\ntransform a variable in a way such that\nthe relationship between the target\nvariable and the feature becomes\nlinear so this method is very model\nspecific let's look at another case\nwhere feature transformation will help\nus to model\nbetter take this plot for instance this\nrepresents a right skewed or positively\nskewed distribution this could be due to\nthe presence of some outliers in the\ndata having a normal distribution is\npreferred of a skewed distribution\nbecause it makes things easier it makes\nit easier to model the\nrelationships also some modeling\ntechniques perform well when we have a\nnormal distribution of variables so\nwhenever we have a skewed distribution\nwe can use Transformations which reduce\nthe\nskewness now note that for right skewed\nor positively skewed distribution we\ntake the square or cube root or log of\nvariable and you can call that the nth\nroot as well and for left skewed or\nnegative skewed we take Square Cube or\nexponential of variables this is called\nfeature transformation\nnow there's one more thing you should\nnote if we taking a log of the variable\nthat has a negative value or a value of\nzero it might show an error can you\nguess\nwhy it's because the log of0 is not\ndefined so instead you can use a simple\ntrick and take\nlog of x + C where C is a\nconstant the objective is that the input\nof the log must be greater than Zer\nright now let's go ahead and look at an\nimplementation of future transformation\nin\nPython in this notebook we'll be\nimplementing feature transformation on\nthe bigm sales\ndata so let's start with importing the\nlibraries and of course loading the data\nset so let's go ahead and do that we've\nrigorously worked with this data set in\nthe last modules and I'm sure you'll be\nfamiliar with all the features by\nnow so here are all the columns in the\ndata set the continuous variables among\nthese are the item weight item\nvisibility and item MRP I'm going to go\nup and I'm going to take up the item\nvisibility variable here you can try the\nsame exercise with other variable so\nlet's go ahead and look at the\ndistribution of the item visibility\nfeature so here we go here's the\ndistribution plot or the histogram plot\nfor the feature as you can see this is a\nright skew\ndistribution let's take a square root of\nthis and check the distribution\nagain so we'll create another variable\nitem visibility square root that will\nstore the square root value of this\nvariable here I'm using the np. sqrt\nfunction to calculate the square root\nvalue so I'm going to go ahead and\nImplement that and look at the\ndistribution\nagain this distribution looks more\nsymmetric we can also see that there are\na large number of values which have\nvisibility zero here so we'll need to\ndeal with them\nseparately now as you've discussed\npreviously we can either take the root\nor the log in case of a right skew\ndistribution so let's go ahead and use\nthe log function now\nhere's another variable we creating\ncalled item visibility log that will\nstore the log values for the item\nvisibility\nfeature now when I run this I get a\nwarning can you guess why that is here's\nthe warning that we're\ngetting well look at the variable\ndistribution so let me go ahead and run\nthis as you can see we have a minimum\nvalue of zero at least one value I'm\nsure there could be more\nbut the log of 0 is not defined that is\nwhy we getting an\nerror one way to deal with this is that\nwe can simply add a constant to every\nvalue in the\nvariable here I'm going to go ahead and\nadd\n0.1 and when we see the distribution\nagain look at this plot we have mostly\nnegative\nvalues and the distribution is not\nexactly perfectly\nnormal this is because the values in the\ncolumn are less than\none let's increase the scale of the\nvalues and keep in mind that increasing\nthe scale will not affect the\ndistribution at\nall here I've multiplied all the values\nwith 100 so let's go ahead and run this\ncode so the new range of values have\nchanged from 0 to 0.3 to 0 to\n30 I'm going to go ahead and use the log\ntransformation\nagain and just plot it out this plot is\na normal distribution and the values as\nyou can see here are also\npositive now let's move to another\nmethod of Feature pre-processing Feature\nscaling take a look at this data set it\nis related to loan applications here we\nhave variables like loan amount Emi\nand the income and these are all in\ndifferent units if you'll notice so loan\namount is in thousands income is in\nhundreds and Emi is in dollars only and\nwe've discussed that for distance-based\nalgorithms like KNN features should be\nin the same scale else we'll get\nambiguous results and that's not what we\nwant in this case we need to perform\nscaling with features either scale up or\ndown to bring all the features to the\nsame\nscale the two most common ways of doing\nfeature scaling are min max scaler and\nstandard scaler let's first talk about\nminmax\nscaling in this method we first\ndetermine the minimum and maximum value\nin the\ncolumn then for each value we first\nsubtract minimum value from\nit and then divide by the difference of\nMaximum and minimum value of the feature\nwhich is range\nthe minmax scaler scales down the value\nof the feature between 0 and 1 you can\ncheck that yourself if you\nwant now if you\nreplace XI with a minimum value the\nnumerator will of course become zero\nright and when you replace it with a\nmaximum value both the numerator and\ndenominator will cancel themselves and\nthe ratio becomes one here you can see\nin the second table all values of these\nthree features are now in the range of 0\nto 1 one after applying min max\nscaling now let's look at the second\nmethod called standard\nscaling in this method we first\ndetermine the mean and standard\ndeviation of the column then for each\nvalue we first subtract the mean from\nthe value and divide it by the standard\ndeviation let's apply this on the same\nexample here you can see that all values\nof these three features are now at\nsimilar\nscale let's do one thing let's Implement\nwhat we have learned so far in\nPython in this video we'll go through\nsome feature scaling methods let's go\nahead and import the libraries pandas\nand numpy and we'll read the big Mar\nsales data set now we going to focus on\ntwo features item visibility and item\nMRP as you can see there's a huge\ndifference between these\nvalues so let's bring these features to\nthe same\nscale we are going to work with the min\nmax scaler here it scales down the\nvalues between 0 and 1 you can see the\nformula here but we don't have to use\nthis we'll rely on python to do it for\nus but it's always good to know and\nunderstand what's going on underneath\nthe code that's where the formula\nhelps so let's first import the minmax\nscaler from the SK learn. preprocessing\nLibrary perfect now we'll create an\ninstance called\nscaler which will'll apply on the data\nwhich stor the two variables item\nvisibility and MRP as you can see here\nand we're going to store this in a new\ndata frame called scaled uncore data\nlet's print out the first few rows as\nyou can see here the variables now have\nthe same range perfect now I'm going to\nuse the do describe\nfunction to see the minimum value for\nboth the\nvariables as you can see it's zero the\nmaximum is one perfect our minmax scaler\nworked exactly as we hoped it\nwould let's try scaling these variables\nusing the standard\nscalar we'll pick the same two\nvariables and we'll first import\nstandard scaler from the SK scalar\npre-processing Library let me do that\nnow we'll create an instance called\nscaler and fit it on the\ndata again we'll store it in a new data\nframe called scale data and let me print\nout the\nresults\ninteresting as you can see here the mean\nis close to zero and the standard\ndeviation is one so these are the two\nmethods very popular methods that we can\nuse to scale our\ndata we've covered some pre-processing\ntechniques for continuous variables so\nfar let's move ahead to the feature\npre-processing techniques for\ncategorical variables we'll start with a\nvery popular one one hot encoding it's\noften also called as dummy\nencoding remember this data set it's\nfrom the bigm sales problem we have\nthree categorical variables highlighted\nin the red here note that most machine\nlearning models cannot deal with\ncategorical variables especially in\npython when we use pyit learn so we need\nto convert these categorical variables\ninto numeric\nvalues let's pick the outlet size for\nnow Outlet size column we can replace\nthis Outlet size column with three\ncolumns Outlet medium Outlet small and\nOutlet\nhigh now the first row has the outlet\nsize medium so we put one in the size\nmedium column as you can see here and\nzero in the other two columns similar\nsimilarly we will perform this step for\nthe rest of the rows against respective\nOutlet size here you can see for item\nidentify NCD 19 the outlet size is\npretty high so we have one in the size\nHigh column and zero in the remaining\ntwo columns the same method can be\napplied for the other categorical\nvariables in our data set like the item\ntype and the item fat content but just\nhold on there is a problem with this\ntype of encoding the item type does not\nhave an order as you can see it just say\nnames of items like dairies soft drinks\nmeat and we can't really say that\nthere's an order to them but the\ncategories in Outlet size and the fat\ncontent do have an order out size small\nmedium and high have an order in them\nright and by using one hard encoding we\nare actually losing this\ninformation such variables which have an\norder between them are called ordinal\nvariables in this case instead of\ncreating three different columns we'll\njust replace the categories in the same\ncolumn by numbers as you can see in this\nexample we have numbers 1 2 and three\nfor small medium and high respectively\none for small two for medium and three\nfor high in this way we actually\npreserving the order information of the\nvariable as well along with encoding in\nnumbers so let's go and open our jupter\nnotebook and try these techniques one\nhot encoding and label\nencoding in this notebook we'll\nimplement the concepts of one hot\nencoding and label encoding on the bigm\nsales data set of course you know what\nthe first steps are we'll import the\nPanda's library and we'll read in the\nbigm sales data set let me just bring up\nthe first five rows here we go we very\nfamiliar with these variables by now\nwe've looked at them plenty of times\nbefore so let's just check the shape\nperfect we have 8500 plus rows and we\nworking with 12 Columns of\nvariables let's use a do D types\nfunction to bring up the data\ntypes so the categorical variables here\nwe can see they have the data type as\nobject all of these are the categorical\nvariables and we need to convert these\ncategorical variables into numbers\nbefore we train a machine learning\nmodel so let's start by encoding a\nsingle variable Outlet\ntype we can determine the total number\nof categories in this variable using the\ndot value uncore counts function and as\nyou can see in this output we have four\ncategories we have Supermarket type 1\ngrocery store Supermarket type 3 and\nSupermarket type 2\nperfect now let's use one hot encoding\non this performing one hot encoding is\nactually very simple in\nPython all we have to do is use the\npandas getor dummies function so in this\ncode block I've applied this getor\ndummies function on the outlet uncore\ntype\nvariable and as you can see in this\noutput We have replaced one column with\nfour columns which have binary\nvalues since the first row had the\ncategory Supermarket type one we have\none in that column and all the other\ncolumns have\nzero similarly for the second row we\nhave one under the column so Market type\n2 and zero in the rest and so\non but you might be wondering if there\nare 10 20 such variables do we have to\nwrite this code line for every single\none of them well no you can simply use\nget dummies on the whole data set\ntogether so let me go ahead and do\nthat\nperfect we can use the pd. getor dummies\nfunction and give the data set name like\nwe've done here it will automatically\nselect the categorical variables and\nperform one hot encoding now we faced\nwith two problems since we've used one\nhard encoding here first is that all the\ncategorical variables are converted into\nzero and one which results in a loss of\nsome important\ninformation for example the variable\nOutlet size had categories high medium\nand small right which of course have an\ninherent order\nbut now look at what's happened when\nwe've done this we missing out on some\nvery important information because the\norder between these variables has now\nbeen\ndestroyed the second problem is that the\nnumber of features have drastically\nincreased from just 12 to 1,600 plus\nlet's see the shape you can clearly see\nwe have 165 variable that is a humongous\namount and if we look closely the\nvariable item identifier has a number of\nof unique values it's essentially like\nan ID variable and hence there are more\nthan 90% of the rowes which have a zero\nagainst them look at this so this\ninformation is not really useful for the\nmodel in this notebook we will address\nthe first problem and we look at the\nsolution to the second problem in an\nupcoming video so to maintain the order\namong the categories and variables\ninstead of using one not encoding we'll\ngo for label encoding so let's go ahead\nand do that we'll import the labor\nencoder class from SK learn.\npreprocessing let me look at the value\ncounts in the outlet size variable\nperfect we have medium small and high\nand we have the value counts in front of\nthem now we'll create an instance called\nLe and use the fitore transform function\nfrom the label encoder class it will\ntransform small as two medium as one and\nhigh is zero now the problem here is\nthat label encoder considers the\nalphabetical order to assign values that\nmight not be what we're looking for\nevery time if we need an alternative\nsolution to this where we can decide the\nnumber we want to assign for each\ncategory manually then we can use the\ndot map function here's the example\nmention the variable name which you've\ndone here Outlet size then we'll use a\nDOT map function and write the number\nagainst each category here I'm assigning\n0er to small 1 to medium two to high so\nlet me just run that perfect so that SS\nthe first challenge that we've\nencountered in one hard\nencoding so far we were dealing with\ncategorical variables having less number\nof categories now imagine if your data\nset has a categorical column with a 100\ndifferent categories and it quite often\ndoes happen in the industry do you think\none encoding is a good idea not\nreally for example here we have a sample\ndata set with a column sit\nimagine if this column has 500 unique\nCities Performing one hot encoding will\ncreate 5 100 different variables with\nzero and one value that's going to be an\nabsolute nightmare to deal with so what\ncan we\ndo well here's the trick we can combine\nsparse classes but wait what are sparse\nclasses classes with relatively low\nfrequency are known as SP classes here's\nthe value count for different\ncities cities having very low frequency\nlike ghati rur and indor are less\nfrequent in the data set compared to\nother cities in the data since these\ncities have a very low frequency we can\ncombine these cities under a new\ncategory other to reduce the number of\nunique\ncategories and this will not explode the\ndimensionality of the data set as\nwell so to reduce this number of\ncategories we can simply combine a few\ncategories and hence reduce the overall\nnumber of classes for the variable based\non the frequency count of\nvariable there can be different ways of\ncombining as well if you have that\ndomain knowledge for example in this\ncase I can combine similar cities\ntogether and similarity can be\nGeographic based or type of City based\nlike Tier 1 tier 2 tier 3 and also\ncreate a region variable which is one\nlevel up in the geographical hierarchy\nbut this is only doable if you have the\ngeographical\ninformation let's go ahead and look at\nan example in Python we'll continue\nworking on the same notebook which we\nsaw in the last video so here we used\nthe bigm sales data\nset and we looked at what are the\ndifferent categorical columns we first\nused one hot encoding on the whole data\nset and discussed that we essentially\nhave two problems that we're working\nwith some variables might have an\ninherent order that was the first\nproblem and the second was that the size\nhas increased drastically remember we\nstarted off with 12 variables but after\nusing one not encoding we ended up with\nover\n1600 to solve the first problem we use\nthe label encoding method and now we can\nlook at dealing with high cardinality or\nthe high number of Dimensions to do this\nwe'll be reducing the number of\ncategories so let's first see which\nvariable has the highest number of\nunique categories we can do this using\nthe Dot N unique functions out of all\nthe categorical variables item\nidentifier has the maximum number of\nunique values now this might be because\neach store has given a certain number or\nidentifier to each individual item let's\nlook at the value count for this\nvariable the maximum frequency is 10 and\nactually there are many values which\noccur just once or twice\nso what we'll do is we're going to\ncombine these low frequency classes so\nwe'll first store the frequency count of\nthe variable in temp and let me print\nout the first few rows okay here we go\nnow we'll create a new column in the\ndata frame item identifier count which\nwill store the value count for each\ncategory we'll do this with the help of\nthe apply function the apply function\nperforms a given task for every Row in\nthe data frame so so here I've used the\napply function on the item identifier\ncolumn for each category in the item\nidentifier it will return the frequency\nfrom the temp that we created here so\nlet me go ahead and run that and\nfinally we want to combine the sparse\nclasses so for all the categories which\nhave frequency less than four I've\nreplaced the category with other so let\nme run this for Loop it might take a\ncouple of moments so\nlet's just uh wait for this to\nrun all right now let's look at the\nfirst seven rows perfect now when we\nlook at the value counts we'll see that\nthe least values we can see is four so\nthe one and two values we saw earlier\nhave now been combined all right so we\nhave so far covered numerous methods to\nperform feature\npre-processing in this video we'll\ndiscuss the different methods for\nfeature\ngeneration feature generation\nessentially means creating new features\nfrom existing\ndata let's take an example to understand\nthis suppose our problem statement is of\nstroke prediction and we given this data\nset you can see that we have features\nlike the person's\nage we have gender work type\nhypertension\nEtc and based on these featur we have to\npredict whether the person will have a\nstroke or not which is essentially this\ncolumn the target variable now let's\nlook at the relationship between the\nindependent variables and the dependent\nvariable first we have the age of the\nperson it's more likely that adults will\nhave a stroke rather than kids so we can\ncreate bins using this age column such\nthat we classify adults in one bin and\nyoung people in the other now this can\nbe done in various ways the simplest\nmethod thir is the one we just discussed\nwhere we set a cut off at a value say 35\nand create two bins the rows which have\nage greater than 35 will be marked one\nand others will be zero so here we've\ncreated two bins we can generate\nmultiple bins in a similar\nmanner for example set age 0 to 12 in\none bin 12 20 in another and so on in\nthis case we will have a new variable\nwhich will be categorical or you can\neven say it'll be ordinal in\nnature look at the example shown here we\nhave four categories child teenager\nadult and senior citizen since the\nvariable here is age we were easily able\nto decide the range values based on our\nexperience this cut off value or\nthreshold value can also be decided\nusing a simple decision\ntree they have built a tree using age as\nthe only feature and stroke as my target\nvariable the decision tree decides the\nbest split of age such that it is able\nto classify that person will have a\nstroke or not here we have threshold\nvalues as\n49.5 66.5 and\n77.5 you can see here the first\nsplit has happened on\n66.5 then in the left branch of the\ndecision tree the split has happened on\n49.5 and for the right Branch it is\n77.5 and we can now generate bins\naccordingly look at the bins again we\nhave on this slide here are the cut off\nvalues obtained using a decision tree\nmodel we saw in the previous\nslide let let me bring up another\nexample of\nbinning in this data set we have BMI\nvalues for each person which as you can\nsee are in\ndecimals here we can round of the\ndecimal values for example 17.6 here and\n17.7 which will both become 17 in a way\nwe're creating bins at a whole number\nlevel right let's now move to the python\nnotebook and take a quick look at the\nimplementation of binning in\nPython let's implement this concept I'll\ngo ahead and import the pandas library\nand we'll be working with the same\nstroke prediction data set that we saw\nin the video\nso we have all sorts of variables here\nwe have the age gender\nhypertension heart disease if the person\nwas ever married or not work type\nresidence type all sorts of things and\nof course we have the final uh Target\nvariable\nstroke so what I'll do here is I'll use\nthe age variable to create\nbins we'll first store the range for\neach category here in the bins\nvariable and this will be in the form of\nof a list these are basically the bin\nedges or the lower and upper values of\nthe range then we'll store the names\nwhich we want to give these ranges as\nyou can see I've given the following\nlabels child teenager young adult\nmiddle-aged and senior citizen and\nstored it in a group list in a list\ncalled\ngroup finally we've created a new\nvariable age uncore category and we use\nthe pd. cut function to bend The\nContinuous values into\ncategories we give the variable age as\ninput and along with that we specified\nthe bin edges and the labels or the\nnames for each group so I'm going to go\nahead and run this code block and let's\nlook at the first five rows perfect as\nyou can see here our binning strategy\nhas worked out\nperfectly first row has age three and\nhas been categorized as a child the\nThird eight again a child age 58 falls\ninto the middle-aged category 17 into\nsenior citizen and 14 as a teenager\nperfect now the same can be done using\nthe bin edges from a decision\ntree we'll create a new list storing the\nnew bin edges as you can see in this\ncode block and the rest of the steps\nwill be the same that we saw earlier we\ncreate a list group that will store the\nlabels we saying B bin 1 bin 2 bin 3 and\nBin 4 here and again we're creating a\nnew variable agore category using the\npd. cut\nfunction to bend the continuous values\ninto\ncategories by giving the variable age as\ninput along with that we specify the bin\nedges and again the labels of the names\nfor each group I'll go ahead and\nimplement this and as you can see our\nbinning strategy yet again has come up\ntrumps the first row which had age three\nfor the person is in bin 1 58 is in bin\n2 8 is in bin 1 17 bin 3 14 again in bin\n1 so I hope you got a sense of how\nbinning works and how we can implement\nit in Python very interesting wasn't\nit all the examples that we' have\ndiscussed so far we're using a single\nvariable let's look at some examples of\nhow we can use more than one variable to\ngenerate new features because that's\nessentially what you'll face in the\nindustry or even when you're competing\nin a data science\ncompetition here we have the loan\nprediction data set the target variable\nis the last column here and we have to\ndetermine whether a loan should be given\nto the person based on the person's\nincome education property area\nEtc now look at these two variables the\napplicant income and the co- applicant\nin adding up these two values will give\nus the total earning of the family which\nas you can imagine could very well be an\nimportant factor in deciding whether a\nloan should be granted or\nnot since we have constructed a new\nfeature which represents the interaction\nof these two features this is called\nfeature\ninteraction similarly we can construct\nother mathematical features like taking\nthe ratio of loan amount and applicant\nincome or the ratio of loan amount and\ntotal income the idea is that if a\nperson a group with a high loan amount\nand low income might have higher chances\nof defaulting here again having some\ndomain knowledge will help you to think\nabout these features moreover we can use\nthe difference of income and loan amount\nas well and so on it's not necessary\nthat we use only two variables you can\ngo ahead and play around with multiple\nvariables as\nwell in this notebook we going to go\nahead and Implement what we have just\nlearned\nI'll import the Panda's Library first\nread the data set and look at the first\nfive rows of our Loan Data set and here\nwe go now after we load the data set we\nneed to go through every feature and\nunderstand what each of these features\nmean and try to identify the interaction\nof which feature would be useful for the\nmodel so I've taken two examples for you\nin this\nnotebook first since we trying to\npredict if a person should be given a\nloan or not apart from the person's own\nincome the income of the spouse could\npotentially be an important\nfactor in our data set we have two\nfeatures applicant income and the co-\napplicant income which you can see here\nwe can add these two to get the total in\nso I'm going to go ahead and do that and\nprint out the first five rows here we go\nyou can add this up and it's perfectly\nvisible in the total underscore income\ncolumn awesome we can create another\nfeature the loan income ratio here we\ndividing the loan amount by the\napplicant income so let me go ahead and\ndo that perfect and we have the loan\nincome ratio in this column and we've\njust created an entirely new\nfeature don't you just love feature\nengineering it's one of the most awesome\naspects of a data scientist role in the\nsame manner that we have seen here I\nwould encourage you to go ahead take up\nthis data set and think of whatever\nfeatures you can come up with there are\nmultiple ones I can guarantee you you\ncan if you just spend 10 minutes\nwondering which features you can create\nyou can come up with at least 20 25 new\nones in this video we'll generate\nfeatures based on available missing\nvalues let's say that we're doing data\nexploration in a data set and and we\nfind that the column smoking uncore\nstatus has a large number of missing\nvalues now our first intuition might be\nto delete this column but missing values\nin the data might have a\npattern and in fact quite a lot of times\ntend to be useful for instance in this\ncase a missing value in that column\nmight indicate that a person does smoke\nbut is actually reluctant to say so I\nmean I'm sure a lot of us can relate to\nthis\nhence we can create a separate column\nthat indicates whether this row has a\nmissing value or not there might be a\nchance that the missing value is not\nrandom at all and there is some hidden\ninformation then this variable will\ncapture that\ninformation you can see here that I have\ncreated a column called smoking uncore\nstatus\nn it has one in a place where smoking\nstatus is missing after this you can\nimpute the missing values like always\nso let's move to the jupyter notebook\nand implement this method we're going to\nuse the stroke prediction data set again\nI'm going to go ahead and import the\nlibraries and uh load the data\nset here the first fire rows we've\nalready looked at this before so what\nI'm going to do is I'm going to use the\ndo isal do su functions to look at the\nnumber of missing values in each\nvariable here we go as you can see the\nBMI and the smoking status variables\nhave a ton of missing value especially\nthe smoking status here so what I'll do\nis in the next CoD line here we are\ncreating a new variable smoking status\nNE which will store one if there's a\nmissing value and zero if there are no\nmissing values I'll go ahead and\nimplement it and look at the first five\nrows of these two\nvariables\nperfect so one remember was when there\nwas a missing value and the smoking\nstatus confirms that yes there is indeed\na missing value here zero means there\nare no missing values which again we can\nconfirm against the smoking status\nvariable and that is how we can create\nnew features using missing values pretty\nintuitive and straightforward wasn't\nit in this video we'll cover another\nvery commonly used feature generation\nmethod called frequency encoding for\ncategorical variables it's often used in\ndata science competitions and has proved\nto work really well it's even helped me\nout quite a lot of times so let's\nunderstand what it\nis here we have a categorical variable\nworkor type now we can determine the\nfrequency of the categories in this\nvariable and normalize the\nvalues the idea essentially is that a\ncategory that has a higher frequency\nwould of course have a higher number\nagainst it and and hence will get more\nimportance for example suppose there's\nan insurance company and they have\nvarious products but they've not given\ninformation about the most selling\nproduct or so in this case frequency\ncount will help us to give this implicit\ninformation to model using frequency\nencoding let me just do this in Python\nto give you a better idea of how\nfrequency encoding works\nlet's spend some time understanding how\nwe can Implement frequency en coding in\nPython so I'm going to import the\nPanda's Library first and let's go to\nthe bigm sales data\nagain here we have a variable item type\nas you can see in this column and I'm\ngoing to apply frequency encoding on\nthis\nvariable now when we look at the\nfrequency of categories in this variable\nyou can clearly see that fruits and\nvegetables here\nhave the highest frequency followed by\nsnack foods so I'm going to go ahead and\nstore the item type count in a variable\ncalled\ntemp here we go\nperfect now we'll create a new variable\nitem type count using the dot apply\nfunction the apply function works like\nthis and you've seen this before it will\ncheck the item type for every single row\nand against the given category of item\ntype it'll return the frequency value\nfrom the temp variable we've just\ncreated so I'm going to go ahead and run\nthis perfect so we've got the item type\ncount against the item type so DA has\n682 instances meet has 425 and so on\nlike we performed frequency encoding\nhere there's another commonly used\nmethod it's called mean encoding and\nthis is often done using the target\nvariable again we have the item type\nvariable and we're going to use the\ntarget variable\nsales so let me just print out the first\nfive rows here we go so now against each\ncategory in item type we can calculate\nthe mean sales in the training\ndata here we go this shows us which\nvariable or which item type has the\nhighest sales it's a brilliant way of\nunderstanding the different item types\nyou have what Revenue they're bringing\nin and not only have we just created a\nnew feature we can now analyze a lot of\nthe things that we have in the bigart\nsales data set using just this\nfunction we've covered feature\nengineering with numerical and\ncategorical variable so far in this\nvideo we'll be focusing on the datetime\nvariable and we learn how to generate\nmore information from a datetime column\nit's a very interesting\nconcept can you think of a few examp\nexamples where we'll find a Time\nvariable in our data set here are a few\nof the top of my head suppose a\nparticular hotel is collecting the data\nof the past bookings and they want to\npredict the number of room bookings For\nan upcoming\nmonth a data set for this problem\nstatement would have features like the\nbooking ID booking date the time of the\nbooking what kind of room was booked the\nnumber of days and nights it was booked\nfor the number of people who stayed in\nthe room Etc I mean there are are a lot\nof variables that can factor in so here\nwe have two datetime features booking\ndate and booking time another example is\nof predicting the price of flight for a\nparticular Airline as you can imagine\nthe price would be higher during the\ntime of vacation or during the weekend\nwhile it should be lower during non\nholiday seasons what are the possible\nfactors that can affect the price of a\nflight ticket here are a few I could\ncome up with the time of arrival and\ndeparture of the flight or the source\nand destination also the date of travel\nis off season or a holiday season also\ncan be an important factor we have three\ndatetime based features date of travel\ntime of arrival and\ndeparture note that using the time of\ndeparture and time of arrival you can\ndetermine the travel duration of the\nflight as\nwell another example and a very common\none could be of stock market analysis\nwhere having the date of course is of\nutmost\nimportance using the date we can find if\nthere is any pattern in the increase and\ndecrease of the price for instance is\nthe closing price more on Mondays and\nlow on Fridays or vice\nversa well now that we understand that\nthere are number of problems where we\ncan have the datetime feature let's see\nwhat valuable information we can extract\nfrom these datetime VAR\ntabls using the date we can determine\nwhich day of the week it is is it a\nMonday is it a Wednesday and so on we\ncan also find out if the day is a\nweekday or a\nweekend any guess why this information\nwould be\nimportant well recall the example of the\nflight ticket price we discussed just a\nfew moments ago the ticket price would\nbe considerably higher on weekends than\non weekdays so do you see where this\nfifth in we can also determine if the\nday is a national holiday or not simply\nby looking at the date feature this\nagain would be useful when we work on\nproblems like predicting the flight\nprice or the number of bookings for a\nhotel using the date we can also extract\nthe month for example flight ticket\nprice might be higher in December since\nit's close to\nChristmas a summer vacations fall in\nJune and the number of room bookings in\na hotel during that month could see a\nsignificant\nrise similarly we can determine the year\nfrom a given date for instance from a\ngiven data of the past five or say 10\nyears the recent values would usually be\ngiven more\nimportance now considering the time\nfeature we can determine the r from the\ntime\nvariable how will this be\nuseful well the price of flight tickets\nat odd hours like 1 a.m. or so are\nusually significantly lower and once you\nhave the r value we can create more\nfeatures like is it morning is it\nafternoon evening is it midnight for\ninstance if you're trying to predict the\nsales of a product in a retail outlet it\nwould be more during the peak hours\nright in the same way we can determine\nif it is the first or second half of the\nday we can also calculate the difference\nbetween time like calculating the light\nduration and the same goes with dates\ncalculating the days of stay in a hotel\nor calculating the age of a person using\nthe date of birth and today's date or\nthe date Hoshi applied for a loan\napplication or Insurance there can be a\nlot more features that you can create\nusing the date variable apart from the\nfeatures that we've discussed you can\nsee a lot of additional features here\nsuch as the day of the week the day of\nthe year what week of the year it is I\nmean there are a lot of variables here\nis a table that shows a list of features\nwe can extract from a datetime column\nwe've taken this from the Panda's\ndocumentation and we've shared the link\njust after this video so apart from the\nfeatures that we've already discussed\nyou can see a lot more features here\nlike the day of the year the week of the\nyear which essentially represent the day\nnumber out of 365 and week number out of\n52 total weeks in the year\nusing the date we can also find out its\nmonth start month end quarter start\nquarter end same for year or is it a\nleap year or not and so you can see the\nsheer amount of insight we can\ngenerate now let's look at an\nexample we have to predict the amount of\nNO2 nitrogen dioxide in the air at a\ngiven day and time how can we use the\ndate and time variable here I want you\nto pause the video and just think about\nit for a second before you\nproceed NO2 primarily gets in the air\nfrom the burning of\nfuel NO2 forms through emissions from\ncars trucks buses power plants and offro\nequipment so intuitively a higher amount\nwe should expect to see in the morning\nbetween say 7: to 10:00 a.m. and in the\nevening between 5: to 8:00 p.m. when\npeople generally travel from office to\nwork and vice versa\nalso during the afternoon NO2 reacts\nwith sunlight to form no o and O but\nduring the night this reaction does not\ntake\nplace let's do one thing let's jump into\na jupyter notebook and spend a few\nmoments working with this data set which\nwill give you a better idea of what we\ncovered in this\nvideo in this notebook we'll go through\nthe same example we saw in the slides so\nlet's go ahead and read the data\nyou can see we have dates in the First\nColumn and NO2 content in the second\ncolumn so here's a look at the different\ndata types we have in these two\nvariables so date time as you can see\nhere is being read as an object data\ntype is that right it's not the first\nand most important step when dealing\nwith the date time column is to convert\nthe data type into date time by default\nas you can see here it is taken as an\nobject and that can give us pretty\nrandom\nresults so what we'll do is we'll use\nthe pandas pd. 2or datetime function we\nhave to give the column name and the\nformat as input format depends on the\nstructure of your date column here we\nhave date month year followed by R\nminutes\nseconds so this is how we can do it so\nlet me just print it out and then look\nat the data types again perfect here are\na few examples of the different uh so\nlet me print the maximum and minimum\nvalues of our date time column we get\nthe minimum to be uh 10th March 2004\nwhich is the first row of the data set\nand you can verify from your end that\nthe max value which you see here is\nactually the last value in the data set\nto do this use the data frame. tail\nfunction that's right data frame. tail\nnow let's see what are the features we\ncan extract from this column first you\ncan extract the r and minute values by\nsimply using the command column\nname do dt. R so let's do that and look\nat the first five values here we go\nthese are the R so 18 would be 600 p.m.\n7 p.m. and so on we can also extract the\nminutes so let's do that and print it\nout it's zero because it's 6 p.m so you\ncan just go through the entire data set\nto understand this in more detail we can\nalso extract which day it is whether\nit's Monday Wednesday or so on we can do\nthis using the column name dt. day of\nweek so here I'll print it out what do\nyou think two and three here\nmeans well this gives us the number\nwhere zero is for Monday and six is for\nSunday if you want to get the name then\nwe can use week daycore name instead of\nday of week so I'll print that out here\nwe go to get the month we can use the\ndt. month function so I'll print this\nout here we go it's the third month of\nthe year so we can similarly determine\nthe year using dt. ear that's something\nthat you can do additionally we can also\nfind out if the given date is at the end\nof the month or the end of the year\nusing the dt. isore monore end so none\nof the dates at least in the first seven\nrows are at the end of the month you can\nalways try other features yourself in\nfact I strongly recommend taking up this\ndata set or any other data set that has\na datetime feature and experimenting\naround using what we've learned here or\nexploring other things that you can do\nwith datetime values that's how you\nlearn new\nthings finally what I'm going to do is\nI'm going to bring all of what we've\nlearned so far together so we'll create\na new data frame called newor DF using\nthe pd. dataframe function here the\nFirst Column is the ear which stores the\nYear from the date we have the month day\nhour basically what we have just seen\nand we also have an additional quarter\nhere we'll just put all of that together\nin a new data frame and print it out\nhere we go here are all the new features\nthat we've just created how cool is that\nnow I'll add all these features right\nback to our original data frame using\nthe pd. concat function basically\nconcatenation and here we have the new\ndata set isn't it amazing we just had\ndate unor time and NO2 when we started\nand now we have all sorts of very useful\nvariables got to love feature\nengineering so far we've discussed\nfeatures we can directly create using\npandas now there are some additional\nfeatures we might want to add to the\ndata like whether the given date is a\nweekday or a weekend since we were able\nto extract the day of the week we can\ncheck if it's a weekend using this value\nthis is the code to do this we've\ncreated a new column called isore\nweekday and then we've run a for Loop to\ncheck the value at each row when the day\nof the week is five or six the value is\nzero\notherwise it's one one meaning weekday\nzero of course meaning weekend so I'm\ngoing to go ahead and run this again\nthis is a computationally heavy for Loop\nso we'll just give it a couple of\nminutes to run and then we'll look at\nthe first five rows of our new data\nframe and here we go so day of the week\n2 as isore week day one one remember is\nthat it's a weekday so clearly this our\nfor Loop has worked out pretty well\nthese are the first five rows of course\nyou can look at the entire data set to\nverify all the values but I can assure\nyou our for Loop has worked to\nPerfection we can also determine the\ndifference between two dates for example\nI've taken up a new data set which I'll\njust read that has two columns\napplication date and a date of birth of\nthe applicant so application receipt\ndate here and the applicant birth date\nso I'll quickly print out the head these\ntwo columns for easier use perfect using\nthese we can determine the age of the\napplicant first to do this we need to\nconvert these variables into the that's\nright datetime format so let me go ahead\nand run this all right now hit here is\nthe difference of the two variables it's\n12,902 days divide this by 365 and\nyou'll get the year to do this for each\nrow I will again use the apply function\nthis this code might look a bit\ncomplicated but is actually very simple\nand efficient for each row dot applyer\nReturns the difference of the two\nvariables and this value returned by the\nfunction is stored in new variable which\nwe calling applicant H so I'm going to\ngo ahead and run this perfect so this is\nhow we can work with a datetime variable\nso many things we can do with a simple\ncolumn again as I mentioned earlier go\nahead experiment with it we have a Time\nseries data set on analytics with this\ndata hack platform go ahead use that\ndata set apply what we've learned here\nand you'll be amazed at the accuracy you\nget using these simple datetime\nfeatures is there any way we can\nautomate this whole process of creating\nnew\nfeatures yes we can there's a library\ncalled feature tools which is an\nopen-source library for performing\nautomated feature engineering let's\nunderstand how it works there are three\nimportant components of feature tools\nentities feature Primitives and deep\nfeature synthesis to thoroughly\nunderstand these let's take up an\nexample data set and it's one you've\nseen before can you recognize this it's\nthe big Mar sales data set in this data\nset we have quite a few number of items\nlike item weight we have item type we\nhave the item MRP Outlet identifier\namong other things and of course the\nlast column here the item Outlet sales\nthat's a Target variable now in feature\ntools this data set is called an entity\nfor now we only have one data frame here\nbut there can be more multiple for\ninstance if we have a data set that\nholds only the variables that you can\nsee in the red border here like item\nidentifier Outlet type Outlet size Etc\nwhile we have another data set that\ncontains a details about things like\nitem weight fat content type and so on\nin that scenario we'll have two data\nsets and each of these individual data\nsets would be called an entity so an\nentity is basically a single table or\ndata frame all the information of the\nentity or entities is stored in an\nentity set in other words we can say\nthat an entity set is a collection of\ntables let's now talk about feature\nPrimitives remember we studied about\nfeature Transformations such as log or\nSquare before as well as feature\naggregations like additions and ratio\npreviously well these aggregations and\nTransformations are called feature\nPrimitives here are a few examples of\nthe various Transformations and\naggregations that we can Implement using\nfeature tools you can go ahead and pause\nthe video for a second and just go\nthrough this list if you\nwant so if I have the following two\nfeatures item weight and item MRP from\nthe bigm sales data set we can take the\nsum or difference or multiplication and\nso on but that's not the limit of what\nwe can do we can even add more variables\nfor example item weight into item MRP\nplus item weight you can think of the\nLimitless things you can do using these\noptions this is the beauty of feature\nengineering now this also is where the\nconcept of deep feature synthesis comes\ninto play deep feature synthesis Stacks\nmultiple transformation and aggregation\noperations although feature tools is\nable to create all these mathematical\nfeatures\nautomatically but there's one thing you\nshould keep in mind it does not have\ndomain knowledge which as we've seen\npreviously can play a critical role in\nbuilding a better\nmodel I would recommend using feature\ntools for generating new features but\nyou should also focus on domain\nunderstanding and apply that knowledge\nto create more domain specific features\nas\nwell let's move to the notebook and\nimplement this in\nPython in this notebook let's go ahead\nand understand how feature tools can be\nimplemented in\nPython now before we run this notebook\nyou'll need to install the feature tools\nlibrary on your machine simply use this\none following command and do that so\nlet's go and import the feature tools\nlibrary and pandas all right we're going\nto be working with the bigm sales data\nset so I'll load that and I'm going to\nstore all the independent variables in\nthe features variable and the target\nvariable which was sales in a variable\nwhich we'll call Y all right now first\nwe'll create an empty entity set using\nthe function ft. entity set I've said\nthe name of this entity set as big Mar\nas you can see here you can of course\nset any name whatever you see fit so let\nme just run this code block here we\ngo now we can add multiple entities to\nthis entity set remember each data frame\nis an\nentity in our example we only have one\ndata frame and hence yes we only have\none\nentity now in this cell We'll add an\nentity to the empty entity set we\ncreated earlier how will we do that by\nusing the entity _ frommore data frame\nfunction we'll name this dataor one and\nas I said you can use any name and we'll\nadd all the features the independent\nvariables to this entity set also uh we\nneed to specify the parameter\nindex because in our data set we don't\nhave a unique ID against each row so I'm\ngoing to go ahead and run this perfect\nall right now we've prepared the data\naccording to feature tools time to\ncreate some new\nfeatures we will use ft. DFS function\nwhich is the Deep feature synthesis\nfunction it returns two things the newly\ncreated features which we are storing in\nfeature uncore Matrix and the feature\ndefinitions which we'll store in feature\n_\ndeps to the function ft. DFS we have to\ngive the entity set the target entity\nwhich is dataor 1 in our case Target\nentity means which is our parent data\nframe on which we want to perform\nfeature Engineering in case we have\nmultiple data frames we'll have to pick\none of them as the target entity then we\nspecify the function we need to perform\non the features of data set using the\nTransCore\nPrimitives parameter I have specified\ntwo for now add numeric and multiply\nnumeric basically add all the numerical\nvariables and multiply all the numeric\nvariables and we've set the depth to one\nwe'll understand what the maxor depth\nparameter does in just a moment when I\nrun this cell we'll see that we have new\nfeatures that we've added to our\noriginal entity so let me go go ahe and\ndo that all right now these are all the\nnew variables starting here that we've\nnow engineered out of our original\nentity so let's see the complete list\nusing the feature undor deps code here\nwe go here's the complete list you can\nsee a sum of two features you can see\nthe multiplication as well here of two\nfeatures with all possible combinations\nand when we look at the shape we can see\nthat now we have 23 variables and we\nstarted with 12 so we created 11 new\nfeatures now if you look closely each\nnew feature is created by performing one\noperation either addition or\nmultiplication this why why do you think\nthis is this is because we set the max\nunderscore depth to one so only one\noperation is being\nperformed let's experiment and change\nthe depth to two which we'll do that so\nrun these cells\nall right so we get all sorts of new\nfeatures again let's look at the\ncomplete list using the feature defs\ncode as you can see here the new\nfeatures have a combination of two\noperations and using this we've created\nabout 50 new features in a matter of\nseconds incredible feature tools is a\nvery powerful library for creating new\nfeatures but just a word of caution not\nall the features will be useful for the\nmodel so just keep that in mind when\nyou're using it thank you\n",
  "words": [
    "welcome",
    "module",
    "feature",
    "engineering",
    "one",
    "fascinating",
    "modules",
    "aspects",
    "machine",
    "learning",
    "paradigm",
    "dive",
    "move",
    "ahead",
    "let",
    "quickly",
    "take",
    "look",
    "covered",
    "far",
    "used",
    "data",
    "build",
    "machine",
    "learning",
    "model",
    "model",
    "basically",
    "function",
    "tries",
    "learn",
    "rel",
    "relationship",
    "dependent",
    "variable",
    "independent",
    "variables",
    "instance",
    "covered",
    "following",
    "basic",
    "algorithms",
    "like",
    "k",
    "n",
    "linear",
    "regression",
    "logistic",
    "regression",
    "decision",
    "tree",
    "recall",
    "linear",
    "regression",
    "function",
    "equal",
    "beta",
    "beta",
    "1",
    "x1",
    "beta",
    "2",
    "x2",
    "betas",
    "essentially",
    "coefficients",
    "variable",
    "similarly",
    "decision",
    "tree",
    "combination",
    "multiple",
    "f",
    "statements",
    "tried",
    "find",
    "pure",
    "nodes",
    "might",
    "noticed",
    "talking",
    "coefficients",
    "decision",
    "tree",
    "nonparametric",
    "algorithm",
    "whereas",
    "linear",
    "regression",
    "parametric",
    "note",
    "methods",
    "looked",
    "far",
    "around",
    "optimizing",
    "ml",
    "algorithms",
    "finding",
    "optimum",
    "model",
    "majorly",
    "worked",
    "data",
    "given",
    "modu",
    "used",
    "existing",
    "data",
    "train",
    "model",
    "add",
    "data",
    "model",
    "able",
    "make",
    "better",
    "predictions",
    "broadly",
    "two",
    "ways",
    "first",
    "add",
    "new",
    "features",
    "information",
    "existing",
    "data",
    "example",
    "trying",
    "predict",
    "daily",
    "sales",
    "product",
    "let",
    "say",
    "cold",
    "drink",
    "college",
    "campus",
    "office",
    "complex",
    "given",
    "data",
    "past",
    "sales",
    "using",
    "need",
    "estimate",
    "sales",
    "next",
    "step",
    "10",
    "days",
    "case",
    "introducing",
    "feature",
    "like",
    "list",
    "holidays",
    "next",
    "10",
    "days",
    "might",
    "help",
    "estimate",
    "sales",
    "correctly",
    "variable",
    "like",
    "daily",
    "average",
    "temperature",
    "sales",
    "cold",
    "ring",
    "might",
    "vary",
    "winters",
    "summers",
    "etc",
    "add",
    "value",
    "model",
    "help",
    "us",
    "estimating",
    "sales",
    "effectively",
    "see",
    "addition",
    "two",
    "variables",
    "actually",
    "helping",
    "us",
    "estimate",
    "sales",
    "next",
    "10",
    "days",
    "another",
    "way",
    "improve",
    "models",
    "performance",
    "using",
    "existing",
    "data",
    "effectively",
    "saying",
    "generate",
    "information",
    "signal",
    "using",
    "existing",
    "features",
    "predict",
    "relationship",
    "independent",
    "variables",
    "dependent",
    "variable",
    "suppose",
    "want",
    "predict",
    "whether",
    "customer",
    "able",
    "pay",
    "loan",
    "details",
    "customer",
    "like",
    "birth",
    "year",
    "gender",
    "salary",
    "income",
    "etc",
    "let",
    "take",
    "application",
    "date",
    "birth",
    "year",
    "two",
    "features",
    "help",
    "us",
    "generate",
    "age",
    "customer",
    "new",
    "variable",
    "age",
    "might",
    "impact",
    "performance",
    "model",
    "able",
    "estimate",
    "default",
    "ratio",
    "customer",
    "right",
    "also",
    "use",
    "income",
    "variable",
    "generate",
    "brand",
    "new",
    "variable",
    "currently",
    "income",
    "continuous",
    "variable",
    "divide",
    "income",
    "categories",
    "say",
    "different",
    "bands",
    "example",
    "low",
    "income",
    "band",
    "high",
    "income",
    "average",
    "case",
    "seen",
    "use",
    "existing",
    "variables",
    "generate",
    "new",
    "variables",
    "like",
    "age",
    "income",
    "band",
    "technique",
    "generating",
    "new",
    "features",
    "using",
    "existing",
    "features",
    "called",
    "feature",
    "engineering",
    "let",
    "put",
    "formal",
    "definition",
    "feature",
    "engineering",
    "feature",
    "engineering",
    "science",
    "extracting",
    "information",
    "existing",
    "data",
    "adding",
    "new",
    "data",
    "actually",
    "making",
    "data",
    "already",
    "useful",
    "respect",
    "problem",
    "hand",
    "said",
    "respect",
    "problem",
    "hand",
    "fair",
    "knowledge",
    "domain",
    "always",
    "help",
    "us",
    "build",
    "better",
    "features",
    "recommend",
    "understanding",
    "problem",
    "statement",
    "domain",
    "well",
    "enough",
    "help",
    "us",
    "build",
    "better",
    "relevant",
    "features",
    "module",
    "look",
    "various",
    "feature",
    "engineering",
    "methods",
    "different",
    "type",
    "data",
    "sets",
    "like",
    "date",
    "time",
    "continuous",
    "categorical",
    "text",
    "others",
    "small",
    "interesting",
    "exercise",
    "slide",
    "subset",
    "two",
    "data",
    "sets",
    "using",
    "far",
    "titanic",
    "survival",
    "prediction",
    "bigm",
    "sales",
    "want",
    "take",
    "think",
    "new",
    "features",
    "create",
    "given",
    "set",
    "features",
    "respective",
    "problem",
    "statements",
    "next",
    "section",
    "shared",
    "problem",
    "statement",
    "data",
    "dictionary",
    "problems",
    "please",
    "go",
    "share",
    "list",
    "features",
    "discussion",
    "portal",
    "interesting",
    "exercise",
    "help",
    "understand",
    "feature",
    "engineering",
    "works",
    "hope",
    "good",
    "understanding",
    "term",
    "feature",
    "engineering",
    "point",
    "look",
    "different",
    "techniques",
    "use",
    "feature",
    "engineering",
    "let",
    "quickly",
    "look",
    "basic",
    "features",
    "create",
    "examples",
    "saw",
    "bigm",
    "sales",
    "data",
    "set",
    "see",
    "feature",
    "item",
    "identifier",
    "first",
    "column",
    "large",
    "number",
    "unique",
    "categories",
    "look",
    "original",
    "data",
    "set",
    "data",
    "set",
    "sample",
    "records",
    "even",
    "see",
    "categories",
    "rows",
    "unique",
    "explore",
    "entire",
    "data",
    "set",
    "first",
    "two",
    "characters",
    "categories",
    "seem",
    "three",
    "unique",
    "categories",
    "either",
    "fd",
    "dr",
    "fd",
    "nc",
    "fd",
    "look",
    "item",
    "type",
    "nc",
    "household",
    "dr",
    "soft",
    "drinks",
    "fd",
    "seems",
    "food",
    "items",
    "like",
    "dairy",
    "meat",
    "snack",
    "foods",
    "frozen",
    "foods",
    "etc",
    "conclude",
    "fd",
    "dr",
    "nc",
    "represent",
    "food",
    "drink",
    "respectively",
    "using",
    "information",
    "new",
    "column",
    "values",
    "like",
    "fd",
    "dr",
    "nc",
    "might",
    "help",
    "us",
    "build",
    "better",
    "models",
    "let",
    "look",
    "another",
    "data",
    "set",
    "let",
    "pull",
    "titanic",
    "one",
    "data",
    "set",
    "also",
    "lot",
    "variables",
    "mentioned",
    "read",
    "problem",
    "statement",
    "data",
    "dictionary",
    "well",
    "starting",
    "model",
    "building",
    "process",
    "help",
    "think",
    "new",
    "features",
    "generate",
    "gone",
    "feature",
    "description",
    "titanic",
    "data",
    "set",
    "would",
    "know",
    "two",
    "variables",
    "sib",
    "sp",
    "par",
    "represent",
    "count",
    "siblings",
    "spouse",
    "parents",
    "child",
    "board",
    "using",
    "information",
    "generate",
    "total",
    "number",
    "family",
    "members",
    "board",
    "add",
    "two",
    "values",
    "sib",
    "sp",
    "plus",
    "p",
    "1",
    "one",
    "observation",
    "person",
    "another",
    "feature",
    "want",
    "discuss",
    "name",
    "text",
    "field",
    "look",
    "closely",
    "name",
    "column",
    "see",
    "title",
    "name",
    "like",
    "mr",
    "mrs",
    "miss",
    "master",
    "well",
    "titles",
    "useful",
    "features",
    "making",
    "predictions",
    "titles",
    "way",
    "represent",
    "age",
    "bracket",
    "passengers",
    "might",
    "help",
    "us",
    "impute",
    "missing",
    "values",
    "age",
    "column",
    "well",
    "similarly",
    "create",
    "many",
    "features",
    "using",
    "given",
    "data",
    "let",
    "look",
    "covering",
    "module",
    "seen",
    "examples",
    "problem",
    "statements",
    "data",
    "set",
    "like",
    "titanic",
    "bigm",
    "sales",
    "numerical",
    "features",
    "categorical",
    "features",
    "text",
    "string",
    "based",
    "features",
    "well",
    "common",
    "variable",
    "types",
    "usually",
    "find",
    "working",
    "another",
    "type",
    "feature",
    "might",
    "encounter",
    "date",
    "time",
    "column",
    "learn",
    "deal",
    "features",
    "module",
    "words",
    "generate",
    "signal",
    "given",
    "data",
    "set",
    "turn",
    "focus",
    "numerical",
    "categorical",
    "variables",
    "video",
    "discuss",
    "different",
    "methods",
    "feature",
    "engineering",
    "broadly",
    "divide",
    "feature",
    "engineering",
    "two",
    "categories",
    "feature",
    "feature",
    "generation",
    "let",
    "briefly",
    "define",
    "two",
    "subcategories",
    "feature",
    "processing",
    "refers",
    "changing",
    "updating",
    "transforming",
    "existing",
    "features",
    "case",
    "creating",
    "new",
    "features",
    "making",
    "features",
    "informative",
    "talk",
    "different",
    "feature",
    "methods",
    "later",
    "part",
    "video",
    "category",
    "feature",
    "generation",
    "generate",
    "new",
    "features",
    "existing",
    "features",
    "feature",
    "different",
    "feature",
    "generation",
    "well",
    "feature",
    "generation",
    "refers",
    "creating",
    "new",
    "features",
    "existing",
    "data",
    "simply",
    "transform",
    "forming",
    "values",
    "existing",
    "features",
    "example",
    "titanic",
    "data",
    "set",
    "saw",
    "created",
    "family",
    "size",
    "extracted",
    "title",
    "name",
    "examples",
    "feature",
    "generation",
    "let",
    "look",
    "categories",
    "details",
    "specific",
    "numerical",
    "categorical",
    "variables",
    "let",
    "start",
    "feature",
    "various",
    "methods",
    "perform",
    "feature",
    "look",
    "one",
    "one",
    "first",
    "method",
    "look",
    "called",
    "feature",
    "transformation",
    "feature",
    "transformation",
    "name",
    "suggests",
    "method",
    "used",
    "transform",
    "features",
    "using",
    "mathematical",
    "operations",
    "example",
    "given",
    "feature",
    "value",
    "take",
    "log",
    "value",
    "square",
    "take",
    "square",
    "root",
    "take",
    "reciprocal",
    "sure",
    "wondering",
    "important",
    "decide",
    "use",
    "technique",
    "well",
    "varies",
    "case",
    "case",
    "example",
    "look",
    "plot",
    "shows",
    "relationship",
    "target",
    "variable",
    "feature",
    "shows",
    "relationship",
    "nonlinear",
    "know",
    "models",
    "like",
    "linear",
    "regression",
    "good",
    "linear",
    "relationship",
    "dependent",
    "independent",
    "variables",
    "case",
    "transform",
    "variable",
    "way",
    "relationship",
    "target",
    "variable",
    "feature",
    "becomes",
    "linear",
    "method",
    "model",
    "specific",
    "let",
    "look",
    "another",
    "case",
    "feature",
    "transformation",
    "help",
    "us",
    "model",
    "better",
    "take",
    "plot",
    "instance",
    "represents",
    "right",
    "skewed",
    "positively",
    "skewed",
    "distribution",
    "could",
    "due",
    "presence",
    "outliers",
    "data",
    "normal",
    "distribution",
    "preferred",
    "skewed",
    "distribution",
    "makes",
    "things",
    "easier",
    "makes",
    "easier",
    "model",
    "relationships",
    "also",
    "modeling",
    "techniques",
    "perform",
    "well",
    "normal",
    "distribution",
    "variables",
    "whenever",
    "skewed",
    "distribution",
    "use",
    "transformations",
    "reduce",
    "skewness",
    "note",
    "right",
    "skewed",
    "positively",
    "skewed",
    "distribution",
    "take",
    "square",
    "cube",
    "root",
    "log",
    "variable",
    "call",
    "nth",
    "root",
    "well",
    "left",
    "skewed",
    "negative",
    "skewed",
    "take",
    "square",
    "cube",
    "exponential",
    "variables",
    "called",
    "feature",
    "transformation",
    "one",
    "thing",
    "note",
    "taking",
    "log",
    "variable",
    "negative",
    "value",
    "value",
    "zero",
    "might",
    "show",
    "error",
    "guess",
    "log",
    "of0",
    "defined",
    "instead",
    "use",
    "simple",
    "trick",
    "take",
    "log",
    "x",
    "c",
    "c",
    "constant",
    "objective",
    "input",
    "log",
    "must",
    "greater",
    "zer",
    "right",
    "let",
    "go",
    "ahead",
    "look",
    "implementation",
    "future",
    "transformation",
    "python",
    "notebook",
    "implementing",
    "feature",
    "transformation",
    "bigm",
    "sales",
    "data",
    "let",
    "start",
    "importing",
    "libraries",
    "course",
    "loading",
    "data",
    "set",
    "let",
    "go",
    "ahead",
    "rigorously",
    "worked",
    "data",
    "set",
    "last",
    "modules",
    "sure",
    "familiar",
    "features",
    "columns",
    "data",
    "set",
    "continuous",
    "variables",
    "among",
    "item",
    "weight",
    "item",
    "visibility",
    "item",
    "mrp",
    "going",
    "go",
    "going",
    "take",
    "item",
    "visibility",
    "variable",
    "try",
    "exercise",
    "variable",
    "let",
    "go",
    "ahead",
    "look",
    "distribution",
    "item",
    "visibility",
    "feature",
    "go",
    "distribution",
    "plot",
    "histogram",
    "plot",
    "feature",
    "see",
    "right",
    "skew",
    "distribution",
    "let",
    "take",
    "square",
    "root",
    "check",
    "distribution",
    "create",
    "another",
    "variable",
    "item",
    "visibility",
    "square",
    "root",
    "store",
    "square",
    "root",
    "value",
    "variable",
    "using",
    "np",
    "sqrt",
    "function",
    "calculate",
    "square",
    "root",
    "value",
    "going",
    "go",
    "ahead",
    "implement",
    "look",
    "distribution",
    "distribution",
    "looks",
    "symmetric",
    "also",
    "see",
    "large",
    "number",
    "values",
    "visibility",
    "zero",
    "need",
    "deal",
    "separately",
    "discussed",
    "previously",
    "either",
    "take",
    "root",
    "log",
    "case",
    "right",
    "skew",
    "distribution",
    "let",
    "go",
    "ahead",
    "use",
    "log",
    "function",
    "another",
    "variable",
    "creating",
    "called",
    "item",
    "visibility",
    "log",
    "store",
    "log",
    "values",
    "item",
    "visibility",
    "feature",
    "run",
    "get",
    "warning",
    "guess",
    "warning",
    "getting",
    "well",
    "look",
    "variable",
    "distribution",
    "let",
    "go",
    "ahead",
    "run",
    "see",
    "minimum",
    "value",
    "zero",
    "least",
    "one",
    "value",
    "sure",
    "could",
    "log",
    "0",
    "defined",
    "getting",
    "error",
    "one",
    "way",
    "deal",
    "simply",
    "add",
    "constant",
    "every",
    "value",
    "variable",
    "going",
    "go",
    "ahead",
    "add",
    "see",
    "distribution",
    "look",
    "plot",
    "mostly",
    "negative",
    "values",
    "distribution",
    "exactly",
    "perfectly",
    "normal",
    "values",
    "column",
    "less",
    "one",
    "let",
    "increase",
    "scale",
    "values",
    "keep",
    "mind",
    "increasing",
    "scale",
    "affect",
    "distribution",
    "multiplied",
    "values",
    "100",
    "let",
    "go",
    "ahead",
    "run",
    "code",
    "new",
    "range",
    "values",
    "changed",
    "0",
    "0",
    "30",
    "going",
    "go",
    "ahead",
    "use",
    "log",
    "transformation",
    "plot",
    "plot",
    "normal",
    "distribution",
    "values",
    "see",
    "also",
    "positive",
    "let",
    "move",
    "another",
    "method",
    "feature",
    "feature",
    "scaling",
    "take",
    "look",
    "data",
    "set",
    "related",
    "loan",
    "applications",
    "variables",
    "like",
    "loan",
    "amount",
    "emi",
    "income",
    "different",
    "units",
    "notice",
    "loan",
    "amount",
    "thousands",
    "income",
    "hundreds",
    "emi",
    "dollars",
    "discussed",
    "algorithms",
    "like",
    "knn",
    "features",
    "scale",
    "else",
    "get",
    "ambiguous",
    "results",
    "want",
    "case",
    "need",
    "perform",
    "scaling",
    "features",
    "either",
    "scale",
    "bring",
    "features",
    "scale",
    "two",
    "common",
    "ways",
    "feature",
    "scaling",
    "min",
    "max",
    "scaler",
    "standard",
    "scaler",
    "let",
    "first",
    "talk",
    "minmax",
    "scaling",
    "method",
    "first",
    "determine",
    "minimum",
    "maximum",
    "value",
    "column",
    "value",
    "first",
    "subtract",
    "minimum",
    "value",
    "divide",
    "difference",
    "maximum",
    "minimum",
    "value",
    "feature",
    "range",
    "minmax",
    "scaler",
    "scales",
    "value",
    "feature",
    "0",
    "1",
    "check",
    "want",
    "replace",
    "xi",
    "minimum",
    "value",
    "numerator",
    "course",
    "become",
    "zero",
    "right",
    "replace",
    "maximum",
    "value",
    "numerator",
    "denominator",
    "cancel",
    "ratio",
    "becomes",
    "one",
    "see",
    "second",
    "table",
    "values",
    "three",
    "features",
    "range",
    "0",
    "1",
    "one",
    "applying",
    "min",
    "max",
    "scaling",
    "let",
    "look",
    "second",
    "method",
    "called",
    "standard",
    "scaling",
    "method",
    "first",
    "determine",
    "mean",
    "standard",
    "deviation",
    "column",
    "value",
    "first",
    "subtract",
    "mean",
    "value",
    "divide",
    "standard",
    "deviation",
    "let",
    "apply",
    "example",
    "see",
    "values",
    "three",
    "features",
    "similar",
    "scale",
    "let",
    "one",
    "thing",
    "let",
    "implement",
    "learned",
    "far",
    "python",
    "video",
    "go",
    "feature",
    "scaling",
    "methods",
    "let",
    "go",
    "ahead",
    "import",
    "libraries",
    "pandas",
    "numpy",
    "read",
    "big",
    "mar",
    "sales",
    "data",
    "set",
    "going",
    "focus",
    "two",
    "features",
    "item",
    "visibility",
    "item",
    "mrp",
    "see",
    "huge",
    "difference",
    "values",
    "let",
    "bring",
    "features",
    "scale",
    "going",
    "work",
    "min",
    "max",
    "scaler",
    "scales",
    "values",
    "0",
    "1",
    "see",
    "formula",
    "use",
    "rely",
    "python",
    "us",
    "always",
    "good",
    "know",
    "understand",
    "going",
    "underneath",
    "code",
    "formula",
    "helps",
    "let",
    "first",
    "import",
    "minmax",
    "scaler",
    "sk",
    "learn",
    "preprocessing",
    "library",
    "perfect",
    "create",
    "instance",
    "called",
    "scaler",
    "apply",
    "data",
    "stor",
    "two",
    "variables",
    "item",
    "visibility",
    "mrp",
    "see",
    "going",
    "store",
    "new",
    "data",
    "frame",
    "called",
    "scaled",
    "uncore",
    "data",
    "let",
    "print",
    "first",
    "rows",
    "see",
    "variables",
    "range",
    "perfect",
    "going",
    "use",
    "describe",
    "function",
    "see",
    "minimum",
    "value",
    "variables",
    "see",
    "zero",
    "maximum",
    "one",
    "perfect",
    "minmax",
    "scaler",
    "worked",
    "exactly",
    "hoped",
    "would",
    "let",
    "try",
    "scaling",
    "variables",
    "using",
    "standard",
    "scalar",
    "pick",
    "two",
    "variables",
    "first",
    "import",
    "standard",
    "scaler",
    "sk",
    "scalar",
    "library",
    "let",
    "create",
    "instance",
    "called",
    "scaler",
    "fit",
    "data",
    "store",
    "new",
    "data",
    "frame",
    "called",
    "scale",
    "data",
    "let",
    "print",
    "results",
    "interesting",
    "see",
    "mean",
    "close",
    "zero",
    "standard",
    "deviation",
    "one",
    "two",
    "methods",
    "popular",
    "methods",
    "use",
    "scale",
    "data",
    "covered",
    "techniques",
    "continuous",
    "variables",
    "far",
    "let",
    "move",
    "ahead",
    "feature",
    "techniques",
    "categorical",
    "variables",
    "start",
    "popular",
    "one",
    "one",
    "hot",
    "encoding",
    "often",
    "also",
    "called",
    "dummy",
    "encoding",
    "remember",
    "data",
    "set",
    "bigm",
    "sales",
    "problem",
    "three",
    "categorical",
    "variables",
    "highlighted",
    "red",
    "note",
    "machine",
    "learning",
    "models",
    "deal",
    "categorical",
    "variables",
    "especially",
    "python",
    "use",
    "pyit",
    "learn",
    "need",
    "convert",
    "categorical",
    "variables",
    "numeric",
    "values",
    "let",
    "pick",
    "outlet",
    "size",
    "outlet",
    "size",
    "column",
    "replace",
    "outlet",
    "size",
    "column",
    "three",
    "columns",
    "outlet",
    "medium",
    "outlet",
    "small",
    "outlet",
    "high",
    "first",
    "row",
    "outlet",
    "size",
    "medium",
    "put",
    "one",
    "size",
    "medium",
    "column",
    "see",
    "zero",
    "two",
    "columns",
    "similar",
    "similarly",
    "perform",
    "step",
    "rest",
    "rows",
    "respective",
    "outlet",
    "size",
    "see",
    "item",
    "identify",
    "ncd",
    "19",
    "outlet",
    "size",
    "pretty",
    "high",
    "one",
    "size",
    "high",
    "column",
    "zero",
    "remaining",
    "two",
    "columns",
    "method",
    "applied",
    "categorical",
    "variables",
    "data",
    "set",
    "like",
    "item",
    "type",
    "item",
    "fat",
    "content",
    "hold",
    "problem",
    "type",
    "encoding",
    "item",
    "type",
    "order",
    "see",
    "say",
    "names",
    "items",
    "like",
    "dairies",
    "soft",
    "drinks",
    "meat",
    "ca",
    "really",
    "say",
    "order",
    "categories",
    "outlet",
    "size",
    "fat",
    "content",
    "order",
    "size",
    "small",
    "medium",
    "high",
    "order",
    "right",
    "using",
    "one",
    "hard",
    "encoding",
    "actually",
    "losing",
    "information",
    "variables",
    "order",
    "called",
    "ordinal",
    "variables",
    "case",
    "instead",
    "creating",
    "three",
    "different",
    "columns",
    "replace",
    "categories",
    "column",
    "numbers",
    "see",
    "example",
    "numbers",
    "1",
    "2",
    "three",
    "small",
    "medium",
    "high",
    "respectively",
    "one",
    "small",
    "two",
    "medium",
    "three",
    "high",
    "way",
    "actually",
    "preserving",
    "order",
    "information",
    "variable",
    "well",
    "along",
    "encoding",
    "numbers",
    "let",
    "go",
    "open",
    "jupter",
    "notebook",
    "try",
    "techniques",
    "one",
    "hot",
    "encoding",
    "label",
    "encoding",
    "notebook",
    "implement",
    "concepts",
    "one",
    "hot",
    "encoding",
    "label",
    "encoding",
    "bigm",
    "sales",
    "data",
    "set",
    "course",
    "know",
    "first",
    "steps",
    "import",
    "panda",
    "library",
    "read",
    "bigm",
    "sales",
    "data",
    "set",
    "let",
    "bring",
    "first",
    "five",
    "rows",
    "go",
    "familiar",
    "variables",
    "looked",
    "plenty",
    "times",
    "let",
    "check",
    "shape",
    "perfect",
    "8500",
    "plus",
    "rows",
    "working",
    "12",
    "columns",
    "variables",
    "let",
    "use",
    "types",
    "function",
    "bring",
    "data",
    "types",
    "categorical",
    "variables",
    "see",
    "data",
    "type",
    "object",
    "categorical",
    "variables",
    "need",
    "convert",
    "categorical",
    "variables",
    "numbers",
    "train",
    "machine",
    "learning",
    "model",
    "let",
    "start",
    "encoding",
    "single",
    "variable",
    "outlet",
    "type",
    "determine",
    "total",
    "number",
    "categories",
    "variable",
    "using",
    "dot",
    "value",
    "uncore",
    "counts",
    "function",
    "see",
    "output",
    "four",
    "categories",
    "supermarket",
    "type",
    "1",
    "grocery",
    "store",
    "supermarket",
    "type",
    "3",
    "supermarket",
    "type",
    "2",
    "perfect",
    "let",
    "use",
    "one",
    "hot",
    "encoding",
    "performing",
    "one",
    "hot",
    "encoding",
    "actually",
    "simple",
    "python",
    "use",
    "pandas",
    "getor",
    "dummies",
    "function",
    "code",
    "block",
    "applied",
    "getor",
    "dummies",
    "function",
    "outlet",
    "uncore",
    "type",
    "variable",
    "see",
    "output",
    "replaced",
    "one",
    "column",
    "four",
    "columns",
    "binary",
    "values",
    "since",
    "first",
    "row",
    "category",
    "supermarket",
    "type",
    "one",
    "one",
    "column",
    "columns",
    "zero",
    "similarly",
    "second",
    "row",
    "one",
    "column",
    "market",
    "type",
    "2",
    "zero",
    "rest",
    "might",
    "wondering",
    "10",
    "20",
    "variables",
    "write",
    "code",
    "line",
    "every",
    "single",
    "one",
    "well",
    "simply",
    "use",
    "get",
    "dummies",
    "whole",
    "data",
    "set",
    "together",
    "let",
    "go",
    "ahead",
    "perfect",
    "use",
    "pd",
    "getor",
    "dummies",
    "function",
    "give",
    "data",
    "set",
    "name",
    "like",
    "done",
    "automatically",
    "select",
    "categorical",
    "variables",
    "perform",
    "one",
    "hot",
    "encoding",
    "faced",
    "two",
    "problems",
    "since",
    "used",
    "one",
    "hard",
    "encoding",
    "first",
    "categorical",
    "variables",
    "converted",
    "zero",
    "one",
    "results",
    "loss",
    "important",
    "information",
    "example",
    "variable",
    "outlet",
    "size",
    "categories",
    "high",
    "medium",
    "small",
    "right",
    "course",
    "inherent",
    "order",
    "look",
    "happened",
    "done",
    "missing",
    "important",
    "information",
    "order",
    "variables",
    "destroyed",
    "second",
    "problem",
    "number",
    "features",
    "drastically",
    "increased",
    "12",
    "plus",
    "let",
    "see",
    "shape",
    "clearly",
    "see",
    "165",
    "variable",
    "humongous",
    "amount",
    "look",
    "closely",
    "variable",
    "item",
    "identifier",
    "number",
    "unique",
    "values",
    "essentially",
    "like",
    "id",
    "variable",
    "hence",
    "90",
    "rowes",
    "zero",
    "look",
    "information",
    "really",
    "useful",
    "model",
    "notebook",
    "address",
    "first",
    "problem",
    "look",
    "solution",
    "second",
    "problem",
    "upcoming",
    "video",
    "maintain",
    "order",
    "among",
    "categories",
    "variables",
    "instead",
    "using",
    "one",
    "encoding",
    "go",
    "label",
    "encoding",
    "let",
    "go",
    "ahead",
    "import",
    "labor",
    "encoder",
    "class",
    "sk",
    "learn",
    "preprocessing",
    "let",
    "look",
    "value",
    "counts",
    "outlet",
    "size",
    "variable",
    "perfect",
    "medium",
    "small",
    "high",
    "value",
    "counts",
    "front",
    "create",
    "instance",
    "called",
    "le",
    "use",
    "fitore",
    "transform",
    "function",
    "label",
    "encoder",
    "class",
    "transform",
    "small",
    "two",
    "medium",
    "one",
    "high",
    "zero",
    "problem",
    "label",
    "encoder",
    "considers",
    "alphabetical",
    "order",
    "assign",
    "values",
    "might",
    "looking",
    "every",
    "time",
    "need",
    "alternative",
    "solution",
    "decide",
    "number",
    "want",
    "assign",
    "category",
    "manually",
    "use",
    "dot",
    "map",
    "function",
    "example",
    "mention",
    "variable",
    "name",
    "done",
    "outlet",
    "size",
    "use",
    "dot",
    "map",
    "function",
    "write",
    "number",
    "category",
    "assigning",
    "0er",
    "small",
    "1",
    "medium",
    "two",
    "high",
    "let",
    "run",
    "perfect",
    "ss",
    "first",
    "challenge",
    "encountered",
    "one",
    "hard",
    "encoding",
    "far",
    "dealing",
    "categorical",
    "variables",
    "less",
    "number",
    "categories",
    "imagine",
    "data",
    "set",
    "categorical",
    "column",
    "100",
    "different",
    "categories",
    "quite",
    "often",
    "happen",
    "industry",
    "think",
    "one",
    "encoding",
    "good",
    "idea",
    "really",
    "example",
    "sample",
    "data",
    "set",
    "column",
    "sit",
    "imagine",
    "column",
    "500",
    "unique",
    "cities",
    "performing",
    "one",
    "hot",
    "encoding",
    "create",
    "5",
    "100",
    "different",
    "variables",
    "zero",
    "one",
    "value",
    "going",
    "absolute",
    "nightmare",
    "deal",
    "well",
    "trick",
    "combine",
    "sparse",
    "classes",
    "wait",
    "sparse",
    "classes",
    "classes",
    "relatively",
    "low",
    "frequency",
    "known",
    "sp",
    "classes",
    "value",
    "count",
    "different",
    "cities",
    "cities",
    "low",
    "frequency",
    "like",
    "ghati",
    "rur",
    "indor",
    "less",
    "frequent",
    "data",
    "set",
    "compared",
    "cities",
    "data",
    "since",
    "cities",
    "low",
    "frequency",
    "combine",
    "cities",
    "new",
    "category",
    "reduce",
    "number",
    "unique",
    "categories",
    "explode",
    "dimensionality",
    "data",
    "set",
    "well",
    "reduce",
    "number",
    "categories",
    "simply",
    "combine",
    "categories",
    "hence",
    "reduce",
    "overall",
    "number",
    "classes",
    "variable",
    "based",
    "frequency",
    "count",
    "variable",
    "different",
    "ways",
    "combining",
    "well",
    "domain",
    "knowledge",
    "example",
    "case",
    "combine",
    "similar",
    "cities",
    "together",
    "similarity",
    "geographic",
    "based",
    "type",
    "city",
    "based",
    "like",
    "tier",
    "1",
    "tier",
    "2",
    "tier",
    "3",
    "also",
    "create",
    "region",
    "variable",
    "one",
    "level",
    "geographical",
    "hierarchy",
    "doable",
    "geographical",
    "information",
    "let",
    "go",
    "ahead",
    "look",
    "example",
    "python",
    "continue",
    "working",
    "notebook",
    "saw",
    "last",
    "video",
    "used",
    "bigm",
    "sales",
    "data",
    "set",
    "looked",
    "different",
    "categorical",
    "columns",
    "first",
    "used",
    "one",
    "hot",
    "encoding",
    "whole",
    "data",
    "set",
    "discussed",
    "essentially",
    "two",
    "problems",
    "working",
    "variables",
    "might",
    "inherent",
    "order",
    "first",
    "problem",
    "second",
    "size",
    "increased",
    "drastically",
    "remember",
    "started",
    "12",
    "variables",
    "using",
    "one",
    "encoding",
    "ended",
    "1600",
    "solve",
    "first",
    "problem",
    "use",
    "label",
    "encoding",
    "method",
    "look",
    "dealing",
    "high",
    "cardinality",
    "high",
    "number",
    "dimensions",
    "reducing",
    "number",
    "categories",
    "let",
    "first",
    "see",
    "variable",
    "highest",
    "number",
    "unique",
    "categories",
    "using",
    "dot",
    "n",
    "unique",
    "functions",
    "categorical",
    "variables",
    "item",
    "identifier",
    "maximum",
    "number",
    "unique",
    "values",
    "might",
    "store",
    "given",
    "certain",
    "number",
    "identifier",
    "individual",
    "item",
    "let",
    "look",
    "value",
    "count",
    "variable",
    "maximum",
    "frequency",
    "10",
    "actually",
    "many",
    "values",
    "occur",
    "twice",
    "going",
    "combine",
    "low",
    "frequency",
    "classes",
    "first",
    "store",
    "frequency",
    "count",
    "variable",
    "temp",
    "let",
    "print",
    "first",
    "rows",
    "okay",
    "go",
    "create",
    "new",
    "column",
    "data",
    "frame",
    "item",
    "identifier",
    "count",
    "store",
    "value",
    "count",
    "category",
    "help",
    "apply",
    "function",
    "apply",
    "function",
    "performs",
    "given",
    "task",
    "every",
    "row",
    "data",
    "frame",
    "used",
    "apply",
    "function",
    "item",
    "identifier",
    "column",
    "category",
    "item",
    "identifier",
    "return",
    "frequency",
    "temp",
    "created",
    "let",
    "go",
    "ahead",
    "run",
    "finally",
    "want",
    "combine",
    "sparse",
    "classes",
    "categories",
    "frequency",
    "less",
    "four",
    "replaced",
    "category",
    "let",
    "run",
    "loop",
    "might",
    "take",
    "couple",
    "moments",
    "let",
    "uh",
    "wait",
    "run",
    "right",
    "let",
    "look",
    "first",
    "seven",
    "rows",
    "perfect",
    "look",
    "value",
    "counts",
    "see",
    "least",
    "values",
    "see",
    "four",
    "one",
    "two",
    "values",
    "saw",
    "earlier",
    "combined",
    "right",
    "far",
    "covered",
    "numerous",
    "methods",
    "perform",
    "feature",
    "video",
    "discuss",
    "different",
    "methods",
    "feature",
    "generation",
    "feature",
    "generation",
    "essentially",
    "means",
    "creating",
    "new",
    "features",
    "existing",
    "data",
    "let",
    "take",
    "example",
    "understand",
    "suppose",
    "problem",
    "statement",
    "stroke",
    "prediction",
    "given",
    "data",
    "set",
    "see",
    "features",
    "like",
    "person",
    "age",
    "gender",
    "work",
    "type",
    "hypertension",
    "etc",
    "based",
    "featur",
    "predict",
    "whether",
    "person",
    "stroke",
    "essentially",
    "column",
    "target",
    "variable",
    "let",
    "look",
    "relationship",
    "independent",
    "variables",
    "dependent",
    "variable",
    "first",
    "age",
    "person",
    "likely",
    "adults",
    "stroke",
    "rather",
    "kids",
    "create",
    "bins",
    "using",
    "age",
    "column",
    "classify",
    "adults",
    "one",
    "bin",
    "young",
    "people",
    "done",
    "various",
    "ways",
    "simplest",
    "method",
    "thir",
    "one",
    "discussed",
    "set",
    "cut",
    "value",
    "say",
    "35",
    "create",
    "two",
    "bins",
    "rows",
    "age",
    "greater",
    "35",
    "marked",
    "one",
    "others",
    "zero",
    "created",
    "two",
    "bins",
    "generate",
    "multiple",
    "bins",
    "similar",
    "manner",
    "example",
    "set",
    "age",
    "0",
    "12",
    "one",
    "bin",
    "12",
    "20",
    "another",
    "case",
    "new",
    "variable",
    "categorical",
    "even",
    "say",
    "ordinal",
    "nature",
    "look",
    "example",
    "shown",
    "four",
    "categories",
    "child",
    "teenager",
    "adult",
    "senior",
    "citizen",
    "since",
    "variable",
    "age",
    "easily",
    "able",
    "decide",
    "range",
    "values",
    "based",
    "experience",
    "cut",
    "value",
    "threshold",
    "value",
    "also",
    "decided",
    "using",
    "simple",
    "decision",
    "tree",
    "built",
    "tree",
    "using",
    "age",
    "feature",
    "stroke",
    "target",
    "variable",
    "decision",
    "tree",
    "decides",
    "best",
    "split",
    "age",
    "able",
    "classify",
    "person",
    "stroke",
    "threshold",
    "values",
    "see",
    "first",
    "split",
    "happened",
    "left",
    "branch",
    "decision",
    "tree",
    "split",
    "happened",
    "right",
    "branch",
    "generate",
    "bins",
    "accordingly",
    "look",
    "bins",
    "slide",
    "cut",
    "values",
    "obtained",
    "using",
    "decision",
    "tree",
    "model",
    "saw",
    "previous",
    "slide",
    "let",
    "let",
    "bring",
    "another",
    "example",
    "binning",
    "data",
    "set",
    "bmi",
    "values",
    "person",
    "see",
    "decimals",
    "round",
    "decimal",
    "values",
    "example",
    "become",
    "17",
    "way",
    "creating",
    "bins",
    "whole",
    "number",
    "level",
    "right",
    "let",
    "move",
    "python",
    "notebook",
    "take",
    "quick",
    "look",
    "implementation",
    "binning",
    "python",
    "let",
    "implement",
    "concept",
    "go",
    "ahead",
    "import",
    "pandas",
    "library",
    "working",
    "stroke",
    "prediction",
    "data",
    "set",
    "saw",
    "video",
    "sorts",
    "variables",
    "age",
    "gender",
    "hypertension",
    "heart",
    "disease",
    "person",
    "ever",
    "married",
    "work",
    "type",
    "residence",
    "type",
    "sorts",
    "things",
    "course",
    "final",
    "uh",
    "target",
    "variable",
    "stroke",
    "use",
    "age",
    "variable",
    "create",
    "bins",
    "first",
    "store",
    "range",
    "category",
    "bins",
    "variable",
    "form",
    "list",
    "basically",
    "bin",
    "edges",
    "lower",
    "upper",
    "values",
    "range",
    "store",
    "names",
    "want",
    "give",
    "ranges",
    "see",
    "given",
    "following",
    "labels",
    "child",
    "teenager",
    "young",
    "adult",
    "senior",
    "citizen",
    "stored",
    "group",
    "list",
    "list",
    "called",
    "group",
    "finally",
    "created",
    "new",
    "variable",
    "age",
    "uncore",
    "category",
    "use",
    "pd",
    "cut",
    "function",
    "bend",
    "continuous",
    "values",
    "categories",
    "give",
    "variable",
    "age",
    "input",
    "along",
    "specified",
    "bin",
    "edges",
    "labels",
    "names",
    "group",
    "going",
    "go",
    "ahead",
    "run",
    "code",
    "block",
    "let",
    "look",
    "first",
    "five",
    "rows",
    "perfect",
    "see",
    "binning",
    "strategy",
    "worked",
    "perfectly",
    "first",
    "row",
    "age",
    "three",
    "categorized",
    "child",
    "third",
    "eight",
    "child",
    "age",
    "58",
    "falls",
    "category",
    "17",
    "senior",
    "citizen",
    "14",
    "teenager",
    "perfect",
    "done",
    "using",
    "bin",
    "edges",
    "decision",
    "tree",
    "create",
    "new",
    "list",
    "storing",
    "new",
    "bin",
    "edges",
    "see",
    "code",
    "block",
    "rest",
    "steps",
    "saw",
    "earlier",
    "create",
    "list",
    "group",
    "store",
    "labels",
    "saying",
    "b",
    "bin",
    "1",
    "bin",
    "2",
    "bin",
    "3",
    "bin",
    "4",
    "creating",
    "new",
    "variable",
    "agore",
    "category",
    "using",
    "pd",
    "cut",
    "function",
    "bend",
    "continuous",
    "values",
    "categories",
    "giving",
    "variable",
    "age",
    "input",
    "along",
    "specify",
    "bin",
    "edges",
    "labels",
    "names",
    "group",
    "go",
    "ahead",
    "implement",
    "see",
    "binning",
    "strategy",
    "yet",
    "come",
    "trumps",
    "first",
    "row",
    "age",
    "three",
    "person",
    "bin",
    "1",
    "58",
    "bin",
    "2",
    "8",
    "bin",
    "1",
    "17",
    "bin",
    "3",
    "14",
    "bin",
    "1",
    "hope",
    "got",
    "sense",
    "binning",
    "works",
    "implement",
    "python",
    "interesting",
    "examples",
    "discussed",
    "far",
    "using",
    "single",
    "variable",
    "let",
    "look",
    "examples",
    "use",
    "one",
    "variable",
    "generate",
    "new",
    "features",
    "essentially",
    "face",
    "industry",
    "even",
    "competing",
    "data",
    "science",
    "competition",
    "loan",
    "prediction",
    "data",
    "set",
    "target",
    "variable",
    "last",
    "column",
    "determine",
    "whether",
    "loan",
    "given",
    "person",
    "based",
    "person",
    "income",
    "education",
    "property",
    "area",
    "etc",
    "look",
    "two",
    "variables",
    "applicant",
    "income",
    "applicant",
    "adding",
    "two",
    "values",
    "give",
    "us",
    "total",
    "earning",
    "family",
    "imagine",
    "could",
    "well",
    "important",
    "factor",
    "deciding",
    "whether",
    "loan",
    "granted",
    "since",
    "constructed",
    "new",
    "feature",
    "represents",
    "interaction",
    "two",
    "features",
    "called",
    "feature",
    "interaction",
    "similarly",
    "construct",
    "mathematical",
    "features",
    "like",
    "taking",
    "ratio",
    "loan",
    "amount",
    "applicant",
    "income",
    "ratio",
    "loan",
    "amount",
    "total",
    "income",
    "idea",
    "person",
    "group",
    "high",
    "loan",
    "amount",
    "low",
    "income",
    "might",
    "higher",
    "chances",
    "defaulting",
    "domain",
    "knowledge",
    "help",
    "think",
    "features",
    "moreover",
    "use",
    "difference",
    "income",
    "loan",
    "amount",
    "well",
    "necessary",
    "use",
    "two",
    "variables",
    "go",
    "ahead",
    "play",
    "around",
    "multiple",
    "variables",
    "well",
    "notebook",
    "going",
    "go",
    "ahead",
    "implement",
    "learned",
    "import",
    "panda",
    "library",
    "first",
    "read",
    "data",
    "set",
    "look",
    "first",
    "five",
    "rows",
    "loan",
    "data",
    "set",
    "go",
    "load",
    "data",
    "set",
    "need",
    "go",
    "every",
    "feature",
    "understand",
    "features",
    "mean",
    "try",
    "identify",
    "interaction",
    "feature",
    "would",
    "useful",
    "model",
    "taken",
    "two",
    "examples",
    "notebook",
    "first",
    "since",
    "trying",
    "predict",
    "person",
    "given",
    "loan",
    "apart",
    "person",
    "income",
    "income",
    "spouse",
    "could",
    "potentially",
    "important",
    "factor",
    "data",
    "set",
    "two",
    "features",
    "applicant",
    "income",
    "applicant",
    "income",
    "see",
    "add",
    "two",
    "get",
    "total",
    "going",
    "go",
    "ahead",
    "print",
    "first",
    "five",
    "rows",
    "go",
    "add",
    "perfectly",
    "visible",
    "total",
    "underscore",
    "income",
    "column",
    "awesome",
    "create",
    "another",
    "feature",
    "loan",
    "income",
    "ratio",
    "dividing",
    "loan",
    "amount",
    "applicant",
    "income",
    "let",
    "go",
    "ahead",
    "perfect",
    "loan",
    "income",
    "ratio",
    "column",
    "created",
    "entirely",
    "new",
    "feature",
    "love",
    "feature",
    "engineering",
    "one",
    "awesome",
    "aspects",
    "data",
    "scientist",
    "role",
    "manner",
    "seen",
    "would",
    "encourage",
    "go",
    "ahead",
    "take",
    "data",
    "set",
    "think",
    "whatever",
    "features",
    "come",
    "multiple",
    "ones",
    "guarantee",
    "spend",
    "10",
    "minutes",
    "wondering",
    "features",
    "create",
    "come",
    "least",
    "20",
    "25",
    "new",
    "ones",
    "video",
    "generate",
    "features",
    "based",
    "available",
    "missing",
    "values",
    "let",
    "say",
    "data",
    "exploration",
    "data",
    "set",
    "find",
    "column",
    "smoking",
    "uncore",
    "status",
    "large",
    "number",
    "missing",
    "values",
    "first",
    "intuition",
    "might",
    "delete",
    "column",
    "missing",
    "values",
    "data",
    "might",
    "pattern",
    "fact",
    "quite",
    "lot",
    "times",
    "tend",
    "useful",
    "instance",
    "case",
    "missing",
    "value",
    "column",
    "might",
    "indicate",
    "person",
    "smoke",
    "actually",
    "reluctant",
    "say",
    "mean",
    "sure",
    "lot",
    "us",
    "relate",
    "hence",
    "create",
    "separate",
    "column",
    "indicates",
    "whether",
    "row",
    "missing",
    "value",
    "might",
    "chance",
    "missing",
    "value",
    "random",
    "hidden",
    "information",
    "variable",
    "capture",
    "information",
    "see",
    "created",
    "column",
    "called",
    "smoking",
    "uncore",
    "status",
    "n",
    "one",
    "place",
    "smoking",
    "status",
    "missing",
    "impute",
    "missing",
    "values",
    "like",
    "always",
    "let",
    "move",
    "jupyter",
    "notebook",
    "implement",
    "method",
    "going",
    "use",
    "stroke",
    "prediction",
    "data",
    "set",
    "going",
    "go",
    "ahead",
    "import",
    "libraries",
    "uh",
    "load",
    "data",
    "set",
    "first",
    "fire",
    "rows",
    "already",
    "looked",
    "going",
    "going",
    "use",
    "isal",
    "su",
    "functions",
    "look",
    "number",
    "missing",
    "values",
    "variable",
    "go",
    "see",
    "bmi",
    "smoking",
    "status",
    "variables",
    "ton",
    "missing",
    "value",
    "especially",
    "smoking",
    "status",
    "next",
    "cod",
    "line",
    "creating",
    "new",
    "variable",
    "smoking",
    "status",
    "ne",
    "store",
    "one",
    "missing",
    "value",
    "zero",
    "missing",
    "values",
    "go",
    "ahead",
    "implement",
    "look",
    "first",
    "five",
    "rows",
    "two",
    "variables",
    "perfect",
    "one",
    "remember",
    "missing",
    "value",
    "smoking",
    "status",
    "confirms",
    "yes",
    "indeed",
    "missing",
    "value",
    "zero",
    "means",
    "missing",
    "values",
    "confirm",
    "smoking",
    "status",
    "variable",
    "create",
    "new",
    "features",
    "using",
    "missing",
    "values",
    "pretty",
    "intuitive",
    "straightforward",
    "video",
    "cover",
    "another",
    "commonly",
    "used",
    "feature",
    "generation",
    "method",
    "called",
    "frequency",
    "encoding",
    "categorical",
    "variables",
    "often",
    "used",
    "data",
    "science",
    "competitions",
    "proved",
    "work",
    "really",
    "well",
    "even",
    "helped",
    "quite",
    "lot",
    "times",
    "let",
    "understand",
    "categorical",
    "variable",
    "workor",
    "type",
    "determine",
    "frequency",
    "categories",
    "variable",
    "normalize",
    "values",
    "idea",
    "essentially",
    "category",
    "higher",
    "frequency",
    "would",
    "course",
    "higher",
    "number",
    "hence",
    "get",
    "importance",
    "example",
    "suppose",
    "insurance",
    "company",
    "various",
    "products",
    "given",
    "information",
    "selling",
    "product",
    "case",
    "frequency",
    "count",
    "help",
    "us",
    "give",
    "implicit",
    "information",
    "model",
    "using",
    "frequency",
    "encoding",
    "let",
    "python",
    "give",
    "better",
    "idea",
    "frequency",
    "encoding",
    "works",
    "let",
    "spend",
    "time",
    "understanding",
    "implement",
    "frequency",
    "en",
    "coding",
    "python",
    "going",
    "import",
    "panda",
    "library",
    "first",
    "let",
    "go",
    "bigm",
    "sales",
    "data",
    "variable",
    "item",
    "type",
    "see",
    "column",
    "going",
    "apply",
    "frequency",
    "encoding",
    "variable",
    "look",
    "frequency",
    "categories",
    "variable",
    "clearly",
    "see",
    "fruits",
    "vegetables",
    "highest",
    "frequency",
    "followed",
    "snack",
    "foods",
    "going",
    "go",
    "ahead",
    "store",
    "item",
    "type",
    "count",
    "variable",
    "called",
    "temp",
    "go",
    "perfect",
    "create",
    "new",
    "variable",
    "item",
    "type",
    "count",
    "using",
    "dot",
    "apply",
    "function",
    "apply",
    "function",
    "works",
    "like",
    "seen",
    "check",
    "item",
    "type",
    "every",
    "single",
    "row",
    "given",
    "category",
    "item",
    "type",
    "return",
    "frequency",
    "value",
    "temp",
    "variable",
    "created",
    "going",
    "go",
    "ahead",
    "run",
    "perfect",
    "got",
    "item",
    "type",
    "count",
    "item",
    "type",
    "da",
    "682",
    "instances",
    "meet",
    "425",
    "like",
    "performed",
    "frequency",
    "encoding",
    "another",
    "commonly",
    "used",
    "method",
    "called",
    "mean",
    "encoding",
    "often",
    "done",
    "using",
    "target",
    "variable",
    "item",
    "type",
    "variable",
    "going",
    "use",
    "target",
    "variable",
    "sales",
    "let",
    "print",
    "first",
    "five",
    "rows",
    "go",
    "category",
    "item",
    "type",
    "calculate",
    "mean",
    "sales",
    "training",
    "data",
    "go",
    "shows",
    "us",
    "variable",
    "item",
    "type",
    "highest",
    "sales",
    "brilliant",
    "way",
    "understanding",
    "different",
    "item",
    "types",
    "revenue",
    "bringing",
    "created",
    "new",
    "feature",
    "analyze",
    "lot",
    "things",
    "bigart",
    "sales",
    "data",
    "set",
    "using",
    "function",
    "covered",
    "feature",
    "engineering",
    "numerical",
    "categorical",
    "variable",
    "far",
    "video",
    "focusing",
    "datetime",
    "variable",
    "learn",
    "generate",
    "information",
    "datetime",
    "column",
    "interesting",
    "concept",
    "think",
    "examp",
    "examples",
    "find",
    "time",
    "variable",
    "data",
    "set",
    "top",
    "head",
    "suppose",
    "particular",
    "hotel",
    "collecting",
    "data",
    "past",
    "bookings",
    "want",
    "predict",
    "number",
    "room",
    "bookings",
    "upcoming",
    "month",
    "data",
    "set",
    "problem",
    "statement",
    "would",
    "features",
    "like",
    "booking",
    "id",
    "booking",
    "date",
    "time",
    "booking",
    "kind",
    "room",
    "booked",
    "number",
    "days",
    "nights",
    "booked",
    "number",
    "people",
    "stayed",
    "room",
    "etc",
    "mean",
    "lot",
    "variables",
    "factor",
    "two",
    "datetime",
    "features",
    "booking",
    "date",
    "booking",
    "time",
    "another",
    "example",
    "predicting",
    "price",
    "flight",
    "particular",
    "airline",
    "imagine",
    "price",
    "would",
    "higher",
    "time",
    "vacation",
    "weekend",
    "lower",
    "non",
    "holiday",
    "seasons",
    "possible",
    "factors",
    "affect",
    "price",
    "flight",
    "ticket",
    "could",
    "come",
    "time",
    "arrival",
    "departure",
    "flight",
    "source",
    "destination",
    "also",
    "date",
    "travel",
    "season",
    "holiday",
    "season",
    "also",
    "important",
    "factor",
    "three",
    "datetime",
    "based",
    "features",
    "date",
    "travel",
    "time",
    "arrival",
    "departure",
    "note",
    "using",
    "time",
    "departure",
    "time",
    "arrival",
    "determine",
    "travel",
    "duration",
    "flight",
    "well",
    "another",
    "example",
    "common",
    "one",
    "could",
    "stock",
    "market",
    "analysis",
    "date",
    "course",
    "utmost",
    "importance",
    "using",
    "date",
    "find",
    "pattern",
    "increase",
    "decrease",
    "price",
    "instance",
    "closing",
    "price",
    "mondays",
    "low",
    "fridays",
    "vice",
    "versa",
    "well",
    "understand",
    "number",
    "problems",
    "datetime",
    "feature",
    "let",
    "see",
    "valuable",
    "information",
    "extract",
    "datetime",
    "var",
    "tabls",
    "using",
    "date",
    "determine",
    "day",
    "week",
    "monday",
    "wednesday",
    "also",
    "find",
    "day",
    "weekday",
    "weekend",
    "guess",
    "information",
    "would",
    "important",
    "well",
    "recall",
    "example",
    "flight",
    "ticket",
    "price",
    "discussed",
    "moments",
    "ago",
    "ticket",
    "price",
    "would",
    "considerably",
    "higher",
    "weekends",
    "weekdays",
    "see",
    "fifth",
    "also",
    "determine",
    "day",
    "national",
    "holiday",
    "simply",
    "looking",
    "date",
    "feature",
    "would",
    "useful",
    "work",
    "problems",
    "like",
    "predicting",
    "flight",
    "price",
    "number",
    "bookings",
    "hotel",
    "using",
    "date",
    "also",
    "extract",
    "month",
    "example",
    "flight",
    "ticket",
    "price",
    "might",
    "higher",
    "december",
    "since",
    "close",
    "christmas",
    "summer",
    "vacations",
    "fall",
    "june",
    "number",
    "room",
    "bookings",
    "hotel",
    "month",
    "could",
    "see",
    "significant",
    "rise",
    "similarly",
    "determine",
    "year",
    "given",
    "date",
    "instance",
    "given",
    "data",
    "past",
    "five",
    "say",
    "10",
    "years",
    "recent",
    "values",
    "would",
    "usually",
    "given",
    "importance",
    "considering",
    "time",
    "feature",
    "determine",
    "r",
    "time",
    "variable",
    "useful",
    "well",
    "price",
    "flight",
    "tickets",
    "odd",
    "hours",
    "like",
    "1",
    "usually",
    "significantly",
    "lower",
    "r",
    "value",
    "create",
    "features",
    "like",
    "morning",
    "afternoon",
    "evening",
    "midnight",
    "instance",
    "trying",
    "predict",
    "sales",
    "product",
    "retail",
    "outlet",
    "would",
    "peak",
    "hours",
    "right",
    "way",
    "determine",
    "first",
    "second",
    "half",
    "day",
    "also",
    "calculate",
    "difference",
    "time",
    "like",
    "calculating",
    "light",
    "duration",
    "goes",
    "dates",
    "calculating",
    "days",
    "stay",
    "hotel",
    "calculating",
    "age",
    "person",
    "using",
    "date",
    "birth",
    "today",
    "date",
    "date",
    "hoshi",
    "applied",
    "loan",
    "application",
    "insurance",
    "lot",
    "features",
    "create",
    "using",
    "date",
    "variable",
    "apart",
    "features",
    "discussed",
    "see",
    "lot",
    "additional",
    "features",
    "day",
    "week",
    "day",
    "year",
    "week",
    "year",
    "mean",
    "lot",
    "variables",
    "table",
    "shows",
    "list",
    "features",
    "extract",
    "datetime",
    "column",
    "taken",
    "panda",
    "documentation",
    "shared",
    "link",
    "video",
    "apart",
    "features",
    "already",
    "discussed",
    "see",
    "lot",
    "features",
    "like",
    "day",
    "year",
    "week",
    "year",
    "essentially",
    "represent",
    "day",
    "number",
    "365",
    "week",
    "number",
    "52",
    "total",
    "weeks",
    "year",
    "using",
    "date",
    "also",
    "find",
    "month",
    "start",
    "month",
    "end",
    "quarter",
    "start",
    "quarter",
    "end",
    "year",
    "leap",
    "year",
    "see",
    "sheer",
    "amount",
    "insight",
    "generate",
    "let",
    "look",
    "example",
    "predict",
    "amount",
    "no2",
    "nitrogen",
    "dioxide",
    "air",
    "given",
    "day",
    "time",
    "use",
    "date",
    "time",
    "variable",
    "want",
    "pause",
    "video",
    "think",
    "second",
    "proceed",
    "no2",
    "primarily",
    "gets",
    "air",
    "burning",
    "fuel",
    "no2",
    "forms",
    "emissions",
    "cars",
    "trucks",
    "buses",
    "power",
    "plants",
    "offro",
    "equipment",
    "intuitively",
    "higher",
    "amount",
    "expect",
    "see",
    "morning",
    "say",
    "7",
    "evening",
    "5",
    "people",
    "generally",
    "travel",
    "office",
    "work",
    "vice",
    "versa",
    "also",
    "afternoon",
    "no2",
    "reacts",
    "sunlight",
    "form",
    "night",
    "reaction",
    "take",
    "place",
    "let",
    "one",
    "thing",
    "let",
    "jump",
    "jupyter",
    "notebook",
    "spend",
    "moments",
    "working",
    "data",
    "set",
    "give",
    "better",
    "idea",
    "covered",
    "video",
    "notebook",
    "go",
    "example",
    "saw",
    "slides",
    "let",
    "go",
    "ahead",
    "read",
    "data",
    "see",
    "dates",
    "first",
    "column",
    "no2",
    "content",
    "second",
    "column",
    "look",
    "different",
    "data",
    "types",
    "two",
    "variables",
    "date",
    "time",
    "see",
    "read",
    "object",
    "data",
    "type",
    "right",
    "first",
    "important",
    "step",
    "dealing",
    "date",
    "time",
    "column",
    "convert",
    "data",
    "type",
    "date",
    "time",
    "default",
    "see",
    "taken",
    "object",
    "give",
    "us",
    "pretty",
    "random",
    "results",
    "use",
    "pandas",
    "pd",
    "2or",
    "datetime",
    "function",
    "give",
    "column",
    "name",
    "format",
    "input",
    "format",
    "depends",
    "structure",
    "date",
    "column",
    "date",
    "month",
    "year",
    "followed",
    "r",
    "minutes",
    "seconds",
    "let",
    "print",
    "look",
    "data",
    "types",
    "perfect",
    "examples",
    "different",
    "uh",
    "let",
    "print",
    "maximum",
    "minimum",
    "values",
    "date",
    "time",
    "column",
    "get",
    "minimum",
    "uh",
    "10th",
    "march",
    "2004",
    "first",
    "row",
    "data",
    "set",
    "verify",
    "end",
    "max",
    "value",
    "see",
    "actually",
    "last",
    "value",
    "data",
    "set",
    "use",
    "data",
    "frame",
    "tail",
    "function",
    "right",
    "data",
    "frame",
    "tail",
    "let",
    "see",
    "features",
    "extract",
    "column",
    "first",
    "extract",
    "r",
    "minute",
    "values",
    "simply",
    "using",
    "command",
    "column",
    "name",
    "dt",
    "r",
    "let",
    "look",
    "first",
    "five",
    "values",
    "go",
    "r",
    "18",
    "would",
    "600",
    "7",
    "also",
    "extract",
    "minutes",
    "let",
    "print",
    "zero",
    "6",
    "go",
    "entire",
    "data",
    "set",
    "understand",
    "detail",
    "also",
    "extract",
    "day",
    "whether",
    "monday",
    "wednesday",
    "using",
    "column",
    "name",
    "dt",
    "day",
    "week",
    "print",
    "think",
    "two",
    "three",
    "means",
    "well",
    "gives",
    "us",
    "number",
    "zero",
    "monday",
    "six",
    "sunday",
    "want",
    "get",
    "name",
    "use",
    "week",
    "daycore",
    "name",
    "instead",
    "day",
    "week",
    "print",
    "go",
    "get",
    "month",
    "use",
    "dt",
    "month",
    "function",
    "print",
    "go",
    "third",
    "month",
    "year",
    "similarly",
    "determine",
    "year",
    "using",
    "dt",
    "ear",
    "something",
    "additionally",
    "also",
    "find",
    "given",
    "date",
    "end",
    "month",
    "end",
    "year",
    "using",
    "dt",
    "isore",
    "monore",
    "end",
    "none",
    "dates",
    "least",
    "first",
    "seven",
    "rows",
    "end",
    "month",
    "always",
    "try",
    "features",
    "fact",
    "strongly",
    "recommend",
    "taking",
    "data",
    "set",
    "data",
    "set",
    "datetime",
    "feature",
    "experimenting",
    "around",
    "using",
    "learned",
    "exploring",
    "things",
    "datetime",
    "values",
    "learn",
    "new",
    "things",
    "finally",
    "going",
    "going",
    "bring",
    "learned",
    "far",
    "together",
    "create",
    "new",
    "data",
    "frame",
    "called",
    "newor",
    "df",
    "using",
    "pd",
    "dataframe",
    "function",
    "first",
    "column",
    "ear",
    "stores",
    "year",
    "date",
    "month",
    "day",
    "hour",
    "basically",
    "seen",
    "also",
    "additional",
    "quarter",
    "put",
    "together",
    "new",
    "data",
    "frame",
    "print",
    "go",
    "new",
    "features",
    "created",
    "cool",
    "add",
    "features",
    "right",
    "back",
    "original",
    "data",
    "frame",
    "using",
    "pd",
    "concat",
    "function",
    "basically",
    "concatenation",
    "new",
    "data",
    "set",
    "amazing",
    "date",
    "unor",
    "time",
    "no2",
    "started",
    "sorts",
    "useful",
    "variables",
    "got",
    "love",
    "feature",
    "engineering",
    "far",
    "discussed",
    "features",
    "directly",
    "create",
    "using",
    "pandas",
    "additional",
    "features",
    "might",
    "want",
    "add",
    "data",
    "like",
    "whether",
    "given",
    "date",
    "weekday",
    "weekend",
    "since",
    "able",
    "extract",
    "day",
    "week",
    "check",
    "weekend",
    "using",
    "value",
    "code",
    "created",
    "new",
    "column",
    "called",
    "isore",
    "weekday",
    "run",
    "loop",
    "check",
    "value",
    "row",
    "day",
    "week",
    "five",
    "six",
    "value",
    "zero",
    "otherwise",
    "one",
    "one",
    "meaning",
    "weekday",
    "zero",
    "course",
    "meaning",
    "weekend",
    "going",
    "go",
    "ahead",
    "run",
    "computationally",
    "heavy",
    "loop",
    "give",
    "couple",
    "minutes",
    "run",
    "look",
    "first",
    "five",
    "rows",
    "new",
    "data",
    "frame",
    "go",
    "day",
    "week",
    "2",
    "isore",
    "week",
    "day",
    "one",
    "one",
    "remember",
    "weekday",
    "clearly",
    "loop",
    "worked",
    "pretty",
    "well",
    "first",
    "five",
    "rows",
    "course",
    "look",
    "entire",
    "data",
    "set",
    "verify",
    "values",
    "assure",
    "loop",
    "worked",
    "perfection",
    "also",
    "determine",
    "difference",
    "two",
    "dates",
    "example",
    "taken",
    "new",
    "data",
    "set",
    "read",
    "two",
    "columns",
    "application",
    "date",
    "date",
    "birth",
    "applicant",
    "application",
    "receipt",
    "date",
    "applicant",
    "birth",
    "date",
    "quickly",
    "print",
    "head",
    "two",
    "columns",
    "easier",
    "use",
    "perfect",
    "using",
    "determine",
    "age",
    "applicant",
    "first",
    "need",
    "convert",
    "variables",
    "right",
    "datetime",
    "format",
    "let",
    "go",
    "ahead",
    "run",
    "right",
    "hit",
    "difference",
    "two",
    "variables",
    "days",
    "divide",
    "365",
    "get",
    "year",
    "row",
    "use",
    "apply",
    "function",
    "code",
    "might",
    "look",
    "bit",
    "complicated",
    "actually",
    "simple",
    "efficient",
    "row",
    "dot",
    "applyer",
    "returns",
    "difference",
    "two",
    "variables",
    "value",
    "returned",
    "function",
    "stored",
    "new",
    "variable",
    "calling",
    "applicant",
    "h",
    "going",
    "go",
    "ahead",
    "run",
    "perfect",
    "work",
    "datetime",
    "variable",
    "many",
    "things",
    "simple",
    "column",
    "mentioned",
    "earlier",
    "go",
    "ahead",
    "experiment",
    "time",
    "series",
    "data",
    "set",
    "analytics",
    "data",
    "hack",
    "platform",
    "go",
    "ahead",
    "use",
    "data",
    "set",
    "apply",
    "learned",
    "amazed",
    "accuracy",
    "get",
    "using",
    "simple",
    "datetime",
    "features",
    "way",
    "automate",
    "whole",
    "process",
    "creating",
    "new",
    "features",
    "yes",
    "library",
    "called",
    "feature",
    "tools",
    "library",
    "performing",
    "automated",
    "feature",
    "engineering",
    "let",
    "understand",
    "works",
    "three",
    "important",
    "components",
    "feature",
    "tools",
    "entities",
    "feature",
    "primitives",
    "deep",
    "feature",
    "synthesis",
    "thoroughly",
    "understand",
    "let",
    "take",
    "example",
    "data",
    "set",
    "one",
    "seen",
    "recognize",
    "big",
    "mar",
    "sales",
    "data",
    "set",
    "data",
    "set",
    "quite",
    "number",
    "items",
    "like",
    "item",
    "weight",
    "item",
    "type",
    "item",
    "mrp",
    "outlet",
    "identifier",
    "among",
    "things",
    "course",
    "last",
    "column",
    "item",
    "outlet",
    "sales",
    "target",
    "variable",
    "feature",
    "tools",
    "data",
    "set",
    "called",
    "entity",
    "one",
    "data",
    "frame",
    "multiple",
    "instance",
    "data",
    "set",
    "holds",
    "variables",
    "see",
    "red",
    "border",
    "like",
    "item",
    "identifier",
    "outlet",
    "type",
    "outlet",
    "size",
    "etc",
    "another",
    "data",
    "set",
    "contains",
    "details",
    "things",
    "like",
    "item",
    "weight",
    "fat",
    "content",
    "type",
    "scenario",
    "two",
    "data",
    "sets",
    "individual",
    "data",
    "sets",
    "would",
    "called",
    "entity",
    "entity",
    "basically",
    "single",
    "table",
    "data",
    "frame",
    "information",
    "entity",
    "entities",
    "stored",
    "entity",
    "set",
    "words",
    "say",
    "entity",
    "set",
    "collection",
    "tables",
    "let",
    "talk",
    "feature",
    "primitives",
    "remember",
    "studied",
    "feature",
    "transformations",
    "log",
    "square",
    "well",
    "feature",
    "aggregations",
    "like",
    "additions",
    "ratio",
    "previously",
    "well",
    "aggregations",
    "transformations",
    "called",
    "feature",
    "primitives",
    "examples",
    "various",
    "transformations",
    "aggregations",
    "implement",
    "using",
    "feature",
    "tools",
    "go",
    "ahead",
    "pause",
    "video",
    "second",
    "go",
    "list",
    "want",
    "following",
    "two",
    "features",
    "item",
    "weight",
    "item",
    "mrp",
    "bigm",
    "sales",
    "data",
    "set",
    "take",
    "sum",
    "difference",
    "multiplication",
    "limit",
    "even",
    "add",
    "variables",
    "example",
    "item",
    "weight",
    "item",
    "mrp",
    "plus",
    "item",
    "weight",
    "think",
    "limitless",
    "things",
    "using",
    "options",
    "beauty",
    "feature",
    "engineering",
    "also",
    "concept",
    "deep",
    "feature",
    "synthesis",
    "comes",
    "play",
    "deep",
    "feature",
    "synthesis",
    "stacks",
    "multiple",
    "transformation",
    "aggregation",
    "operations",
    "although",
    "feature",
    "tools",
    "able",
    "create",
    "mathematical",
    "features",
    "automatically",
    "one",
    "thing",
    "keep",
    "mind",
    "domain",
    "knowledge",
    "seen",
    "previously",
    "play",
    "critical",
    "role",
    "building",
    "better",
    "model",
    "would",
    "recommend",
    "using",
    "feature",
    "tools",
    "generating",
    "new",
    "features",
    "also",
    "focus",
    "domain",
    "understanding",
    "apply",
    "knowledge",
    "create",
    "domain",
    "specific",
    "features",
    "well",
    "let",
    "move",
    "notebook",
    "implement",
    "python",
    "notebook",
    "let",
    "go",
    "ahead",
    "understand",
    "feature",
    "tools",
    "implemented",
    "python",
    "run",
    "notebook",
    "need",
    "install",
    "feature",
    "tools",
    "library",
    "machine",
    "simply",
    "use",
    "one",
    "following",
    "command",
    "let",
    "go",
    "import",
    "feature",
    "tools",
    "library",
    "pandas",
    "right",
    "going",
    "working",
    "bigm",
    "sales",
    "data",
    "set",
    "load",
    "going",
    "store",
    "independent",
    "variables",
    "features",
    "variable",
    "target",
    "variable",
    "sales",
    "variable",
    "call",
    "right",
    "first",
    "create",
    "empty",
    "entity",
    "set",
    "using",
    "function",
    "entity",
    "set",
    "said",
    "name",
    "entity",
    "set",
    "big",
    "mar",
    "see",
    "course",
    "set",
    "name",
    "whatever",
    "see",
    "fit",
    "let",
    "run",
    "code",
    "block",
    "go",
    "add",
    "multiple",
    "entities",
    "entity",
    "set",
    "remember",
    "data",
    "frame",
    "entity",
    "example",
    "one",
    "data",
    "frame",
    "hence",
    "yes",
    "one",
    "entity",
    "cell",
    "add",
    "entity",
    "empty",
    "entity",
    "set",
    "created",
    "earlier",
    "using",
    "entity",
    "frommore",
    "data",
    "frame",
    "function",
    "name",
    "dataor",
    "one",
    "said",
    "use",
    "name",
    "add",
    "features",
    "independent",
    "variables",
    "entity",
    "set",
    "also",
    "uh",
    "need",
    "specify",
    "parameter",
    "index",
    "data",
    "set",
    "unique",
    "id",
    "row",
    "going",
    "go",
    "ahead",
    "run",
    "perfect",
    "right",
    "prepared",
    "data",
    "according",
    "feature",
    "tools",
    "time",
    "create",
    "new",
    "features",
    "use",
    "dfs",
    "function",
    "deep",
    "feature",
    "synthesis",
    "function",
    "returns",
    "two",
    "things",
    "newly",
    "created",
    "features",
    "storing",
    "feature",
    "uncore",
    "matrix",
    "feature",
    "definitions",
    "store",
    "feature",
    "deps",
    "function",
    "dfs",
    "give",
    "entity",
    "set",
    "target",
    "entity",
    "dataor",
    "1",
    "case",
    "target",
    "entity",
    "means",
    "parent",
    "data",
    "frame",
    "want",
    "perform",
    "feature",
    "engineering",
    "case",
    "multiple",
    "data",
    "frames",
    "pick",
    "one",
    "target",
    "entity",
    "specify",
    "function",
    "need",
    "perform",
    "features",
    "data",
    "set",
    "using",
    "transcore",
    "primitives",
    "parameter",
    "specified",
    "two",
    "add",
    "numeric",
    "multiply",
    "numeric",
    "basically",
    "add",
    "numerical",
    "variables",
    "multiply",
    "numeric",
    "variables",
    "set",
    "depth",
    "one",
    "understand",
    "maxor",
    "depth",
    "parameter",
    "moment",
    "run",
    "cell",
    "see",
    "new",
    "features",
    "added",
    "original",
    "entity",
    "let",
    "go",
    "go",
    "ahe",
    "right",
    "new",
    "variables",
    "starting",
    "engineered",
    "original",
    "entity",
    "let",
    "see",
    "complete",
    "list",
    "using",
    "feature",
    "undor",
    "deps",
    "code",
    "go",
    "complete",
    "list",
    "see",
    "sum",
    "two",
    "features",
    "see",
    "multiplication",
    "well",
    "two",
    "features",
    "possible",
    "combinations",
    "look",
    "shape",
    "see",
    "23",
    "variables",
    "started",
    "12",
    "created",
    "11",
    "new",
    "features",
    "look",
    "closely",
    "new",
    "feature",
    "created",
    "performing",
    "one",
    "operation",
    "either",
    "addition",
    "multiplication",
    "think",
    "set",
    "max",
    "underscore",
    "depth",
    "one",
    "one",
    "operation",
    "performed",
    "let",
    "experiment",
    "change",
    "depth",
    "two",
    "run",
    "cells",
    "right",
    "get",
    "sorts",
    "new",
    "features",
    "let",
    "look",
    "complete",
    "list",
    "using",
    "feature",
    "defs",
    "code",
    "see",
    "new",
    "features",
    "combination",
    "two",
    "operations",
    "using",
    "created",
    "50",
    "new",
    "features",
    "matter",
    "seconds",
    "incredible",
    "feature",
    "tools",
    "powerful",
    "library",
    "creating",
    "new",
    "features",
    "word",
    "caution",
    "features",
    "useful",
    "model",
    "keep",
    "mind",
    "using",
    "thank"
  ],
  "keywords": [
    "feature",
    "engineering",
    "one",
    "machine",
    "move",
    "ahead",
    "let",
    "take",
    "look",
    "covered",
    "far",
    "used",
    "data",
    "model",
    "basically",
    "function",
    "learn",
    "relationship",
    "variable",
    "independent",
    "variables",
    "instance",
    "like",
    "linear",
    "regression",
    "decision",
    "tree",
    "1",
    "2",
    "essentially",
    "similarly",
    "multiple",
    "find",
    "might",
    "note",
    "methods",
    "worked",
    "given",
    "existing",
    "add",
    "able",
    "better",
    "two",
    "first",
    "new",
    "features",
    "information",
    "example",
    "predict",
    "sales",
    "say",
    "using",
    "need",
    "next",
    "10",
    "days",
    "case",
    "list",
    "help",
    "etc",
    "value",
    "us",
    "see",
    "actually",
    "another",
    "way",
    "generate",
    "want",
    "whether",
    "loan",
    "birth",
    "year",
    "income",
    "date",
    "age",
    "ratio",
    "right",
    "also",
    "use",
    "continuous",
    "divide",
    "categories",
    "different",
    "low",
    "high",
    "seen",
    "called",
    "useful",
    "problem",
    "knowledge",
    "domain",
    "understanding",
    "statement",
    "well",
    "various",
    "type",
    "time",
    "categorical",
    "small",
    "interesting",
    "titanic",
    "prediction",
    "bigm",
    "think",
    "create",
    "set",
    "problems",
    "go",
    "understand",
    "works",
    "techniques",
    "examples",
    "saw",
    "item",
    "identifier",
    "column",
    "number",
    "unique",
    "even",
    "rows",
    "three",
    "fd",
    "values",
    "lot",
    "read",
    "would",
    "count",
    "child",
    "total",
    "person",
    "name",
    "missing",
    "numerical",
    "based",
    "types",
    "working",
    "deal",
    "video",
    "generation",
    "creating",
    "category",
    "simply",
    "transform",
    "created",
    "size",
    "start",
    "perform",
    "method",
    "transformation",
    "log",
    "square",
    "root",
    "important",
    "plot",
    "target",
    "skewed",
    "distribution",
    "could",
    "things",
    "zero",
    "simple",
    "python",
    "notebook",
    "course",
    "last",
    "columns",
    "weight",
    "visibility",
    "mrp",
    "going",
    "try",
    "check",
    "store",
    "implement",
    "discussed",
    "run",
    "get",
    "minimum",
    "0",
    "every",
    "scale",
    "code",
    "range",
    "scaling",
    "amount",
    "bring",
    "max",
    "scaler",
    "standard",
    "determine",
    "maximum",
    "difference",
    "second",
    "mean",
    "apply",
    "learned",
    "import",
    "pandas",
    "work",
    "library",
    "perfect",
    "frame",
    "uncore",
    "print",
    "hot",
    "encoding",
    "remember",
    "outlet",
    "medium",
    "row",
    "order",
    "label",
    "five",
    "12",
    "single",
    "dot",
    "four",
    "since",
    "pd",
    "give",
    "done",
    "hence",
    "idea",
    "cities",
    "combine",
    "classes",
    "frequency",
    "loop",
    "uh",
    "stroke",
    "bins",
    "bin",
    "cut",
    "binning",
    "edges",
    "group",
    "applicant",
    "higher",
    "smoking",
    "status",
    "datetime",
    "month",
    "booking",
    "price",
    "flight",
    "weekend",
    "extract",
    "day",
    "week",
    "weekday",
    "r",
    "end",
    "no2",
    "dt",
    "tools",
    "entity"
  ]
}