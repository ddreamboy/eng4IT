{
  "text": "hi everyone my name is B Hamed and\nwelcome to this video so guys in this\nvideo we'll be learning the data\npreprocessing part uh in our previous\nvideo I already discussed about end to\nend gener TBI pipeline so there I told\nyou what is the use of data\npre-processing right because if you want\nto use the model that means large\nlanguage model the first thing you have\nto do the data P processing Because\nunless and until you are not processing\nthe data how your model will try to\nunderstand that one right that is the\nidea so here we'll be learning various\nkinds of technique uh to clean up about\ndata so for this what I have done I have\ncreated a beautiful uh collab notebook\nso there actually I have uh added all\nthe examples you can uh use for the data\ncleanup operation so guys now let's try\nto see how we can do the data\npreprocessing part so guys as you can\nsee this is The Notebook I already\nprepared so here you can see I'm using\none data set from Kagel so let me open\nthe\nlink um this is the link so the data set\nname is IMDb uh data set and it is\nhaving actually 50k uh movie reviews\nokay 50k actually movie reviews if you\nare already from let's say machine\nlearning deep learning background I\nthink you know about this data set right\nit's like very common data set and why I\ntook this particular data set because in\nthis data set you will see uh there are\nso many U actually unnecessary text okay\nbecause it's a movie review so what they\ndid actually they extracted they scra\nthis data from the IMDb website if you\ndon't know this is the IMDB website IMDb\nso in this website you will see uh all\nthe movies reviews and rating and what\nthey did actually they published this\ndata set in the Kagel website so that if\nanyone is working in the field of let's\nsay genit tvi or natural language\nprocessing they can use the data set now\nhere what you just need to do you just\nneed to download this data okay it's\naround uh I think 27 MB just click on\ndownload button it will download okay so\nI already downloaded this data set so it\nis available inside my download folder\nso I'm going to upload in my collab\nnotebook so here first of all what you\nhave to do you have to connect this\nparticular notebook so there is a\nconnect button just try to connect and\nno need to worry I will also share this\nnotebook Link in the resources section\nfrom there you can open it up so my\nnotebook is connected so first of all\nlet's import uh some of the library\nfirst of all I need something called\npandas because if you see the data uh\nit's a csb data okay it's a csb data so\nlet me upload and let me show you so if\nyou want to upload anything in the\nGoogle Drive just try to right click and\nthere is a upload button click on upload\nand try to upload this data\nhere now see it's a CSV file okay and if\nI want to load any kinds of CSV file\nJson file or let's Excel file whatever\nfile you can use the pandas package for\nthat so you can see my data set is\nupload it now if I want to load the data\nset what I have to do I have to assign\nthe path and see you don't need to\nexecute deser the code because uh this\ncode I have added let's say if your data\nset is available in your Google Drive\nthat time what you have to do you have\nto Mount Your Google Drive first of all\nMount means you will be connecting with\nyour Google Drive then we'll be\nrelocating the folder okay like inside\nwhich folder you kept your data okay\nwith the the help of CD command CD means\nchange directory okay then after that\nwhat you will do he will assign the data\npath but here I haven't kept my data\ninside my Google Drive I kept inside my\ncollab actually you can see drive this\nis the collab di I'm using here you will\nget around 74 GB of space so here you\nalso can keep your data so I don't need\nto execute this code what I will do I'll\njust go below and if I check my current\nworking directory that means PWD you'll\nsee I'm inside content content means\nthis is the directory right now now here\nI'll just simply Define my data path\nI'll copy the path copy and let me paste\nit here okay that's it now let me\nexecute now see if I now load the data\npd. csb I'm doing so now see it will\nload the data see it has loaded the data\nif you want to see the shape of the data\nthis is the shape okay you have around\n50 uh 50k actually movies movies reviews\nin this particular csb file and two\ncolumns two columns means is the reviews\ncolumn other is like the sentiment\ncolumn okay sentiment means whether it's\na positive sentiment whether it's a\nnegative sentiment this kinds of\nsentiment you will get here I hope it is\nclear now see here I'm having 50k movie\nreviews but here I'm not going to use\nall the reviews here I'm going to show\nyou the demo like how we can perform the\ntext preprocessing and if I'm taking all\nthe 50k reviews so it will take like\nlots of time um to process those are the\ntext so what I will do I'll only take\nthe 100 example okay the first 100\nexample I I'll be taking and on top of\nthat I will perform all the text\nprocessing task right so this is the\ncode you can execute so it will load 100\nexample now if I show you the shape see\nnow we are having 100 example and only\ntwo columns fine now if I want to show\nyou the data see this is the data so I\nthink you remember in my uh theoretical\nclass I was discussing about some\npre-processing technique uh here I think\nH so here you can perform something\ncalled HTML tag removal Emoji handle art\nthen spelling correction then in the\nbasic preprocessing we saw that we can\nperform something called tokenization\nthen we had some optional pre-processing\nas well like stop word streaming LZ pun\nCH lower case Okay language detection\neach and everything so first thing we'll\nbe learning how we can perform the lower\ncase operation and why lower case\nimportant I already explained here I\nthink you remember let's say let's say\nif one of the name is containing\nuppercase character it will consider\nthese are actually separate name okay\nthese are actually separate entity that\nis the idea so that's how we have to\nbring everything in a lowercase\ncharacter so that's why you have to\napply this lower operation and how to\nperform lower operation I think you\nalready know in Python we are having a\nfunction called Lower with the help of\nlower also we can do it right now see\nhere let me show you one example let's\nsay I'm taking the reviews three so here\nI'm taking the three three three number\nrows this is the three number rows now\nyou can see some of the uh character is\nuppercase character here so this is\nuppercase this is uppercase okay so\nthat's how actually you will see\ndifferent different uppercase character\nwould be there now if I want to make\nthem lower case what I have to do first\nof all I have to select my column like\nin which column you have to apply the\nlower function I have to apply on top of\nmy review column now first of all I'm\nconverting everything to the string okay\nstring data type then I'm applying the\nlower because lower is a string method\nokay lower is a string method I think\nyou already know that then whatever\nchanges actually I'm doing I'm saving\ninside my column that means I'm just\ndoing the permanent change okay inside\nmy column so that's why I have given\nreview again that is the idea now if I\nexecute now see if I show you the data\nnow see guys all the character has\nbecome lower case right now now if I\nwant to show you the now if I again\nexecute that review three you'll see\nthat all the character has converted to\nthe lowercase character okay that is the\nidea now the next thing we'll be\nlearning how we can handle the HTML tags\nthat means how we can remove the HTML\ntags for this here I have written a\nfunction here I'm using something called\nregular expression regx okay so inside\nregx you can give a pattern let's say\nhere you are giving a pattern if you're\nare getting this kinds of symbol okay if\nyou are getting these kinds of symbol\nit's a like HTML tag you have to remove\nthose HTML tags and you have to replace\nwith empty okay empty string that is the\nidea now this is the function we can use\nnow if I execute now let's say this is a\none text I have prepared you can see in\nthis text actually we are having lots of\nHTML tags now if I pass this particular\ntext to my function see it will\nautomatically remove all the tags now\nsee I'm only getting the text okay\nrelevant text that is the idea so this\nnotebook I prepared in such a way so\nthat you can use it as a template let's\nsay whenever you need anything any kinds\nof functionality you can come here you\ncan copy those function so please try to\nkeep this particular notebook with you\nbecause this is is going to help you a\nlot okay whenever you'll be developing\nthe projects this is going to help you a\nlot now if you want to apply on top of\nthe entire data set again just call this\ncolumn name let's say review column okay\nand there is a function called apply and\ninside that just try to pass this\nfunction okay apply function takes\nactually uh one function object now here\nI'm giving the function object so what\nit will do it will try to apply this\nparticular function on top of the entire\nuh rows you are having in your data set\nokay now see if I execute and and the\nchanges actually I'm doing I'm saving\neverything permanent okay now let me\nexecute now if I show you any kinds of\nrandom let's AR row now you'll see all\nthe uh now let's see if I also show you\num seven okay seven number rows now\nlet's try to see there is no HTML tags\nin this particular text you can pick up\nany kinds of let's say index let's say\nif I show you the\n10 nowhere you will see the HTML tags\nhere now we'll be learning how we can\nremove actually URL let's say if you are\nhaving some URL in the text how we and\nremove it for this again I'm using\nregular expression and there is a\npattern I have given if you are getting\nthese kinds of let's say a word HTTP\nthen slash then ww that means it is a\nURL and you have to remove the URL with\nthe empty string okay this is the\nfunction now let me execute now here I\nhave just mentioned some of the URL so\nthis is my YouTube channel URL this is\nmy LinkedIn URL and google.com and\nkaggle.com okay now these are the text I\nprepared one by one now let's say if I'm\npassing any kinds of text inside my\nremove URL function it will remove that\nUR URL let me show you see I'm giving\nthe text to that means my LinkedIn URL\nnow you can see check out my LinkedIn I\nhope it is clear see again I'm telling\nyou it's not a mandatory things let's\nsay you need URL in your data at that\ntime you can keep it let's say you need\nactually HTML tags you can keep it but\nif you don't need it you can remove it\nbecause I already told you uh nowadays\nactually we are having Advanced genv\napplication it also supports all kinds\nof text like emojis HTML okay everything\nit supports so if you're are creating\nthese kinds of advanc let say u i mean\napplication that time you need these\nother data you don't need to remove it\nokay but sometimes actually you also\nneed to remove this data set so that's\nwhy I'm showing you how you can remove\nit and if you want to keep it you can\nalso keep it it's up to you okay you\nhave to decide based on your project\narchitecture that time this is the idea\nnow we'll be learning how we can handle\nthe punctuation so if you want to see\nthe punctuation so there is a string\npackage you can use now if you just\nwrite string. punctuation you will see\nall kinds of punctuations are available\nnow what I have done I just stor these\nare the fation in a variable called\nexclude now here I have written a\nfunction okay here I've written a\nfunction called remove punctuation and\nhere I've written a for Loop so I'm just\nlooping through this punctuation one by\none and user is giving the text and I'm\njust checking whether if there is any\npunctuation okay I'm just replacing with\nthe empty string now let me show you how\nit will work now let's say this is one\ntext string with a punctuation you can\nsee there are so many punctuation I have\nassigned now if I pass this particular\ntext to my punctuation functions it will\nremove the punctuation now see there is\nno punctuation right now even I'm also\ncalculating the time like how much time\nit is taking to remove the punctuation\nbecause there is another way you can\nfollow to remove the punctuation I'll\ntell you how you can do it see this is\nthe function guys uh so here you can use\nsomething called text. translate inside\nthat just try to use this particular\nfunction okay make translate and inside\nthat just try to mention the punctuation\nso what it will do it will uh take your\ntext and it will remove all the funu so\nthis is another approach now see if I\ncalculate the time of this function you\nwill see that this is the time that\nmeans this function is taking less time\nthan your this function because here you\nare using one for Loop and for Loop has\nthe linear time complexity I think you\nknow that if you are familiar with DSA\nconcept I you know that it is having\nlinear time time complexity okay so this\nparticular approach is good let's say if\nyou are applying this particular Logic\non top of 50k data set just try to think\nhow much time it will take this full\nloop and in other hand if you're using\nthis particular method it will take very\nless time to perform the operation now\nif you want to see the time difference\nyou can also see the time difference now\nif I show you\nmy uh text now see inside this text\nactually I'm having lots of punctuation\nnow what I will do I will use my uh\nremove function one that means this\nparticular function and inside that I'm\ngoing to pass my entire review now see\nit will remove the punctuation okay see\nall the function has been removed now\nyou can also pass the entire data like\nthat you can also pass the entire data\nit will remove all the punctuation\ninside your entire data now we'll be\nlearning how we can handle the chat\nconversation see sometimes whenever we\nfrom the chatting operation we give uh\nlike lots of shortcut let's say if I\nwant to write as far as I know what you\nwill give you will give AF a ik then\nlet's say away from keyboard AFK then as\nsoon as possible ASAP that's how we use\nlots of chat keyword okay we use lots of\nchat shortcut keyword okay here I have\nlisted down some of them you can see for\nyour information FYI so that's how I\nhave listed all the chat conversation\nshort uh word now let's say you are\nworking with actually social media data\nset in social media data set you will\nsee these kinds of data a lot people\nwill be using short form okay short form\nso how we can handle this particular\nshort form for this first of all try to\ncreate a dictionary like that the entire\ndictionary you have to create then after\nthat here I've written a function so\nthis is the function chat conversation\nhandle so inside that I'm just taking\nthe text okay I'm just taking the text\nand I'm checking and inside that with\nthe help of this full loop I'm checking\nif we are having these kinds of word\nokay if you're having these kinds of\nword what we doing we're just mapping\nwith the value that means let's say if\nanyone having actually this particular\nlet's say shortcut word let's say FYI\nwhat I will do instead of FYI I will\njust return for your information because\nthis is a dictionary if I if I want to\nget the value I want to call the key\nokay that's how we are mapping now see\nif I execute the program now let's see\nhere we are giving a short message uh do\nthis work as up now see it will return\nme do this work as soon as possible okay\nbecause here it is coming here and it is\nmapping and it is giving me this value\nokay this is the idea now let me see how\nwe can handle the Inc correct text let's\nsay sometimes what happens whenever you\nare using real time data there would be\nlots of spelling M mistake right let's\nsay this is one example certain so\ncertain spelling is not correct then\ncondition spelling is not correct that's\nhow so that's how you'll see different\ndifferent word is having the spelling\nmistake so how to handle this spelling\nmistake for this you have to use one\npackage called text blob so let me\nimport this text\nblob and now see here I'm having my\nincorrect text now if I pass this\nincorrect text to my text blob and if I\ncall this particular function called\ncorrect now see it will uh handle\neverything now see certain conditions\nduring several see all the word has been\ncorrected so this is one amazing package\nyou can use if you want to handle the\nspelling okay spelling of any word now\nthe next thing we'll be learning how we\ncan handle the stop words so inside\nEnglish language not only English\nlanguage inside all kinds of language\nwe're having some stop words okay now\nhere we're working with the English\nlanguage so let me show you some English\nrelated stop wordss for this I will be\nimporting stop wordss from the nltk is a\nso nltk is nothing but it's a natural\nlanguage toolkit Library so with the\nhelp of NLP also you can perform lots of\nNLP related task so here you can see I'm\nimporting the stop word so here I'm\nperforming nltk do download it will\ndownload all the stop wordss from the\ninternet now see now see if I uh click\nthis sell it will download the stop\nwordss now if you want to list down all\nthe stop wordss you can just write stop\nwords. wordss and here you can specify\nthe language so here I working with the\nso here I'm working with the English\nlanguage so here I've given the English\nlet's see you are working with Hindi\nBengali you can give that language also\nit will give you the stop word related\nthat language so you can uh see the\ndocumentation of nlk we'll see that how\nwe can pass the parameter here now see\nthese are the words we are having inside\nEnglish so this is called stop word so\nthis word doesn't have any kind of\nmeaning okay in a sentence okay we use\nit uh to represent one sentence but\nthere is no meaning so let me show you\nwhy I'm telling there is no meaning\nlet's if you want to perform uh\nsentiment analysis so let's say there is\none uh review we are having so let me\njust write this\nmovie is\nawesome I loved\nit now just try to see here you are\nhaving some stop word right like is is\nthere this is there I is there it is\nthere right but if I want to get the\nsentiment of this particular let's say\nreviews I can see movies is required\nawesome is required\nloved is required now if I'm getting\nthis kinds of word actually this kinds\nof positive word that means it's a\npositive sentiment okay it's a positive\nsentiment yes or no right so here\nactually I don't need these are the stop\nword okay I don't need this are the stop\nword to understand whether this\nparticular reviews is a positive or\nnegative and if you're using these are\nthe stop word in the sentence what will\nhappen whenever you will perform the\ntext vectorization it will make actually\nextra Dimension okay it will make the\nextra dimension in the data and whenever\nit is making the extra Dimension that\nmeans if Dimension is increasing that\ntime uh your model might get uh\ndifficulties right because we know that\nthere is a concept of cards of\ndimensionality so we always need to\nreduce the dimensionality somehow I\nthink you have learned in your machine\nlearning okay machine learning let's say\ntopic so that is why we don't need these\nare the stop WS so we have to remove\nthis particular stop W sometimes and\nsometimes actually we have to also keep\nit so these are the stop W guys you saw\nnow let me show you the length so around\nwe are having 170\nNine stop wordss present inside English\nnow here I've written a function so this\nfunction will remove the stop wordss\nfrom a text now let me show you let's\nsay this is a text I have given so\ninside that you can see different\ndifferent stop wordss are there now if I\npass to my function so see now see there\nis no stop word in this particular text\nright now okay that's how you can use\nthis particular function now again this\nis my data and if I want to apply on top\nof my entire reviews I can do it I can\nuse the apply function and I can pass my\nuh function object remove stop words\nand if you want to uh store permanently\nwhat you can do you can write this code\nokay re uh DF reviews is equal to DF\nreviews apply stop wordss okay it will\nsave everything permanent but I don't\nwant to save it permanent as of now\nbecause I'm showing you as a demo if you\nwant to do the perment you can do it so\nnow guys I think it is clear how we can\nuh remove the stop words now the next\nthing we'll be learning how to handle\nthe Emoji okay see Emoji is nothing but\nit's a unic code actually uh character\nokay if I show you if you just write\nemoji\nuni\ncodee you will see different different\nuni codes of different different emojis\nso let me open it up see uh here we are\nhaving different different emojis based\non that we are having the uni code okay\nUnicode character okay Unicode character\nso that's why I just collected some of\nthe Unicode character uh like for the\nemotions emojis symbols then uh picture\nof graphs then we're having transport\nmap symbol flag okay so these are the\nimages related uni code I collected here\nand I just written a function okay and\nagain I'm using the regular expression\nso here I'm telling if you're getting\nthese kinds of uni code in a sentence\nthat means the Emoji so what you have to\ndo you have to remove this emoji with\nthe empty space okay now let me show you\nso let's say this is one text I'm giving\nlove the the movie it was flying case\nokay now see if I pass this particular\ntext now see it will remove the Emojis\nautomatically now this is the next one\nnow see only LMO is coming now sometimes\nactually I told you emojis are required\nbecause let's say I told you in the chat\nGPT example so if you pass any kinds of\nemoji through the chat GPT it will also\nable to understand okay what you are\ntrying to say let's say if I pass any\nkind of emoji here let's say I'll give\nthis\nEmoji hey there what's on your mind\ntoday see it is trying to understand my\nfeelings right now if I want to handle\nthese kinds of situations what I have to\ndo I have to keep the Emoji that time\nwhat I can do I can uh extract the\nmeaning of the Emoji so for this I can\nuse one Library called uh Emoji okay now\nlet me show you first of all you have to\ninstall Sol\nit now just import the Emoji and inside\nEmoji you are having one method called\ndemo eyes okay now inside that just try\nto pass the text python is fire I'm\ngiving the fire Emoji now see it will\nautomatically convert to the word python\nis fire okay that means it is trying to\nextract the meaning of that particular\nEmoji right now I hope you you cleared\nso that's how whenever you are passing\nany kind of emoji as input to the Chart\nGPT it is trying to convert this Emoji\nto the word and is trying to understand\nwhat you are trying to say now there is\nanother example I have given love this\nmovie it was flying case see see love\nthis movie it was face blowing a keys\nnow we'll be understanding the\ntokenization I told you we are having\ntwo kinds of tokenization sentence level\ntokenization and Word level tokenization\nso let's try to see see if you want to\nperform the tokenization uh directly you\ncan use the split function because split\nalso will give you the individual word\nin the list see if I have one sentence\nnow if I perform the split operation see\nI'm giving I'm getting actually\nindividual part so with the help of\nsplit also you can perform the\ntokenization so similar wise you can\nalso do the sentence level tokenization\nthis is the word level tokenization now\nfor this you have to mention this\nparticular fully stop sign so whenever\nit is getting the fly stop that means\nthis is one sentence okay now see if I\nexecute so here I'm having three\nsentence so I am going to DHI I will\nstay there for 3 Days Let's uh hope the\ntree to be great okay see three sentence\nI'm getting so this is called sentence\nlevel tokenization so again some of the\nexample with the split\nfunction now with the help of regular\nexpression you can also do the um\ntokenization so this is one example I\ngive with the regular expression so here\nis my sentence and it will give you the\nindividual word this is the sentence\nlevel tokenization okay and this is the\npattern for the word level this is the\npattern for the sentence level okay this\nis the idea now you can also use\nsomething called nltk okay that means\nnatural language toolkit library for\nthis tokenization as well inside that we\nare having two fun two actually function\nmod level tokenizer and sentence level\ntokenizer now let me and if you want to\nperform the tokenization you have to\ndownload this particular thing called p\nn KT okay this particular thing you have\nto download okay now see here is my\nsentence and I want to perform Word\nlevel tokenization I will pass this so\nit will give me the B level tokenization\nso automatically this function will\nhandle now if you want to perform\nsentence level tokenization you can use\nsend tokenizer okay from here and you\nare getting the sentence level\ntokenization okay so again some of the\nexample you can try I have given and I\ncreated this notebook in a such a way\nyou can use it as a template I already\ntold you I have written like like the\nfunction wise right if you need any\nkinds of let's say um I mean cleanup\ntechnique you can copy from here and you\ncan use it in your code that's that's\nthe idea now there is another package\nyou can use called spacy with the help\nof spacy also you can perform the\ntokenization fine so you can explore\nthis part now let me go to the steamr\nokay I already told you what is steamr\nsteamr means you are trying to bring the\ndifferent different word in a root form\nthat that means uh let's say you are\nhaving play playing played so what you\nwill do you will apple and you will just\ntry to convert it is to the and you just\ntry to convert to the root word that\nmeans play right because it is meaning\nthe same okay in the sentence so now let\nme show you so inside nltk we are having\nthis streamr post poster pter streamr\nnow we are importing portal steamer and\nhere we have created a function steam\nword so whenever you will give any kinds\nof let's say uh sentence it will perform\nthe steaming operation now see here I'm\ngiving work Works working work now if I\ngive this particular sentence it will\ngive me the root form that means walk\nwalk walk and all okay now see here I\nkept one sentence so this is the entire\nsentence you can see now I want to\nperform streaming operation on top of\nthe sentence so I'm using my function\ninside that I'm passing the sentence now\nsee uh it will give me the um steaming\nword right now now see probably it has\nbeen uh probable okay probable that's\nwhy I told you streaming is not readable\nsometimes you will get some kinds of\nword it's not readable but your model\nwill try to understand okay but as a\nhuman it's not read see favorite has\nbeen converted to favorite right now\nokay so in case actually what you can do\nyou can use something called LZ okay LZ\nwill handle these kinds of situation it\nwill give you readable word actually now\nsee this is the LZ code so it is\navailable inside nltk I'm importing the\nLZ initializing the lamati and if you\nwant to use LZ you have to download\nthese at the things wet and OMW and now\nif I execute this code you will see that\nit will give you the LZ for all the word\nsee\nso this is the word this is the LZ this\nis the word this is the LZ now see it's\nreadable okay it's readable then your\nsteaming one I op it is clear fine so\nthat's why I just written uh streaming\nand LZ are same to retrieve root words\nbut LZ is worked uh good LZ is slow and\nstreaming is fast because LZ will give\nyou the readable output that's why it's\nlittle bit slow than your streaming okay\nI hope it is clear so yes these are the\ntechnique you can follow for the text\npreprocessing if you're having any kinds\nof text you can perform text\npreprocessing with the help of these are\nthe technique you can clean up your text\nokay and again I'm tell telling you it's\nnot required to perform all the text\ncleaning uh let's say uh I mean\ntechnique sometimes if you need anything\njust try to keep it as it is that is the\nidea fine so yes this is all from this\nvideo and what you can do right now you\ncan download any other data set from the\nkagle kaggle.com because kagle is having\ndifferent different data set not only\nmovie data set you will also get\nsomething called Twitter data set I\nthink Twitter data set is also available\nsee Twitter data set is also available\njust try to download the Twitter\nsentiment data set and try to apply\nthese are the text preprocessing on top\nof the Twitter dat data set okay so this\nshould be one task guys from my side\nplease try to attempt Because unless and\nuntil you are not practicing things\nwould be more complicated and whenever\nyou will be doing the Practical okay by\nyourself things would be more clear here\nso in the next video we'll be learning\nhow we can perform the tech data\nrepresentation that means text\nrepresentation how we can vectorize our\ntext that means we'll be converting our\ntext to numbers okay for the model so\nyes this is all from this video I hope\nyou like liked it thank you so much for\nwatching this video and I will see you\nnext time\n",
  "words": [
    "hi",
    "everyone",
    "name",
    "b",
    "hamed",
    "welcome",
    "video",
    "guys",
    "video",
    "learning",
    "data",
    "preprocessing",
    "part",
    "uh",
    "previous",
    "video",
    "already",
    "discussed",
    "end",
    "end",
    "gener",
    "tbi",
    "pipeline",
    "told",
    "use",
    "data",
    "right",
    "want",
    "use",
    "model",
    "means",
    "large",
    "language",
    "model",
    "first",
    "thing",
    "data",
    "p",
    "processing",
    "unless",
    "processing",
    "data",
    "model",
    "try",
    "understand",
    "one",
    "right",
    "idea",
    "learning",
    "various",
    "kinds",
    "technique",
    "uh",
    "clean",
    "data",
    "done",
    "created",
    "beautiful",
    "uh",
    "collab",
    "notebook",
    "actually",
    "uh",
    "added",
    "examples",
    "uh",
    "use",
    "data",
    "cleanup",
    "operation",
    "guys",
    "let",
    "try",
    "see",
    "data",
    "preprocessing",
    "part",
    "guys",
    "see",
    "notebook",
    "already",
    "prepared",
    "see",
    "using",
    "one",
    "data",
    "set",
    "kagel",
    "let",
    "open",
    "link",
    "um",
    "link",
    "data",
    "set",
    "name",
    "imdb",
    "uh",
    "data",
    "set",
    "actually",
    "50k",
    "uh",
    "movie",
    "reviews",
    "okay",
    "50k",
    "actually",
    "movie",
    "reviews",
    "already",
    "let",
    "say",
    "machine",
    "learning",
    "deep",
    "learning",
    "background",
    "think",
    "know",
    "data",
    "set",
    "right",
    "like",
    "common",
    "data",
    "set",
    "took",
    "particular",
    "data",
    "set",
    "data",
    "set",
    "see",
    "uh",
    "many",
    "u",
    "actually",
    "unnecessary",
    "text",
    "okay",
    "movie",
    "review",
    "actually",
    "extracted",
    "scra",
    "data",
    "imdb",
    "website",
    "know",
    "imdb",
    "website",
    "imdb",
    "website",
    "see",
    "uh",
    "movies",
    "reviews",
    "rating",
    "actually",
    "published",
    "data",
    "set",
    "kagel",
    "website",
    "anyone",
    "working",
    "field",
    "let",
    "say",
    "genit",
    "tvi",
    "natural",
    "language",
    "processing",
    "use",
    "data",
    "set",
    "need",
    "need",
    "download",
    "data",
    "okay",
    "around",
    "uh",
    "think",
    "27",
    "mb",
    "click",
    "download",
    "button",
    "download",
    "okay",
    "already",
    "downloaded",
    "data",
    "set",
    "available",
    "inside",
    "download",
    "folder",
    "going",
    "upload",
    "collab",
    "notebook",
    "first",
    "connect",
    "particular",
    "notebook",
    "connect",
    "button",
    "try",
    "connect",
    "need",
    "worry",
    "also",
    "share",
    "notebook",
    "link",
    "resources",
    "section",
    "open",
    "notebook",
    "connected",
    "first",
    "let",
    "import",
    "uh",
    "library",
    "first",
    "need",
    "something",
    "called",
    "pandas",
    "see",
    "data",
    "uh",
    "csb",
    "data",
    "okay",
    "csb",
    "data",
    "let",
    "upload",
    "let",
    "show",
    "want",
    "upload",
    "anything",
    "google",
    "drive",
    "try",
    "right",
    "click",
    "upload",
    "button",
    "click",
    "upload",
    "try",
    "upload",
    "data",
    "see",
    "csv",
    "file",
    "okay",
    "want",
    "load",
    "kinds",
    "csv",
    "file",
    "json",
    "file",
    "let",
    "excel",
    "file",
    "whatever",
    "file",
    "use",
    "pandas",
    "package",
    "see",
    "data",
    "set",
    "upload",
    "want",
    "load",
    "data",
    "set",
    "assign",
    "path",
    "see",
    "need",
    "execute",
    "deser",
    "code",
    "uh",
    "code",
    "added",
    "let",
    "say",
    "data",
    "set",
    "available",
    "google",
    "drive",
    "time",
    "mount",
    "google",
    "drive",
    "first",
    "mount",
    "means",
    "connecting",
    "google",
    "drive",
    "relocating",
    "folder",
    "okay",
    "like",
    "inside",
    "folder",
    "kept",
    "data",
    "okay",
    "help",
    "cd",
    "command",
    "cd",
    "means",
    "change",
    "directory",
    "okay",
    "assign",
    "data",
    "path",
    "kept",
    "data",
    "inside",
    "google",
    "drive",
    "kept",
    "inside",
    "collab",
    "actually",
    "see",
    "drive",
    "collab",
    "di",
    "using",
    "get",
    "around",
    "74",
    "gb",
    "space",
    "also",
    "keep",
    "data",
    "need",
    "execute",
    "code",
    "go",
    "check",
    "current",
    "working",
    "directory",
    "means",
    "pwd",
    "see",
    "inside",
    "content",
    "content",
    "means",
    "directory",
    "right",
    "simply",
    "define",
    "data",
    "path",
    "copy",
    "path",
    "copy",
    "let",
    "paste",
    "okay",
    "let",
    "execute",
    "see",
    "load",
    "data",
    "pd",
    "csb",
    "see",
    "load",
    "data",
    "see",
    "loaded",
    "data",
    "want",
    "see",
    "shape",
    "data",
    "shape",
    "okay",
    "around",
    "50",
    "uh",
    "50k",
    "actually",
    "movies",
    "movies",
    "reviews",
    "particular",
    "csb",
    "file",
    "two",
    "columns",
    "two",
    "columns",
    "means",
    "reviews",
    "column",
    "like",
    "sentiment",
    "column",
    "okay",
    "sentiment",
    "means",
    "whether",
    "positive",
    "sentiment",
    "whether",
    "negative",
    "sentiment",
    "kinds",
    "sentiment",
    "get",
    "hope",
    "clear",
    "see",
    "50k",
    "movie",
    "reviews",
    "going",
    "use",
    "reviews",
    "going",
    "show",
    "demo",
    "like",
    "perform",
    "text",
    "preprocessing",
    "taking",
    "50k",
    "reviews",
    "take",
    "like",
    "lots",
    "time",
    "um",
    "process",
    "text",
    "take",
    "100",
    "example",
    "okay",
    "first",
    "100",
    "example",
    "taking",
    "top",
    "perform",
    "text",
    "processing",
    "task",
    "right",
    "code",
    "execute",
    "load",
    "100",
    "example",
    "show",
    "shape",
    "see",
    "100",
    "example",
    "two",
    "columns",
    "fine",
    "want",
    "show",
    "data",
    "see",
    "data",
    "think",
    "remember",
    "uh",
    "theoretical",
    "class",
    "discussing",
    "technique",
    "uh",
    "think",
    "h",
    "perform",
    "something",
    "called",
    "html",
    "tag",
    "removal",
    "emoji",
    "handle",
    "art",
    "spelling",
    "correction",
    "basic",
    "preprocessing",
    "saw",
    "perform",
    "something",
    "called",
    "tokenization",
    "optional",
    "well",
    "like",
    "stop",
    "word",
    "streaming",
    "lz",
    "pun",
    "ch",
    "lower",
    "case",
    "okay",
    "language",
    "detection",
    "everything",
    "first",
    "thing",
    "learning",
    "perform",
    "lower",
    "case",
    "operation",
    "lower",
    "case",
    "important",
    "already",
    "explained",
    "think",
    "remember",
    "let",
    "say",
    "let",
    "say",
    "one",
    "name",
    "containing",
    "uppercase",
    "character",
    "consider",
    "actually",
    "separate",
    "name",
    "okay",
    "actually",
    "separate",
    "entity",
    "idea",
    "bring",
    "everything",
    "lowercase",
    "character",
    "apply",
    "lower",
    "operation",
    "perform",
    "lower",
    "operation",
    "think",
    "already",
    "know",
    "python",
    "function",
    "called",
    "lower",
    "help",
    "lower",
    "also",
    "right",
    "see",
    "let",
    "show",
    "one",
    "example",
    "let",
    "say",
    "taking",
    "reviews",
    "three",
    "taking",
    "three",
    "three",
    "three",
    "number",
    "rows",
    "three",
    "number",
    "rows",
    "see",
    "uh",
    "character",
    "uppercase",
    "character",
    "uppercase",
    "uppercase",
    "okay",
    "actually",
    "see",
    "different",
    "different",
    "uppercase",
    "character",
    "would",
    "want",
    "make",
    "lower",
    "case",
    "first",
    "select",
    "column",
    "like",
    "column",
    "apply",
    "lower",
    "function",
    "apply",
    "top",
    "review",
    "column",
    "first",
    "converting",
    "everything",
    "string",
    "okay",
    "string",
    "data",
    "type",
    "applying",
    "lower",
    "lower",
    "string",
    "method",
    "okay",
    "lower",
    "string",
    "method",
    "think",
    "already",
    "know",
    "whatever",
    "changes",
    "actually",
    "saving",
    "inside",
    "column",
    "means",
    "permanent",
    "change",
    "okay",
    "inside",
    "column",
    "given",
    "review",
    "idea",
    "execute",
    "see",
    "show",
    "data",
    "see",
    "guys",
    "character",
    "become",
    "lower",
    "case",
    "right",
    "want",
    "show",
    "execute",
    "review",
    "three",
    "see",
    "character",
    "converted",
    "lowercase",
    "character",
    "okay",
    "idea",
    "next",
    "thing",
    "learning",
    "handle",
    "html",
    "tags",
    "means",
    "remove",
    "html",
    "tags",
    "written",
    "function",
    "using",
    "something",
    "called",
    "regular",
    "expression",
    "regx",
    "okay",
    "inside",
    "regx",
    "give",
    "pattern",
    "let",
    "say",
    "giving",
    "pattern",
    "getting",
    "kinds",
    "symbol",
    "okay",
    "getting",
    "kinds",
    "symbol",
    "like",
    "html",
    "tag",
    "remove",
    "html",
    "tags",
    "replace",
    "empty",
    "okay",
    "empty",
    "string",
    "idea",
    "function",
    "use",
    "execute",
    "let",
    "say",
    "one",
    "text",
    "prepared",
    "see",
    "text",
    "actually",
    "lots",
    "html",
    "tags",
    "pass",
    "particular",
    "text",
    "function",
    "see",
    "automatically",
    "remove",
    "tags",
    "see",
    "getting",
    "text",
    "okay",
    "relevant",
    "text",
    "idea",
    "notebook",
    "prepared",
    "way",
    "use",
    "template",
    "let",
    "say",
    "whenever",
    "need",
    "anything",
    "kinds",
    "functionality",
    "come",
    "copy",
    "function",
    "please",
    "try",
    "keep",
    "particular",
    "notebook",
    "going",
    "help",
    "lot",
    "okay",
    "whenever",
    "developing",
    "projects",
    "going",
    "help",
    "lot",
    "want",
    "apply",
    "top",
    "entire",
    "data",
    "set",
    "call",
    "column",
    "name",
    "let",
    "say",
    "review",
    "column",
    "okay",
    "function",
    "called",
    "apply",
    "inside",
    "try",
    "pass",
    "function",
    "okay",
    "apply",
    "function",
    "takes",
    "actually",
    "uh",
    "one",
    "function",
    "object",
    "giving",
    "function",
    "object",
    "try",
    "apply",
    "particular",
    "function",
    "top",
    "entire",
    "uh",
    "rows",
    "data",
    "set",
    "okay",
    "see",
    "execute",
    "changes",
    "actually",
    "saving",
    "everything",
    "permanent",
    "okay",
    "let",
    "execute",
    "show",
    "kinds",
    "random",
    "let",
    "ar",
    "row",
    "see",
    "uh",
    "let",
    "see",
    "also",
    "show",
    "um",
    "seven",
    "okay",
    "seven",
    "number",
    "rows",
    "let",
    "try",
    "see",
    "html",
    "tags",
    "particular",
    "text",
    "pick",
    "kinds",
    "let",
    "say",
    "index",
    "let",
    "say",
    "show",
    "10",
    "nowhere",
    "see",
    "html",
    "tags",
    "learning",
    "remove",
    "actually",
    "url",
    "let",
    "say",
    "url",
    "text",
    "remove",
    "using",
    "regular",
    "expression",
    "pattern",
    "given",
    "getting",
    "kinds",
    "let",
    "say",
    "word",
    "http",
    "slash",
    "ww",
    "means",
    "url",
    "remove",
    "url",
    "empty",
    "string",
    "okay",
    "function",
    "let",
    "execute",
    "mentioned",
    "url",
    "youtube",
    "channel",
    "url",
    "linkedin",
    "url",
    "okay",
    "text",
    "prepared",
    "one",
    "one",
    "let",
    "say",
    "passing",
    "kinds",
    "text",
    "inside",
    "remove",
    "url",
    "function",
    "remove",
    "ur",
    "url",
    "let",
    "show",
    "see",
    "giving",
    "text",
    "means",
    "linkedin",
    "url",
    "see",
    "check",
    "linkedin",
    "hope",
    "clear",
    "see",
    "telling",
    "mandatory",
    "things",
    "let",
    "say",
    "need",
    "url",
    "data",
    "time",
    "keep",
    "let",
    "say",
    "need",
    "actually",
    "html",
    "tags",
    "keep",
    "need",
    "remove",
    "already",
    "told",
    "uh",
    "nowadays",
    "actually",
    "advanced",
    "genv",
    "application",
    "also",
    "supports",
    "kinds",
    "text",
    "like",
    "emojis",
    "html",
    "okay",
    "everything",
    "supports",
    "creating",
    "kinds",
    "advanc",
    "let",
    "say",
    "u",
    "mean",
    "application",
    "time",
    "need",
    "data",
    "need",
    "remove",
    "okay",
    "sometimes",
    "actually",
    "also",
    "need",
    "remove",
    "data",
    "set",
    "showing",
    "remove",
    "want",
    "keep",
    "also",
    "keep",
    "okay",
    "decide",
    "based",
    "project",
    "architecture",
    "time",
    "idea",
    "learning",
    "handle",
    "punctuation",
    "want",
    "see",
    "punctuation",
    "string",
    "package",
    "use",
    "write",
    "string",
    "punctuation",
    "see",
    "kinds",
    "punctuations",
    "available",
    "done",
    "stor",
    "fation",
    "variable",
    "called",
    "exclude",
    "written",
    "function",
    "okay",
    "written",
    "function",
    "called",
    "remove",
    "punctuation",
    "written",
    "loop",
    "looping",
    "punctuation",
    "one",
    "one",
    "user",
    "giving",
    "text",
    "checking",
    "whether",
    "punctuation",
    "okay",
    "replacing",
    "empty",
    "string",
    "let",
    "show",
    "work",
    "let",
    "say",
    "one",
    "text",
    "string",
    "punctuation",
    "see",
    "many",
    "punctuation",
    "assigned",
    "pass",
    "particular",
    "text",
    "punctuation",
    "functions",
    "remove",
    "punctuation",
    "see",
    "punctuation",
    "right",
    "even",
    "also",
    "calculating",
    "time",
    "like",
    "much",
    "time",
    "taking",
    "remove",
    "punctuation",
    "another",
    "way",
    "follow",
    "remove",
    "punctuation",
    "tell",
    "see",
    "function",
    "guys",
    "uh",
    "use",
    "something",
    "called",
    "text",
    "translate",
    "inside",
    "try",
    "use",
    "particular",
    "function",
    "okay",
    "make",
    "translate",
    "inside",
    "try",
    "mention",
    "punctuation",
    "uh",
    "take",
    "text",
    "remove",
    "funu",
    "another",
    "approach",
    "see",
    "calculate",
    "time",
    "function",
    "see",
    "time",
    "means",
    "function",
    "taking",
    "less",
    "time",
    "function",
    "using",
    "one",
    "loop",
    "loop",
    "linear",
    "time",
    "complexity",
    "think",
    "know",
    "familiar",
    "dsa",
    "concept",
    "know",
    "linear",
    "time",
    "time",
    "complexity",
    "okay",
    "particular",
    "approach",
    "good",
    "let",
    "say",
    "applying",
    "particular",
    "logic",
    "top",
    "50k",
    "data",
    "set",
    "try",
    "think",
    "much",
    "time",
    "take",
    "full",
    "loop",
    "hand",
    "using",
    "particular",
    "method",
    "take",
    "less",
    "time",
    "perform",
    "operation",
    "want",
    "see",
    "time",
    "difference",
    "also",
    "see",
    "time",
    "difference",
    "show",
    "uh",
    "text",
    "see",
    "inside",
    "text",
    "actually",
    "lots",
    "punctuation",
    "use",
    "uh",
    "remove",
    "function",
    "one",
    "means",
    "particular",
    "function",
    "inside",
    "going",
    "pass",
    "entire",
    "review",
    "see",
    "remove",
    "punctuation",
    "okay",
    "see",
    "function",
    "removed",
    "also",
    "pass",
    "entire",
    "data",
    "like",
    "also",
    "pass",
    "entire",
    "data",
    "remove",
    "punctuation",
    "inside",
    "entire",
    "data",
    "learning",
    "handle",
    "chat",
    "conversation",
    "see",
    "sometimes",
    "whenever",
    "chatting",
    "operation",
    "give",
    "uh",
    "like",
    "lots",
    "shortcut",
    "let",
    "say",
    "want",
    "write",
    "far",
    "know",
    "give",
    "give",
    "af",
    "ik",
    "let",
    "say",
    "away",
    "keyboard",
    "afk",
    "soon",
    "possible",
    "asap",
    "use",
    "lots",
    "chat",
    "keyword",
    "okay",
    "use",
    "lots",
    "chat",
    "shortcut",
    "keyword",
    "okay",
    "listed",
    "see",
    "information",
    "fyi",
    "listed",
    "chat",
    "conversation",
    "short",
    "uh",
    "word",
    "let",
    "say",
    "working",
    "actually",
    "social",
    "media",
    "data",
    "set",
    "social",
    "media",
    "data",
    "set",
    "see",
    "kinds",
    "data",
    "lot",
    "people",
    "using",
    "short",
    "form",
    "okay",
    "short",
    "form",
    "handle",
    "particular",
    "short",
    "form",
    "first",
    "try",
    "create",
    "dictionary",
    "like",
    "entire",
    "dictionary",
    "create",
    "written",
    "function",
    "function",
    "chat",
    "conversation",
    "handle",
    "inside",
    "taking",
    "text",
    "okay",
    "taking",
    "text",
    "checking",
    "inside",
    "help",
    "full",
    "loop",
    "checking",
    "kinds",
    "word",
    "okay",
    "kinds",
    "word",
    "mapping",
    "value",
    "means",
    "let",
    "say",
    "anyone",
    "actually",
    "particular",
    "let",
    "say",
    "shortcut",
    "word",
    "let",
    "say",
    "fyi",
    "instead",
    "fyi",
    "return",
    "information",
    "dictionary",
    "want",
    "get",
    "value",
    "want",
    "call",
    "key",
    "okay",
    "mapping",
    "see",
    "execute",
    "program",
    "let",
    "see",
    "giving",
    "short",
    "message",
    "uh",
    "work",
    "see",
    "return",
    "work",
    "soon",
    "possible",
    "okay",
    "coming",
    "mapping",
    "giving",
    "value",
    "okay",
    "idea",
    "let",
    "see",
    "handle",
    "inc",
    "correct",
    "text",
    "let",
    "say",
    "sometimes",
    "happens",
    "whenever",
    "using",
    "real",
    "time",
    "data",
    "would",
    "lots",
    "spelling",
    "mistake",
    "right",
    "let",
    "say",
    "one",
    "example",
    "certain",
    "certain",
    "spelling",
    "correct",
    "condition",
    "spelling",
    "correct",
    "see",
    "different",
    "different",
    "word",
    "spelling",
    "mistake",
    "handle",
    "spelling",
    "mistake",
    "use",
    "one",
    "package",
    "called",
    "text",
    "blob",
    "let",
    "import",
    "text",
    "blob",
    "see",
    "incorrect",
    "text",
    "pass",
    "incorrect",
    "text",
    "text",
    "blob",
    "call",
    "particular",
    "function",
    "called",
    "correct",
    "see",
    "uh",
    "handle",
    "everything",
    "see",
    "certain",
    "conditions",
    "several",
    "see",
    "word",
    "corrected",
    "one",
    "amazing",
    "package",
    "use",
    "want",
    "handle",
    "spelling",
    "okay",
    "spelling",
    "word",
    "next",
    "thing",
    "learning",
    "handle",
    "stop",
    "words",
    "inside",
    "english",
    "language",
    "english",
    "language",
    "inside",
    "kinds",
    "language",
    "stop",
    "words",
    "okay",
    "working",
    "english",
    "language",
    "let",
    "show",
    "english",
    "related",
    "stop",
    "wordss",
    "importing",
    "stop",
    "wordss",
    "nltk",
    "nltk",
    "nothing",
    "natural",
    "language",
    "toolkit",
    "library",
    "help",
    "nlp",
    "also",
    "perform",
    "lots",
    "nlp",
    "related",
    "task",
    "see",
    "importing",
    "stop",
    "word",
    "performing",
    "nltk",
    "download",
    "download",
    "stop",
    "wordss",
    "internet",
    "see",
    "see",
    "uh",
    "click",
    "sell",
    "download",
    "stop",
    "wordss",
    "want",
    "list",
    "stop",
    "wordss",
    "write",
    "stop",
    "words",
    "wordss",
    "specify",
    "language",
    "working",
    "working",
    "english",
    "language",
    "given",
    "english",
    "let",
    "see",
    "working",
    "hindi",
    "bengali",
    "give",
    "language",
    "also",
    "give",
    "stop",
    "word",
    "related",
    "language",
    "uh",
    "see",
    "documentation",
    "nlk",
    "see",
    "pass",
    "parameter",
    "see",
    "words",
    "inside",
    "english",
    "called",
    "stop",
    "word",
    "word",
    "kind",
    "meaning",
    "okay",
    "sentence",
    "okay",
    "use",
    "uh",
    "represent",
    "one",
    "sentence",
    "meaning",
    "let",
    "show",
    "telling",
    "meaning",
    "let",
    "want",
    "perform",
    "uh",
    "sentiment",
    "analysis",
    "let",
    "say",
    "one",
    "uh",
    "review",
    "let",
    "write",
    "movie",
    "awesome",
    "loved",
    "try",
    "see",
    "stop",
    "word",
    "right",
    "like",
    "right",
    "want",
    "get",
    "sentiment",
    "particular",
    "let",
    "say",
    "reviews",
    "see",
    "movies",
    "required",
    "awesome",
    "required",
    "loved",
    "required",
    "getting",
    "kinds",
    "word",
    "actually",
    "kinds",
    "positive",
    "word",
    "means",
    "positive",
    "sentiment",
    "okay",
    "positive",
    "sentiment",
    "yes",
    "right",
    "actually",
    "need",
    "stop",
    "word",
    "okay",
    "need",
    "stop",
    "word",
    "understand",
    "whether",
    "particular",
    "reviews",
    "positive",
    "negative",
    "using",
    "stop",
    "word",
    "sentence",
    "happen",
    "whenever",
    "perform",
    "text",
    "vectorization",
    "make",
    "actually",
    "extra",
    "dimension",
    "okay",
    "make",
    "extra",
    "dimension",
    "data",
    "whenever",
    "making",
    "extra",
    "dimension",
    "means",
    "dimension",
    "increasing",
    "time",
    "uh",
    "model",
    "might",
    "get",
    "uh",
    "difficulties",
    "right",
    "know",
    "concept",
    "cards",
    "dimensionality",
    "always",
    "need",
    "reduce",
    "dimensionality",
    "somehow",
    "think",
    "learned",
    "machine",
    "learning",
    "okay",
    "machine",
    "learning",
    "let",
    "say",
    "topic",
    "need",
    "stop",
    "ws",
    "remove",
    "particular",
    "stop",
    "w",
    "sometimes",
    "sometimes",
    "actually",
    "also",
    "keep",
    "stop",
    "w",
    "guys",
    "saw",
    "let",
    "show",
    "length",
    "around",
    "170",
    "nine",
    "stop",
    "wordss",
    "present",
    "inside",
    "english",
    "written",
    "function",
    "function",
    "remove",
    "stop",
    "wordss",
    "text",
    "let",
    "show",
    "let",
    "say",
    "text",
    "given",
    "inside",
    "see",
    "different",
    "different",
    "stop",
    "wordss",
    "pass",
    "function",
    "see",
    "see",
    "stop",
    "word",
    "particular",
    "text",
    "right",
    "okay",
    "use",
    "particular",
    "function",
    "data",
    "want",
    "apply",
    "top",
    "entire",
    "reviews",
    "use",
    "apply",
    "function",
    "pass",
    "uh",
    "function",
    "object",
    "remove",
    "stop",
    "words",
    "want",
    "uh",
    "store",
    "permanently",
    "write",
    "code",
    "okay",
    "uh",
    "df",
    "reviews",
    "equal",
    "df",
    "reviews",
    "apply",
    "stop",
    "wordss",
    "okay",
    "save",
    "everything",
    "permanent",
    "want",
    "save",
    "permanent",
    "showing",
    "demo",
    "want",
    "perment",
    "guys",
    "think",
    "clear",
    "uh",
    "remove",
    "stop",
    "words",
    "next",
    "thing",
    "learning",
    "handle",
    "emoji",
    "okay",
    "see",
    "emoji",
    "nothing",
    "unic",
    "code",
    "actually",
    "uh",
    "character",
    "okay",
    "show",
    "write",
    "emoji",
    "uni",
    "codee",
    "see",
    "different",
    "different",
    "uni",
    "codes",
    "different",
    "different",
    "emojis",
    "let",
    "open",
    "see",
    "uh",
    "different",
    "different",
    "emojis",
    "based",
    "uni",
    "code",
    "okay",
    "unicode",
    "character",
    "okay",
    "unicode",
    "character",
    "collected",
    "unicode",
    "character",
    "uh",
    "like",
    "emotions",
    "emojis",
    "symbols",
    "uh",
    "picture",
    "graphs",
    "transport",
    "map",
    "symbol",
    "flag",
    "okay",
    "images",
    "related",
    "uni",
    "code",
    "collected",
    "written",
    "function",
    "okay",
    "using",
    "regular",
    "expression",
    "telling",
    "getting",
    "kinds",
    "uni",
    "code",
    "sentence",
    "means",
    "emoji",
    "remove",
    "emoji",
    "empty",
    "space",
    "okay",
    "let",
    "show",
    "let",
    "say",
    "one",
    "text",
    "giving",
    "love",
    "movie",
    "flying",
    "case",
    "okay",
    "see",
    "pass",
    "particular",
    "text",
    "see",
    "remove",
    "emojis",
    "automatically",
    "next",
    "one",
    "see",
    "lmo",
    "coming",
    "sometimes",
    "actually",
    "told",
    "emojis",
    "required",
    "let",
    "say",
    "told",
    "chat",
    "gpt",
    "example",
    "pass",
    "kinds",
    "emoji",
    "chat",
    "gpt",
    "also",
    "able",
    "understand",
    "okay",
    "trying",
    "say",
    "let",
    "say",
    "pass",
    "kind",
    "emoji",
    "let",
    "say",
    "give",
    "emoji",
    "hey",
    "mind",
    "today",
    "see",
    "trying",
    "understand",
    "feelings",
    "right",
    "want",
    "handle",
    "kinds",
    "situations",
    "keep",
    "emoji",
    "time",
    "uh",
    "extract",
    "meaning",
    "emoji",
    "use",
    "one",
    "library",
    "called",
    "uh",
    "emoji",
    "okay",
    "let",
    "show",
    "first",
    "install",
    "sol",
    "import",
    "emoji",
    "inside",
    "emoji",
    "one",
    "method",
    "called",
    "demo",
    "eyes",
    "okay",
    "inside",
    "try",
    "pass",
    "text",
    "python",
    "fire",
    "giving",
    "fire",
    "emoji",
    "see",
    "automatically",
    "convert",
    "word",
    "python",
    "fire",
    "okay",
    "means",
    "trying",
    "extract",
    "meaning",
    "particular",
    "emoji",
    "right",
    "hope",
    "cleared",
    "whenever",
    "passing",
    "kind",
    "emoji",
    "input",
    "chart",
    "gpt",
    "trying",
    "convert",
    "emoji",
    "word",
    "trying",
    "understand",
    "trying",
    "say",
    "another",
    "example",
    "given",
    "love",
    "movie",
    "flying",
    "case",
    "see",
    "see",
    "love",
    "movie",
    "face",
    "blowing",
    "keys",
    "understanding",
    "tokenization",
    "told",
    "two",
    "kinds",
    "tokenization",
    "sentence",
    "level",
    "tokenization",
    "word",
    "level",
    "tokenization",
    "let",
    "try",
    "see",
    "see",
    "want",
    "perform",
    "tokenization",
    "uh",
    "directly",
    "use",
    "split",
    "function",
    "split",
    "also",
    "give",
    "individual",
    "word",
    "list",
    "see",
    "one",
    "sentence",
    "perform",
    "split",
    "operation",
    "see",
    "giving",
    "getting",
    "actually",
    "individual",
    "part",
    "help",
    "split",
    "also",
    "perform",
    "tokenization",
    "similar",
    "wise",
    "also",
    "sentence",
    "level",
    "tokenization",
    "word",
    "level",
    "tokenization",
    "mention",
    "particular",
    "fully",
    "stop",
    "sign",
    "whenever",
    "getting",
    "fly",
    "stop",
    "means",
    "one",
    "sentence",
    "okay",
    "see",
    "execute",
    "three",
    "sentence",
    "going",
    "dhi",
    "stay",
    "3",
    "days",
    "let",
    "uh",
    "hope",
    "tree",
    "great",
    "okay",
    "see",
    "three",
    "sentence",
    "getting",
    "called",
    "sentence",
    "level",
    "tokenization",
    "example",
    "split",
    "function",
    "help",
    "regular",
    "expression",
    "also",
    "um",
    "tokenization",
    "one",
    "example",
    "give",
    "regular",
    "expression",
    "sentence",
    "give",
    "individual",
    "word",
    "sentence",
    "level",
    "tokenization",
    "okay",
    "pattern",
    "word",
    "level",
    "pattern",
    "sentence",
    "level",
    "okay",
    "idea",
    "also",
    "use",
    "something",
    "called",
    "nltk",
    "okay",
    "means",
    "natural",
    "language",
    "toolkit",
    "library",
    "tokenization",
    "well",
    "inside",
    "two",
    "fun",
    "two",
    "actually",
    "function",
    "mod",
    "level",
    "tokenizer",
    "sentence",
    "level",
    "tokenizer",
    "let",
    "want",
    "perform",
    "tokenization",
    "download",
    "particular",
    "thing",
    "called",
    "p",
    "n",
    "kt",
    "okay",
    "particular",
    "thing",
    "download",
    "okay",
    "see",
    "sentence",
    "want",
    "perform",
    "word",
    "level",
    "tokenization",
    "pass",
    "give",
    "b",
    "level",
    "tokenization",
    "automatically",
    "function",
    "handle",
    "want",
    "perform",
    "sentence",
    "level",
    "tokenization",
    "use",
    "send",
    "tokenizer",
    "okay",
    "getting",
    "sentence",
    "level",
    "tokenization",
    "okay",
    "example",
    "try",
    "given",
    "created",
    "notebook",
    "way",
    "use",
    "template",
    "already",
    "told",
    "written",
    "like",
    "like",
    "function",
    "wise",
    "right",
    "need",
    "kinds",
    "let",
    "say",
    "um",
    "mean",
    "cleanup",
    "technique",
    "copy",
    "use",
    "code",
    "idea",
    "another",
    "package",
    "use",
    "called",
    "spacy",
    "help",
    "spacy",
    "also",
    "perform",
    "tokenization",
    "fine",
    "explore",
    "part",
    "let",
    "go",
    "steamr",
    "okay",
    "already",
    "told",
    "steamr",
    "steamr",
    "means",
    "trying",
    "bring",
    "different",
    "different",
    "word",
    "root",
    "form",
    "means",
    "uh",
    "let",
    "say",
    "play",
    "playing",
    "played",
    "apple",
    "try",
    "convert",
    "try",
    "convert",
    "root",
    "word",
    "means",
    "play",
    "right",
    "meaning",
    "okay",
    "sentence",
    "let",
    "show",
    "inside",
    "nltk",
    "streamr",
    "post",
    "poster",
    "pter",
    "streamr",
    "importing",
    "portal",
    "steamer",
    "created",
    "function",
    "steam",
    "word",
    "whenever",
    "give",
    "kinds",
    "let",
    "say",
    "uh",
    "sentence",
    "perform",
    "steaming",
    "operation",
    "see",
    "giving",
    "work",
    "works",
    "working",
    "work",
    "give",
    "particular",
    "sentence",
    "give",
    "root",
    "form",
    "means",
    "walk",
    "walk",
    "walk",
    "okay",
    "see",
    "kept",
    "one",
    "sentence",
    "entire",
    "sentence",
    "see",
    "want",
    "perform",
    "streaming",
    "operation",
    "top",
    "sentence",
    "using",
    "function",
    "inside",
    "passing",
    "sentence",
    "see",
    "uh",
    "give",
    "um",
    "steaming",
    "word",
    "right",
    "see",
    "probably",
    "uh",
    "probable",
    "okay",
    "probable",
    "told",
    "streaming",
    "readable",
    "sometimes",
    "get",
    "kinds",
    "word",
    "readable",
    "model",
    "try",
    "understand",
    "okay",
    "human",
    "read",
    "see",
    "favorite",
    "converted",
    "favorite",
    "right",
    "okay",
    "case",
    "actually",
    "use",
    "something",
    "called",
    "lz",
    "okay",
    "lz",
    "handle",
    "kinds",
    "situation",
    "give",
    "readable",
    "word",
    "actually",
    "see",
    "lz",
    "code",
    "available",
    "inside",
    "nltk",
    "importing",
    "lz",
    "initializing",
    "lamati",
    "want",
    "use",
    "lz",
    "download",
    "things",
    "wet",
    "omw",
    "execute",
    "code",
    "see",
    "give",
    "lz",
    "word",
    "see",
    "word",
    "lz",
    "word",
    "lz",
    "see",
    "readable",
    "okay",
    "readable",
    "steaming",
    "one",
    "op",
    "clear",
    "fine",
    "written",
    "uh",
    "streaming",
    "lz",
    "retrieve",
    "root",
    "words",
    "lz",
    "worked",
    "uh",
    "good",
    "lz",
    "slow",
    "streaming",
    "fast",
    "lz",
    "give",
    "readable",
    "output",
    "little",
    "bit",
    "slow",
    "streaming",
    "okay",
    "hope",
    "clear",
    "yes",
    "technique",
    "follow",
    "text",
    "preprocessing",
    "kinds",
    "text",
    "perform",
    "text",
    "preprocessing",
    "help",
    "technique",
    "clean",
    "text",
    "okay",
    "tell",
    "telling",
    "required",
    "perform",
    "text",
    "cleaning",
    "uh",
    "let",
    "say",
    "uh",
    "mean",
    "technique",
    "sometimes",
    "need",
    "anything",
    "try",
    "keep",
    "idea",
    "fine",
    "yes",
    "video",
    "right",
    "download",
    "data",
    "set",
    "kagle",
    "kagle",
    "different",
    "different",
    "data",
    "set",
    "movie",
    "data",
    "set",
    "also",
    "get",
    "something",
    "called",
    "twitter",
    "data",
    "set",
    "think",
    "twitter",
    "data",
    "set",
    "also",
    "available",
    "see",
    "twitter",
    "data",
    "set",
    "also",
    "available",
    "try",
    "download",
    "twitter",
    "sentiment",
    "data",
    "set",
    "try",
    "apply",
    "text",
    "preprocessing",
    "top",
    "twitter",
    "dat",
    "data",
    "set",
    "okay",
    "one",
    "task",
    "guys",
    "side",
    "please",
    "try",
    "attempt",
    "unless",
    "practicing",
    "things",
    "would",
    "complicated",
    "whenever",
    "practical",
    "okay",
    "things",
    "would",
    "clear",
    "next",
    "video",
    "learning",
    "perform",
    "tech",
    "data",
    "representation",
    "means",
    "text",
    "representation",
    "vectorize",
    "text",
    "means",
    "converting",
    "text",
    "numbers",
    "okay",
    "model",
    "yes",
    "video",
    "hope",
    "like",
    "liked",
    "thank",
    "much",
    "watching",
    "video",
    "see",
    "next",
    "time"
  ],
  "keywords": [
    "name",
    "video",
    "guys",
    "learning",
    "data",
    "preprocessing",
    "uh",
    "already",
    "told",
    "use",
    "right",
    "want",
    "model",
    "means",
    "language",
    "first",
    "thing",
    "try",
    "understand",
    "one",
    "idea",
    "kinds",
    "technique",
    "notebook",
    "actually",
    "operation",
    "let",
    "see",
    "using",
    "set",
    "um",
    "50k",
    "movie",
    "reviews",
    "okay",
    "say",
    "think",
    "know",
    "like",
    "particular",
    "text",
    "review",
    "working",
    "need",
    "download",
    "available",
    "inside",
    "going",
    "upload",
    "also",
    "something",
    "called",
    "show",
    "google",
    "drive",
    "file",
    "load",
    "package",
    "execute",
    "code",
    "time",
    "help",
    "get",
    "keep",
    "two",
    "column",
    "sentiment",
    "positive",
    "hope",
    "clear",
    "perform",
    "taking",
    "take",
    "lots",
    "example",
    "top",
    "html",
    "emoji",
    "handle",
    "spelling",
    "tokenization",
    "stop",
    "word",
    "streaming",
    "lz",
    "lower",
    "case",
    "everything",
    "uppercase",
    "character",
    "apply",
    "function",
    "three",
    "different",
    "string",
    "given",
    "next",
    "tags",
    "remove",
    "written",
    "regular",
    "expression",
    "give",
    "pattern",
    "giving",
    "getting",
    "empty",
    "pass",
    "whenever",
    "entire",
    "url",
    "emojis",
    "sometimes",
    "punctuation",
    "write",
    "loop",
    "work",
    "chat",
    "short",
    "form",
    "words",
    "english",
    "wordss",
    "nltk",
    "meaning",
    "sentence",
    "required",
    "uni",
    "trying",
    "level",
    "split",
    "readable",
    "twitter"
  ]
}