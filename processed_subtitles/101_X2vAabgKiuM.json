{
  "text": "welcome everyone to free code camp i\nchrisley on behalf of edureka will take\nthis session on natural language\nprocessing popularly known as nlp now\nedureka is a global e-learning company\nthat provides online training courses on\nthe latest trending technologies so\nwithout any further delay let's have a\nlook at the agenda for this session\nso i'll start off by explaining the\nevolution of the human language then\nwe'll understand what is nlp and how it\ncame into the picture moving forward\nwe'll have a look at the various\napplication of nlp in the industry and\nnext we'll understand the different\ncomponents of nlp and the difficulties\nfaced while implementing those and\nfinally i'll finish off this video by\nexplaining you guys the various steps or\nthe paths involved in the natural\nlanguage processing along with the demo\nfor each one of those steps\nso the success of human race is because\nof our ability to communicate that is\ninformation sharing using this ability\nwe have marched ahead of other animals\nand have become the most sophisticated\ncreatures and this is what\ndifferentiates us among all the other\nanimals we begin to look for ways to\npreserve our thoughts feelings messages\nand other information we started with\noral communication like other animals\nbut because of its informal nature we\nbegan painting on walls and caves where\nwe lived now there was a need to\nstandardize the drawing so that everyone\ncould understand and that's where the\nconcept of developing a language came in\nhowever many such standards came up\nresulting in many languages with each\nlanguage having its own basic sets of\nalphabets combination of alphabets which\nwere known as words and the combination\nof words which were arranged\nmeaningfully which became the sentence\nnow each language has a set of rules\nbased on words and are combined to form\nthese sentences now these set of rules\nare nothing but what we call it as\ngrammar now i'm not gonna take any more\ntime explaining you guys about grammar\nand all now coming to today's world\naccording to the industry estimates only\n21 of the available data is present in\nthe structured form data is being\ngenerated as we speak as we tweet as we\nsend a message on whatsapp instagram\nimessaging and various other platforms\nmajority of this data exist in the\ntextual form which is highly\nunstructured in nature now in order to\nproduce significant and actionable\ninsights from this text data it is\nimportant to get acquainted with the\ntechniques and the principle of natural\nlanguage processing so let's understand\nwhat exactly is nlp\nnow natural language processing that is\nnlp refers to the artificial\nintelligence method communicating with\nan intelligent system using natural\nlanguage now it is a part of computer\nscience and artificial intelligence\nwhich deals with the human language by\nutilizing nlp and its components one can\norganize the massive chunks of text data\nperform numerous automated tasks and\nsolve a wide range of problems such as\nautomation summarization machine\ntranslation named entity recognition\nrelationship extraction sentimental\nanalysis speech recognition and topic\nsegmentations now we'll learn about all\nof these later in this video now the\ngoal here is to process i'd rather say\nunderstand the natural language in order\nto perform useful tasks some of these\ntasks include making appointment buying\nthings spell checking generating\nresponses and social media monitoring\nnow if we look at the various\napplication of nlp in the industry\nfirstly we have the spell checking which\nis usually there in you can find it\nmostly in words or the document reader\neven online also you can do the spell\nchecking now next we have keyword search\nand it is also a field where nlp is\nheavily used now extracting information\nfrom websites or any particular document\nalso requires the knowledge of nlp now\none of the coolest application of nlp is\nthe address in matching which is\nbasically a recommendation of ads based\non your search what it does is analyzes\nthe text of the data which you are\nalready using or searched and match it\nwith the text data of the advertisement\nnow sentimental analysis is also a very\nmajor part of nlp another application is\nthe speaker ignition now here we are\nalso talking about the voice assistants\nlike the siri google assistant the\ncortana and we need to thank apple for\ncreating the first voice assistant that\nis siri now next we have the\nimplementation of chatbots now most of\nyou guys might have used the customer\nchat services provided in various apps\nnow most of these apps use the chatbot\nwhich is it uses nlp to process the data\nwhich we entered and then it provides\nresponse based on an input that is also\nan application of natural language\nprocessing now another application of\nnlp is the machine translation now the\nmost common example of it is the google\ntranslate as you know and now it uses\nnlp to translate the data or i should\nsay the text from one language to the\nother and that too in real time now nlp\nconsists of two components\nwhich is the natural language\nunderstanding referred to as nlu and the\nnatural language generation which is\nreferred to as nlg now understanding the\nnatural language involves\nmapping the giving input in natural\nlanguage into useful representation and\nanalyzing different aspects of the\nlanguage now natural language generation\nis the process of producing meaningful\nphrases and sentences in the form of\nnatural language from some internal\nrepresentation now it involves text\nplanning which includes retrieving the\nrelevant contents from the knowledge\nbase it involves sentence planning which\nincludes choosing require words from\nmeaningful phrases setting tone of the\nsentences\nand finally we have text realization it\nis mapping sentence plan into the\nsentence structure\nnow we'll learn about this later in this\nvideo and usually natural language\nunderstanding which is nlu is much much\nharder than energy now you might be\nthinking that even a small child can\nunderstand a language so how come it is\nso easy for human beings is so difficult\nfor the computer to process it so let's\nunderstand what are the difficulties a\nmachine faces while understanding a\nlanguage\nso in natural language understanding\nthere are certain ambiguities which are\nthe lexical ambiguities syntactical\nambiguity and the referential ambiguity\nnow understanding a new language is very\nhard taking our english into\nconsideration there are a lot of\nambiguity and that to in different\nlevels now starting with lexical\nambiguity lexical ambiguity is the\npresence of two or more possible\nmeanings within a single word it is also\ncalled semantic ambiguity for example\nlet's consider the following sentences\nand let's focus on the italicized rules\nnow she is looking for a match now what\ndo you infer here from the match word is\nshe looking for a match that is head to\nend match or is she looking for a match\nas in a partner the fisherman went to a\nbank is it the bank where we withdraw\nour money or is it the bank where he\nrows his boat or he catches the fishes\nnow syntactical ambiguity in english\ngrammar this ambiguity is the presence\nof two or more possible meanings within\na single sentence or a sequence of words\nit is also called structure ambiguity or\ngrammatical ambiguity now let's have a\nlook at these sentences the chicken is\nready to eat so is the chicken ready to\neat something or is the chicken ready\nfor us to eat so this is a kind of\nsyntactical ambiguity which is often\nvery hard to info for a new person or\ni'd rather say a computer because it\nmeans the meaning of the sentence is\ndifferent for the different tones or in\ndifferent aspects so for example if i\nlook at the last statement i saw the man\nwith the binoculars so do i have a\nbanner or the man has a binocular\nit might be possible that you might be\nthinking that i saw the man with\nbinoculars\nmeans that i have the banners but\nsomewhere some people might think that\nthe guy which i am seeing has the\nbinoculars rather than me so that is\nsyntactical ambiguity now coming to the\nthird ambiguity which is the referential\nambiguity now this ambiguity arises when\nwe refer to something using pronouns now\nthe boy told his father the theft he was\nvery upset now when we talk about he was\nvery upset if you focus on the\nitalicized word he does this mean that\nthe boy was upset or the thief was upset\nor the father was upset nobody knows\nthis is referential ambiguity\nnow coming back to nlp\nfor using nlp onto our system or doing\nany natural language processing we need\nto install the nltk library that is the\nnatural language toolkit so nltk is a\nleading platform for building python\nprograms to work with human language\ndata it provides easy to use interfaces\nto 50 corpora and lexical resources such\nas wordnet along with the suit of text\nprocessing libraries for classification\ntokenization stemming tagging and much\nmore\nnow let me show you how you can download\nan ltk\nnow in order to download nltk just go to\nyour python shell and just type in the\nword nltk dot download using the\nparenthesis and then you will get this\ntype of a window pop-up which is the\nnltk downloader you just need to select\nall option and click on the download\nbutton and it will download all the\ncorpora and the\ntext it has all the packages it has into\none single place and you can choose the\ndirectory where you want to install it\nit's better if you download it in your\npython directory only it will be easier\nfor you to access all the files and all\nthe text which it has to offer now when\nwe process text there are a few\nterminologies which we need to\nunderstand\nso the first terminology here we are\ntalking about is tokenization so it is a\nprocess of breaking up strings into\ntokens which in turn are small\nstructures or units that can be used for\ntokenization now it involves three steps\nbreaking a complex sentence into words\nunderstanding the importance of each of\nthe words with respect to the sentence\nand produce a structural description on\nan input sentence so if we take the\nsentence today we will understand\ntokenization so as you can see we have\nfive tokens the first one today we will\nunderstand tokenization so all of these\nwords in computer terms are known as\ntokens and this is what is referred to\nas tokenization so let me show you guys\nhow you can implement tokenization using\nthe nltk library\nso here i'm using jupiter notebook\nyou are free to use any sort of id also\nmy personal preference is jupyter\nnotebook so first of all let's import\nthe os the nltk library which we have\ndownload and the nl ticket corpus\nnow let's have a look at the\ncorpora which is being provided by the\nnltk\nthat is the whole data so as you can see\nwe have so many files\nand all of these files have different\nfunctionalities some have textual data\nsome have different functions associated\nwith it we have stopwatch as you can see\nhere your state union names we have\ntwitter sample data we have different\nkind of data and different kind of\nfunctions here\nso let's take the brown into\nconsideration as you can see here we\nhave brown and brown zip so first we all\nwe need to do is import the brown and\nthen let's have a look at the words\nwhich are present in the brown you can\nsee we have the fluton country grand\njury said and it's going on and on\nnow let's have a look at the different\ngutenberg fields so as you can see under\ngutenberg file we have austin mr text we\nhave the bible text we have the blake\npoems the carol alice text\nwe have the edgeworth parents.txt\nshakespeares we have we have the\nshakespeare we have the whitman leaves\nso nltk is a very big directory and a\nvery big library to download you might\nneed a couple of minutes to download\nthis library\nso let's take the shakespeare hamlet.txt\nand if you look at the\nwords which are inside this hamlet file\nwe see it starts with the tragedy of\nhamlet by and it goes on and on so if we\nhave a look at the first 500 words of\nthis textual paragraph or what we say\nthe textual file\nso i'm using here for word in hamlet and\ni'm using the colon and 500 that is the\nend point so as you can see it starts\nwith the tragedy of hamlet by william\nshakespeare 1599 actus primus schona\nprima and it goes on and on\nso for natural language processing you\ncan use either of the text which is\nprovided here for understanding or you\ncan create your own words\nso for example here i have defined a\nparagraph based on artificial\nintelligence\nokay so it goes on like according to the\nfather of artificial intelligence john\nmccartney it is the science of\nengineering and so on and on so let us\nfirst define this string okay ai now why\ni'm taking a string is because it is\neasy to show you guys how to work on a\nstring so if we do the type ai you can\nsee it is sdr which is string\nnow under nltk we have the nltk.tokenize\nand we are going to import the word\ntokenize\nright as a function will understand how\nit works\nnow we will run the word underscore\ntokenize function over the paragraph and\nassign it a name\nlet's assign it as ai underscore tokens\nso now if we'll have a look at the air\nunderscore tokens\nyou can see it has divided the whole ai\nparagraph which we gave into tokens\nso as you can see it has taken a comma\nalso into a consideration the hyphen\nalso and it goes on and on\nnow let's have a look at the number of\ntokens where we have here\nso for that we are going to use the\nlength function so as you can see we\nhave 273 tokens\nnow from nltk we have a probability\nfunction which is the frequency distinct\nso\ni'll show you what it does\nso for a word in ea underscore tokens\nf-test and we are going to convert it to\nlower keys so as to avoid the\nprobability of considering a word with\nuppercase and lowercase as different and\nthen we are going to assign it a number\nthis is basically a word count program\nand this is being implemented using the\nfrequency distinct function which is\nalready present in the nltk library so\nlet's see what's the output of this one\nso as you can see\ncomma has appeared 30 times\nfull stop has appeared 9 times question\nmark 1 and so on and on like you see\nintelligence has appeared 6 times\nintelligent sixth time intelligently has\nappeared one time\nnow suppose if you want to know the\nfrequency of any particular word here so\nfor that we are going to use the\nfunction f test\nthat is the distinct frequency so we are\ngoing to use that function over the\nparticular word so for example let's say\ni want to know the frequency of\nartificial\nso as you can see it is three times\nand if we check it in the database you\ncan see it is artificial it is given as\nthree\nnow if you want to have an look at the\nnumber of distinct words here\nall we need to do is pass on the f-test\nfunction to the length function so you\ncan see it's 121. so earlier we had 273\ntokens and now from that we have 121\ndistinct tokens\nnow suppose if we were to select the top\n10\ntokens with the highest frequency for\nthat i am assigning a new f test\nunderscore top 10 and i am using the\nmost underscore common function here and\npassing 10 that is the number of items i\nwant\nso\nlet's see the output\nso as you can see\nas i mentioned earlier comma appears 30\ntimes that is the highest frequency of\nany world and\nis appeased five times so these are the\ntop ten words which are the most\nreoccurring words in the given paragraph\nor the given sentence\nnow let's use the blank line tokenizer\nover the same string to tokenize a\nparagraph with respect to a blank string\nso as you can see we are importing the\nblank line underscore tokenize\nearlier what we did was import the word\nunderscore tokenize and now we are using\nthe blank line under stroke noise and\nagain we are passing the same ai\nparagraph which i gave earlier and then\nwe are checking the length of the ai\nunderscore blank so as you can see it\nprovides us the output nine now what it\ntells us is the number of paragraphs\nwhich are separated by a new line in our\ngiven document\nso suppose you want to have a look at\nthe first paragraph or supposedly the\nsecond paragraph\nall you do is pass on the number and it\nwill give you the whole paragraph as you\nwant which is separated by a new line of\ncourse\nnow coming back to our tokenization part\nwe have\ndiagrams diagrams and engrams now\ndiagrams are tokens of two consecutive\nwritten words similarly diagrams are\nreferred to tokens of three consecutive\nwritten words and usually n-grams is\nreferred to as tokens of any number of\nconsecutive written words for n numbers\nso let's see how we can implement the\nsame using\nnltk libraries for diagrams diagrams and\nthe engrams\nso first what we need to do is import\nbackgrounds diagrams and engrams from\nnltk.util\nso let's take a string the best and the\nmost visual thing in the world cannot be\nseen or even test\nthey must be filled with the heart what\na beautiful code so let us now first\ncreate the tokens of the our string\nusing the word underscore tokenize as we\ndid earlier now to create a background\nwhat we need to do is use the list\nfunction and inside that we are going to\nuse the nltk.diagrams\nand pass on the tokens\nso as you can see it has created a\ndiagram of the given document similarly\nif we create the trigrams and the\nengrams\nso all you need to do is change the\nbigrams to trigrams and it will give you\nthe trigram list now let us now create\nan n-gram list okay\nso guys as you can see here we are using\nthe same function lltk.n grams and\ninside that we are passing the quotes\nunder course token and\nhere in place of n we are going to give\nour number so let's say suppose i\nprovide five here so as you can see it\nhas given us an n-gram of length five\nnow once we have got all the words or as\ni say the tokens we need to make some\nchanges to the tokens and for that we\nhave stemming\nnow what stemming does is normalize the\nwords into its base root form so if we\nhave a look at the words here we have\naffectation effects affections affected\naffection and affecting now all of these\nwords originate from a single root world\nthat is the effect now stemming\nalgorithm works by cutting off the end\nor the beginning of the word taking into\naccount a list of common prefixes and\nsuffixes that can be found in an\ninfected world now this indiscriminate\ncutting can be successful in some\noccasions but not always\nand that is why we affirm that this\napproach presents some limitations now\nlet's see how we can implement stemming\nand we'll see what are the limitations\nof stemming and how we can overcome them\nnow there are quite a few different\ntypes of stemmer so let's start with the\nportal stemmer so for that we are going\nto use from nltk.stem import portastimo\nand let's see what does this give us the\noutput of stemming the word having so as\nyou can see it has given us the root\nword have\nnow similarly if we provide a list of\nwords such as give giving given and gave\nand i have given this name of words to\nstem\nso forwards inverse system print words\nand we are using the portastimer which\nis the psd.stem method so as you can see\nit has given us the output give give\ngiven and gave so you can see the\nstemmer remove the only ing and replace\nit with e now there is another stemmer\nwhich is known as the lancaster stemmer\nso let's try to stem the same thing\nusing the lancast system and see what is\nthe difference\nso let's stem the same thing using the\nlancast system and see what are the\ndifferences we have\nso first of all we are going to import\nthe landcast system and we are going to\nprovide lst which is the lancast system\nof function and in the similar manner\nthat we did for the portastema let us\nexecute the lancast system also so as\nyou can see here the stemmer has stemmed\nall the words as a result of it you can\nconclude\nthat the lancaster stemmer is more\naggressive than the potter stemmer now\nthe use of each of the stemmers depend\non the type of the task you want to\nperform\nnow we have another stemmer which is\nknown as the snow world stimmer now for\nsnowball stimmer we have to provide the\nlanguage which we are using\nso similarly if we use the snowball\nstemmer on the given words\nas you can see it has given us a\ndifferent output from the previous\nlancaster stemmer so as you can see the\noutput is the same as that of the portal\nstemmer here but it differs in different\nterms now the use of each of this\nstemmer depends on the type of the task\nyou want to perform for example if you\nwant to check how many times the word\ngiv is used above you can use the\nlancaster's demo and for other purposes\nyou have the snowballs number and the\nporter stem as well so what happens is\nthat sometimes\nstemming does not work properly it does\nnot always result to give us the root\nword so for example if we take the word\nfish and fishes and fishing all of that\nstems into fish so lemmetization is an\nanother concept\nso on one hand where stemming usually\nworks by cutting off the end and the\nbeginning of the wood limitization takes\ninto consideration the morphological\nanalysis of the world so to do so it is\nnecessary to have a detailed dictionary\nwhich the algorithm can look into to\nlink the form back to its lemma\nnow what limitization does is groups\ntogether different infected forms of the\nword called lemma it is somehow similar\nto stemming as it maps several words\ninto one common root now one thing to\nkeep in consideration here is the output\nof limitization is a proper word so for\nexample if we look back to our output\ngiven by the lancaster's demo you can\nsee it has given us the output give\nwhich is not a word so the output of\nlimitization is a proper word\nand\nfor example if you take a limitation of\ngone going it all goes into the word go\nnow again we can see how it works with\nthe same example of words let's try\nlimitization using the nltk library\nso first of all we are going to import\nthe word net\nas mentioned earlier it requires a\ndictionary which the algorithm can look\ninto to link back the form into its\noriginal lemma and since the output is a\nperfect word so it needs to have\nadditionally so for here we are going to\nimport the wordnet dictionary and we are\ngoing to import the word netlemortizer\nso let us first\ntake the word corpora and see what its\nlemma is\nso what do you think guys what will be\nthe output\nas you can see it has given the right\noutput which is the corpus\nso let's use limitation on the given\nwords\nso as you can see here the lemmatizer\nhas kept the words as it is this is\nbecause we haven't assigned any pos tags\nhere and hence it has assumed all the\nwords as none now we'll learn about pos\nlater in this video but just to give you\na hint of what pos is pos is basically\nparts of speech\nso as to define which word is a noun\nwhich is a pronoun\nand which is a subject and much more\nnow do you know there are several words\nin the english language such as\ni at for begin gone no various\nwhich are thought of as useful in the\nformation of sentence and without it the\nsentences won't even make sense\nbut these do not provide any help in nlp\nso these lists of words are known as\nstop words\nso you might be confused as if are they\nhelpful or not\nit is helpful in the english language\nbut it is not helpful in the language\nprocessing so nltk has its own list of\nstop word you can use the same by\nimporting it from nltk.corpus\nso once we import the stopwatch we can\njust have a look at the different\nstoppers which is provided by nltk\nso we need to mention which language we\nare using so let's have a look at the\nnumber of stoppers we have in english\nformat so just 179\nso remember guys when we use the fdist\nunderscore top 10 to check the top 10\ntokens which have the highest number of\nfrequency\nso let us take that again\nso as you can see here apart from the\nword intelligence and intelligent\nall of the words are usually stop words\nor basically i should say that they do\nnot match any particular word they are\nlike special digits and characters which\ndo not add any value to the language\nprocessing\nand hence it can be removed\nso first of all we will use the compile\nfrom the re module to create a string\nthat matches any digit or the special\ncharacter now we'll create an empty list\nand append the words without any\npunctuation into the list\nso i'm naming this as post punctuation\nand if you have a look at the output of\nthe post punctuation\nso as you can see\nit has removed all the various numbers\nand digits and the comma and the\ndifferent elements\nnow when i was talking about pos which\nis parts of speech\nnow generally speaking the grammatical\ntype of the word\nthe verb the noun adjective adverb and\narticle now it indicates how a word\nfunctions in meaning as well as\ngrammatically within the sentence\na word can have more than one parts of\nspeech based on the context in which it\nis used for example if we take the\nsentence google something on the\ninternet\nnow here google is used as a verb\nalthough it is a proper noun now these\nare some sort of ambiguities and the\ndifficulties which makes the natural\nlanguage understanding even much more\nharder as compared to natural language\ngeneration because once you understand\nthe language generation is pretty easy\nso pos tags are usually used to describe\nwhether the word is a noun\nan adjective a pronoun\na proper noun singular plural verb is it\na symbol is it an adverb so as you can\nsee here we have so many tags and\ndescriptions\nfor the different kinds of words\nall the way ranging from coordinating\nconjunction to what work wrp\nnow let's take an example of these two\nsentences so the first sentence is the\nwaiter clears the plates from the table\nso as you can see from the starting if\nwe use the word take into consideration\nthe it is a determiner\nnow waiter is a noun cleared is a verb\nthe is again determiner the plates are\nnoun from is not defined here the is\nagain the determiner and the table is\nagain a noun\nnow again if we take into consideration\nthe sentence\nthe dog ate the cat\nsimilarly this is the determiner dog\nnoun eight is the verb and again it's\nthe same determiner and the noun\nso let's see how we can implement pos\ntags and do the tagging using the nltk\nlibrary so let us take a sentence\ntimothy is a natural when it comes to\ndrawing first of all we'll tokenize it\nusing the word underscore tokenize\nand then we are going to use the pos\nunderscore tag on all of these tokens\nso as you can see it has defined timothy\nas a noun is as a verb as a determiner\nnatural as an adjective when as a wrp\nobjective and it as a preposition it\ncomes as a verb to and drawing as a verb\nas well\nnow let's take another example that john\nis eating a delicious cake\nso as you can see here the tiger has\ntagged both the is\nand eating as well because it has\nconsidered is eating as a single term\nnow this is one of the small\nshortcomings of the pos taggers when it\ncomes to tying the words\nnow another concept in natural language\nprocessing is ner which is known as\nnamed entity recognition\nso the process of detecting the named\nentities such as a movie a monetary\nvalue be it an organization a location\nquantities and a person from a text is\nknown as named intelligent recognition\nnow there are three phases of ner which\nis first is the noun phrase\nidentification now this step deals with\nextracting all the noun phrases from a\ntext using dependency passing and paths\nof speech tagging which is the pos tag\nnow secondly we have the phrase\nclassification now this is the\nclassification step in which all the\nextracted nouns and phrase are\nclassified into respective categories\nsuch as location names and much more\nnow apart from this one can curate the\nlookup tables and dictionaries by\ncombining information from the different\nsources and finally we have the entity\ndisambiguation now sometimes it is\npossible that the entities are\nmisclassified hence creating a\nvalidation layer on top of the result is\nvery useful the use of knowledge graphs\ncan be exploited for this purpose now\nthe popular knowledge graphs are the\ngoogle knowledge craft the ibm watson\nand also wikipedia\nso if we have a look at a certain\nexample suppose this is the sentence the\ngoogle ceo sundar pichai introduced the\nnew pixel at minnesota roy center event\nso as you can see\ngoogle is an organization sundar pichai\nis a person minnesota is a location\nhenry center event is also an\norganization this is an additional layer\non top of the pos tagging so as to\nclarify and give us more depth into what\nthe sentence is about and what the\nsentence is conveying us so for using\nner in python you need to import the any\nunderscore chunk from the nltk module in\npython so once we have imported any\nunderscore chunk\nnow let us take this sentence into\nconsideration which is the us president\nstays in the white house now again what\nwe need to do is tokenize this sentence\nand after tokenizing what we need to do\nis add the pos tags\nso that it will be easier for us to\nconclude the ners\nso we are passing the any underscore\ntags into any underscore chunks function\nand let's see what's the output so as\nyou can see it has given d as a\ndeterminer it has given us as an\norganization and white house is clubbed\ntogether as a single entity and is\nconsidered as a facility so as you can\nsee adding a layer of dictionary and\nthen adding the tags\nand then creating the name entity\nrecognition makes the understanding of\nlanguage so much more easier\nnow as you can see in the nei entity\nlist we have geosocial political group\ngeopolitical entity we have facility\nlocation\norganization and person so as you saw\njust from the previous example\nas you can see we have given\norganization\nwe have facility\nnow an important thing to consider in\nnlp is also\nthe syntax now any linguistics syntax is\nthe set of rules principles and the\nprocesses that govern the structure of a\nsentence in a given language the term\nsyntax is also used to refer to the\nstudy of such principles and processes\nso we have a certain rules\nas to what part of sentence should come\nup at what position now with these rules\nwe create a syntax tree whenever there\nis a sentence as an input so syntax tree\nin layman terms is basically a tree\nrepresentation of the syntactic\nstructure of sentences or strings now it\nis a way of representing the syntax of a\nprogramming language as a hierarchical\ntree-like structure and this structure\nis used for generating symbol tables for\ncompilers and later code generation the\ntree represents all the constructs in\nthe language and their subsequent rules\nnow consider the statement the cat sat\non a mat\nso as you can see this is how a syntax\ntrade looks like\nwe have a sentence we have the noun\nphrase the preposition phrase and again\nthe noun phrase is divided into article\nand noun then we have the verb which is\nsat again we have the preposition which\nis on and again finally we have the noun\nphrase which consists of article and the\nnoun now in order to render syntax trees\nin your notebook you need to install\nghost strips which is a rendering engine\nso you can download ghost strip from\nthis downloads page\ni'll not go much into the details of\nthat\nnow let us discuss\nan important concept with respect to\nanalyzing the sentence structure which\nis chunking now chunking basically means\npicking up individual pieces of\ninformation and grouping them into\nbigger pieces\nso as we saw earlier that we have a\nsentence and we divided it into\ndifferent tokens that was tokenization\nand this is sort of like the opposite\npart or we should say the opposite of\nwhat we call known as tokenization a\nlittle bit of changes to that\ntokenization part we'll see what are the\ndifferent changes now the bigger pieces\nare usually known as chunks here now in\nthe context of nlp chunking means\ngrouping of words or the tokens into\nchunks now let's have a look at the\nexample of chunking here\nso let's consider the statement we got\nthe pink panther\nso as you can see here the pink which is\nan adjective panther which is a noun and\nthough which is the determiner are\nchunked together into a noun phrase\nnow this also helps in determining and\nthe processing of the language\nso suppose if someone is asking whom did\nwe caught this morning so the regular\nresponse to this question would be we\ncaught the pink panther now the question\nis asking who so the pink panther\nbecomes a noun phrase basically so this\nis something what the chunking does is\nthat it understands the language and\nwhen it has understood what it does is\nbasically picks up the individual pieces\nof information and groups them into\nchunks\nso that it will be easier for us to\nprocess that data\nso let's take a new sentence the big cat\nate little mouse who was\nafter the fresh cheese\nso let's tokenize it and add the post\ntags also so as you can see just under\none line or i should say and one command\ni have tokenized it and i have added the\npos tags also\nso let's define the grammar here\nso next what we are going to do is\ncreate a regular expression parser for\nthe grammar np which is the grammar\nwhich we have provided\nand then we'll create the chunk\nunderscore result and we'll pass this\nwhole sentence or i should say the\ntokens into the chunks\nthere was a slider as nltk was unable to\nfile the js file but as you can see here\nwe have a tree in which the np is\nthe big cat\nthe big cat is a noun phrase it is a\nverb tree then again we have the noun\nphrase which is the little mouse who is\na word phrase was is a verb after is in\nand again we have the noun phrase the\nfresh cheese so you can see here\nalthough we do not have a particular\ntree like structure we can see that from\nthe outer we can see we have a tree\nstarting from the start is here and the\nend is here and you can see it starts\nwith the noun phrase the big cat now the\nbig cat as i mentioned earlier in our\nprevious example similarly to the pink\npanther it has been taken into\nconsideration as a noun phrase which is\nbasically a chunk it has created\ndifferent chunks in the given sentence i\nshould say\nso this is it guys i hope you got an\nidea of what the different parts of nlp\nis what is nlp how it is used\nthe different elements of nlp such as\nstarting from tokenization stop words\nstemming limitization again we have the\nstopwatch part of speech pos tags ner\nnamed entity recognition and after ner\nwe had the syntax\nwe created a syntax tree to know how\nexactly the sentence is arranged and how\nit uses the dictionary the pos tags and\nthe tokenization to create a particular\ntree so as to form a meaning out of that\nsentence\nand finally we are using chunking as to\nchunk together the small tokens into\nmeaningful words so guys i hope you\nliked this session and i'm sure you guys\nwill start implementing these procedures\non the given text using the nltk library\nand let me tell you one thing guys the\nnltk library is filled with lots and\nlots of text data and lots and lots of\nexample this is just the beginning of it\nand you can dig deeper into nlp and go\ninto topics like context free grammar\nand much more which is already there in\nthe nltk package and is very useful when\nit comes to natural language processing\nthank you\n",
  "words": [
    "welcome",
    "everyone",
    "free",
    "code",
    "camp",
    "chrisley",
    "behalf",
    "edureka",
    "take",
    "session",
    "natural",
    "language",
    "processing",
    "popularly",
    "known",
    "nlp",
    "edureka",
    "global",
    "company",
    "provides",
    "online",
    "training",
    "courses",
    "latest",
    "trending",
    "technologies",
    "without",
    "delay",
    "let",
    "look",
    "agenda",
    "session",
    "start",
    "explaining",
    "evolution",
    "human",
    "language",
    "understand",
    "nlp",
    "came",
    "picture",
    "moving",
    "forward",
    "look",
    "various",
    "application",
    "nlp",
    "industry",
    "next",
    "understand",
    "different",
    "components",
    "nlp",
    "difficulties",
    "faced",
    "implementing",
    "finally",
    "finish",
    "video",
    "explaining",
    "guys",
    "various",
    "steps",
    "paths",
    "involved",
    "natural",
    "language",
    "processing",
    "along",
    "demo",
    "one",
    "steps",
    "success",
    "human",
    "race",
    "ability",
    "communicate",
    "information",
    "sharing",
    "using",
    "ability",
    "marched",
    "ahead",
    "animals",
    "become",
    "sophisticated",
    "creatures",
    "differentiates",
    "us",
    "among",
    "animals",
    "begin",
    "look",
    "ways",
    "preserve",
    "thoughts",
    "feelings",
    "messages",
    "information",
    "started",
    "oral",
    "communication",
    "like",
    "animals",
    "informal",
    "nature",
    "began",
    "painting",
    "walls",
    "caves",
    "lived",
    "need",
    "standardize",
    "drawing",
    "everyone",
    "could",
    "understand",
    "concept",
    "developing",
    "language",
    "came",
    "however",
    "many",
    "standards",
    "came",
    "resulting",
    "many",
    "languages",
    "language",
    "basic",
    "sets",
    "alphabets",
    "combination",
    "alphabets",
    "known",
    "words",
    "combination",
    "words",
    "arranged",
    "meaningfully",
    "became",
    "sentence",
    "language",
    "set",
    "rules",
    "based",
    "words",
    "combined",
    "form",
    "sentences",
    "set",
    "rules",
    "nothing",
    "call",
    "grammar",
    "gon",
    "na",
    "take",
    "time",
    "explaining",
    "guys",
    "grammar",
    "coming",
    "today",
    "world",
    "according",
    "industry",
    "estimates",
    "21",
    "available",
    "data",
    "present",
    "structured",
    "form",
    "data",
    "generated",
    "speak",
    "tweet",
    "send",
    "message",
    "whatsapp",
    "instagram",
    "imessaging",
    "various",
    "platforms",
    "majority",
    "data",
    "exist",
    "textual",
    "form",
    "highly",
    "unstructured",
    "nature",
    "order",
    "produce",
    "significant",
    "actionable",
    "insights",
    "text",
    "data",
    "important",
    "get",
    "acquainted",
    "techniques",
    "principle",
    "natural",
    "language",
    "processing",
    "let",
    "understand",
    "exactly",
    "nlp",
    "natural",
    "language",
    "processing",
    "nlp",
    "refers",
    "artificial",
    "intelligence",
    "method",
    "communicating",
    "intelligent",
    "system",
    "using",
    "natural",
    "language",
    "part",
    "computer",
    "science",
    "artificial",
    "intelligence",
    "deals",
    "human",
    "language",
    "utilizing",
    "nlp",
    "components",
    "one",
    "organize",
    "massive",
    "chunks",
    "text",
    "data",
    "perform",
    "numerous",
    "automated",
    "tasks",
    "solve",
    "wide",
    "range",
    "problems",
    "automation",
    "summarization",
    "machine",
    "translation",
    "named",
    "entity",
    "recognition",
    "relationship",
    "extraction",
    "sentimental",
    "analysis",
    "speech",
    "recognition",
    "topic",
    "segmentations",
    "learn",
    "later",
    "video",
    "goal",
    "process",
    "rather",
    "say",
    "understand",
    "natural",
    "language",
    "order",
    "perform",
    "useful",
    "tasks",
    "tasks",
    "include",
    "making",
    "appointment",
    "buying",
    "things",
    "spell",
    "checking",
    "generating",
    "responses",
    "social",
    "media",
    "monitoring",
    "look",
    "various",
    "application",
    "nlp",
    "industry",
    "firstly",
    "spell",
    "checking",
    "usually",
    "find",
    "mostly",
    "words",
    "document",
    "reader",
    "even",
    "online",
    "also",
    "spell",
    "checking",
    "next",
    "keyword",
    "search",
    "also",
    "field",
    "nlp",
    "heavily",
    "used",
    "extracting",
    "information",
    "websites",
    "particular",
    "document",
    "also",
    "requires",
    "knowledge",
    "nlp",
    "one",
    "coolest",
    "application",
    "nlp",
    "address",
    "matching",
    "basically",
    "recommendation",
    "ads",
    "based",
    "search",
    "analyzes",
    "text",
    "data",
    "already",
    "using",
    "searched",
    "match",
    "text",
    "data",
    "advertisement",
    "sentimental",
    "analysis",
    "also",
    "major",
    "part",
    "nlp",
    "another",
    "application",
    "speaker",
    "ignition",
    "also",
    "talking",
    "voice",
    "assistants",
    "like",
    "siri",
    "google",
    "assistant",
    "cortana",
    "need",
    "thank",
    "apple",
    "creating",
    "first",
    "voice",
    "assistant",
    "siri",
    "next",
    "implementation",
    "chatbots",
    "guys",
    "might",
    "used",
    "customer",
    "chat",
    "services",
    "provided",
    "various",
    "apps",
    "apps",
    "use",
    "chatbot",
    "uses",
    "nlp",
    "process",
    "data",
    "entered",
    "provides",
    "response",
    "based",
    "input",
    "also",
    "application",
    "natural",
    "language",
    "processing",
    "another",
    "application",
    "nlp",
    "machine",
    "translation",
    "common",
    "example",
    "google",
    "translate",
    "know",
    "uses",
    "nlp",
    "translate",
    "data",
    "say",
    "text",
    "one",
    "language",
    "real",
    "time",
    "nlp",
    "consists",
    "two",
    "components",
    "natural",
    "language",
    "understanding",
    "referred",
    "nlu",
    "natural",
    "language",
    "generation",
    "referred",
    "nlg",
    "understanding",
    "natural",
    "language",
    "involves",
    "mapping",
    "giving",
    "input",
    "natural",
    "language",
    "useful",
    "representation",
    "analyzing",
    "different",
    "aspects",
    "language",
    "natural",
    "language",
    "generation",
    "process",
    "producing",
    "meaningful",
    "phrases",
    "sentences",
    "form",
    "natural",
    "language",
    "internal",
    "representation",
    "involves",
    "text",
    "planning",
    "includes",
    "retrieving",
    "relevant",
    "contents",
    "knowledge",
    "base",
    "involves",
    "sentence",
    "planning",
    "includes",
    "choosing",
    "require",
    "words",
    "meaningful",
    "phrases",
    "setting",
    "tone",
    "sentences",
    "finally",
    "text",
    "realization",
    "mapping",
    "sentence",
    "plan",
    "sentence",
    "structure",
    "learn",
    "later",
    "video",
    "usually",
    "natural",
    "language",
    "understanding",
    "nlu",
    "much",
    "much",
    "harder",
    "energy",
    "might",
    "thinking",
    "even",
    "small",
    "child",
    "understand",
    "language",
    "come",
    "easy",
    "human",
    "beings",
    "difficult",
    "computer",
    "process",
    "let",
    "understand",
    "difficulties",
    "machine",
    "faces",
    "understanding",
    "language",
    "natural",
    "language",
    "understanding",
    "certain",
    "ambiguities",
    "lexical",
    "ambiguities",
    "syntactical",
    "ambiguity",
    "referential",
    "ambiguity",
    "understanding",
    "new",
    "language",
    "hard",
    "taking",
    "english",
    "consideration",
    "lot",
    "ambiguity",
    "different",
    "levels",
    "starting",
    "lexical",
    "ambiguity",
    "lexical",
    "ambiguity",
    "presence",
    "two",
    "possible",
    "meanings",
    "within",
    "single",
    "word",
    "also",
    "called",
    "semantic",
    "ambiguity",
    "example",
    "let",
    "consider",
    "following",
    "sentences",
    "let",
    "focus",
    "italicized",
    "rules",
    "looking",
    "match",
    "infer",
    "match",
    "word",
    "looking",
    "match",
    "head",
    "end",
    "match",
    "looking",
    "match",
    "partner",
    "fisherman",
    "went",
    "bank",
    "bank",
    "withdraw",
    "money",
    "bank",
    "rows",
    "boat",
    "catches",
    "fishes",
    "syntactical",
    "ambiguity",
    "english",
    "grammar",
    "ambiguity",
    "presence",
    "two",
    "possible",
    "meanings",
    "within",
    "single",
    "sentence",
    "sequence",
    "words",
    "also",
    "called",
    "structure",
    "ambiguity",
    "grammatical",
    "ambiguity",
    "let",
    "look",
    "sentences",
    "chicken",
    "ready",
    "eat",
    "chicken",
    "ready",
    "eat",
    "something",
    "chicken",
    "ready",
    "us",
    "eat",
    "kind",
    "syntactical",
    "ambiguity",
    "often",
    "hard",
    "info",
    "new",
    "person",
    "rather",
    "say",
    "computer",
    "means",
    "meaning",
    "sentence",
    "different",
    "different",
    "tones",
    "different",
    "aspects",
    "example",
    "look",
    "last",
    "statement",
    "saw",
    "man",
    "binoculars",
    "banner",
    "man",
    "binocular",
    "might",
    "possible",
    "might",
    "thinking",
    "saw",
    "man",
    "binoculars",
    "means",
    "banners",
    "somewhere",
    "people",
    "might",
    "think",
    "guy",
    "seeing",
    "binoculars",
    "rather",
    "syntactical",
    "ambiguity",
    "coming",
    "third",
    "ambiguity",
    "referential",
    "ambiguity",
    "ambiguity",
    "arises",
    "refer",
    "something",
    "using",
    "pronouns",
    "boy",
    "told",
    "father",
    "theft",
    "upset",
    "talk",
    "upset",
    "focus",
    "italicized",
    "word",
    "mean",
    "boy",
    "upset",
    "thief",
    "upset",
    "father",
    "upset",
    "nobody",
    "knows",
    "referential",
    "ambiguity",
    "coming",
    "back",
    "nlp",
    "using",
    "nlp",
    "onto",
    "system",
    "natural",
    "language",
    "processing",
    "need",
    "install",
    "nltk",
    "library",
    "natural",
    "language",
    "toolkit",
    "nltk",
    "leading",
    "platform",
    "building",
    "python",
    "programs",
    "work",
    "human",
    "language",
    "data",
    "provides",
    "easy",
    "use",
    "interfaces",
    "50",
    "corpora",
    "lexical",
    "resources",
    "wordnet",
    "along",
    "suit",
    "text",
    "processing",
    "libraries",
    "classification",
    "tokenization",
    "stemming",
    "tagging",
    "much",
    "let",
    "show",
    "download",
    "ltk",
    "order",
    "download",
    "nltk",
    "go",
    "python",
    "shell",
    "type",
    "word",
    "nltk",
    "dot",
    "download",
    "using",
    "parenthesis",
    "get",
    "type",
    "window",
    "nltk",
    "downloader",
    "need",
    "select",
    "option",
    "click",
    "download",
    "button",
    "download",
    "corpora",
    "text",
    "packages",
    "one",
    "single",
    "place",
    "choose",
    "directory",
    "want",
    "install",
    "better",
    "download",
    "python",
    "directory",
    "easier",
    "access",
    "files",
    "text",
    "offer",
    "process",
    "text",
    "terminologies",
    "need",
    "understand",
    "first",
    "terminology",
    "talking",
    "tokenization",
    "process",
    "breaking",
    "strings",
    "tokens",
    "turn",
    "small",
    "structures",
    "units",
    "used",
    "tokenization",
    "involves",
    "three",
    "steps",
    "breaking",
    "complex",
    "sentence",
    "words",
    "understanding",
    "importance",
    "words",
    "respect",
    "sentence",
    "produce",
    "structural",
    "description",
    "input",
    "sentence",
    "take",
    "sentence",
    "today",
    "understand",
    "tokenization",
    "see",
    "five",
    "tokens",
    "first",
    "one",
    "today",
    "understand",
    "tokenization",
    "words",
    "computer",
    "terms",
    "known",
    "tokens",
    "referred",
    "tokenization",
    "let",
    "show",
    "guys",
    "implement",
    "tokenization",
    "using",
    "nltk",
    "library",
    "using",
    "jupiter",
    "notebook",
    "free",
    "use",
    "sort",
    "id",
    "also",
    "personal",
    "preference",
    "jupyter",
    "notebook",
    "first",
    "let",
    "import",
    "os",
    "nltk",
    "library",
    "download",
    "nl",
    "ticket",
    "corpus",
    "let",
    "look",
    "corpora",
    "provided",
    "nltk",
    "whole",
    "data",
    "see",
    "many",
    "files",
    "files",
    "different",
    "functionalities",
    "textual",
    "data",
    "different",
    "functions",
    "associated",
    "stopwatch",
    "see",
    "state",
    "union",
    "names",
    "twitter",
    "sample",
    "data",
    "different",
    "kind",
    "data",
    "different",
    "kind",
    "functions",
    "let",
    "take",
    "brown",
    "consideration",
    "see",
    "brown",
    "brown",
    "zip",
    "first",
    "need",
    "import",
    "brown",
    "let",
    "look",
    "words",
    "present",
    "brown",
    "see",
    "fluton",
    "country",
    "grand",
    "jury",
    "said",
    "going",
    "let",
    "look",
    "different",
    "gutenberg",
    "fields",
    "see",
    "gutenberg",
    "file",
    "austin",
    "mr",
    "text",
    "bible",
    "text",
    "blake",
    "poems",
    "carol",
    "alice",
    "text",
    "edgeworth",
    "shakespeares",
    "shakespeare",
    "whitman",
    "leaves",
    "nltk",
    "big",
    "directory",
    "big",
    "library",
    "download",
    "might",
    "need",
    "couple",
    "minutes",
    "download",
    "library",
    "let",
    "take",
    "shakespeare",
    "look",
    "words",
    "inside",
    "hamlet",
    "file",
    "see",
    "starts",
    "tragedy",
    "hamlet",
    "goes",
    "look",
    "first",
    "500",
    "words",
    "textual",
    "paragraph",
    "say",
    "textual",
    "file",
    "using",
    "word",
    "hamlet",
    "using",
    "colon",
    "500",
    "end",
    "point",
    "see",
    "starts",
    "tragedy",
    "hamlet",
    "william",
    "shakespeare",
    "1599",
    "actus",
    "primus",
    "schona",
    "prima",
    "goes",
    "natural",
    "language",
    "processing",
    "use",
    "either",
    "text",
    "provided",
    "understanding",
    "create",
    "words",
    "example",
    "defined",
    "paragraph",
    "based",
    "artificial",
    "intelligence",
    "okay",
    "goes",
    "like",
    "according",
    "father",
    "artificial",
    "intelligence",
    "john",
    "mccartney",
    "science",
    "engineering",
    "let",
    "us",
    "first",
    "define",
    "string",
    "okay",
    "ai",
    "taking",
    "string",
    "easy",
    "show",
    "guys",
    "work",
    "string",
    "type",
    "ai",
    "see",
    "sdr",
    "string",
    "nltk",
    "going",
    "import",
    "word",
    "tokenize",
    "right",
    "function",
    "understand",
    "works",
    "run",
    "word",
    "underscore",
    "tokenize",
    "function",
    "paragraph",
    "assign",
    "name",
    "let",
    "assign",
    "ai",
    "underscore",
    "tokens",
    "look",
    "air",
    "underscore",
    "tokens",
    "see",
    "divided",
    "whole",
    "ai",
    "paragraph",
    "gave",
    "tokens",
    "see",
    "taken",
    "comma",
    "also",
    "consideration",
    "hyphen",
    "also",
    "goes",
    "let",
    "look",
    "number",
    "tokens",
    "going",
    "use",
    "length",
    "function",
    "see",
    "273",
    "tokens",
    "nltk",
    "probability",
    "function",
    "frequency",
    "distinct",
    "show",
    "word",
    "ea",
    "underscore",
    "tokens",
    "going",
    "convert",
    "lower",
    "keys",
    "avoid",
    "probability",
    "considering",
    "word",
    "uppercase",
    "lowercase",
    "different",
    "going",
    "assign",
    "number",
    "basically",
    "word",
    "count",
    "program",
    "implemented",
    "using",
    "frequency",
    "distinct",
    "function",
    "already",
    "present",
    "nltk",
    "library",
    "let",
    "see",
    "output",
    "one",
    "see",
    "comma",
    "appeared",
    "30",
    "times",
    "full",
    "stop",
    "appeared",
    "9",
    "times",
    "question",
    "mark",
    "1",
    "like",
    "see",
    "intelligence",
    "appeared",
    "6",
    "times",
    "intelligent",
    "sixth",
    "time",
    "intelligently",
    "appeared",
    "one",
    "time",
    "suppose",
    "want",
    "know",
    "frequency",
    "particular",
    "word",
    "going",
    "use",
    "function",
    "f",
    "test",
    "distinct",
    "frequency",
    "going",
    "use",
    "function",
    "particular",
    "word",
    "example",
    "let",
    "say",
    "want",
    "know",
    "frequency",
    "artificial",
    "see",
    "three",
    "times",
    "check",
    "database",
    "see",
    "artificial",
    "given",
    "three",
    "want",
    "look",
    "number",
    "distinct",
    "words",
    "need",
    "pass",
    "function",
    "length",
    "function",
    "see",
    "earlier",
    "273",
    "tokens",
    "121",
    "distinct",
    "tokens",
    "suppose",
    "select",
    "top",
    "10",
    "tokens",
    "highest",
    "frequency",
    "assigning",
    "new",
    "f",
    "test",
    "underscore",
    "top",
    "10",
    "using",
    "underscore",
    "common",
    "function",
    "passing",
    "10",
    "number",
    "items",
    "want",
    "let",
    "see",
    "output",
    "see",
    "mentioned",
    "earlier",
    "comma",
    "appears",
    "30",
    "times",
    "highest",
    "frequency",
    "world",
    "appeased",
    "five",
    "times",
    "top",
    "ten",
    "words",
    "reoccurring",
    "words",
    "given",
    "paragraph",
    "given",
    "sentence",
    "let",
    "use",
    "blank",
    "line",
    "tokenizer",
    "string",
    "tokenize",
    "paragraph",
    "respect",
    "blank",
    "string",
    "see",
    "importing",
    "blank",
    "line",
    "underscore",
    "tokenize",
    "earlier",
    "import",
    "word",
    "underscore",
    "tokenize",
    "using",
    "blank",
    "line",
    "stroke",
    "noise",
    "passing",
    "ai",
    "paragraph",
    "gave",
    "earlier",
    "checking",
    "length",
    "ai",
    "underscore",
    "blank",
    "see",
    "provides",
    "us",
    "output",
    "nine",
    "tells",
    "us",
    "number",
    "paragraphs",
    "separated",
    "new",
    "line",
    "given",
    "document",
    "suppose",
    "want",
    "look",
    "first",
    "paragraph",
    "supposedly",
    "second",
    "paragraph",
    "pass",
    "number",
    "give",
    "whole",
    "paragraph",
    "want",
    "separated",
    "new",
    "line",
    "course",
    "coming",
    "back",
    "tokenization",
    "part",
    "diagrams",
    "diagrams",
    "engrams",
    "diagrams",
    "tokens",
    "two",
    "consecutive",
    "written",
    "words",
    "similarly",
    "diagrams",
    "referred",
    "tokens",
    "three",
    "consecutive",
    "written",
    "words",
    "usually",
    "referred",
    "tokens",
    "number",
    "consecutive",
    "written",
    "words",
    "n",
    "numbers",
    "let",
    "see",
    "implement",
    "using",
    "nltk",
    "libraries",
    "diagrams",
    "diagrams",
    "engrams",
    "first",
    "need",
    "import",
    "backgrounds",
    "diagrams",
    "engrams",
    "let",
    "take",
    "string",
    "best",
    "visual",
    "thing",
    "world",
    "seen",
    "even",
    "test",
    "must",
    "filled",
    "heart",
    "beautiful",
    "code",
    "let",
    "us",
    "first",
    "create",
    "tokens",
    "string",
    "using",
    "word",
    "underscore",
    "tokenize",
    "earlier",
    "create",
    "background",
    "need",
    "use",
    "list",
    "function",
    "inside",
    "going",
    "use",
    "pass",
    "tokens",
    "see",
    "created",
    "diagram",
    "given",
    "document",
    "similarly",
    "create",
    "trigrams",
    "engrams",
    "need",
    "change",
    "bigrams",
    "trigrams",
    "give",
    "trigram",
    "list",
    "let",
    "us",
    "create",
    "list",
    "okay",
    "guys",
    "see",
    "using",
    "function",
    "grams",
    "inside",
    "passing",
    "quotes",
    "course",
    "token",
    "place",
    "n",
    "going",
    "give",
    "number",
    "let",
    "say",
    "suppose",
    "provide",
    "five",
    "see",
    "given",
    "us",
    "length",
    "five",
    "got",
    "words",
    "say",
    "tokens",
    "need",
    "make",
    "changes",
    "tokens",
    "stemming",
    "stemming",
    "normalize",
    "words",
    "base",
    "root",
    "form",
    "look",
    "words",
    "affectation",
    "effects",
    "affections",
    "affected",
    "affection",
    "affecting",
    "words",
    "originate",
    "single",
    "root",
    "world",
    "effect",
    "stemming",
    "algorithm",
    "works",
    "cutting",
    "end",
    "beginning",
    "word",
    "taking",
    "account",
    "list",
    "common",
    "prefixes",
    "suffixes",
    "found",
    "infected",
    "world",
    "indiscriminate",
    "cutting",
    "successful",
    "occasions",
    "always",
    "affirm",
    "approach",
    "presents",
    "limitations",
    "let",
    "see",
    "implement",
    "stemming",
    "see",
    "limitations",
    "stemming",
    "overcome",
    "quite",
    "different",
    "types",
    "stemmer",
    "let",
    "start",
    "portal",
    "stemmer",
    "going",
    "use",
    "import",
    "portastimo",
    "let",
    "see",
    "give",
    "us",
    "output",
    "stemming",
    "word",
    "see",
    "given",
    "us",
    "root",
    "word",
    "similarly",
    "provide",
    "list",
    "words",
    "give",
    "giving",
    "given",
    "gave",
    "given",
    "name",
    "words",
    "stem",
    "forwards",
    "inverse",
    "system",
    "print",
    "words",
    "using",
    "portastimer",
    "method",
    "see",
    "given",
    "us",
    "output",
    "give",
    "give",
    "given",
    "gave",
    "see",
    "stemmer",
    "remove",
    "ing",
    "replace",
    "e",
    "another",
    "stemmer",
    "known",
    "lancaster",
    "stemmer",
    "let",
    "try",
    "stem",
    "thing",
    "using",
    "lancast",
    "system",
    "see",
    "difference",
    "let",
    "stem",
    "thing",
    "using",
    "lancast",
    "system",
    "see",
    "differences",
    "first",
    "going",
    "import",
    "landcast",
    "system",
    "going",
    "provide",
    "lst",
    "lancast",
    "system",
    "function",
    "similar",
    "manner",
    "portastema",
    "let",
    "us",
    "execute",
    "lancast",
    "system",
    "also",
    "see",
    "stemmer",
    "stemmed",
    "words",
    "result",
    "conclude",
    "lancaster",
    "stemmer",
    "aggressive",
    "potter",
    "stemmer",
    "use",
    "stemmers",
    "depend",
    "type",
    "task",
    "want",
    "perform",
    "another",
    "stemmer",
    "known",
    "snow",
    "world",
    "stimmer",
    "snowball",
    "stimmer",
    "provide",
    "language",
    "using",
    "similarly",
    "use",
    "snowball",
    "stemmer",
    "given",
    "words",
    "see",
    "given",
    "us",
    "different",
    "output",
    "previous",
    "lancaster",
    "stemmer",
    "see",
    "output",
    "portal",
    "stemmer",
    "differs",
    "different",
    "terms",
    "use",
    "stemmer",
    "depends",
    "type",
    "task",
    "want",
    "perform",
    "example",
    "want",
    "check",
    "many",
    "times",
    "word",
    "giv",
    "used",
    "use",
    "lancaster",
    "demo",
    "purposes",
    "snowballs",
    "number",
    "porter",
    "stem",
    "well",
    "happens",
    "sometimes",
    "stemming",
    "work",
    "properly",
    "always",
    "result",
    "give",
    "us",
    "root",
    "word",
    "example",
    "take",
    "word",
    "fish",
    "fishes",
    "fishing",
    "stems",
    "fish",
    "lemmetization",
    "another",
    "concept",
    "one",
    "hand",
    "stemming",
    "usually",
    "works",
    "cutting",
    "end",
    "beginning",
    "wood",
    "limitization",
    "takes",
    "consideration",
    "morphological",
    "analysis",
    "world",
    "necessary",
    "detailed",
    "dictionary",
    "algorithm",
    "look",
    "link",
    "form",
    "back",
    "lemma",
    "limitization",
    "groups",
    "together",
    "different",
    "infected",
    "forms",
    "word",
    "called",
    "lemma",
    "somehow",
    "similar",
    "stemming",
    "maps",
    "several",
    "words",
    "one",
    "common",
    "root",
    "one",
    "thing",
    "keep",
    "consideration",
    "output",
    "limitization",
    "proper",
    "word",
    "example",
    "look",
    "back",
    "output",
    "given",
    "lancaster",
    "demo",
    "see",
    "given",
    "us",
    "output",
    "give",
    "word",
    "output",
    "limitization",
    "proper",
    "word",
    "example",
    "take",
    "limitation",
    "gone",
    "going",
    "goes",
    "word",
    "go",
    "see",
    "works",
    "example",
    "words",
    "let",
    "try",
    "limitization",
    "using",
    "nltk",
    "library",
    "first",
    "going",
    "import",
    "word",
    "net",
    "mentioned",
    "earlier",
    "requires",
    "dictionary",
    "algorithm",
    "look",
    "link",
    "back",
    "form",
    "original",
    "lemma",
    "since",
    "output",
    "perfect",
    "word",
    "needs",
    "additionally",
    "going",
    "import",
    "wordnet",
    "dictionary",
    "going",
    "import",
    "word",
    "netlemortizer",
    "let",
    "us",
    "first",
    "take",
    "word",
    "corpora",
    "see",
    "lemma",
    "think",
    "guys",
    "output",
    "see",
    "given",
    "right",
    "output",
    "corpus",
    "let",
    "use",
    "limitation",
    "given",
    "words",
    "see",
    "lemmatizer",
    "kept",
    "words",
    "assigned",
    "pos",
    "tags",
    "hence",
    "assumed",
    "words",
    "none",
    "learn",
    "pos",
    "later",
    "video",
    "give",
    "hint",
    "pos",
    "pos",
    "basically",
    "parts",
    "speech",
    "define",
    "word",
    "noun",
    "pronoun",
    "subject",
    "much",
    "know",
    "several",
    "words",
    "english",
    "language",
    "begin",
    "gone",
    "various",
    "thought",
    "useful",
    "formation",
    "sentence",
    "without",
    "sentences",
    "wo",
    "even",
    "make",
    "sense",
    "provide",
    "help",
    "nlp",
    "lists",
    "words",
    "known",
    "stop",
    "words",
    "might",
    "confused",
    "helpful",
    "helpful",
    "english",
    "language",
    "helpful",
    "language",
    "processing",
    "nltk",
    "list",
    "stop",
    "word",
    "use",
    "importing",
    "import",
    "stopwatch",
    "look",
    "different",
    "stoppers",
    "provided",
    "nltk",
    "need",
    "mention",
    "language",
    "using",
    "let",
    "look",
    "number",
    "stoppers",
    "english",
    "format",
    "179",
    "remember",
    "guys",
    "use",
    "fdist",
    "underscore",
    "top",
    "10",
    "check",
    "top",
    "10",
    "tokens",
    "highest",
    "number",
    "frequency",
    "let",
    "us",
    "take",
    "see",
    "apart",
    "word",
    "intelligence",
    "intelligent",
    "words",
    "usually",
    "stop",
    "words",
    "basically",
    "say",
    "match",
    "particular",
    "word",
    "like",
    "special",
    "digits",
    "characters",
    "add",
    "value",
    "language",
    "processing",
    "hence",
    "removed",
    "first",
    "use",
    "compile",
    "module",
    "create",
    "string",
    "matches",
    "digit",
    "special",
    "character",
    "create",
    "empty",
    "list",
    "append",
    "words",
    "without",
    "punctuation",
    "list",
    "naming",
    "post",
    "punctuation",
    "look",
    "output",
    "post",
    "punctuation",
    "see",
    "removed",
    "various",
    "numbers",
    "digits",
    "comma",
    "different",
    "elements",
    "talking",
    "pos",
    "parts",
    "speech",
    "generally",
    "speaking",
    "grammatical",
    "type",
    "word",
    "verb",
    "noun",
    "adjective",
    "adverb",
    "article",
    "indicates",
    "word",
    "functions",
    "meaning",
    "well",
    "grammatically",
    "within",
    "sentence",
    "word",
    "one",
    "parts",
    "speech",
    "based",
    "context",
    "used",
    "example",
    "take",
    "sentence",
    "google",
    "something",
    "internet",
    "google",
    "used",
    "verb",
    "although",
    "proper",
    "noun",
    "sort",
    "ambiguities",
    "difficulties",
    "makes",
    "natural",
    "language",
    "understanding",
    "even",
    "much",
    "harder",
    "compared",
    "natural",
    "language",
    "generation",
    "understand",
    "language",
    "generation",
    "pretty",
    "easy",
    "pos",
    "tags",
    "usually",
    "used",
    "describe",
    "whether",
    "word",
    "noun",
    "adjective",
    "pronoun",
    "proper",
    "noun",
    "singular",
    "plural",
    "verb",
    "symbol",
    "adverb",
    "see",
    "many",
    "tags",
    "descriptions",
    "different",
    "kinds",
    "words",
    "way",
    "ranging",
    "coordinating",
    "conjunction",
    "work",
    "wrp",
    "let",
    "take",
    "example",
    "two",
    "sentences",
    "first",
    "sentence",
    "waiter",
    "clears",
    "plates",
    "table",
    "see",
    "starting",
    "use",
    "word",
    "take",
    "consideration",
    "determiner",
    "waiter",
    "noun",
    "cleared",
    "verb",
    "determiner",
    "plates",
    "noun",
    "defined",
    "determiner",
    "table",
    "noun",
    "take",
    "consideration",
    "sentence",
    "dog",
    "ate",
    "cat",
    "similarly",
    "determiner",
    "dog",
    "noun",
    "eight",
    "verb",
    "determiner",
    "noun",
    "let",
    "see",
    "implement",
    "pos",
    "tags",
    "tagging",
    "using",
    "nltk",
    "library",
    "let",
    "us",
    "take",
    "sentence",
    "timothy",
    "natural",
    "comes",
    "drawing",
    "first",
    "tokenize",
    "using",
    "word",
    "underscore",
    "tokenize",
    "going",
    "use",
    "pos",
    "underscore",
    "tag",
    "tokens",
    "see",
    "defined",
    "timothy",
    "noun",
    "verb",
    "determiner",
    "natural",
    "adjective",
    "wrp",
    "objective",
    "preposition",
    "comes",
    "verb",
    "drawing",
    "verb",
    "well",
    "let",
    "take",
    "another",
    "example",
    "john",
    "eating",
    "delicious",
    "cake",
    "see",
    "tiger",
    "tagged",
    "eating",
    "well",
    "considered",
    "eating",
    "single",
    "term",
    "one",
    "small",
    "shortcomings",
    "pos",
    "taggers",
    "comes",
    "tying",
    "words",
    "another",
    "concept",
    "natural",
    "language",
    "processing",
    "ner",
    "known",
    "named",
    "entity",
    "recognition",
    "process",
    "detecting",
    "named",
    "entities",
    "movie",
    "monetary",
    "value",
    "organization",
    "location",
    "quantities",
    "person",
    "text",
    "known",
    "named",
    "intelligent",
    "recognition",
    "three",
    "phases",
    "ner",
    "first",
    "noun",
    "phrase",
    "identification",
    "step",
    "deals",
    "extracting",
    "noun",
    "phrases",
    "text",
    "using",
    "dependency",
    "passing",
    "paths",
    "speech",
    "tagging",
    "pos",
    "tag",
    "secondly",
    "phrase",
    "classification",
    "classification",
    "step",
    "extracted",
    "nouns",
    "phrase",
    "classified",
    "respective",
    "categories",
    "location",
    "names",
    "much",
    "apart",
    "one",
    "curate",
    "lookup",
    "tables",
    "dictionaries",
    "combining",
    "information",
    "different",
    "sources",
    "finally",
    "entity",
    "disambiguation",
    "sometimes",
    "possible",
    "entities",
    "misclassified",
    "hence",
    "creating",
    "validation",
    "layer",
    "top",
    "result",
    "useful",
    "use",
    "knowledge",
    "graphs",
    "exploited",
    "purpose",
    "popular",
    "knowledge",
    "graphs",
    "google",
    "knowledge",
    "craft",
    "ibm",
    "watson",
    "also",
    "wikipedia",
    "look",
    "certain",
    "example",
    "suppose",
    "sentence",
    "google",
    "ceo",
    "sundar",
    "pichai",
    "introduced",
    "new",
    "pixel",
    "minnesota",
    "roy",
    "center",
    "event",
    "see",
    "google",
    "organization",
    "sundar",
    "pichai",
    "person",
    "minnesota",
    "location",
    "henry",
    "center",
    "event",
    "also",
    "organization",
    "additional",
    "layer",
    "top",
    "pos",
    "tagging",
    "clarify",
    "give",
    "us",
    "depth",
    "sentence",
    "sentence",
    "conveying",
    "us",
    "using",
    "ner",
    "python",
    "need",
    "import",
    "underscore",
    "chunk",
    "nltk",
    "module",
    "python",
    "imported",
    "underscore",
    "chunk",
    "let",
    "us",
    "take",
    "sentence",
    "consideration",
    "us",
    "president",
    "stays",
    "white",
    "house",
    "need",
    "tokenize",
    "sentence",
    "tokenizing",
    "need",
    "add",
    "pos",
    "tags",
    "easier",
    "us",
    "conclude",
    "ners",
    "passing",
    "underscore",
    "tags",
    "underscore",
    "chunks",
    "function",
    "let",
    "see",
    "output",
    "see",
    "given",
    "determiner",
    "given",
    "us",
    "organization",
    "white",
    "house",
    "clubbed",
    "together",
    "single",
    "entity",
    "considered",
    "facility",
    "see",
    "adding",
    "layer",
    "dictionary",
    "adding",
    "tags",
    "creating",
    "name",
    "entity",
    "recognition",
    "makes",
    "understanding",
    "language",
    "much",
    "easier",
    "see",
    "nei",
    "entity",
    "list",
    "geosocial",
    "political",
    "group",
    "geopolitical",
    "entity",
    "facility",
    "location",
    "organization",
    "person",
    "saw",
    "previous",
    "example",
    "see",
    "given",
    "organization",
    "facility",
    "important",
    "thing",
    "consider",
    "nlp",
    "also",
    "syntax",
    "linguistics",
    "syntax",
    "set",
    "rules",
    "principles",
    "processes",
    "govern",
    "structure",
    "sentence",
    "given",
    "language",
    "term",
    "syntax",
    "also",
    "used",
    "refer",
    "study",
    "principles",
    "processes",
    "certain",
    "rules",
    "part",
    "sentence",
    "come",
    "position",
    "rules",
    "create",
    "syntax",
    "tree",
    "whenever",
    "sentence",
    "input",
    "syntax",
    "tree",
    "layman",
    "terms",
    "basically",
    "tree",
    "representation",
    "syntactic",
    "structure",
    "sentences",
    "strings",
    "way",
    "representing",
    "syntax",
    "programming",
    "language",
    "hierarchical",
    "structure",
    "structure",
    "used",
    "generating",
    "symbol",
    "tables",
    "compilers",
    "later",
    "code",
    "generation",
    "tree",
    "represents",
    "constructs",
    "language",
    "subsequent",
    "rules",
    "consider",
    "statement",
    "cat",
    "sat",
    "mat",
    "see",
    "syntax",
    "trade",
    "looks",
    "like",
    "sentence",
    "noun",
    "phrase",
    "preposition",
    "phrase",
    "noun",
    "phrase",
    "divided",
    "article",
    "noun",
    "verb",
    "sat",
    "preposition",
    "finally",
    "noun",
    "phrase",
    "consists",
    "article",
    "noun",
    "order",
    "render",
    "syntax",
    "trees",
    "notebook",
    "need",
    "install",
    "ghost",
    "strips",
    "rendering",
    "engine",
    "download",
    "ghost",
    "strip",
    "downloads",
    "page",
    "go",
    "much",
    "details",
    "let",
    "us",
    "discuss",
    "important",
    "concept",
    "respect",
    "analyzing",
    "sentence",
    "structure",
    "chunking",
    "chunking",
    "basically",
    "means",
    "picking",
    "individual",
    "pieces",
    "information",
    "grouping",
    "bigger",
    "pieces",
    "saw",
    "earlier",
    "sentence",
    "divided",
    "different",
    "tokens",
    "tokenization",
    "sort",
    "like",
    "opposite",
    "part",
    "say",
    "opposite",
    "call",
    "known",
    "tokenization",
    "little",
    "bit",
    "changes",
    "tokenization",
    "part",
    "see",
    "different",
    "changes",
    "bigger",
    "pieces",
    "usually",
    "known",
    "chunks",
    "context",
    "nlp",
    "chunking",
    "means",
    "grouping",
    "words",
    "tokens",
    "chunks",
    "let",
    "look",
    "example",
    "chunking",
    "let",
    "consider",
    "statement",
    "got",
    "pink",
    "panther",
    "see",
    "pink",
    "adjective",
    "panther",
    "noun",
    "though",
    "determiner",
    "chunked",
    "together",
    "noun",
    "phrase",
    "also",
    "helps",
    "determining",
    "processing",
    "language",
    "suppose",
    "someone",
    "asking",
    "caught",
    "morning",
    "regular",
    "response",
    "question",
    "would",
    "caught",
    "pink",
    "panther",
    "question",
    "asking",
    "pink",
    "panther",
    "becomes",
    "noun",
    "phrase",
    "basically",
    "something",
    "chunking",
    "understands",
    "language",
    "understood",
    "basically",
    "picks",
    "individual",
    "pieces",
    "information",
    "groups",
    "chunks",
    "easier",
    "us",
    "process",
    "data",
    "let",
    "take",
    "new",
    "sentence",
    "big",
    "cat",
    "ate",
    "little",
    "mouse",
    "fresh",
    "cheese",
    "let",
    "tokenize",
    "add",
    "post",
    "tags",
    "also",
    "see",
    "one",
    "line",
    "say",
    "one",
    "command",
    "tokenized",
    "added",
    "pos",
    "tags",
    "also",
    "let",
    "define",
    "grammar",
    "next",
    "going",
    "create",
    "regular",
    "expression",
    "parser",
    "grammar",
    "np",
    "grammar",
    "provided",
    "create",
    "chunk",
    "underscore",
    "result",
    "pass",
    "whole",
    "sentence",
    "say",
    "tokens",
    "chunks",
    "slider",
    "nltk",
    "unable",
    "file",
    "js",
    "file",
    "see",
    "tree",
    "np",
    "big",
    "cat",
    "big",
    "cat",
    "noun",
    "phrase",
    "verb",
    "tree",
    "noun",
    "phrase",
    "little",
    "mouse",
    "word",
    "phrase",
    "verb",
    "noun",
    "phrase",
    "fresh",
    "cheese",
    "see",
    "although",
    "particular",
    "tree",
    "like",
    "structure",
    "see",
    "outer",
    "see",
    "tree",
    "starting",
    "start",
    "end",
    "see",
    "starts",
    "noun",
    "phrase",
    "big",
    "cat",
    "big",
    "cat",
    "mentioned",
    "earlier",
    "previous",
    "example",
    "similarly",
    "pink",
    "panther",
    "taken",
    "consideration",
    "noun",
    "phrase",
    "basically",
    "chunk",
    "created",
    "different",
    "chunks",
    "given",
    "sentence",
    "say",
    "guys",
    "hope",
    "got",
    "idea",
    "different",
    "parts",
    "nlp",
    "nlp",
    "used",
    "different",
    "elements",
    "nlp",
    "starting",
    "tokenization",
    "stop",
    "words",
    "stemming",
    "limitization",
    "stopwatch",
    "part",
    "speech",
    "pos",
    "tags",
    "ner",
    "named",
    "entity",
    "recognition",
    "ner",
    "syntax",
    "created",
    "syntax",
    "tree",
    "know",
    "exactly",
    "sentence",
    "arranged",
    "uses",
    "dictionary",
    "pos",
    "tags",
    "tokenization",
    "create",
    "particular",
    "tree",
    "form",
    "meaning",
    "sentence",
    "finally",
    "using",
    "chunking",
    "chunk",
    "together",
    "small",
    "tokens",
    "meaningful",
    "words",
    "guys",
    "hope",
    "liked",
    "session",
    "sure",
    "guys",
    "start",
    "implementing",
    "procedures",
    "given",
    "text",
    "using",
    "nltk",
    "library",
    "let",
    "tell",
    "one",
    "thing",
    "guys",
    "nltk",
    "library",
    "filled",
    "lots",
    "lots",
    "text",
    "data",
    "lots",
    "lots",
    "example",
    "beginning",
    "dig",
    "deeper",
    "nlp",
    "go",
    "topics",
    "like",
    "context",
    "free",
    "grammar",
    "much",
    "already",
    "nltk",
    "package",
    "useful",
    "comes",
    "natural",
    "language",
    "processing",
    "thank"
  ],
  "keywords": [
    "free",
    "code",
    "take",
    "session",
    "natural",
    "language",
    "processing",
    "known",
    "nlp",
    "provides",
    "without",
    "let",
    "look",
    "start",
    "explaining",
    "human",
    "understand",
    "came",
    "various",
    "application",
    "industry",
    "next",
    "different",
    "components",
    "difficulties",
    "finally",
    "video",
    "guys",
    "steps",
    "demo",
    "one",
    "information",
    "using",
    "animals",
    "us",
    "like",
    "need",
    "drawing",
    "concept",
    "many",
    "words",
    "sentence",
    "set",
    "rules",
    "based",
    "form",
    "sentences",
    "grammar",
    "time",
    "coming",
    "today",
    "world",
    "data",
    "present",
    "textual",
    "order",
    "text",
    "important",
    "artificial",
    "intelligence",
    "intelligent",
    "system",
    "part",
    "computer",
    "chunks",
    "perform",
    "tasks",
    "machine",
    "named",
    "entity",
    "recognition",
    "analysis",
    "speech",
    "learn",
    "later",
    "process",
    "rather",
    "say",
    "useful",
    "spell",
    "checking",
    "usually",
    "document",
    "even",
    "also",
    "used",
    "particular",
    "knowledge",
    "basically",
    "already",
    "match",
    "another",
    "talking",
    "google",
    "creating",
    "first",
    "might",
    "provided",
    "use",
    "uses",
    "input",
    "common",
    "example",
    "know",
    "two",
    "understanding",
    "referred",
    "generation",
    "involves",
    "representation",
    "meaningful",
    "phrases",
    "structure",
    "much",
    "small",
    "easy",
    "certain",
    "ambiguities",
    "lexical",
    "syntactical",
    "ambiguity",
    "referential",
    "new",
    "taking",
    "english",
    "consideration",
    "starting",
    "possible",
    "within",
    "single",
    "word",
    "called",
    "consider",
    "looking",
    "end",
    "bank",
    "chicken",
    "ready",
    "eat",
    "something",
    "kind",
    "person",
    "means",
    "meaning",
    "statement",
    "saw",
    "man",
    "binoculars",
    "father",
    "upset",
    "back",
    "install",
    "nltk",
    "library",
    "python",
    "work",
    "corpora",
    "classification",
    "tokenization",
    "stemming",
    "tagging",
    "show",
    "download",
    "go",
    "type",
    "directory",
    "want",
    "easier",
    "files",
    "tokens",
    "three",
    "respect",
    "see",
    "five",
    "terms",
    "implement",
    "notebook",
    "sort",
    "import",
    "whole",
    "functions",
    "stopwatch",
    "brown",
    "going",
    "file",
    "shakespeare",
    "big",
    "inside",
    "hamlet",
    "starts",
    "goes",
    "paragraph",
    "create",
    "defined",
    "okay",
    "define",
    "string",
    "ai",
    "tokenize",
    "function",
    "works",
    "underscore",
    "assign",
    "name",
    "divided",
    "gave",
    "comma",
    "number",
    "length",
    "frequency",
    "distinct",
    "output",
    "appeared",
    "times",
    "stop",
    "question",
    "suppose",
    "test",
    "check",
    "given",
    "pass",
    "earlier",
    "top",
    "10",
    "highest",
    "passing",
    "mentioned",
    "blank",
    "line",
    "give",
    "diagrams",
    "engrams",
    "consecutive",
    "written",
    "similarly",
    "thing",
    "list",
    "created",
    "provide",
    "got",
    "changes",
    "root",
    "algorithm",
    "cutting",
    "beginning",
    "stemmer",
    "stem",
    "lancaster",
    "lancast",
    "result",
    "previous",
    "well",
    "limitization",
    "dictionary",
    "lemma",
    "together",
    "proper",
    "pos",
    "tags",
    "hence",
    "parts",
    "noun",
    "helpful",
    "add",
    "punctuation",
    "post",
    "verb",
    "adjective",
    "article",
    "context",
    "determiner",
    "cat",
    "comes",
    "preposition",
    "eating",
    "ner",
    "organization",
    "location",
    "phrase",
    "layer",
    "chunk",
    "facility",
    "syntax",
    "tree",
    "chunking",
    "pieces",
    "little",
    "pink",
    "panther",
    "lots"
  ]
}