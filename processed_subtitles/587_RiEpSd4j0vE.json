{
  "text": "foreign\nwelcome to yet another session based on\nscikit-learn today we are going to\ngeneralize how scikit-learn workflow is\nbasic programming intuition behind it\nand then we'll cover the first step of\nevery machine learning problem solving\nmethodology that is making sure data is\nclean and generalizable in more\ntechnical words this step is called\npre-processing so by the end of this\nsession you'll understand the workflow\nof scikit-learn and how you can carry\nout data pre-processing I hope the\nagenda for this session is clear to all\nof you guys but before we get started\nwith this session please make sure that\nyou hit the Subscribe button and Bell\nicon so that you never miss any update\nfrom intellipath YouTube channel okay\nthat being said let's dive into this\nsession and talk about how scikit-learn\nworkflow is now if you guys talk in most\nbasic sense the scikit-learn workflow\nbegins with some sort of data you then\neventually provide that data to the\nmodel and this model will learn from\nprovided data and then it will further\nbe able to make predictions that's the\ngeneral workflow in the most basic sense\nbut that's quite vague so let's go a\nlittle deeper now what do we mean by\ngiving a data set to the model typically\nif we have a data set that is useful to\nmake some predictions we split it into\ntwo parts and the common notation to\ncall the splitted data is one to call X\nand other to call Y now this x here is\nsomething that is representing\neverything that I'll be using to make\npredictions what I mean by that is this\nx will contain the features of an event\nthat will describe the outcome of that\nspecific event for example Heavy Rain\nfalse drainage system are the features\nthat will lead to events such as water\nlogging that means the outcome here is\nwater logging and Rain plus faulty\ndrainage system are the parameters\nresponsible for that event now why in\nour case will be the output data I mean\nit will contain the result which will\noccur on a given set of parameters for\nexample let's say I have an iris data\nset now in this data set I'll have the\nclass of plant as my target variable and\nfeatures such as sample length and width\nas well as petal length and width acting\nas parameters which will describe the\ntype of plant now our model should find\npatterns in these features which make\nthe a particular plan belong to a\ncertain category but before that we'll\nfeed this X and Y data to our model then\nwe'll Train The Logical ml algorithm\nover this provided data basically we'll\nfit our data to this model but before I\ntalk more about that let's visit our\ncode editor and get ourselves a data set\nthat scikit-learn provides the data set\nwill be the same I mean the iris one\nwhose use Library so for that purpose\nlet's visit the code editor\nnow let me import this scikit-learn\nLibrary the command to do that is import\nsklearn and I'll run this block\nnow to get our data set we have a\ncommand and that command is from sklearn\ndot data sets\nimport\nload underscore Iris\nso iris is basically a data set that is\nalready stored inside sqln Library so we\nwill be importing it\nusing this load Iris method\nso let's run this block as well now next\nwe'll visualize how this data looks and\nfor that we'll just write load\nunderscore Iris command and\nthis will actually load the data on our\ncode editor\nso let's run this\nhere you can see that there are input\nvariables and there are some Target\nvariables as well all right and this is\nthe information about our data set now\nif I want to visualize X and Y\nseparately then I can do that by adding\nreturn underscore X underscore y to the\nprevious functional argument\nso I'll copy this command\nI'll add the argument that we just\ntalked about that is\nreturn\nunderscore X underscore\ny\nand I'll run this command oh wait so\nI'll have to set this true as well\nnow here you can see that both the input\nfeatures and the output feature has been\nseparated Clearly Now moving forward\nwe'll be storing this data for future\ncomputation in variables of our own\nlet's say those variables are again X\nand Y and to sort of store this data in\nthese X and Y variables will have to use\nthe load command again so we'll use x\ncomma y\nstores\nload underscore Iris\nand return underscore\nX underscore\ny\nequal to true\nand we'll run this block and with this\nsuccessful execution I can say that I\nhave a feature data and output data\nseparated in X and Y variables okay now\nwe have data in a format that can be fed\nto a machine learning model to sort of\nget an overview of the procedure will\nactually formulate a model but before\nthat we should conceptually visualize\nwhat a machine learning model actually\ndoes and for that purpose let's go back\nto the presentation now when you create\na model initially it's not directly\nfilled with data the model creation\ninvolves two steps in scikit-learn\nbasically we first create or generate a\nmodel and then after that we make the\nmodel learn our data in scikit-learn all\nmodels are just python objects and then\nthis learning over here in scikit-learn\nterminology is often denoted with DOT\nfit methodology during this typical Step\nUp dot fit we actually pass the set of\nvariables that we have termed as X and Y\nrepresenting the feature data and output\nnow remember guys our model must pass\nthrough both of these phases so that it\ncan make the prediction now that being\nsaid I hope that you guys have collected\nsome intuition out of this let me take\nall of you back to the notebook in order\nto show you how easily the said notion\ncan be coded okay guys there is one more\nthing I want you guys to be clear of now\nthe problem that we are dealing with\nhere right now is the classification\nproblem in this problem we have to\nclassify our rows into different plant\nclasses right well we'll be talking\nabout the concept of classification\nlater on in this series but for now let\nme tell you that we can use models like\nlinear regression k n or svm to solve\nthese classification problems now first\nlet me pick up the linear regression\nmodel to call an object of this model\ninside a notebook I'll have to write a\ncommand that is from\nSK learn\ndot linear\nunderscore model import\nlinear\nregression now I'll run this block and\nI'll take new one now for the model\ncreation stuff what I'll have to do is\nI'll have to create a variable name\nmodel and assign this called object to\nit that means what I'll do is I'll\ncreate new variable and I'll put this\nfunction linear regression into it so\nlet me do that\nnow I'll run this block and you can see\nthat the model has been created now guys\nthis is the phase where model is not\nlearning anything here we are just\ncreating it so this is the first stage\nthat we talked about so if I were to\ncall a method model.predict right now it\nmust return an error let me check that\nso if I call model Dot predict\nover the data samples X\nand if I run this statement I must get\nan error and see we are getting it here\nand so for dodging this error all we\nhave to do is fit our model to the data\nfor that purpose let me take a new block\nhere what we'll do is we'll fit our data\nand for that we have a command\nnamed as fit\nand will pass X and Y to it\nyeah you can see that our model is being\nfit with linear regression object or\nalgorithm now once this step is done the\nmodel will pick up patterns from the\ndata set this time when I try to call\nthe predict function our model will be\nable to make some sort of deductions for\nright now we are not going to discuss\nwhat this machine learning model\nactually does because our priority right\nnow is to understand the overview of ml\nmodeling workflow well one more thing\nguys the best thing about scikit-learn\nis that API for all the machine learning\nmodels will remain the same I mean we\njust created the linear regression model\nsimilarly the API structure will prevail\nfor all other models well before that\nlet me actually see if this model is\npredicting the output or not so I'll use\nmodel.predict function and I'll pass X\nto it and it must produce some output\nthat matches with y\nso guys here you can see that we are\ngetting some sort of predictions all\nright now this was the one model what\nabout other models well let's say I want\nto create one more ml model that is K\nnearest neighbor so the first thing I'll\ndo is I'll invoke the K nearest neighbor\nclassifier object and for that I'll use\nthe command that is SK learn\ndot Neighbors\nimport K Neighbors regressor\nand now I'll store this inside the new\nvariable\nand I'll run this block now in The Next\nStep I'll fit our data to this new\nalgorithm\nso Mod Dot fit\nX comma Y and I'll run this now our K\nnearest neighbor regressor will\ngeneralize over the provided data and to\ncheck if it is making right predictions\nor not I'll use the prediction method so\nI'll use mod.predict\nover\nthe input data and I'll run this block\nnow guys you can see that this is\nactually making very close predictions\nright so let me also show you the output\ndata see here it is so it is actually\nmaking very close predictions now we'll\ntalk about the structure of this\nalgorithm later words and why linear\nregression perform bad on this\nparticular use case but for now on let's\njust focus on the workflow of this\nmodeling technique now guys we just saw\nthe predicted data and the given output\ndata and we made a comparison but what\nif I want to visualize this data what\ncan I do well for that purpose I'll have\nto import the matplotlib library the\nmatplotlib library contains lot of graph\nplotting techniques that will allow me\nto plot graph for the predicted data and\nthe actual data so for that purpose I'll\nbe using scatter plot here now what I'll\ndo is I'll put predicted values on x\naxis and given output values on y-axis\nso let me code this quickly import\nmatplotlib\nadd PLT then predicted data is equal to\nmodel dot predict\nX and then I'll plot\nand then I'll plot the scatter\ngraph\nand I'll pass predicted data on x axis\nand y on y that is our output variable\nright so let me run this block and guys\nby looking at this graph you can see\nthat the predictions we have made and\ngiven output matches in all the\nscenarios what that means is our model\nhas learned the pattern in data\naccurately which means there is good\nsignal and low noise but this might not\nPrevail with every data set or the\nproblem we'll discuss more about how\nmodels work and how to choose the best\nmodel but for now this is the basic\nstructure of machine learning solution\nbuildup and its very basic sense but\nguys keep this in mind that this is not\nhow a typical machine learning problem\nworks or this is not how the typical\nmachine learning problem should be coded\nthe data you get might not be well\noptimized and there might be a degree of\ndifference between measurements and data\nlike that cannot be fed to the machine\nlearning model that adds adds one more\nlayer to our machine learning procedure\nthat is data cleaning and pre-processing\nso moving forward we'll take a deep dive\ninto the concept of this data cleaning\nand pre-processing so guys basically\nevery machine learning exploration\nbegins with exporting the data set in\nthe last demo where we understood how\nthe scikit-learn API works we directly\nimported the scikit-learn data set and\nstored it inside one variable but this\ntime I'll show you how to store data set\ninside a data frame now if you guys are\nwondering what exactly is this data\nframe then let me make this clear guys\ndata frame is a unique two-dimensional\ndata structure implemented in pandas\nlibrary of python I mean it contains\nrows and columns like SQL tables or a\nspreadsheet in terms of programming you\ncan visualize it as a dictionary of a\nseries of objects all right okay now\nthat being said the first thing we'll\nhave to do is import the pandas Library\nthe command is quite simple import\npandas\nas PD and I'll run this block now next\nis getting a data to store inside the\ndata frame the data set we are going to\nuse is the Titanic data set now again\nthis is the data set that's part of\nscikit-learn framework and it is\ncommonly used for Learning and data\nexploration purposes if you want to make\na career in data science then intellipat\nhas IIT Madras Advanced Data science and\nAI certification program\nthis course is of very high quality and\ncost effective as it is taught by IIT\nprofessors and Industry experts so guys\nto load this data set we'll have to\nimport one functionality that is fetch\nunderscore openml now the command to do\nthat is from\nsklearn dot data sets\nimport\nfetch underscore openml\nnow I'll run this and it will import the\nfetch openml functionality next we'll\nimport our data set using the fetch\nopenml function and we'll store it\ninside the data frame so how can I do\nthat well DF is equal to fetch\nunderscore openml\nthe data set that I am going to load\nthat is Titanic and I want to use\nactually a very specific version of this\ndata set that is version one\nand I'll set as underscore frame equal\nto true\nand we'll be taking it as a data right\nokay now let's run this block and check\nif our data set is imported and stored\ninside our data frame or not for that\npurpose we'll use the command known as\nDF dot info so let me write that command\nquickly\nand here you can see the information\nabout our data set so basically our data\nset contains 13 columns right and all of\nthem are basically non-null values right\nat the bottom most part you can also\nfind out the data types that are part of\nthis data set here you can see that we\nhave two categorical variables we have\nsix float features and then we have five\nobject type features now let's find out\nif there are missing values in our data\nset the pandas function we have for this\npurpose is dot is null\nso let me use that function quickly DF\ndot is null\nand I'll run this and here you can see\nthat it is highlighting the areas where\na data set contains null values right so\nwherever it is true that means there is\na null value inside that row or that\nparticular column all right guys so this\nis not actually a better way to\nvisualize right so for that I'll\ncalculate the overall null values inside\neach column and the command to do that\nis very simple DF dot is null dot sum so\nI'm summing null values across every\ncolumn all right so let's run this\ncommand and here you can see that there\nare like 263 null values in h column\n1014 null values in K bin column two\nnull values in M Bar column\n1188 in body and same for home.dest and\nbody now the data type here is integer64\nthat is the numbers return here are\ninteger obviously now the question that\nshould strike your mind is how\nsignificant are these null values and is\nit necessary to dodge them well let me\nhelp you guys visualize this with help\nup and graph for this purpose we'll be\nusing the seabon library so let me first\nimport it so I'll import c bond library\nwith command import C bone\nadds SNS and I'll run this block now the\nlibrary has been imported after\nimporting I'll also set the graph\nstyling with the help of set function in\ncball so SNS dot set then we'll\ncalculate the missing value percentage\nfor each feature now how can we do that\nactually Well what we'll do is we'll\ndivide the number of null values entries\nby the number of rows in our data set\nand to convert it into percentage we'll\nmultiply it by 100 and let me put that\nin a programming syntax here so it will\nlook like Miss value percentage\nwill be equal to PD dot data frame\nDF dot is null\ndot sum\ndivided by the length of\nDF all right and I'll multiply it by\n100.\nnow the next step will be the plotting\ngraph we'll plot it as a bar graph and\nwe'll keep the percentage on y-axis okay\nso the command I'll use for that is Miss\nunderscore value percentage\nDot Plot kind of graph I am going to use\nit's again as I mentioned bar then the\ntitle that I want to give to this graph\nthat is missing values\nand then y label that is percentage all\nright so let me run this block\nand here you can clearly deduce that we\ndo have multiple null entries now the\nproblem with that is if we don't have\nappropriate data our model won't be able\nto learn properly right for example\nconsider you don't have any study\nmaterial and suddenly your faculty takes\nyour examination will you be able to\nperform great in that examination you\nwon't be because you won't know the\nconcepts right and same prevails for\nmachine learning and this will actually\nlead to scenario where our model will\nmake very blunt predictions and will\nhave very less accuracy score so we'll\nhave to find a resolution to add\nsomething in place of these missing\nvalues or drop the entire feature so\nthat it won't affect learning adversely\nall right so first let me walk you guys\nthrough the concept of dropping a\nfeature now in our entire data set the\nbody feature has the most null values as\nyou can see here right so what we'll do\nis we'll drop this column we'll print\nthe size of data set the function we\nhave for that purpose is dot shape\nfunction so the command for printing the\nshape will be print the size\nof a\ndata set\nTF dot shape all right now I'll run this\ncommand and we'll get the shape of our\ndata set all right that means there are\n13 columns and 1300 0 9 rows all right\nnow I wanna drop one column right\nso let me move ahead with that the\ncommand for that will be DF dot drop\nwhich is the function that is used to\ndrop the column\nand inside it I'll pass the column that\nI want to drop that is body and I'll set\naxis equal to 1 so that it will remove\nthe column if I set access is equal to 0\nthen it will actually remove the row all\nright and I'll set in place\nequal to true\nand then\nI'll enter another printing statement\nwhere I'll print sides of the data set\nafter dropping\ncolumn to dropping a feature let's say\nand again it will pass the same DF dot\nshape argument and let's run this block\nall right so here you can see that one\ncolumn has been removed all right now\nthe in place argument that we have added\nin this drop function is something that\nwill keep true right so what this does\nis it tells The Interpreter that make\nsure the changes that we have done are\nbeing converted into permanent changes\nbasically guys Panda shows the data\nframe which changes we make but it will\nnot modify the original data frame DF\nand to make sure that DF is updated we\nuse this in place argument all right\nokay I hope so this strategy is clear to\nall of you guys next we'll look into\nanother method that is value imputation\nso guys deleting feature is never\npreferred because by removing a column\nwhere actually missing one reason which\ncauses the course of outcome or which\ncontributes towards the output right and\nwe don't want to see that happening\nbecause our model won't be able to\ngeneralize properly otherwise in\nscikit-learn we have SIMPLE computer\nclass which can help us impute missing\nvalues quite easily this simple computer\nis a very convenient strategy for\nmissing data imputation it replaces all\nmissing values with a statistic\ncalculated from the other values in a\ncolumn this strategy can often lead to\nimpressive results and avoid discarding\nmeaningful data when constructing your\nmachine learning algorithm the\nstatistics that this imputer uses are\nmean median and mode these three methods\ncompute the numeric output out of\navailable data to replace null values\nand by making use of them it has been\nobserved that machine learning models\nperform very well and become capable of\ngeneralizing a new set of data so first\nof all let let us import the simple\nimputer into our notebook and for that\nlet me visit the code editor now I'll\ntake a new block of code and I'll impute\nthis simple emulator and the command to\ndo that is from sklearn dot impute\nimport simple computer\nall right\nnow we'll impute the values for the h\ncolumn here all right first of all let\nme print the number of null values in\nthis column so the statement I'll write\nas print\nnumber of\nnull values\nbefore imputing\nand I'll pass\nthis DF dot age\nis null\nargument all right so what this will do\nis this will return the total number of\nnull values inside this H column all\nright so let me run this command\nand here you can see that there are 263\nnull values inside this H column all\nright next we'll create simple imputer\ninstances but before that let me tell\nyou about the arguments that include so\nbasically it includes three important\narguments the first one is missing\nvalues the missing values is a\nplaceholder which has to be imputed I\nmean basically it is the null value in\nour data set by default it is said to be\nNan right then we have second argument\nthat is strategy the data which will\nreplace by NN values from the data set\nis known as statistical strategy the\nstrategy argument can take values such\nas mean median most frequent and\nconstant and then we have third\nimportant argument as fill value the\nconstant value to be given to the Nan\ndata using the constant strategy should\nbe mentioned in fill value section all\nright now here we'll use the mean\nstrategy all right so the way to invoke\nthis simple computer is that create a\nnew variable and invoke it simple\ncomputer\nand set the strategy to mean as we have\nmentioned\nnow we will apply this Transformer that\nwe have just generated to the H column\nwith fit underscore transform method so\nwhat fit underscore transform method\nwill do is it will fit our data to this\ncomputer and it will generate the\nnon-null values to replace the null\nvalues that is Nan values all right so\ncommand I'll write for that as DF h\nequal to impute dot fit underscore\ntransform\nDF\ncolumn h\nall right now next we'll print\nnumber of null values\nin h column\nafter imputation\nall right passing argument will be\nbasically the same so we'll copy it and\nwe'll paste it here\nnow let me run this block\nand here you can see that there are zero\nnull values inside H column right now\nwhat that means is we have successfully\nimputed values for our age column okay\nguys I hope this is clear to all of you\nnow now let me show you guys how we can\nimpute missing values for this whole\ndata set Well what we'll do is we'll\nfigure out parameters differently by\ndefining one python function separately\nthe reason behind doing this is pretty\nsimple guys the data set contains\ndifferent data types some of which are\neven string format and computations like\nmean median or mode cannot be achieved\non string data right hence we need to\nprogram the separate function that will\nallow us to visualize what sort of\nelements are inside our data set right\nokay so let me Define this function as\nget underscore parameters So Def get\nunderscore parameters\nand I'll pass DF as an argument inside\nthis function I'll create the parameters\ndictionary after this I'll create for\nLoop and I'll iterate Through The\nColumns of our data frame I'll choose\nthe column that contains null values\nright so the command for this will be\nfor column in\nDF dot columns\nand we'll choose null columns right it's\nnull dot any\nnow if\nDF column\ndot d type that means the data type of\nentries inside that column is equal to\nfloat 64 or FDF\ncolumn Dot D type is equal to int 64.\nor\nit is equal to int 32 then set strategy\nequal to mean all right so if we have\nthe numerical variables then definitely\nwe can use mean as strategy right\notherwise what we'll do is else will use\nstrategy as\nmost frequent\nall right\nso let me run this part so there is no\nbug in this much part now we guys have\ndecided the strategy but there is one\nmore problem guys that needs addressing\nin Python when we deal with mixed data\ntypes columns are converted into ndra\nformat in broadest upcasting so to dodge\nthat we'll create a custom missing value\narray actually we'll create a 2d array\ncontaining column and null type so for\nthat we'll actually have to figure out\nmissing values as well so I'll create\nthe new variable\nnamed as missing underscore values and\nI'll set DF\ncolumn\nDF column Dot\nis null\ndot values\nzero now similarly the parameters\ndictionary\nwill store missing values\nadds\nparameter that we created in last line\nthat is again a missing value\nand strategy\nwill be strategy\nand will return\nthe parameters\nand now\nlet me pass the argument and run this\nblock the argument should be get\nunderscore parameters\nand DF as an argument all right so let\nme run this block quickly yeah guys\nthere was an indentation error in our\nblock so I have removed it now here you\ncan find out that there are missing\nvalues and there are different\nstrategies right for cabin we have none\nas missing value and strategy will be\nmost frequent for embark missing value\nwill be NN and strategy will be most\nfrequent again for fair the missing\nvalue will be Nan and strategy will be\nmean and same different strategies for\ndifferent columns all right so now we\nhave got the parameters all right so\nlet's make use of them and actually\npredict the values right the first thing\nwe'll do is we'll store this parameter\ndictionary into a new parameter variable\nwhich will be available outside the\nlocal scope of previous function right\nso the way to do that is Define new\nparameters and store these parameters\ninside it\nI'll run this command okay next we'll\niterate through the parameter dictionary\nwe'll set missing underscore values and\nstrategy depending upon the data type of\neach column and then we'll pass it to\nthe simple computer let me do that\nquickly here so for column comma\nparameter\nin parameters\nparameters dot items\nmissing values\nequal to\nparam\nmissing values strategy\nwill be equal to\nthat is stored inside our parameter now\nwe'll import the imputer and for that\npurpose and for that purpose the command\nI'll write as input imputer equal to\nsimple computer\nand I'll set missing values\nequal to missing values itself\nthe variable that we just abstracted\nfrom this parameters dictionary and\nstrategy\nstrategy which we also have gotten out\nof this parameters dictionary now I'll\nfit\ndata to it so DF call\nthat means all the columns inside our\ndata frame if you want to make a career\nin data science then intellipat has IIT\nMadras Advanced Data science and AI\ncertification program\nthis course is of very high quality and\ncost effective as it is taught by IIT\nprofessors and Industry experts will be\nfitted to\nthis simple imputer using fit underscore\ntransform method\nand will only perform this over column\nMatrix all right so now let me run this\nblock\nyeah it's successfully compiled and\nfinally let me also print the sum of\nnull values inside our data frame so DF\ndot is null dot sum\nand here you'll find out that there are\nno more null weight\nso let me run this again\nand you'll find out that there are no\nnull values inside our data set right\nnow next we have feature engineering so\nso guys feature engineering is the\nprocess of selecting manipulating and\ntransforming raw data into features that\ncan be used in supervised learning in\norder to make machine learning work well\non new task it might be necessary to\ndesign and train better features as you\nmay know a feature is a measurable input\nthat can be used in a predictive model\nit could be the color of the object or\nthe sound of someone's voice feature\nEngineering in simple terms is the act\nof converting raw observations into\ndesired features using statistical or\nmachine learning approaches now I'll\nshow you the example of feature\nengineering but before that let me show\nyou how our data set looks so I'll use\nDF dot head command here which will show\nus the way our data looks all right so\nhere you can see these two columns right\nsib SP and Pad so CBS SP is the feature\nin our data set that captures the number\nof siblings passengers have traveled\nwith and Patch captures the number of\nparents and childrens that the passenger\ntraveled with so we can use feature\nengineering to infer the person traveled\nalone or by with his family by looking\ninto these two parameters right and for\nthat we'll have to combine these\nparameters so let me put down what I\nhave said in context of program real\nquick so what we are gonna do is we are\ngonna check if the person has traveled\nalone or with family so we'll merge this\ncbsp and Patch columns together so for\nthat DF family\nwill be equal to\nDF\nSP\nplus DF\nparch now if DF Dot\nloc\ndot DF family\nso inside the data frame the location\nwhere DF column is\nif the roads value is greater than 0\nthen\nthe person will be considered as\ntraveled alone\nand the value will be set to zero all\nright and similarly if DF Dot Lock\nis equal to 0 then travel alone\nand the value that we'll put will be 1.\nnow DF\ntraveled\nunderscore alone\nvalue underscore counts\nDot Plot title\nequal to\npassenger\ntraveled\nalone\nand the type of graph we want to show\nwill be bar now I'll run this block\nthere is an error guys so let me check\nthis error\nokay so here we have used the double\nsquare box maybe because of that we are\ngetting this error so I'll remove it and\nI'll run the code and yeah here you can\nsee that we have the data where\npassenger traveled alone and when he did\nnot travel alone so guys this is how you\nare supposed to carry out feature\nengineering and create a meaningful\nparameter out of the very very raw\nparameters that are provided to you so\nthis was all about the notion of feature\nengineering now the next point I have on\nmy itinerary is encoding features into\nformat that can be fed to the machine\nlearning model now when dealing with\nclassification problems you need to\nencode categorical features numerically\non an container scale the scikit-learn\nAPI requires categorical features code\neditor first I'll import the one hot\nencoder from Escalon\nthen I'll set so guys the column that we\nare going to transform with one hot\nencoding F6 so basically we have two\nsixes in our data set that is female and\nmale so female and male are both in\ntextual format we want to convert it\ninto binary format so for that we'll use\nthese two characters and this six column\nitself so we'll set female comma male\nequal to one hot\nencoder\ndot fit underscore transform\nDF\nsex column and we'll convert it to the\narray\nnow let me show you how this is achieved\nhere\nso\nwhat we want to print is 6 then\nthe female\nand the mail so this will generate\nencodings for both sex female and male\nparameters so let's visualize how it\nlooks\nyeah here we are getting an error that\nis data frame object has no attribute to\narray that is true so all I have to do\nis take this two array out from here\nguys the reason behind this error is\nagain we are dealing with a column so\nwe'll need to add one more box brackets\nwe'll add them and we'll run this code\nthis is working fine here you can see\nhow one hot encoding looks like but this\nis quite redundant isn't it all this\ninformation could be stored in single\ncolumn where female is 0 and male is 1\nright to do so we'll select the mail\ncolumn from the array resulting from the\nfit underscore transform method so what\nwe'll do is we'll\ncreate the new coding block and inside\nit df6\nwill be one hot\nencoder\ndot fit underscore transform\ninside it again will pass the sixth\ncolumn\nand we'll convert this whole thing to\narray so that\nit will be saved in a column format all\nright and to save it in a column format\nI'll have to pass this as an argument\nwith this indexing we can say that the\nformat our data will be stored inside\ndfset column will be in a tabular column\nwise format all right so\nnow let's run this command\nso we haven't converted this into a\nmethod so that was the error\nnow\nthe next thing will be visualizing the\ndata so let me show you how one hot\nencoding looks now here check out the\nsix column guys\nso here you'll see that sixth column has\nbeen replaced with zeros and ones so now\nzeros will be Min and one will be female\nall right now I hope this one and one\nhot encoding part is clear to all of you\nguys after this we have data scaling so\nif the data in any condition has data\npoints far from each other scaling is a\ntechnique to make them closer to each\nother or in simpler words we can say\nthat the scaling is used for making data\npoints generalized so that the distance\nbetween them will be lower as we know\nmost of the machine learning models\nlearn from the data by the time the\nlearning model Maps the data from the\ninput to Output\nand the distribution of the data points\ncan be different for every feature of\nthe data larger differences between the\ndata points of input variables increases\nthe uncertainty in the result of the\nmodel the machine learning models\nprovide weights to the input variables\naccording to their data points and\ninferences for output in that case if\nthe difference between the data points\nis so high the model will need to\nprovide the large weight to the points\nand in final result the model with a\nlarge weight value is often unstable\nright this means the model I can produce\npoor results this means the model can\nproduce poor results or can perform\npoorly during learning I am not saying\nthat all the algorithms will face this\nproblem but most of the basic algorithms\nlike linear and logistic regression\nartificial neural networks clustering\nalgorithms with K values Etc face the\neffect of the difference in scale for\ninput variables scaling the target value\nis a good idea in regression modeling\nscaling up the data makes it easy for\nmodel to learn and understand the\nproblem in the case of neural networks\nan independent variable with spread of\nvalues may result in large loss in\ntraining and testing and cause the\nlearning process to be unstable for\nexample one feature can contain data in\npounds and other in kilograms to\ninterpret properly these features need\nto be on same scale they should be at\nleast in kilograms or they should be at\nleast in pounds so that is the reason\nwhy we need data normalization\ndata we can use two methods that are\navailable in scikit-learn that is\nstandard scalar and min max scalar let's\nfirst talk about min max scalar for each\nvalue in a feature min max scalar\nsubtracts the minimum value in the\nfeature and then divides by the range\nthe range is the difference between\noriginal maximum and original minimum\nguys basically this min max scalar\npreserves the shape of original\ndistribution it doesn't meaningfully\nchange the information embedded in the\noriginal data like you can see the graph\nover here right so what it does is it\nconverts it into range of 0 to 1 all\nright that is all you need to remember\nabout min max scalar next we have\nstandard scalar standard scalar follows\nthe standard normal distribution that is\nit assumes a normal distribution for\ndata within each feature the scaling\nmakes the distribution centered around 0\nwith a standard deviation of 1 and the\nmean removed for a data sample X its\ncore for standard scalar is calculated\nas x i minus mean of x divided by\nstandard deviation of X which is the\nmean is represented with mu and standard\ndeviation is presented with Sigma sine\nand again the mean can be forward\ncalculated using this formula and\nstandard deviation can be calculated\nusing the formula given here all right\nguys now I am not gonna talk about the\nmathematical details about both of these\ntechniques I'll simply show you how you\ncan Implement these scaling methods in\nPython program all right so let me visit\nthe code Editor to do that now first\nthing first let me import the standard\nscalar to our notebook for that we have\ncommand from a scale on\ndot free processing\nimport\nstandard\nscalar\nall right I'll run this command\nnow the next step will be selecting the\nnumerical columns because we can only\nscale numerical columns right so let me\nfind out the numerical columns first for\nthat I'll create the new variable named\nas numerical columns and inside it I'll\nstore\nthe selected data type columns that is\nint 64\nfloat\n64.\nand integer 32.\nand\nI'll print these columns\nso let me run this here you can see that\nthese are the numerical columns we have\nin our data set now what we'll do is\nwe'll apply our standard scalar all\nright so first of all I'll invoke the\nobject of standard scalar using the\nsyntax new variable is equal to standard\nscalar all right\nnow I'll run this command again next\nI'll create new data frame which stores\nthe num columns\nthat is numerical columns and I'll apply\nSS dot fit underscore transform it\nand again I'll pass\nall the numeric columns\nnow\ndot describe\nI'll run this\nnow here you can see that all the values\nhas been standardized all these values\nare between 0 and 1's proximity all\nright guys now all of these values are\nin log format so if you convert these\nvalues into simple numbers you'll find\nout that these values lie between 0 and\n1. so this is how standard scalar works\nnow let me also show you how min max\nscalar works now we'll import the min\nmax scalar so the command for that is\nfrom Escalon Dot preprocessing\nimport\nmin max scalar\nnow after that we have already found out\nthe numerical columns so we'll again\ncall that num columns variable that we\ncreated previously so right now all we\nneed to do is we'll need to pass this\nmin max scalar to some variable so that\nit will be invoked\nand then\nDF dot num underscore columns will be\nequal to\nminmac dot fit underscore transform\nagain will pass\nnum underscore columns\nand will print\nThe Columns but guys we have already\napplied standardization to this data so\nI don't know how these values will be\nwell they are quite nice all right\nbecause the data was previously\nstandardized itself so because of that\nour min max scalar is putting it into\nmore perspective all right so these\nvalues are quite processable and if we\nfeed them to the network machine\nlearning model it will be able to\nproduce some sort of very accurate\nprediction which is close to our output\nparameter all right now I hope this min\nmax scalar and standard scalar is clear\nto all of you guys out there let me tell\nyou that this was just an overview of\nhow data can be handled okay we'll be\ncarrying out more such operations down\nthe line throughout this series so with\nthis session just try to build a basic\nintuition for this pre-processing\nprocess all right and I wish to thank\nyou all of you guys for being here till\nthe end of this session I hope this\nsession was informative and entrailing\nyou have liked this video a thumbs up\nwould be much appreciated also if you\nhave any concerns about this set concept\nthen please put them in the comment box\nbelow our 24x7 team of experts would be\nobliged to resolve all of them for you\nguys also make sure you are subscribed\nto the intellipath YouTube channel so\nthat you never miss upcoming multiple\nupdates if you want to make a career in\ndata science then intellipat has IIT\nMadras Advanced Data science and AI\ncertification program\nthis course is of very high quality and\ncost effective as it is taught by IIT\nprofessors and Industry experts\n",
  "words": [
    "foreign",
    "welcome",
    "yet",
    "another",
    "session",
    "based",
    "today",
    "going",
    "generalize",
    "workflow",
    "basic",
    "programming",
    "intuition",
    "behind",
    "cover",
    "first",
    "step",
    "every",
    "machine",
    "learning",
    "problem",
    "solving",
    "methodology",
    "making",
    "sure",
    "data",
    "clean",
    "generalizable",
    "technical",
    "words",
    "step",
    "called",
    "end",
    "session",
    "understand",
    "workflow",
    "carry",
    "data",
    "hope",
    "agenda",
    "session",
    "clear",
    "guys",
    "get",
    "started",
    "session",
    "please",
    "make",
    "sure",
    "hit",
    "subscribe",
    "button",
    "bell",
    "icon",
    "never",
    "miss",
    "update",
    "intellipath",
    "youtube",
    "channel",
    "okay",
    "said",
    "let",
    "dive",
    "session",
    "talk",
    "workflow",
    "guys",
    "talk",
    "basic",
    "sense",
    "workflow",
    "begins",
    "sort",
    "data",
    "eventually",
    "provide",
    "data",
    "model",
    "model",
    "learn",
    "provided",
    "data",
    "able",
    "make",
    "predictions",
    "general",
    "workflow",
    "basic",
    "sense",
    "quite",
    "vague",
    "let",
    "go",
    "little",
    "deeper",
    "mean",
    "giving",
    "data",
    "set",
    "model",
    "typically",
    "data",
    "set",
    "useful",
    "make",
    "predictions",
    "split",
    "two",
    "parts",
    "common",
    "notation",
    "call",
    "splitted",
    "data",
    "one",
    "call",
    "x",
    "call",
    "x",
    "something",
    "representing",
    "everything",
    "using",
    "make",
    "predictions",
    "mean",
    "x",
    "contain",
    "features",
    "event",
    "describe",
    "outcome",
    "specific",
    "event",
    "example",
    "heavy",
    "rain",
    "false",
    "drainage",
    "system",
    "features",
    "lead",
    "events",
    "water",
    "logging",
    "means",
    "outcome",
    "water",
    "logging",
    "rain",
    "plus",
    "faulty",
    "drainage",
    "system",
    "parameters",
    "responsible",
    "event",
    "case",
    "output",
    "data",
    "mean",
    "contain",
    "result",
    "occur",
    "given",
    "set",
    "parameters",
    "example",
    "let",
    "say",
    "iris",
    "data",
    "set",
    "data",
    "set",
    "class",
    "plant",
    "target",
    "variable",
    "features",
    "sample",
    "length",
    "width",
    "well",
    "petal",
    "length",
    "width",
    "acting",
    "parameters",
    "describe",
    "type",
    "plant",
    "model",
    "find",
    "patterns",
    "features",
    "make",
    "particular",
    "plan",
    "belong",
    "certain",
    "category",
    "feed",
    "x",
    "data",
    "model",
    "train",
    "logical",
    "ml",
    "algorithm",
    "provided",
    "data",
    "basically",
    "fit",
    "data",
    "model",
    "talk",
    "let",
    "visit",
    "code",
    "editor",
    "get",
    "data",
    "set",
    "provides",
    "data",
    "set",
    "mean",
    "iris",
    "one",
    "whose",
    "use",
    "library",
    "purpose",
    "let",
    "visit",
    "code",
    "editor",
    "let",
    "import",
    "library",
    "command",
    "import",
    "sklearn",
    "run",
    "block",
    "get",
    "data",
    "set",
    "command",
    "command",
    "sklearn",
    "dot",
    "data",
    "sets",
    "import",
    "load",
    "underscore",
    "iris",
    "iris",
    "basically",
    "data",
    "set",
    "already",
    "stored",
    "inside",
    "sqln",
    "library",
    "importing",
    "using",
    "load",
    "iris",
    "method",
    "let",
    "run",
    "block",
    "well",
    "next",
    "visualize",
    "data",
    "looks",
    "write",
    "load",
    "underscore",
    "iris",
    "command",
    "actually",
    "load",
    "data",
    "code",
    "editor",
    "let",
    "run",
    "see",
    "input",
    "variables",
    "target",
    "variables",
    "well",
    "right",
    "information",
    "data",
    "set",
    "want",
    "visualize",
    "x",
    "separately",
    "adding",
    "return",
    "underscore",
    "x",
    "underscore",
    "previous",
    "functional",
    "argument",
    "copy",
    "command",
    "add",
    "argument",
    "talked",
    "return",
    "underscore",
    "x",
    "underscore",
    "run",
    "command",
    "oh",
    "wait",
    "set",
    "true",
    "well",
    "see",
    "input",
    "features",
    "output",
    "feature",
    "separated",
    "clearly",
    "moving",
    "forward",
    "storing",
    "data",
    "future",
    "computation",
    "variables",
    "let",
    "say",
    "variables",
    "x",
    "sort",
    "store",
    "data",
    "x",
    "variables",
    "use",
    "load",
    "command",
    "use",
    "x",
    "comma",
    "stores",
    "load",
    "underscore",
    "iris",
    "return",
    "underscore",
    "x",
    "underscore",
    "equal",
    "true",
    "run",
    "block",
    "successful",
    "execution",
    "say",
    "feature",
    "data",
    "output",
    "data",
    "separated",
    "x",
    "variables",
    "okay",
    "data",
    "format",
    "fed",
    "machine",
    "learning",
    "model",
    "sort",
    "get",
    "overview",
    "procedure",
    "actually",
    "formulate",
    "model",
    "conceptually",
    "visualize",
    "machine",
    "learning",
    "model",
    "actually",
    "purpose",
    "let",
    "go",
    "back",
    "presentation",
    "create",
    "model",
    "initially",
    "directly",
    "filled",
    "data",
    "model",
    "creation",
    "involves",
    "two",
    "steps",
    "basically",
    "first",
    "create",
    "generate",
    "model",
    "make",
    "model",
    "learn",
    "data",
    "models",
    "python",
    "objects",
    "learning",
    "terminology",
    "often",
    "denoted",
    "dot",
    "fit",
    "methodology",
    "typical",
    "step",
    "dot",
    "fit",
    "actually",
    "pass",
    "set",
    "variables",
    "termed",
    "x",
    "representing",
    "feature",
    "data",
    "output",
    "remember",
    "guys",
    "model",
    "must",
    "pass",
    "phases",
    "make",
    "prediction",
    "said",
    "hope",
    "guys",
    "collected",
    "intuition",
    "let",
    "take",
    "back",
    "notebook",
    "order",
    "show",
    "easily",
    "said",
    "notion",
    "coded",
    "okay",
    "guys",
    "one",
    "thing",
    "want",
    "guys",
    "clear",
    "problem",
    "dealing",
    "right",
    "classification",
    "problem",
    "problem",
    "classify",
    "rows",
    "different",
    "plant",
    "classes",
    "right",
    "well",
    "talking",
    "concept",
    "classification",
    "later",
    "series",
    "let",
    "tell",
    "use",
    "models",
    "like",
    "linear",
    "regression",
    "k",
    "n",
    "svm",
    "solve",
    "classification",
    "problems",
    "first",
    "let",
    "pick",
    "linear",
    "regression",
    "model",
    "call",
    "object",
    "model",
    "inside",
    "notebook",
    "write",
    "command",
    "sk",
    "learn",
    "dot",
    "linear",
    "underscore",
    "model",
    "import",
    "linear",
    "regression",
    "run",
    "block",
    "take",
    "new",
    "one",
    "model",
    "creation",
    "stuff",
    "create",
    "variable",
    "name",
    "model",
    "assign",
    "called",
    "object",
    "means",
    "create",
    "new",
    "variable",
    "put",
    "function",
    "linear",
    "regression",
    "let",
    "run",
    "block",
    "see",
    "model",
    "created",
    "guys",
    "phase",
    "model",
    "learning",
    "anything",
    "creating",
    "first",
    "stage",
    "talked",
    "call",
    "method",
    "right",
    "must",
    "return",
    "error",
    "let",
    "check",
    "call",
    "model",
    "dot",
    "predict",
    "data",
    "samples",
    "x",
    "run",
    "statement",
    "must",
    "get",
    "error",
    "see",
    "getting",
    "dodging",
    "error",
    "fit",
    "model",
    "data",
    "purpose",
    "let",
    "take",
    "new",
    "block",
    "fit",
    "data",
    "command",
    "named",
    "fit",
    "pass",
    "x",
    "yeah",
    "see",
    "model",
    "fit",
    "linear",
    "regression",
    "object",
    "algorithm",
    "step",
    "done",
    "model",
    "pick",
    "patterns",
    "data",
    "set",
    "time",
    "try",
    "call",
    "predict",
    "function",
    "model",
    "able",
    "make",
    "sort",
    "deductions",
    "right",
    "going",
    "discuss",
    "machine",
    "learning",
    "model",
    "actually",
    "priority",
    "right",
    "understand",
    "overview",
    "ml",
    "modeling",
    "workflow",
    "well",
    "one",
    "thing",
    "guys",
    "best",
    "thing",
    "api",
    "machine",
    "learning",
    "models",
    "remain",
    "mean",
    "created",
    "linear",
    "regression",
    "model",
    "similarly",
    "api",
    "structure",
    "prevail",
    "models",
    "well",
    "let",
    "actually",
    "see",
    "model",
    "predicting",
    "output",
    "use",
    "function",
    "pass",
    "x",
    "must",
    "produce",
    "output",
    "matches",
    "guys",
    "see",
    "getting",
    "sort",
    "predictions",
    "right",
    "one",
    "model",
    "models",
    "well",
    "let",
    "say",
    "want",
    "create",
    "one",
    "ml",
    "model",
    "k",
    "nearest",
    "neighbor",
    "first",
    "thing",
    "invoke",
    "k",
    "nearest",
    "neighbor",
    "classifier",
    "object",
    "use",
    "command",
    "sk",
    "learn",
    "dot",
    "neighbors",
    "import",
    "k",
    "neighbors",
    "regressor",
    "store",
    "inside",
    "new",
    "variable",
    "run",
    "block",
    "next",
    "step",
    "fit",
    "data",
    "new",
    "algorithm",
    "mod",
    "dot",
    "fit",
    "x",
    "comma",
    "run",
    "k",
    "nearest",
    "neighbor",
    "regressor",
    "generalize",
    "provided",
    "data",
    "check",
    "making",
    "right",
    "predictions",
    "use",
    "prediction",
    "method",
    "use",
    "input",
    "data",
    "run",
    "block",
    "guys",
    "see",
    "actually",
    "making",
    "close",
    "predictions",
    "right",
    "let",
    "also",
    "show",
    "output",
    "data",
    "see",
    "actually",
    "making",
    "close",
    "predictions",
    "talk",
    "structure",
    "algorithm",
    "later",
    "words",
    "linear",
    "regression",
    "perform",
    "bad",
    "particular",
    "use",
    "case",
    "let",
    "focus",
    "workflow",
    "modeling",
    "technique",
    "guys",
    "saw",
    "predicted",
    "data",
    "given",
    "output",
    "data",
    "made",
    "comparison",
    "want",
    "visualize",
    "data",
    "well",
    "purpose",
    "import",
    "matplotlib",
    "library",
    "matplotlib",
    "library",
    "contains",
    "lot",
    "graph",
    "plotting",
    "techniques",
    "allow",
    "plot",
    "graph",
    "predicted",
    "data",
    "actual",
    "data",
    "purpose",
    "using",
    "scatter",
    "plot",
    "put",
    "predicted",
    "values",
    "x",
    "axis",
    "given",
    "output",
    "values",
    "let",
    "code",
    "quickly",
    "import",
    "matplotlib",
    "add",
    "plt",
    "predicted",
    "data",
    "equal",
    "model",
    "dot",
    "predict",
    "x",
    "plot",
    "plot",
    "scatter",
    "graph",
    "pass",
    "predicted",
    "data",
    "x",
    "axis",
    "output",
    "variable",
    "right",
    "let",
    "run",
    "block",
    "guys",
    "looking",
    "graph",
    "see",
    "predictions",
    "made",
    "given",
    "output",
    "matches",
    "scenarios",
    "means",
    "model",
    "learned",
    "pattern",
    "data",
    "accurately",
    "means",
    "good",
    "signal",
    "low",
    "noise",
    "might",
    "prevail",
    "every",
    "data",
    "set",
    "problem",
    "discuss",
    "models",
    "work",
    "choose",
    "best",
    "model",
    "basic",
    "structure",
    "machine",
    "learning",
    "solution",
    "buildup",
    "basic",
    "sense",
    "guys",
    "keep",
    "mind",
    "typical",
    "machine",
    "learning",
    "problem",
    "works",
    "typical",
    "machine",
    "learning",
    "problem",
    "coded",
    "data",
    "get",
    "might",
    "well",
    "optimized",
    "might",
    "degree",
    "difference",
    "measurements",
    "data",
    "like",
    "fed",
    "machine",
    "learning",
    "model",
    "adds",
    "adds",
    "one",
    "layer",
    "machine",
    "learning",
    "procedure",
    "data",
    "cleaning",
    "moving",
    "forward",
    "take",
    "deep",
    "dive",
    "concept",
    "data",
    "cleaning",
    "guys",
    "basically",
    "every",
    "machine",
    "learning",
    "exploration",
    "begins",
    "exporting",
    "data",
    "set",
    "last",
    "demo",
    "understood",
    "api",
    "works",
    "directly",
    "imported",
    "data",
    "set",
    "stored",
    "inside",
    "one",
    "variable",
    "time",
    "show",
    "store",
    "data",
    "set",
    "inside",
    "data",
    "frame",
    "guys",
    "wondering",
    "exactly",
    "data",
    "frame",
    "let",
    "make",
    "clear",
    "guys",
    "data",
    "frame",
    "unique",
    "data",
    "structure",
    "implemented",
    "pandas",
    "library",
    "python",
    "mean",
    "contains",
    "rows",
    "columns",
    "like",
    "sql",
    "tables",
    "spreadsheet",
    "terms",
    "programming",
    "visualize",
    "dictionary",
    "series",
    "objects",
    "right",
    "okay",
    "said",
    "first",
    "thing",
    "import",
    "pandas",
    "library",
    "command",
    "quite",
    "simple",
    "import",
    "pandas",
    "pd",
    "run",
    "block",
    "next",
    "getting",
    "data",
    "store",
    "inside",
    "data",
    "frame",
    "data",
    "set",
    "going",
    "use",
    "titanic",
    "data",
    "set",
    "data",
    "set",
    "part",
    "framework",
    "commonly",
    "used",
    "learning",
    "data",
    "exploration",
    "purposes",
    "want",
    "make",
    "career",
    "data",
    "science",
    "intellipat",
    "iit",
    "madras",
    "advanced",
    "data",
    "science",
    "ai",
    "certification",
    "program",
    "course",
    "high",
    "quality",
    "cost",
    "effective",
    "taught",
    "iit",
    "professors",
    "industry",
    "experts",
    "guys",
    "load",
    "data",
    "set",
    "import",
    "one",
    "functionality",
    "fetch",
    "underscore",
    "openml",
    "command",
    "sklearn",
    "dot",
    "data",
    "sets",
    "import",
    "fetch",
    "underscore",
    "openml",
    "run",
    "import",
    "fetch",
    "openml",
    "functionality",
    "next",
    "import",
    "data",
    "set",
    "using",
    "fetch",
    "openml",
    "function",
    "store",
    "inside",
    "data",
    "frame",
    "well",
    "df",
    "equal",
    "fetch",
    "underscore",
    "openml",
    "data",
    "set",
    "going",
    "load",
    "titanic",
    "want",
    "use",
    "actually",
    "specific",
    "version",
    "data",
    "set",
    "version",
    "one",
    "set",
    "underscore",
    "frame",
    "equal",
    "true",
    "taking",
    "data",
    "right",
    "okay",
    "let",
    "run",
    "block",
    "check",
    "data",
    "set",
    "imported",
    "stored",
    "inside",
    "data",
    "frame",
    "purpose",
    "use",
    "command",
    "known",
    "df",
    "dot",
    "info",
    "let",
    "write",
    "command",
    "quickly",
    "see",
    "information",
    "data",
    "set",
    "basically",
    "data",
    "set",
    "contains",
    "13",
    "columns",
    "right",
    "basically",
    "values",
    "right",
    "bottom",
    "part",
    "also",
    "find",
    "data",
    "types",
    "part",
    "data",
    "set",
    "see",
    "two",
    "categorical",
    "variables",
    "six",
    "float",
    "features",
    "five",
    "object",
    "type",
    "features",
    "let",
    "find",
    "missing",
    "values",
    "data",
    "set",
    "pandas",
    "function",
    "purpose",
    "dot",
    "null",
    "let",
    "use",
    "function",
    "quickly",
    "df",
    "dot",
    "null",
    "run",
    "see",
    "highlighting",
    "areas",
    "data",
    "set",
    "contains",
    "null",
    "values",
    "right",
    "wherever",
    "true",
    "means",
    "null",
    "value",
    "inside",
    "row",
    "particular",
    "column",
    "right",
    "guys",
    "actually",
    "better",
    "way",
    "visualize",
    "right",
    "calculate",
    "overall",
    "null",
    "values",
    "inside",
    "column",
    "command",
    "simple",
    "df",
    "dot",
    "null",
    "dot",
    "sum",
    "summing",
    "null",
    "values",
    "across",
    "every",
    "column",
    "right",
    "let",
    "run",
    "command",
    "see",
    "like",
    "263",
    "null",
    "values",
    "h",
    "column",
    "1014",
    "null",
    "values",
    "k",
    "bin",
    "column",
    "two",
    "null",
    "values",
    "bar",
    "column",
    "1188",
    "body",
    "body",
    "data",
    "type",
    "integer64",
    "numbers",
    "return",
    "integer",
    "obviously",
    "question",
    "strike",
    "mind",
    "significant",
    "null",
    "values",
    "necessary",
    "dodge",
    "well",
    "let",
    "help",
    "guys",
    "visualize",
    "help",
    "graph",
    "purpose",
    "using",
    "seabon",
    "library",
    "let",
    "first",
    "import",
    "import",
    "c",
    "bond",
    "library",
    "command",
    "import",
    "c",
    "bone",
    "adds",
    "sns",
    "run",
    "block",
    "library",
    "imported",
    "importing",
    "also",
    "set",
    "graph",
    "styling",
    "help",
    "set",
    "function",
    "cball",
    "sns",
    "dot",
    "set",
    "calculate",
    "missing",
    "value",
    "percentage",
    "feature",
    "actually",
    "well",
    "divide",
    "number",
    "null",
    "values",
    "entries",
    "number",
    "rows",
    "data",
    "set",
    "convert",
    "percentage",
    "multiply",
    "100",
    "let",
    "put",
    "programming",
    "syntax",
    "look",
    "like",
    "miss",
    "value",
    "percentage",
    "equal",
    "pd",
    "dot",
    "data",
    "frame",
    "df",
    "dot",
    "null",
    "dot",
    "sum",
    "divided",
    "length",
    "df",
    "right",
    "multiply",
    "next",
    "step",
    "plotting",
    "graph",
    "plot",
    "bar",
    "graph",
    "keep",
    "percentage",
    "okay",
    "command",
    "use",
    "miss",
    "underscore",
    "value",
    "percentage",
    "dot",
    "plot",
    "kind",
    "graph",
    "going",
    "use",
    "mentioned",
    "bar",
    "title",
    "want",
    "give",
    "graph",
    "missing",
    "values",
    "label",
    "percentage",
    "right",
    "let",
    "run",
    "block",
    "clearly",
    "deduce",
    "multiple",
    "null",
    "entries",
    "problem",
    "appropriate",
    "data",
    "model",
    "wo",
    "able",
    "learn",
    "properly",
    "right",
    "example",
    "consider",
    "study",
    "material",
    "suddenly",
    "faculty",
    "takes",
    "examination",
    "able",
    "perform",
    "great",
    "examination",
    "wo",
    "wo",
    "know",
    "concepts",
    "right",
    "prevails",
    "machine",
    "learning",
    "actually",
    "lead",
    "scenario",
    "model",
    "make",
    "blunt",
    "predictions",
    "less",
    "accuracy",
    "score",
    "find",
    "resolution",
    "add",
    "something",
    "place",
    "missing",
    "values",
    "drop",
    "entire",
    "feature",
    "wo",
    "affect",
    "learning",
    "adversely",
    "right",
    "first",
    "let",
    "walk",
    "guys",
    "concept",
    "dropping",
    "feature",
    "entire",
    "data",
    "set",
    "body",
    "feature",
    "null",
    "values",
    "see",
    "right",
    "drop",
    "column",
    "print",
    "size",
    "data",
    "set",
    "function",
    "purpose",
    "dot",
    "shape",
    "function",
    "command",
    "printing",
    "shape",
    "print",
    "size",
    "data",
    "set",
    "tf",
    "dot",
    "shape",
    "right",
    "run",
    "command",
    "get",
    "shape",
    "data",
    "set",
    "right",
    "means",
    "13",
    "columns",
    "1300",
    "0",
    "9",
    "rows",
    "right",
    "wan",
    "na",
    "drop",
    "one",
    "column",
    "right",
    "let",
    "move",
    "ahead",
    "command",
    "df",
    "dot",
    "drop",
    "function",
    "used",
    "drop",
    "column",
    "inside",
    "pass",
    "column",
    "want",
    "drop",
    "body",
    "set",
    "axis",
    "equal",
    "1",
    "remove",
    "column",
    "set",
    "access",
    "equal",
    "0",
    "actually",
    "remove",
    "row",
    "right",
    "set",
    "place",
    "equal",
    "true",
    "enter",
    "another",
    "printing",
    "statement",
    "print",
    "sides",
    "data",
    "set",
    "dropping",
    "column",
    "dropping",
    "feature",
    "let",
    "say",
    "pass",
    "df",
    "dot",
    "shape",
    "argument",
    "let",
    "run",
    "block",
    "right",
    "see",
    "one",
    "column",
    "removed",
    "right",
    "place",
    "argument",
    "added",
    "drop",
    "function",
    "something",
    "keep",
    "true",
    "right",
    "tells",
    "interpreter",
    "make",
    "sure",
    "changes",
    "done",
    "converted",
    "permanent",
    "changes",
    "basically",
    "guys",
    "panda",
    "shows",
    "data",
    "frame",
    "changes",
    "make",
    "modify",
    "original",
    "data",
    "frame",
    "df",
    "make",
    "sure",
    "df",
    "updated",
    "use",
    "place",
    "argument",
    "right",
    "okay",
    "hope",
    "strategy",
    "clear",
    "guys",
    "next",
    "look",
    "another",
    "method",
    "value",
    "imputation",
    "guys",
    "deleting",
    "feature",
    "never",
    "preferred",
    "removing",
    "column",
    "actually",
    "missing",
    "one",
    "reason",
    "causes",
    "course",
    "outcome",
    "contributes",
    "towards",
    "output",
    "right",
    "want",
    "see",
    "happening",
    "model",
    "wo",
    "able",
    "generalize",
    "properly",
    "otherwise",
    "simple",
    "computer",
    "class",
    "help",
    "us",
    "impute",
    "missing",
    "values",
    "quite",
    "easily",
    "simple",
    "computer",
    "convenient",
    "strategy",
    "missing",
    "data",
    "imputation",
    "replaces",
    "missing",
    "values",
    "statistic",
    "calculated",
    "values",
    "column",
    "strategy",
    "often",
    "lead",
    "impressive",
    "results",
    "avoid",
    "discarding",
    "meaningful",
    "data",
    "constructing",
    "machine",
    "learning",
    "algorithm",
    "statistics",
    "imputer",
    "uses",
    "mean",
    "median",
    "mode",
    "three",
    "methods",
    "compute",
    "numeric",
    "output",
    "available",
    "data",
    "replace",
    "null",
    "values",
    "making",
    "use",
    "observed",
    "machine",
    "learning",
    "models",
    "perform",
    "well",
    "become",
    "capable",
    "generalizing",
    "new",
    "set",
    "data",
    "first",
    "let",
    "let",
    "us",
    "import",
    "simple",
    "imputer",
    "notebook",
    "let",
    "visit",
    "code",
    "editor",
    "take",
    "new",
    "block",
    "code",
    "impute",
    "simple",
    "emulator",
    "command",
    "sklearn",
    "dot",
    "impute",
    "import",
    "simple",
    "computer",
    "right",
    "impute",
    "values",
    "h",
    "column",
    "right",
    "first",
    "let",
    "print",
    "number",
    "null",
    "values",
    "column",
    "statement",
    "write",
    "print",
    "number",
    "null",
    "values",
    "imputing",
    "pass",
    "df",
    "dot",
    "age",
    "null",
    "argument",
    "right",
    "return",
    "total",
    "number",
    "null",
    "values",
    "inside",
    "h",
    "column",
    "right",
    "let",
    "run",
    "command",
    "see",
    "263",
    "null",
    "values",
    "inside",
    "h",
    "column",
    "right",
    "next",
    "create",
    "simple",
    "imputer",
    "instances",
    "let",
    "tell",
    "arguments",
    "include",
    "basically",
    "includes",
    "three",
    "important",
    "arguments",
    "first",
    "one",
    "missing",
    "values",
    "missing",
    "values",
    "placeholder",
    "imputed",
    "mean",
    "basically",
    "null",
    "value",
    "data",
    "set",
    "default",
    "said",
    "nan",
    "right",
    "second",
    "argument",
    "strategy",
    "data",
    "replace",
    "nn",
    "values",
    "data",
    "set",
    "known",
    "statistical",
    "strategy",
    "strategy",
    "argument",
    "take",
    "values",
    "mean",
    "median",
    "frequent",
    "constant",
    "third",
    "important",
    "argument",
    "fill",
    "value",
    "constant",
    "value",
    "given",
    "nan",
    "data",
    "using",
    "constant",
    "strategy",
    "mentioned",
    "fill",
    "value",
    "section",
    "right",
    "use",
    "mean",
    "strategy",
    "right",
    "way",
    "invoke",
    "simple",
    "computer",
    "create",
    "new",
    "variable",
    "invoke",
    "simple",
    "computer",
    "set",
    "strategy",
    "mean",
    "mentioned",
    "apply",
    "transformer",
    "generated",
    "h",
    "column",
    "fit",
    "underscore",
    "transform",
    "method",
    "fit",
    "underscore",
    "transform",
    "method",
    "fit",
    "data",
    "computer",
    "generate",
    "values",
    "replace",
    "null",
    "values",
    "nan",
    "values",
    "right",
    "command",
    "write",
    "df",
    "h",
    "equal",
    "impute",
    "dot",
    "fit",
    "underscore",
    "transform",
    "df",
    "column",
    "h",
    "right",
    "next",
    "print",
    "number",
    "null",
    "values",
    "h",
    "column",
    "imputation",
    "right",
    "passing",
    "argument",
    "basically",
    "copy",
    "paste",
    "let",
    "run",
    "block",
    "see",
    "zero",
    "null",
    "values",
    "inside",
    "h",
    "column",
    "right",
    "means",
    "successfully",
    "imputed",
    "values",
    "age",
    "column",
    "okay",
    "guys",
    "hope",
    "clear",
    "let",
    "show",
    "guys",
    "impute",
    "missing",
    "values",
    "whole",
    "data",
    "set",
    "well",
    "figure",
    "parameters",
    "differently",
    "defining",
    "one",
    "python",
    "function",
    "separately",
    "reason",
    "behind",
    "pretty",
    "simple",
    "guys",
    "data",
    "set",
    "contains",
    "different",
    "data",
    "types",
    "even",
    "string",
    "format",
    "computations",
    "like",
    "mean",
    "median",
    "mode",
    "achieved",
    "string",
    "data",
    "right",
    "hence",
    "need",
    "program",
    "separate",
    "function",
    "allow",
    "us",
    "visualize",
    "sort",
    "elements",
    "inside",
    "data",
    "set",
    "right",
    "okay",
    "let",
    "define",
    "function",
    "get",
    "underscore",
    "parameters",
    "def",
    "get",
    "underscore",
    "parameters",
    "pass",
    "df",
    "argument",
    "inside",
    "function",
    "create",
    "parameters",
    "dictionary",
    "create",
    "loop",
    "iterate",
    "columns",
    "data",
    "frame",
    "choose",
    "column",
    "contains",
    "null",
    "values",
    "right",
    "command",
    "column",
    "df",
    "dot",
    "columns",
    "choose",
    "null",
    "columns",
    "right",
    "null",
    "dot",
    "df",
    "column",
    "dot",
    "type",
    "means",
    "data",
    "type",
    "entries",
    "inside",
    "column",
    "equal",
    "float",
    "64",
    "fdf",
    "column",
    "dot",
    "type",
    "equal",
    "int",
    "equal",
    "int",
    "32",
    "set",
    "strategy",
    "equal",
    "mean",
    "right",
    "numerical",
    "variables",
    "definitely",
    "use",
    "mean",
    "strategy",
    "right",
    "otherwise",
    "else",
    "use",
    "strategy",
    "frequent",
    "right",
    "let",
    "run",
    "part",
    "bug",
    "much",
    "part",
    "guys",
    "decided",
    "strategy",
    "one",
    "problem",
    "guys",
    "needs",
    "addressing",
    "python",
    "deal",
    "mixed",
    "data",
    "types",
    "columns",
    "converted",
    "ndra",
    "format",
    "broadest",
    "upcasting",
    "dodge",
    "create",
    "custom",
    "missing",
    "value",
    "array",
    "actually",
    "create",
    "2d",
    "array",
    "containing",
    "column",
    "null",
    "type",
    "actually",
    "figure",
    "missing",
    "values",
    "well",
    "create",
    "new",
    "variable",
    "named",
    "missing",
    "underscore",
    "values",
    "set",
    "df",
    "column",
    "df",
    "column",
    "dot",
    "null",
    "dot",
    "values",
    "zero",
    "similarly",
    "parameters",
    "dictionary",
    "store",
    "missing",
    "values",
    "adds",
    "parameter",
    "created",
    "last",
    "line",
    "missing",
    "value",
    "strategy",
    "strategy",
    "return",
    "parameters",
    "let",
    "pass",
    "argument",
    "run",
    "block",
    "argument",
    "get",
    "underscore",
    "parameters",
    "df",
    "argument",
    "right",
    "let",
    "run",
    "block",
    "quickly",
    "yeah",
    "guys",
    "indentation",
    "error",
    "block",
    "removed",
    "find",
    "missing",
    "values",
    "different",
    "strategies",
    "right",
    "cabin",
    "none",
    "missing",
    "value",
    "strategy",
    "frequent",
    "embark",
    "missing",
    "value",
    "nn",
    "strategy",
    "frequent",
    "fair",
    "missing",
    "value",
    "nan",
    "strategy",
    "mean",
    "different",
    "strategies",
    "different",
    "columns",
    "right",
    "got",
    "parameters",
    "right",
    "let",
    "make",
    "use",
    "actually",
    "predict",
    "values",
    "right",
    "first",
    "thing",
    "store",
    "parameter",
    "dictionary",
    "new",
    "parameter",
    "variable",
    "available",
    "outside",
    "local",
    "scope",
    "previous",
    "function",
    "right",
    "way",
    "define",
    "new",
    "parameters",
    "store",
    "parameters",
    "inside",
    "run",
    "command",
    "okay",
    "next",
    "iterate",
    "parameter",
    "dictionary",
    "set",
    "missing",
    "underscore",
    "values",
    "strategy",
    "depending",
    "upon",
    "data",
    "type",
    "column",
    "pass",
    "simple",
    "computer",
    "let",
    "quickly",
    "column",
    "comma",
    "parameter",
    "parameters",
    "parameters",
    "dot",
    "items",
    "missing",
    "values",
    "equal",
    "param",
    "missing",
    "values",
    "strategy",
    "equal",
    "stored",
    "inside",
    "parameter",
    "import",
    "imputer",
    "purpose",
    "purpose",
    "command",
    "write",
    "input",
    "imputer",
    "equal",
    "simple",
    "computer",
    "set",
    "missing",
    "values",
    "equal",
    "missing",
    "values",
    "variable",
    "abstracted",
    "parameters",
    "dictionary",
    "strategy",
    "strategy",
    "also",
    "gotten",
    "parameters",
    "dictionary",
    "fit",
    "data",
    "df",
    "call",
    "means",
    "columns",
    "inside",
    "data",
    "frame",
    "want",
    "make",
    "career",
    "data",
    "science",
    "intellipat",
    "iit",
    "madras",
    "advanced",
    "data",
    "science",
    "ai",
    "certification",
    "program",
    "course",
    "high",
    "quality",
    "cost",
    "effective",
    "taught",
    "iit",
    "professors",
    "industry",
    "experts",
    "fitted",
    "simple",
    "imputer",
    "using",
    "fit",
    "underscore",
    "transform",
    "method",
    "perform",
    "column",
    "matrix",
    "right",
    "let",
    "run",
    "block",
    "yeah",
    "successfully",
    "compiled",
    "finally",
    "let",
    "also",
    "print",
    "sum",
    "null",
    "values",
    "inside",
    "data",
    "frame",
    "df",
    "dot",
    "null",
    "dot",
    "sum",
    "find",
    "null",
    "weight",
    "let",
    "run",
    "find",
    "null",
    "values",
    "inside",
    "data",
    "set",
    "right",
    "next",
    "feature",
    "engineering",
    "guys",
    "feature",
    "engineering",
    "process",
    "selecting",
    "manipulating",
    "transforming",
    "raw",
    "data",
    "features",
    "used",
    "supervised",
    "learning",
    "order",
    "make",
    "machine",
    "learning",
    "work",
    "well",
    "new",
    "task",
    "might",
    "necessary",
    "design",
    "train",
    "better",
    "features",
    "may",
    "know",
    "feature",
    "measurable",
    "input",
    "used",
    "predictive",
    "model",
    "could",
    "color",
    "object",
    "sound",
    "someone",
    "voice",
    "feature",
    "engineering",
    "simple",
    "terms",
    "act",
    "converting",
    "raw",
    "observations",
    "desired",
    "features",
    "using",
    "statistical",
    "machine",
    "learning",
    "approaches",
    "show",
    "example",
    "feature",
    "engineering",
    "let",
    "show",
    "data",
    "set",
    "looks",
    "use",
    "df",
    "dot",
    "head",
    "command",
    "show",
    "us",
    "way",
    "data",
    "looks",
    "right",
    "see",
    "two",
    "columns",
    "right",
    "sib",
    "sp",
    "pad",
    "cbs",
    "sp",
    "feature",
    "data",
    "set",
    "captures",
    "number",
    "siblings",
    "passengers",
    "traveled",
    "patch",
    "captures",
    "number",
    "parents",
    "childrens",
    "passenger",
    "traveled",
    "use",
    "feature",
    "engineering",
    "infer",
    "person",
    "traveled",
    "alone",
    "family",
    "looking",
    "two",
    "parameters",
    "right",
    "combine",
    "parameters",
    "let",
    "put",
    "said",
    "context",
    "program",
    "real",
    "quick",
    "gon",
    "na",
    "gon",
    "na",
    "check",
    "person",
    "traveled",
    "alone",
    "family",
    "merge",
    "cbsp",
    "patch",
    "columns",
    "together",
    "df",
    "family",
    "equal",
    "df",
    "sp",
    "plus",
    "df",
    "parch",
    "df",
    "dot",
    "loc",
    "dot",
    "df",
    "family",
    "inside",
    "data",
    "frame",
    "location",
    "df",
    "column",
    "roads",
    "value",
    "greater",
    "0",
    "person",
    "considered",
    "traveled",
    "alone",
    "value",
    "set",
    "zero",
    "right",
    "similarly",
    "df",
    "dot",
    "lock",
    "equal",
    "0",
    "travel",
    "alone",
    "value",
    "put",
    "df",
    "traveled",
    "underscore",
    "alone",
    "value",
    "underscore",
    "counts",
    "dot",
    "plot",
    "title",
    "equal",
    "passenger",
    "traveled",
    "alone",
    "type",
    "graph",
    "want",
    "show",
    "bar",
    "run",
    "block",
    "error",
    "guys",
    "let",
    "check",
    "error",
    "okay",
    "used",
    "double",
    "square",
    "box",
    "maybe",
    "getting",
    "error",
    "remove",
    "run",
    "code",
    "yeah",
    "see",
    "data",
    "passenger",
    "traveled",
    "alone",
    "travel",
    "alone",
    "guys",
    "supposed",
    "carry",
    "feature",
    "engineering",
    "create",
    "meaningful",
    "parameter",
    "raw",
    "parameters",
    "provided",
    "notion",
    "feature",
    "engineering",
    "next",
    "point",
    "itinerary",
    "encoding",
    "features",
    "format",
    "fed",
    "machine",
    "learning",
    "model",
    "dealing",
    "classification",
    "problems",
    "need",
    "encode",
    "categorical",
    "features",
    "numerically",
    "container",
    "scale",
    "api",
    "requires",
    "categorical",
    "features",
    "code",
    "editor",
    "first",
    "import",
    "one",
    "hot",
    "encoder",
    "escalon",
    "set",
    "guys",
    "column",
    "going",
    "transform",
    "one",
    "hot",
    "encoding",
    "f6",
    "basically",
    "two",
    "sixes",
    "data",
    "set",
    "female",
    "male",
    "female",
    "male",
    "textual",
    "format",
    "want",
    "convert",
    "binary",
    "format",
    "use",
    "two",
    "characters",
    "six",
    "column",
    "set",
    "female",
    "comma",
    "male",
    "equal",
    "one",
    "hot",
    "encoder",
    "dot",
    "fit",
    "underscore",
    "transform",
    "df",
    "sex",
    "column",
    "convert",
    "array",
    "let",
    "show",
    "achieved",
    "want",
    "print",
    "6",
    "female",
    "mail",
    "generate",
    "encodings",
    "sex",
    "female",
    "male",
    "parameters",
    "let",
    "visualize",
    "looks",
    "yeah",
    "getting",
    "error",
    "data",
    "frame",
    "object",
    "attribute",
    "array",
    "true",
    "take",
    "two",
    "array",
    "guys",
    "reason",
    "behind",
    "error",
    "dealing",
    "column",
    "need",
    "add",
    "one",
    "box",
    "brackets",
    "add",
    "run",
    "code",
    "working",
    "fine",
    "see",
    "one",
    "hot",
    "encoding",
    "looks",
    "like",
    "quite",
    "redundant",
    "information",
    "could",
    "stored",
    "single",
    "column",
    "female",
    "0",
    "male",
    "1",
    "right",
    "select",
    "mail",
    "column",
    "array",
    "resulting",
    "fit",
    "underscore",
    "transform",
    "method",
    "create",
    "new",
    "coding",
    "block",
    "inside",
    "df6",
    "one",
    "hot",
    "encoder",
    "dot",
    "fit",
    "underscore",
    "transform",
    "inside",
    "pass",
    "sixth",
    "column",
    "convert",
    "whole",
    "thing",
    "array",
    "saved",
    "column",
    "format",
    "right",
    "save",
    "column",
    "format",
    "pass",
    "argument",
    "indexing",
    "say",
    "format",
    "data",
    "stored",
    "inside",
    "dfset",
    "column",
    "tabular",
    "column",
    "wise",
    "format",
    "right",
    "let",
    "run",
    "command",
    "converted",
    "method",
    "error",
    "next",
    "thing",
    "visualizing",
    "data",
    "let",
    "show",
    "one",
    "hot",
    "encoding",
    "looks",
    "check",
    "six",
    "column",
    "guys",
    "see",
    "sixth",
    "column",
    "replaced",
    "zeros",
    "ones",
    "zeros",
    "min",
    "one",
    "female",
    "right",
    "hope",
    "one",
    "one",
    "hot",
    "encoding",
    "part",
    "clear",
    "guys",
    "data",
    "scaling",
    "data",
    "condition",
    "data",
    "points",
    "far",
    "scaling",
    "technique",
    "make",
    "closer",
    "simpler",
    "words",
    "say",
    "scaling",
    "used",
    "making",
    "data",
    "points",
    "generalized",
    "distance",
    "lower",
    "know",
    "machine",
    "learning",
    "models",
    "learn",
    "data",
    "time",
    "learning",
    "model",
    "maps",
    "data",
    "input",
    "output",
    "distribution",
    "data",
    "points",
    "different",
    "every",
    "feature",
    "data",
    "larger",
    "differences",
    "data",
    "points",
    "input",
    "variables",
    "increases",
    "uncertainty",
    "result",
    "model",
    "machine",
    "learning",
    "models",
    "provide",
    "weights",
    "input",
    "variables",
    "according",
    "data",
    "points",
    "inferences",
    "output",
    "case",
    "difference",
    "data",
    "points",
    "high",
    "model",
    "need",
    "provide",
    "large",
    "weight",
    "points",
    "final",
    "result",
    "model",
    "large",
    "weight",
    "value",
    "often",
    "unstable",
    "right",
    "means",
    "model",
    "produce",
    "poor",
    "results",
    "means",
    "model",
    "produce",
    "poor",
    "results",
    "perform",
    "poorly",
    "learning",
    "saying",
    "algorithms",
    "face",
    "problem",
    "basic",
    "algorithms",
    "like",
    "linear",
    "logistic",
    "regression",
    "artificial",
    "neural",
    "networks",
    "clustering",
    "algorithms",
    "k",
    "values",
    "etc",
    "face",
    "effect",
    "difference",
    "scale",
    "input",
    "variables",
    "scaling",
    "target",
    "value",
    "good",
    "idea",
    "regression",
    "modeling",
    "scaling",
    "data",
    "makes",
    "easy",
    "model",
    "learn",
    "understand",
    "problem",
    "case",
    "neural",
    "networks",
    "independent",
    "variable",
    "spread",
    "values",
    "may",
    "result",
    "large",
    "loss",
    "training",
    "testing",
    "cause",
    "learning",
    "process",
    "unstable",
    "example",
    "one",
    "feature",
    "contain",
    "data",
    "pounds",
    "kilograms",
    "interpret",
    "properly",
    "features",
    "need",
    "scale",
    "least",
    "kilograms",
    "least",
    "pounds",
    "reason",
    "need",
    "data",
    "normalization",
    "data",
    "use",
    "two",
    "methods",
    "available",
    "standard",
    "scalar",
    "min",
    "max",
    "scalar",
    "let",
    "first",
    "talk",
    "min",
    "max",
    "scalar",
    "value",
    "feature",
    "min",
    "max",
    "scalar",
    "subtracts",
    "minimum",
    "value",
    "feature",
    "divides",
    "range",
    "range",
    "difference",
    "original",
    "maximum",
    "original",
    "minimum",
    "guys",
    "basically",
    "min",
    "max",
    "scalar",
    "preserves",
    "shape",
    "original",
    "distribution",
    "meaningfully",
    "change",
    "information",
    "embedded",
    "original",
    "data",
    "like",
    "see",
    "graph",
    "right",
    "converts",
    "range",
    "0",
    "1",
    "right",
    "need",
    "remember",
    "min",
    "max",
    "scalar",
    "next",
    "standard",
    "scalar",
    "standard",
    "scalar",
    "follows",
    "standard",
    "normal",
    "distribution",
    "assumes",
    "normal",
    "distribution",
    "data",
    "within",
    "feature",
    "scaling",
    "makes",
    "distribution",
    "centered",
    "around",
    "0",
    "standard",
    "deviation",
    "1",
    "mean",
    "removed",
    "data",
    "sample",
    "x",
    "core",
    "standard",
    "scalar",
    "calculated",
    "x",
    "minus",
    "mean",
    "x",
    "divided",
    "standard",
    "deviation",
    "x",
    "mean",
    "represented",
    "mu",
    "standard",
    "deviation",
    "presented",
    "sigma",
    "sine",
    "mean",
    "forward",
    "calculated",
    "using",
    "formula",
    "standard",
    "deviation",
    "calculated",
    "using",
    "formula",
    "given",
    "right",
    "guys",
    "gon",
    "na",
    "talk",
    "mathematical",
    "details",
    "techniques",
    "simply",
    "show",
    "implement",
    "scaling",
    "methods",
    "python",
    "program",
    "right",
    "let",
    "visit",
    "code",
    "editor",
    "first",
    "thing",
    "first",
    "let",
    "import",
    "standard",
    "scalar",
    "notebook",
    "command",
    "scale",
    "dot",
    "free",
    "processing",
    "import",
    "standard",
    "scalar",
    "right",
    "run",
    "command",
    "next",
    "step",
    "selecting",
    "numerical",
    "columns",
    "scale",
    "numerical",
    "columns",
    "right",
    "let",
    "find",
    "numerical",
    "columns",
    "first",
    "create",
    "new",
    "variable",
    "named",
    "numerical",
    "columns",
    "inside",
    "store",
    "selected",
    "data",
    "type",
    "columns",
    "int",
    "64",
    "float",
    "integer",
    "print",
    "columns",
    "let",
    "run",
    "see",
    "numerical",
    "columns",
    "data",
    "set",
    "apply",
    "standard",
    "scalar",
    "right",
    "first",
    "invoke",
    "object",
    "standard",
    "scalar",
    "using",
    "syntax",
    "new",
    "variable",
    "equal",
    "standard",
    "scalar",
    "right",
    "run",
    "command",
    "next",
    "create",
    "new",
    "data",
    "frame",
    "stores",
    "num",
    "columns",
    "numerical",
    "columns",
    "apply",
    "ss",
    "dot",
    "fit",
    "underscore",
    "transform",
    "pass",
    "numeric",
    "columns",
    "dot",
    "describe",
    "run",
    "see",
    "values",
    "standardized",
    "values",
    "0",
    "1",
    "proximity",
    "right",
    "guys",
    "values",
    "log",
    "format",
    "convert",
    "values",
    "simple",
    "numbers",
    "find",
    "values",
    "lie",
    "0",
    "standard",
    "scalar",
    "works",
    "let",
    "also",
    "show",
    "min",
    "max",
    "scalar",
    "works",
    "import",
    "min",
    "max",
    "scalar",
    "command",
    "escalon",
    "dot",
    "preprocessing",
    "import",
    "min",
    "max",
    "scalar",
    "already",
    "found",
    "numerical",
    "columns",
    "call",
    "num",
    "columns",
    "variable",
    "created",
    "previously",
    "right",
    "need",
    "need",
    "pass",
    "min",
    "max",
    "scalar",
    "variable",
    "invoked",
    "df",
    "dot",
    "num",
    "underscore",
    "columns",
    "equal",
    "minmac",
    "dot",
    "fit",
    "underscore",
    "transform",
    "pass",
    "num",
    "underscore",
    "columns",
    "print",
    "columns",
    "guys",
    "already",
    "applied",
    "standardization",
    "data",
    "know",
    "values",
    "well",
    "quite",
    "nice",
    "right",
    "data",
    "previously",
    "standardized",
    "min",
    "max",
    "scalar",
    "putting",
    "perspective",
    "right",
    "values",
    "quite",
    "processable",
    "feed",
    "network",
    "machine",
    "learning",
    "model",
    "able",
    "produce",
    "sort",
    "accurate",
    "prediction",
    "close",
    "output",
    "parameter",
    "right",
    "hope",
    "min",
    "max",
    "scalar",
    "standard",
    "scalar",
    "clear",
    "guys",
    "let",
    "tell",
    "overview",
    "data",
    "handled",
    "okay",
    "carrying",
    "operations",
    "line",
    "throughout",
    "series",
    "session",
    "try",
    "build",
    "basic",
    "intuition",
    "process",
    "right",
    "wish",
    "thank",
    "guys",
    "till",
    "end",
    "session",
    "hope",
    "session",
    "informative",
    "entrailing",
    "liked",
    "video",
    "thumbs",
    "would",
    "much",
    "appreciated",
    "also",
    "concerns",
    "set",
    "concept",
    "please",
    "put",
    "comment",
    "box",
    "24x7",
    "team",
    "experts",
    "would",
    "obliged",
    "resolve",
    "guys",
    "also",
    "make",
    "sure",
    "subscribed",
    "intellipath",
    "youtube",
    "channel",
    "never",
    "miss",
    "upcoming",
    "multiple",
    "updates",
    "want",
    "make",
    "career",
    "data",
    "science",
    "intellipat",
    "iit",
    "madras",
    "advanced",
    "data",
    "science",
    "ai",
    "certification",
    "program",
    "course",
    "high",
    "quality",
    "cost",
    "effective",
    "taught",
    "iit",
    "professors",
    "industry",
    "experts"
  ],
  "keywords": [
    "session",
    "going",
    "workflow",
    "basic",
    "first",
    "step",
    "every",
    "machine",
    "learning",
    "problem",
    "making",
    "sure",
    "data",
    "hope",
    "clear",
    "guys",
    "get",
    "make",
    "miss",
    "okay",
    "said",
    "let",
    "talk",
    "sort",
    "model",
    "learn",
    "provided",
    "able",
    "predictions",
    "quite",
    "mean",
    "set",
    "two",
    "call",
    "one",
    "x",
    "using",
    "features",
    "example",
    "means",
    "parameters",
    "case",
    "output",
    "result",
    "given",
    "say",
    "iris",
    "variable",
    "well",
    "type",
    "find",
    "algorithm",
    "basically",
    "fit",
    "visit",
    "code",
    "editor",
    "use",
    "library",
    "purpose",
    "import",
    "command",
    "sklearn",
    "run",
    "block",
    "dot",
    "load",
    "underscore",
    "stored",
    "inside",
    "method",
    "next",
    "visualize",
    "looks",
    "write",
    "actually",
    "see",
    "input",
    "variables",
    "right",
    "information",
    "want",
    "return",
    "argument",
    "add",
    "true",
    "feature",
    "store",
    "comma",
    "equal",
    "format",
    "create",
    "models",
    "python",
    "pass",
    "must",
    "take",
    "notebook",
    "show",
    "thing",
    "classification",
    "rows",
    "different",
    "concept",
    "like",
    "linear",
    "regression",
    "k",
    "object",
    "new",
    "put",
    "function",
    "created",
    "error",
    "check",
    "predict",
    "getting",
    "yeah",
    "api",
    "structure",
    "produce",
    "invoke",
    "also",
    "perform",
    "predicted",
    "contains",
    "graph",
    "plot",
    "values",
    "quickly",
    "might",
    "works",
    "difference",
    "adds",
    "frame",
    "pandas",
    "columns",
    "dictionary",
    "simple",
    "part",
    "used",
    "science",
    "iit",
    "program",
    "course",
    "high",
    "experts",
    "fetch",
    "openml",
    "df",
    "missing",
    "null",
    "value",
    "column",
    "way",
    "sum",
    "h",
    "bar",
    "body",
    "help",
    "percentage",
    "number",
    "convert",
    "wo",
    "know",
    "place",
    "drop",
    "print",
    "shape",
    "0",
    "na",
    "1",
    "original",
    "strategy",
    "reason",
    "computer",
    "us",
    "impute",
    "calculated",
    "imputer",
    "nan",
    "frequent",
    "transform",
    "need",
    "numerical",
    "array",
    "parameter",
    "engineering",
    "traveled",
    "alone",
    "family",
    "encoding",
    "scale",
    "hot",
    "female",
    "male",
    "min",
    "scaling",
    "points",
    "distribution",
    "standard",
    "scalar",
    "max",
    "deviation",
    "num"
  ]
}