{
  "text": "In this course you will learn all about natural \nlanguage processing and how to apply it to real  \nworld problems using the spacey library. Dr. \nMattingly is extremely knowledgeable in this area,  \nand he's an excellent teacher. Hi, and welcome \nto this video. My name is Dr. William Mattingly,  \nand I specialize in multilingual natural \nlanguage processing, I come to NLP from a  \nhumanities perspective, I have my PhD in medieval \nhistory, but I use spacey on a regular basis to  \ndo all of my NLP needs. So what you're going to \nget out of this video over the next few hours  \nis a basic understanding of what natural language \nprocessing is or NLP, and also how to apply it  \nto domain specific problems, or problems that \nexist within your own area of expertise. I happen  \nto use this all the time to analyze historical \ndocuments, or financial documents for my own  \npersonal investments. Over the next few hours, \nyou're going to learn a lot about NLP language as  \na whole and most importantly, the spacey library. \nI like the spacey library because it's easy to  \nuse, and easy to also implement really kind of \ngeneral solutions to general problems with the  \noff the shelf models that are already available \nto you. I'm going to walk you through in part one  \nof this video series how to get the most out \nof spacey with these off the shelf features.  \nIn part two, we're going to start tackling some \nof the features that don't exist in off the shelf  \nmodels. And I'm going to show you how to use rules \nbased pipes or components in spacey to actually  \nsole domain specific problems and your own area \nfrom the entity ruler to the matcher to actually  \ninjecting robust complex regular expression or \nregex patterns, and a custom spacey component  \nthat doesn't actually exist at the moment. I'm \ngoing to be showing you all that in part two,  \nso that in part three, we can take the lessons \nthat we learned in part one and part two, and  \nactually apply them to solve a very kind of common \nproblem that exists in NLP and that is information  \nextraction from financial documents. So finding \nthings that are of relevance, such as stocks,  \nmarkets, indexes and stock exchanges. If you join \nme over the next few hours, you will leave this  \nlesson with a good understanding of the standing \nof spacey and also a good understanding of kind  \nof the off the shelf components that are there \nand a way to take the off the shelf components  \nand apply them to your own domain. If you also \njoin me in this video and you like it, please let  \nme know in the comments down below because I am \ninterested in making a second part to this video  \nthat will explore not only the rules based aspects \nof spacey, but the machine learning based aspects  \nof spacey. So teaching you how to train your \nown models to do your own things such as  \ntraining a dependency parser, training a named \nentity recognizer things like this, which are not  \ncovered in this video. Nevertheless, if you join \nme for this one and you like it, you will find  \npart two, much easier to understand. So sit back, \nrelax, and let's jump into what NLP is, what kind  \nof things you can do with NLP such as information \nextraction, and what the spacey library is and how  \nthis course will be laid out. If you like this \nvideo, also consider subscribing to my channel  \nPython tutorials for digital humanities, \nwhich is linked in the description down below.  \nEven if you're not a digital humanists like \nme, you will find these Python tutorials useful  \nbecause they take Python and make it accessible \nto students of all levels. specifically those who  \nare beginners, I walk you through not only the \nbasics of Python, but also I walk you through  \nstep by step some of the more common libraries \nthat you need. A lot of the channel deals with  \ntexts or text based problems. But other content \ndeals with things like machine learning, and  \nimage classification and OCR, all in Python. So \nbefore we begin with spacey, I think we should  \nspend a little bit of time talking about what \nNLP or natural language processing actually is.  \nNatural Language Processing is the process \nby which we try to get a computer system  \nto understand and parse and extract human language \noftentimes with raw text. There are a couple  \ndifferent areas of natural language processing. \nThere's named entity recognition, part of speech  \ntagging, syntactic parsing, text categorization, \nalso known as text classification, co reference  \nresolution machine translation. Adjacent to NLP \nis another kind of computational linguistics field  \ncalled natural language understanding NLU \nThis is where we train computer systems to  \ndo things like relation extraction, semantic \nparsing, question and answering this is where  \nbots really kind of come into play, summarization, \nsentiment analysis and paraphrasing. NLP and NLU  \nare used by a wide array of industries, from \nfinance industry, all the way through to law  \nand academia with researchers trying to do \ninformation extraction from texts. Within an LP,  \nthere's a couple different applications. The first \nand probably the most important is information  \nextraction. This is the process by which we try to \nget a computer system to extract information that  \nwe find relevant to our own research or needs. So \nfor example, as we're gonna see, in part three of  \nthis video, when we need to apply spacey to the \nfinancial sector, a person interested in finances  \nmight need an LP to go through and extract things \nlike company names, stocks, indexes, things that  \nare referenced within maybe news articles, from \nReuters to New York Times to Wall Street Journal.  \nThis is an example of using NLP to extract \ninformation. A good way to think about NLP  \nis application in this area, is it takes in some \nunstructured data, in this case, raw text, and  \nextracts structured data from it or metadata. So \nit finds the things that you want it to find and  \nextracts them for you. Now while there's ways to \ndo this with gazetteers, and list matching, using  \nan NLP framework, like spacey, which I'll talk \nabout in just a second, has certain advantages,  \nthe main one being that you can use and leverage \nthings that have been parsed syntactically or  \nsemantically. So things like the part of speech of \na word things like its dependencies, things like  \nits co reference, these are things that the spacey \nframework allow for you to do off the shelf,  \nand also train into machine learning models, and \nwork into pipelines with rules. So that's kind of  \none aspect of NLP. And one way it's used. Another \nway it's used is to read in data and classify it.  \nThis is known as text categorization. And we \nsee that on the left hand side of this image,  \ntext categorization or text classification. And we \nconclude in this sentiment analysis for the most  \npart as well, is a way we take information into \na computer system, again, unstructured data or  \nraw text, and we classify it in some way. you've \nactually seen this at work for many decades now,  \nwith spam detection, spam detection is nearly \nperfect, it needs to be continually updated.  \nBut for the most part, it is a solved problem. The \nreason why you have emails that automatically go  \nto your spam folder, is because there's a machine \nlearning model that sits on the background of  \nyour on the back end of your email server. And \nwhat it does is it actually looks at the emails,  \nit sees if it fat fits the pattern for what it's \nseen as spam before, and it assigns it a spam  \nlabel. This is known as classification. This is \nalso used by researchers, especially in the legal  \nindustry, lawyers oftentimes receive hundreds of \n1000s of documents, if not millions of documents,  \nthey don't necessarily have the human time to \ngo through and analyze every single document  \nverbatim. It is important to kind of get a quick \numbrella sense of the documents without actually  \nhaving to go through and read them page by \npage. And so what lawyers will oftentimes do  \nis use NLP to do classification and information \nextraction, they will find keywords that are  \nrelevant to their case, or they will find \ndocuments that are classified according to the  \nrelevant fields of their case. And that way, they \ncan take a million documents and reduce it down  \nto maybe only a handful, maybe 1000 that they have \nto read verbatim. This is a real world application  \nof NLP or natural language processing. And \nboth of these tasks can be achieved through  \nthe spacey framework. spacey is a framework \nfor doing NLP right now. As of 2021, it's only  \navailable I believe in Python, I think there is a \ncommunity that's working on an application with R  \nbut I don't know that for certain. But spacey \nis one of many NLP frameworks that Python has  \navailable. If you're interested in looking at all \nof them, you can explore things like NLT Kay, the  \nnatural language toolkit stanza, which I believe \nis coming out of the same program at Stanford.  \nThere's many out there, but I find spacey to be \nthe best of all of them for a couple different  \nreasons. Reason one is that they provide for you \noff the shelf models that benchmark very well  \nmeaning they perform very quickly. And they also \nhave very good accuracy metrics such as precision  \nrecall, and F score. And I'm not going to talk \ntoo much about the way we measure machine learning  \naccuracy right now, but know that they are quite \ngood. Second, spacey has the ability to leverage  \ncurrent natural language processing methods, \nspecifically transformer models, also known,  \nusually kind of collectively as Bert models, even \nthough that's not entirely accurate, but it allows  \nfor you to use an off the shelf transformer \nmodel. And third, it provides the framework for  \ndoing custom training relatively easily compared \nto these other NLP frameworks that are out there.  \nFinally, the fourth reason why I picked spacey \nover other NLP frameworks is because it scales  \nwell. spacey was designed by explosion AI, and the \nentire Purpose of spacey is to work at scale AI  \nat scale, we mean working with large quantities of \ndocuments efficiently, effectively and accurately.  \nspacey scales well because it can process hundreds \nof 1000s of documents with relative ease in  \na relatively short period of time, especially if \nyou stick with more rules based pipes, which we're  \ngoing to talk about in part two of this video. So \nthose are the two things you really need to know  \nabout NLP, and spacey in general, we're going to \ntalk about spacey in depth as we explore it both  \nthrough this video. And and the free textbook \nI provide to go along with this video, which is  \nlocated at spacey dot python humanities.com. And \nit should be linked in the description down below  \nthis video and the textbook I meant to work in \ntandem. Some stuff that I cover in the video  \nmight not necessarily be in the textbook \nbecause it doesn't lend itself well to  \ntext representation. And the same goes for the \nopposite some stuff that I don't have the time  \nto cover verbatim In this video, I cover \nin a little bit more depth in the video.  \nAnd in the book, I think that you should try \nto use both of these, what I would recommend  \nis doing one pass through this whole video, watch \nit in its entirety and get an umbrella sense of  \neverything that space you can do. And everything \nthat we're going to cover, I would then go back  \nand try to replicate each stage of this process on \na separate window or on a separate screen and try  \nto kind of follow along and code and then I would \ngo back through a third time and try to watch the  \nfirst part Why talk about what we're going to be \ndoing and try to do it on your own without looking  \nat the textbook or the video. If you can do that \nby your third pass, you'll be in very good shape  \nto start using spacey to solve your own domain \nspecific problems. NLP is a complex field and  \napplying NLP is really complex. But fortunately, \nframeworks like spacey make this project and this  \nprocess a lot easier. I encourage you to spend a \nfew hours in this video get to know spacey and I  \nthink you're going to find that you can do things \nthat you didn't think possible and relatively  \nshort order. So sit back, relax and enjoy this \nvideo series on spacey. In order to use spacey,  \nyou're first going to have to install spacey. Now \nthere's a few different ways to do this. Depending  \non your environment and your operating system, \nI recommend going to spacey.io backslash usage  \nand kind of enter in the correct framework that \nyou're working with. So if you're using Mac OS  \nversus windows versus Linux, you can go through \nand in this very handy kind of user interface, you  \ncan go through and select the different features \nthat matter most to you. I'm working with Windows,  \nI'm going to be using PIP in this case, and \nI'm going to be doing everything on the CPU.  \nAnd I'm going to be working with English. So I've \nestablished all of those different parameters.  \nAnd it goes through and it tells me exactly \nhow to go through and install it using PIP  \nin the terminal. So I encourage you to \ngo through and pause the video right now  \ngo ahead and install Windows however you want to. \nI'm going to be walking through how to install it  \nwithin the Jupyter Notebook that we're going to \nbe moving to in just a second. I want you to not  \nwork with the GPU at all. Working with spacey on \nthe GPU requires a lot more understanding about  \nwhat the GPU is used for specifically, in training \nmachine learning models. It requires you to have  \nCUDA installed correctly. It requires a \ncouple other things that I don't really  \nhave the time to get into in this video, but we'll \nbe addressing in a more advanced spacey tutorial  \nvideo. So for right now, I recommend selecting \nyour o s selecting either can use PIP or conda  \nand then selecting CPU. And since you're going to \nbe working through this video with English texts,  \nI encourage you to select English right now \nand go ahead and just install or download  \nthe N core web SM model. This is the small \nmodel. I'll talk about that in just a second.  \nSo the first thing we're going to do in our \nJupyter Notebook is we're going to be using the  \nthe exclamation mark to delineate in the cell that \nthis is a terminal command, we're going to say pip  \ninstall spacey, your output when you execute \nthis cell is going to look a little different  \nthan mine. I already have spacey installed in this \nenvironment. And so mind kind of goes through and  \nlooks like this yours will actually go through and \ninstead of saying requirement already satisfied  \nit'll be actually passing out the the different \nthings that it's actually installing to install  \nspacey and all of its dependencies. The next thing \nthat you're going to do is you're going to again,  \nyou follow the instructions, and you're \ngoing to be doing Python dash m space spacey,  \nspace download, and then the model that you want \nto download. So let's go ahead and do that right  \nnow. So let's go ahead and say Python m spacing. \nDownload to this is a spacey terminal command.  \nAnd we're going to download the N core web SM \nand again, I already have this model downloaded  \nSo on my end, spacey is going to look a \nlittle differently than as it's going to  \nlook on your end as it prints off on the Jupyter \nNotebook. And if we give it a just a second,  \neverything will go through, and it says that \nit's collected it, it's downloading it. And we  \nare all very happy now. And so now that we've got \nspacey installed correctly, and that we've got the  \nsmall model downloaded correctly, we can go ahead \nand start actually using spacey and make sure  \neverything's correct. The first thing we're going \nto do is we're going to import the spacey library  \nas you would with any other Python library. If \nyou're not familiar with this, a library is simply  \na set of classes and functions that you can import \ninto a Python script so that you don't have to  \nwrite a whole bunch of extra code. Libraries \nare massive collections of classes and functions  \nthat you can call. So when we import spacey, \nwe're importing the whole library of spacey  \nand now that we've seen something like this, \nwe know that spacey has imported correctly,  \nas long as you're not getting an error message, \neverything was in was imported fine. The next  \nthing that we need to do is we want to make sure \nthat our English core web SM are small English  \nmodel was downloaded correctly. So the next thing \nthat we need to do is we need to create an NLP  \nobject. I'm going to be talking a lot more about \nthis as we move forward. Right now, this is just  \ntroubleshooting to make sure that we've installed \nspacey correctly and we've downloaded our model  \ncorrectly. So we're going to use the spacey dot \nload command. This is going to take one argument,  \nit's going to be a string that is going to \ncorrespond to the model that you've installed.  \nAnd this case n cor web s n. And if you \nexecute this cell and you have no errors,  \nyou have successfully installed spacey correctly \nand you've downloaded the English core web SM  \nmodel correctly. So go ahead take time, and get \nall this stuff set up. Pause the video if you need  \nto, and then pop back and we're going to start \nactually working through the basics of spacey.  \nI'm now going to move into kind of an \noverview of kind of what's within spacey,  \nwhy it's useful and kind of some of the basic \nfeatures of it that you need to be familiar with.  \nAnd I'm going to be working from the Jupyter \nNotebook that I talked about and the introduction  \nto this video. If we scroll down to the bottom of \nchapter one, the basics of spacey, then you get  \npast the install section, you get to this section \non containers. So what are containers? Well,  \ncontainers within spacey are objects that \ncontain a large quantity of data about a text.  \nThere are several different containers that \nyou can work with. In spacey, there's the doc,  \nthe doc Ben example, language, \nlexeme span, span group and token,  \nwe're going to be dealing with the lexeme a \nlittle bit in this video series. And we're  \ngoing to be dealing with the language container \na little bit in this video series. But really,  \nthe three big things that we're going to be \ntalking about again and again is the dock  \nthe span and the token. And I think when you \nfirst come to spacey, there's a little bit of  \na learning curve about what these things are, what \nthey do, how they are structured hierarchically.  \nAnd for that reason I've created this, \nin my opinion, kind of easy to understand  \nimage of what different containers are. So if \nyou think about what spacey is as a pyramid,  \nso a hierarchical system, we've got all \nthese different containers structured around,  \nreally the dock object, your Docker container, \nor your dock object contains a whole bunch of  \nmetadata about the text that you pass to the \nspacey pipeline, which we're going to see  \nin practice, and just a few minutes. The doc \nobject contains a bunch of different things.  \nIt contains attributes. And these attributes \ncan be things like, like sentences. So if you  \niterate over doc dot cents, you can actually \naccess all the different sentences found within  \nthat doc object. If you iterate over each \nindividual item, or index and your doc object,  \nyou can get individual tokens. tokens are going \nto be things like words or punctuation marks  \nsomething within your sentence or text \nthat has a self contained important value,  \neither syntactically or semantically. So this \nis going to be things like words a comma period,  \na semi colon, a quotation mark, things like this, \nthese are all going to be your tokens. And we're  \ngoing to see how tokens are a little different \nthan just splitting words up with traditional  \nstring methods and Python. The next thing that \nyou should be kind of familiar with are spans.  \nSo spans are important because they kind of exist \nwithin and without of the doc object. So unlike  \nthe token, which is an index of the doc object, \na span can be a token itself, but it can also  \nbe a sequence of multiple tokens, we're gonna see \nthat at play. So imagine if you had a span in its  \ncategory, maybe group one are our places. So a \nsingle token might be like a city like Berlin,  \nbut span group two, this could be something like \nfull proper names. So of people, for example. So  \nthis could be like, as we're going to see Martin \nLuther King, this would be a sequence of tokens, a  \nsequence of three different items in the sentence \nthat make up one span, or one self contained item.  \nSo Martin Luther King, would be a person who's \na collection of a sequence of individual tokens.  \nIf that doesn't make sense, right now, this \nimage will be reinforced as we go through  \nand learn more about spacey in practice. For \nright now, I want you to be just understanding  \nthat the doc object is the thing around which \nall of spacey sits, this is going to be the  \nobject that you create. This is going to be the \nobject that contains all the metadata that you  \nneed to access. And this is going to be the \nobject that you tried to essentially improve  \nwith different custom components, factories, and \npipelines. As you go through and do more advanced  \nthings with spacey, we're going to now see in \njust a few seconds how that dock object is kind  \nof similar to the text itself. But how it's \nvery, very different and much more powerful.  \nWe're now going to be moving on to chapter two \nof this textbook, which is going to deal with  \nkind of getting used to the in depth features \nof spacing. If you want to pause the video or  \nkeep this notebook or this book open up to \nkind of separate from this video and follow  \nalong. As we go through and explore it in live \ncoding, we're going to be talking about a few  \ndifferent things as we explore chapter two, \nthis will be a lot longer than chapter one,  \nwe're going to be not only importing spacey, but \nactually going through and loading up a model,  \ncreating a dog object around that model. So that \nwe're going to work with container and practice.  \nAnd then we're going to see how that container \nstores a lot of different features or metadata  \nattributes about the text. And while \nthey look the same on the surface,  \nthey're actually quite different. So let's \ngo ahead and work within our same Jupyter  \nNotebook where we've imported spacey and we have \nalready created the NLP object. The first thing  \nthat I want to do is I want to open up a text to \nstart working with within this repo, we've got  \na data folder. Within this data sub folder, \nI've got a couple different Wikipedia openings,  \nI've got one on MLK that we're going to be using \na little later in this video. And then I have one  \non the United States, this is wiki underscore us. \nThat's going to be what we work with right now.  \nSo let's use our width operator and open up \nthe data backslash wiki underscore us dot txt.  \nWe're gonna just read that in as F. And then we're \ngoing to create this text object which is going to  \nbe equal to F dot read. And now that we've got \nour text object created, let's go ahead and see  \nwhat this looks like. So let's print text. And \nwe see that it's a standard Wikipedia article  \nkind of follows that same introductory format and \nit's about four or five paragraphs long with a  \nlot of the features left in such as the brackets \nthat delineate some kind of a footnote. We're not  \ngoing to worry too much about cleaning this up \nright now, because we're interested in not with  \ncleaning our data so much as just starting \nto work with the doc object in spacey.  \nSo the first thing that you want to do is \nyou're going to want to create a doc object\n",
  "words": [
    "course",
    "learn",
    "natural",
    "language",
    "processing",
    "apply",
    "real",
    "world",
    "problems",
    "using",
    "spacey",
    "library",
    "mattingly",
    "extremely",
    "knowledgeable",
    "area",
    "excellent",
    "teacher",
    "hi",
    "welcome",
    "video",
    "name",
    "william",
    "mattingly",
    "specialize",
    "multilingual",
    "natural",
    "language",
    "processing",
    "come",
    "nlp",
    "humanities",
    "perspective",
    "phd",
    "medieval",
    "history",
    "use",
    "spacey",
    "regular",
    "basis",
    "nlp",
    "needs",
    "going",
    "get",
    "video",
    "next",
    "hours",
    "basic",
    "understanding",
    "natural",
    "language",
    "processing",
    "nlp",
    "also",
    "apply",
    "domain",
    "specific",
    "problems",
    "problems",
    "exist",
    "within",
    "area",
    "expertise",
    "happen",
    "use",
    "time",
    "analyze",
    "historical",
    "documents",
    "financial",
    "documents",
    "personal",
    "investments",
    "next",
    "hours",
    "going",
    "learn",
    "lot",
    "nlp",
    "language",
    "whole",
    "importantly",
    "spacey",
    "library",
    "like",
    "spacey",
    "library",
    "easy",
    "use",
    "easy",
    "also",
    "implement",
    "really",
    "kind",
    "general",
    "solutions",
    "general",
    "problems",
    "shelf",
    "models",
    "already",
    "available",
    "going",
    "walk",
    "part",
    "one",
    "video",
    "series",
    "get",
    "spacey",
    "shelf",
    "features",
    "part",
    "two",
    "going",
    "start",
    "tackling",
    "features",
    "exist",
    "shelf",
    "models",
    "going",
    "show",
    "use",
    "rules",
    "based",
    "pipes",
    "components",
    "spacey",
    "actually",
    "sole",
    "domain",
    "specific",
    "problems",
    "area",
    "entity",
    "ruler",
    "matcher",
    "actually",
    "injecting",
    "robust",
    "complex",
    "regular",
    "expression",
    "regex",
    "patterns",
    "custom",
    "spacey",
    "component",
    "actually",
    "exist",
    "moment",
    "going",
    "showing",
    "part",
    "two",
    "part",
    "three",
    "take",
    "lessons",
    "learned",
    "part",
    "one",
    "part",
    "two",
    "actually",
    "apply",
    "solve",
    "kind",
    "common",
    "problem",
    "exists",
    "nlp",
    "information",
    "extraction",
    "financial",
    "documents",
    "finding",
    "things",
    "relevance",
    "stocks",
    "markets",
    "indexes",
    "stock",
    "exchanges",
    "join",
    "next",
    "hours",
    "leave",
    "lesson",
    "good",
    "understanding",
    "standing",
    "spacey",
    "also",
    "good",
    "understanding",
    "kind",
    "shelf",
    "components",
    "way",
    "take",
    "shelf",
    "components",
    "apply",
    "domain",
    "also",
    "join",
    "video",
    "like",
    "please",
    "let",
    "know",
    "comments",
    "interested",
    "making",
    "second",
    "part",
    "video",
    "explore",
    "rules",
    "based",
    "aspects",
    "spacey",
    "machine",
    "learning",
    "based",
    "aspects",
    "spacey",
    "teaching",
    "train",
    "models",
    "things",
    "training",
    "dependency",
    "parser",
    "training",
    "named",
    "entity",
    "recognizer",
    "things",
    "like",
    "covered",
    "video",
    "nevertheless",
    "join",
    "one",
    "like",
    "find",
    "part",
    "two",
    "much",
    "easier",
    "understand",
    "sit",
    "back",
    "relax",
    "let",
    "jump",
    "nlp",
    "kind",
    "things",
    "nlp",
    "information",
    "extraction",
    "spacey",
    "library",
    "course",
    "laid",
    "like",
    "video",
    "also",
    "consider",
    "subscribing",
    "channel",
    "python",
    "tutorials",
    "digital",
    "humanities",
    "linked",
    "description",
    "even",
    "digital",
    "humanists",
    "like",
    "find",
    "python",
    "tutorials",
    "useful",
    "take",
    "python",
    "make",
    "accessible",
    "students",
    "levels",
    "specifically",
    "beginners",
    "walk",
    "basics",
    "python",
    "also",
    "walk",
    "step",
    "step",
    "common",
    "libraries",
    "need",
    "lot",
    "channel",
    "deals",
    "texts",
    "text",
    "based",
    "problems",
    "content",
    "deals",
    "things",
    "like",
    "machine",
    "learning",
    "image",
    "classification",
    "ocr",
    "python",
    "begin",
    "spacey",
    "think",
    "spend",
    "little",
    "bit",
    "time",
    "talking",
    "nlp",
    "natural",
    "language",
    "processing",
    "actually",
    "natural",
    "language",
    "processing",
    "process",
    "try",
    "get",
    "computer",
    "system",
    "understand",
    "parse",
    "extract",
    "human",
    "language",
    "oftentimes",
    "raw",
    "text",
    "couple",
    "different",
    "areas",
    "natural",
    "language",
    "processing",
    "named",
    "entity",
    "recognition",
    "part",
    "speech",
    "tagging",
    "syntactic",
    "parsing",
    "text",
    "categorization",
    "also",
    "known",
    "text",
    "classification",
    "co",
    "reference",
    "resolution",
    "machine",
    "translation",
    "adjacent",
    "nlp",
    "another",
    "kind",
    "computational",
    "linguistics",
    "field",
    "called",
    "natural",
    "language",
    "understanding",
    "nlu",
    "train",
    "computer",
    "systems",
    "things",
    "like",
    "relation",
    "extraction",
    "semantic",
    "parsing",
    "question",
    "answering",
    "bots",
    "really",
    "kind",
    "come",
    "play",
    "summarization",
    "sentiment",
    "analysis",
    "paraphrasing",
    "nlp",
    "nlu",
    "used",
    "wide",
    "array",
    "industries",
    "finance",
    "industry",
    "way",
    "law",
    "academia",
    "researchers",
    "trying",
    "information",
    "extraction",
    "texts",
    "within",
    "lp",
    "couple",
    "different",
    "applications",
    "first",
    "probably",
    "important",
    "information",
    "extraction",
    "process",
    "try",
    "get",
    "computer",
    "system",
    "extract",
    "information",
    "find",
    "relevant",
    "research",
    "needs",
    "example",
    "gon",
    "na",
    "see",
    "part",
    "three",
    "video",
    "need",
    "apply",
    "spacey",
    "financial",
    "sector",
    "person",
    "interested",
    "finances",
    "might",
    "need",
    "lp",
    "go",
    "extract",
    "things",
    "like",
    "company",
    "names",
    "stocks",
    "indexes",
    "things",
    "referenced",
    "within",
    "maybe",
    "news",
    "articles",
    "reuters",
    "new",
    "york",
    "times",
    "wall",
    "street",
    "journal",
    "example",
    "using",
    "nlp",
    "extract",
    "information",
    "good",
    "way",
    "think",
    "nlp",
    "application",
    "area",
    "takes",
    "unstructured",
    "data",
    "case",
    "raw",
    "text",
    "extracts",
    "structured",
    "data",
    "metadata",
    "finds",
    "things",
    "want",
    "find",
    "extracts",
    "ways",
    "gazetteers",
    "list",
    "matching",
    "using",
    "nlp",
    "framework",
    "like",
    "spacey",
    "talk",
    "second",
    "certain",
    "advantages",
    "main",
    "one",
    "use",
    "leverage",
    "things",
    "parsed",
    "syntactically",
    "semantically",
    "things",
    "like",
    "part",
    "speech",
    "word",
    "things",
    "like",
    "dependencies",
    "things",
    "like",
    "co",
    "reference",
    "things",
    "spacey",
    "framework",
    "allow",
    "shelf",
    "also",
    "train",
    "machine",
    "learning",
    "models",
    "work",
    "pipelines",
    "rules",
    "kind",
    "one",
    "aspect",
    "nlp",
    "one",
    "way",
    "used",
    "another",
    "way",
    "used",
    "read",
    "data",
    "classify",
    "known",
    "text",
    "categorization",
    "see",
    "left",
    "hand",
    "side",
    "image",
    "text",
    "categorization",
    "text",
    "classification",
    "conclude",
    "sentiment",
    "analysis",
    "part",
    "well",
    "way",
    "take",
    "information",
    "computer",
    "system",
    "unstructured",
    "data",
    "raw",
    "text",
    "classify",
    "way",
    "actually",
    "seen",
    "work",
    "many",
    "decades",
    "spam",
    "detection",
    "spam",
    "detection",
    "nearly",
    "perfect",
    "needs",
    "continually",
    "updated",
    "part",
    "solved",
    "problem",
    "reason",
    "emails",
    "automatically",
    "go",
    "spam",
    "folder",
    "machine",
    "learning",
    "model",
    "sits",
    "background",
    "back",
    "end",
    "email",
    "server",
    "actually",
    "looks",
    "emails",
    "sees",
    "fat",
    "fits",
    "pattern",
    "seen",
    "spam",
    "assigns",
    "spam",
    "label",
    "known",
    "classification",
    "also",
    "used",
    "researchers",
    "especially",
    "legal",
    "industry",
    "lawyers",
    "oftentimes",
    "receive",
    "hundreds",
    "1000s",
    "documents",
    "millions",
    "documents",
    "necessarily",
    "human",
    "time",
    "go",
    "analyze",
    "every",
    "single",
    "document",
    "verbatim",
    "important",
    "kind",
    "get",
    "quick",
    "umbrella",
    "sense",
    "documents",
    "without",
    "actually",
    "go",
    "read",
    "page",
    "page",
    "lawyers",
    "oftentimes",
    "use",
    "nlp",
    "classification",
    "information",
    "extraction",
    "find",
    "keywords",
    "relevant",
    "case",
    "find",
    "documents",
    "classified",
    "according",
    "relevant",
    "fields",
    "case",
    "way",
    "take",
    "million",
    "documents",
    "reduce",
    "maybe",
    "handful",
    "maybe",
    "1000",
    "read",
    "verbatim",
    "real",
    "world",
    "application",
    "nlp",
    "natural",
    "language",
    "processing",
    "tasks",
    "achieved",
    "spacey",
    "framework",
    "spacey",
    "framework",
    "nlp",
    "right",
    "2021",
    "available",
    "believe",
    "python",
    "think",
    "community",
    "working",
    "application",
    "r",
    "know",
    "certain",
    "spacey",
    "one",
    "many",
    "nlp",
    "frameworks",
    "python",
    "available",
    "interested",
    "looking",
    "explore",
    "things",
    "like",
    "nlt",
    "kay",
    "natural",
    "language",
    "toolkit",
    "stanza",
    "believe",
    "coming",
    "program",
    "stanford",
    "many",
    "find",
    "spacey",
    "best",
    "couple",
    "different",
    "reasons",
    "reason",
    "one",
    "provide",
    "shelf",
    "models",
    "benchmark",
    "well",
    "meaning",
    "perform",
    "quickly",
    "also",
    "good",
    "accuracy",
    "metrics",
    "precision",
    "recall",
    "f",
    "score",
    "going",
    "talk",
    "much",
    "way",
    "measure",
    "machine",
    "learning",
    "accuracy",
    "right",
    "know",
    "quite",
    "good",
    "second",
    "spacey",
    "ability",
    "leverage",
    "current",
    "natural",
    "language",
    "processing",
    "methods",
    "specifically",
    "transformer",
    "models",
    "also",
    "known",
    "usually",
    "kind",
    "collectively",
    "bert",
    "models",
    "even",
    "though",
    "entirely",
    "accurate",
    "allows",
    "use",
    "shelf",
    "transformer",
    "model",
    "third",
    "provides",
    "framework",
    "custom",
    "training",
    "relatively",
    "easily",
    "compared",
    "nlp",
    "frameworks",
    "finally",
    "fourth",
    "reason",
    "picked",
    "spacey",
    "nlp",
    "frameworks",
    "scales",
    "well",
    "spacey",
    "designed",
    "explosion",
    "ai",
    "entire",
    "purpose",
    "spacey",
    "work",
    "scale",
    "ai",
    "scale",
    "mean",
    "working",
    "large",
    "quantities",
    "documents",
    "efficiently",
    "effectively",
    "accurately",
    "spacey",
    "scales",
    "well",
    "process",
    "hundreds",
    "1000s",
    "documents",
    "relative",
    "ease",
    "relatively",
    "short",
    "period",
    "time",
    "especially",
    "stick",
    "rules",
    "based",
    "pipes",
    "going",
    "talk",
    "part",
    "two",
    "video",
    "two",
    "things",
    "really",
    "need",
    "know",
    "nlp",
    "spacey",
    "general",
    "going",
    "talk",
    "spacey",
    "depth",
    "explore",
    "video",
    "free",
    "textbook",
    "provide",
    "go",
    "along",
    "video",
    "located",
    "spacey",
    "dot",
    "python",
    "linked",
    "description",
    "video",
    "textbook",
    "meant",
    "work",
    "tandem",
    "stuff",
    "cover",
    "video",
    "might",
    "necessarily",
    "textbook",
    "lend",
    "well",
    "text",
    "representation",
    "goes",
    "opposite",
    "stuff",
    "time",
    "cover",
    "verbatim",
    "video",
    "cover",
    "little",
    "bit",
    "depth",
    "video",
    "book",
    "think",
    "try",
    "use",
    "would",
    "recommend",
    "one",
    "pass",
    "whole",
    "video",
    "watch",
    "entirety",
    "get",
    "umbrella",
    "sense",
    "everything",
    "space",
    "everything",
    "going",
    "cover",
    "would",
    "go",
    "back",
    "try",
    "replicate",
    "stage",
    "process",
    "separate",
    "window",
    "separate",
    "screen",
    "try",
    "kind",
    "follow",
    "along",
    "code",
    "would",
    "go",
    "back",
    "third",
    "time",
    "try",
    "watch",
    "first",
    "part",
    "talk",
    "going",
    "try",
    "without",
    "looking",
    "textbook",
    "video",
    "third",
    "pass",
    "good",
    "shape",
    "start",
    "using",
    "spacey",
    "solve",
    "domain",
    "specific",
    "problems",
    "nlp",
    "complex",
    "field",
    "applying",
    "nlp",
    "really",
    "complex",
    "fortunately",
    "frameworks",
    "like",
    "spacey",
    "make",
    "project",
    "process",
    "lot",
    "easier",
    "encourage",
    "spend",
    "hours",
    "video",
    "get",
    "know",
    "spacey",
    "think",
    "going",
    "find",
    "things",
    "think",
    "possible",
    "relatively",
    "short",
    "order",
    "sit",
    "back",
    "relax",
    "enjoy",
    "video",
    "series",
    "spacey",
    "order",
    "use",
    "spacey",
    "first",
    "going",
    "install",
    "spacey",
    "different",
    "ways",
    "depending",
    "environment",
    "operating",
    "system",
    "recommend",
    "going",
    "backslash",
    "usage",
    "kind",
    "enter",
    "correct",
    "framework",
    "working",
    "using",
    "mac",
    "os",
    "versus",
    "windows",
    "versus",
    "linux",
    "go",
    "handy",
    "kind",
    "user",
    "interface",
    "go",
    "select",
    "different",
    "features",
    "matter",
    "working",
    "windows",
    "going",
    "using",
    "pip",
    "case",
    "going",
    "everything",
    "cpu",
    "going",
    "working",
    "english",
    "established",
    "different",
    "parameters",
    "goes",
    "tells",
    "exactly",
    "go",
    "install",
    "using",
    "pip",
    "terminal",
    "encourage",
    "go",
    "pause",
    "video",
    "right",
    "go",
    "ahead",
    "install",
    "windows",
    "however",
    "want",
    "going",
    "walking",
    "install",
    "within",
    "jupyter",
    "notebook",
    "going",
    "moving",
    "second",
    "want",
    "work",
    "gpu",
    "working",
    "spacey",
    "gpu",
    "requires",
    "lot",
    "understanding",
    "gpu",
    "used",
    "specifically",
    "training",
    "machine",
    "learning",
    "models",
    "requires",
    "cuda",
    "installed",
    "correctly",
    "requires",
    "couple",
    "things",
    "really",
    "time",
    "get",
    "video",
    "addressing",
    "advanced",
    "spacey",
    "tutorial",
    "video",
    "right",
    "recommend",
    "selecting",
    "selecting",
    "either",
    "use",
    "pip",
    "conda",
    "selecting",
    "cpu",
    "since",
    "going",
    "working",
    "video",
    "english",
    "texts",
    "encourage",
    "select",
    "english",
    "right",
    "go",
    "ahead",
    "install",
    "download",
    "n",
    "core",
    "web",
    "sm",
    "model",
    "small",
    "model",
    "talk",
    "second",
    "first",
    "thing",
    "going",
    "jupyter",
    "notebook",
    "going",
    "using",
    "exclamation",
    "mark",
    "delineate",
    "cell",
    "terminal",
    "command",
    "going",
    "say",
    "pip",
    "install",
    "spacey",
    "output",
    "execute",
    "cell",
    "going",
    "look",
    "little",
    "different",
    "mine",
    "already",
    "spacey",
    "installed",
    "environment",
    "mind",
    "kind",
    "goes",
    "looks",
    "like",
    "actually",
    "go",
    "instead",
    "saying",
    "requirement",
    "already",
    "satisfied",
    "actually",
    "passing",
    "different",
    "things",
    "actually",
    "installing",
    "install",
    "spacey",
    "dependencies",
    "next",
    "thing",
    "going",
    "going",
    "follow",
    "instructions",
    "going",
    "python",
    "dash",
    "space",
    "spacey",
    "space",
    "download",
    "model",
    "want",
    "download",
    "let",
    "go",
    "ahead",
    "right",
    "let",
    "go",
    "ahead",
    "say",
    "python",
    "spacing",
    "download",
    "spacey",
    "terminal",
    "command",
    "going",
    "download",
    "n",
    "core",
    "web",
    "sm",
    "already",
    "model",
    "downloaded",
    "end",
    "spacey",
    "going",
    "look",
    "little",
    "differently",
    "going",
    "look",
    "end",
    "prints",
    "jupyter",
    "notebook",
    "give",
    "second",
    "everything",
    "go",
    "says",
    "collected",
    "downloading",
    "happy",
    "got",
    "spacey",
    "installed",
    "correctly",
    "got",
    "small",
    "model",
    "downloaded",
    "correctly",
    "go",
    "ahead",
    "start",
    "actually",
    "using",
    "spacey",
    "make",
    "sure",
    "everything",
    "correct",
    "first",
    "thing",
    "going",
    "going",
    "import",
    "spacey",
    "library",
    "would",
    "python",
    "library",
    "familiar",
    "library",
    "simply",
    "set",
    "classes",
    "functions",
    "import",
    "python",
    "script",
    "write",
    "whole",
    "bunch",
    "extra",
    "code",
    "libraries",
    "massive",
    "collections",
    "classes",
    "functions",
    "call",
    "import",
    "spacey",
    "importing",
    "whole",
    "library",
    "spacey",
    "seen",
    "something",
    "like",
    "know",
    "spacey",
    "imported",
    "correctly",
    "long",
    "getting",
    "error",
    "message",
    "everything",
    "imported",
    "fine",
    "next",
    "thing",
    "need",
    "want",
    "make",
    "sure",
    "english",
    "core",
    "web",
    "sm",
    "small",
    "english",
    "model",
    "downloaded",
    "correctly",
    "next",
    "thing",
    "need",
    "need",
    "create",
    "nlp",
    "object",
    "going",
    "talking",
    "lot",
    "move",
    "forward",
    "right",
    "troubleshooting",
    "make",
    "sure",
    "installed",
    "spacey",
    "correctly",
    "downloaded",
    "model",
    "correctly",
    "going",
    "use",
    "spacey",
    "dot",
    "load",
    "command",
    "going",
    "take",
    "one",
    "argument",
    "going",
    "string",
    "going",
    "correspond",
    "model",
    "installed",
    "case",
    "n",
    "cor",
    "web",
    "execute",
    "cell",
    "errors",
    "successfully",
    "installed",
    "spacey",
    "correctly",
    "downloaded",
    "english",
    "core",
    "web",
    "sm",
    "model",
    "correctly",
    "go",
    "ahead",
    "take",
    "time",
    "get",
    "stuff",
    "set",
    "pause",
    "video",
    "need",
    "pop",
    "back",
    "going",
    "start",
    "actually",
    "working",
    "basics",
    "spacey",
    "going",
    "move",
    "kind",
    "overview",
    "kind",
    "within",
    "spacey",
    "useful",
    "kind",
    "basic",
    "features",
    "need",
    "familiar",
    "going",
    "working",
    "jupyter",
    "notebook",
    "talked",
    "introduction",
    "video",
    "scroll",
    "bottom",
    "chapter",
    "one",
    "basics",
    "spacey",
    "get",
    "past",
    "install",
    "section",
    "get",
    "section",
    "containers",
    "containers",
    "well",
    "containers",
    "within",
    "spacey",
    "objects",
    "contain",
    "large",
    "quantity",
    "data",
    "text",
    "several",
    "different",
    "containers",
    "work",
    "spacey",
    "doc",
    "doc",
    "ben",
    "example",
    "language",
    "lexeme",
    "span",
    "span",
    "group",
    "token",
    "going",
    "dealing",
    "lexeme",
    "little",
    "bit",
    "video",
    "series",
    "going",
    "dealing",
    "language",
    "container",
    "little",
    "bit",
    "video",
    "series",
    "really",
    "three",
    "big",
    "things",
    "going",
    "talking",
    "dock",
    "span",
    "token",
    "think",
    "first",
    "come",
    "spacey",
    "little",
    "bit",
    "learning",
    "curve",
    "things",
    "structured",
    "hierarchically",
    "reason",
    "created",
    "opinion",
    "kind",
    "easy",
    "understand",
    "image",
    "different",
    "containers",
    "think",
    "spacey",
    "pyramid",
    "hierarchical",
    "system",
    "got",
    "different",
    "containers",
    "structured",
    "around",
    "really",
    "dock",
    "object",
    "docker",
    "container",
    "dock",
    "object",
    "contains",
    "whole",
    "bunch",
    "metadata",
    "text",
    "pass",
    "spacey",
    "pipeline",
    "going",
    "see",
    "practice",
    "minutes",
    "doc",
    "object",
    "contains",
    "bunch",
    "different",
    "things",
    "contains",
    "attributes",
    "attributes",
    "things",
    "like",
    "like",
    "sentences",
    "iterate",
    "doc",
    "dot",
    "cents",
    "actually",
    "access",
    "different",
    "sentences",
    "found",
    "within",
    "doc",
    "object",
    "iterate",
    "individual",
    "item",
    "index",
    "doc",
    "object",
    "get",
    "individual",
    "tokens",
    "tokens",
    "going",
    "things",
    "like",
    "words",
    "punctuation",
    "marks",
    "something",
    "within",
    "sentence",
    "text",
    "self",
    "contained",
    "important",
    "value",
    "either",
    "syntactically",
    "semantically",
    "going",
    "things",
    "like",
    "words",
    "comma",
    "period",
    "semi",
    "colon",
    "quotation",
    "mark",
    "things",
    "like",
    "going",
    "tokens",
    "going",
    "see",
    "tokens",
    "little",
    "different",
    "splitting",
    "words",
    "traditional",
    "string",
    "methods",
    "python",
    "next",
    "thing",
    "kind",
    "familiar",
    "spans",
    "spans",
    "important",
    "kind",
    "exist",
    "within",
    "without",
    "doc",
    "object",
    "unlike",
    "token",
    "index",
    "doc",
    "object",
    "span",
    "token",
    "also",
    "sequence",
    "multiple",
    "tokens",
    "gon",
    "na",
    "see",
    "play",
    "imagine",
    "span",
    "category",
    "maybe",
    "group",
    "one",
    "places",
    "single",
    "token",
    "might",
    "like",
    "city",
    "like",
    "berlin",
    "span",
    "group",
    "two",
    "could",
    "something",
    "like",
    "full",
    "proper",
    "names",
    "people",
    "example",
    "could",
    "like",
    "going",
    "see",
    "martin",
    "luther",
    "king",
    "would",
    "sequence",
    "tokens",
    "sequence",
    "three",
    "different",
    "items",
    "sentence",
    "make",
    "one",
    "span",
    "one",
    "self",
    "contained",
    "item",
    "martin",
    "luther",
    "king",
    "would",
    "person",
    "collection",
    "sequence",
    "individual",
    "tokens",
    "make",
    "sense",
    "right",
    "image",
    "reinforced",
    "go",
    "learn",
    "spacey",
    "practice",
    "right",
    "want",
    "understanding",
    "doc",
    "object",
    "thing",
    "around",
    "spacey",
    "sits",
    "going",
    "object",
    "create",
    "going",
    "object",
    "contains",
    "metadata",
    "need",
    "access",
    "going",
    "object",
    "tried",
    "essentially",
    "improve",
    "different",
    "custom",
    "components",
    "factories",
    "pipelines",
    "go",
    "advanced",
    "things",
    "spacey",
    "going",
    "see",
    "seconds",
    "dock",
    "object",
    "kind",
    "similar",
    "text",
    "different",
    "much",
    "powerful",
    "going",
    "moving",
    "chapter",
    "two",
    "textbook",
    "going",
    "deal",
    "kind",
    "getting",
    "used",
    "depth",
    "features",
    "spacing",
    "want",
    "pause",
    "video",
    "keep",
    "notebook",
    "book",
    "open",
    "kind",
    "separate",
    "video",
    "follow",
    "along",
    "go",
    "explore",
    "live",
    "coding",
    "going",
    "talking",
    "different",
    "things",
    "explore",
    "chapter",
    "two",
    "lot",
    "longer",
    "chapter",
    "one",
    "going",
    "importing",
    "spacey",
    "actually",
    "going",
    "loading",
    "model",
    "creating",
    "dog",
    "object",
    "around",
    "model",
    "going",
    "work",
    "container",
    "practice",
    "going",
    "see",
    "container",
    "stores",
    "lot",
    "different",
    "features",
    "metadata",
    "attributes",
    "text",
    "look",
    "surface",
    "actually",
    "quite",
    "different",
    "let",
    "go",
    "ahead",
    "work",
    "within",
    "jupyter",
    "notebook",
    "imported",
    "spacey",
    "already",
    "created",
    "nlp",
    "object",
    "first",
    "thing",
    "want",
    "want",
    "open",
    "text",
    "start",
    "working",
    "within",
    "repo",
    "got",
    "data",
    "folder",
    "within",
    "data",
    "sub",
    "folder",
    "got",
    "couple",
    "different",
    "wikipedia",
    "openings",
    "got",
    "one",
    "mlk",
    "going",
    "using",
    "little",
    "later",
    "video",
    "one",
    "united",
    "states",
    "wiki",
    "underscore",
    "us",
    "going",
    "work",
    "right",
    "let",
    "use",
    "width",
    "operator",
    "open",
    "data",
    "backslash",
    "wiki",
    "underscore",
    "us",
    "dot",
    "txt",
    "gon",
    "na",
    "read",
    "going",
    "create",
    "text",
    "object",
    "going",
    "equal",
    "f",
    "dot",
    "read",
    "got",
    "text",
    "object",
    "created",
    "let",
    "go",
    "ahead",
    "see",
    "looks",
    "like",
    "let",
    "print",
    "text",
    "see",
    "standard",
    "wikipedia",
    "article",
    "kind",
    "follows",
    "introductory",
    "format",
    "four",
    "five",
    "paragraphs",
    "long",
    "lot",
    "features",
    "left",
    "brackets",
    "delineate",
    "kind",
    "footnote",
    "going",
    "worry",
    "much",
    "cleaning",
    "right",
    "interested",
    "cleaning",
    "data",
    "much",
    "starting",
    "work",
    "doc",
    "object",
    "spacey",
    "first",
    "thing",
    "want",
    "going",
    "want",
    "create",
    "doc",
    "object"
  ],
  "keywords": [
    "learn",
    "natural",
    "language",
    "processing",
    "apply",
    "problems",
    "using",
    "spacey",
    "library",
    "area",
    "video",
    "come",
    "nlp",
    "use",
    "needs",
    "going",
    "get",
    "next",
    "hours",
    "understanding",
    "also",
    "domain",
    "specific",
    "exist",
    "within",
    "time",
    "documents",
    "financial",
    "lot",
    "whole",
    "like",
    "easy",
    "really",
    "kind",
    "general",
    "shelf",
    "models",
    "already",
    "available",
    "walk",
    "part",
    "one",
    "series",
    "features",
    "two",
    "start",
    "rules",
    "based",
    "components",
    "actually",
    "entity",
    "complex",
    "custom",
    "three",
    "take",
    "information",
    "extraction",
    "things",
    "join",
    "good",
    "way",
    "let",
    "know",
    "interested",
    "second",
    "explore",
    "machine",
    "learning",
    "train",
    "training",
    "find",
    "much",
    "understand",
    "back",
    "python",
    "make",
    "specifically",
    "basics",
    "need",
    "texts",
    "text",
    "image",
    "classification",
    "think",
    "little",
    "bit",
    "talking",
    "process",
    "try",
    "computer",
    "system",
    "extract",
    "oftentimes",
    "raw",
    "couple",
    "different",
    "categorization",
    "known",
    "used",
    "first",
    "important",
    "relevant",
    "example",
    "gon",
    "na",
    "see",
    "might",
    "go",
    "maybe",
    "application",
    "data",
    "case",
    "structured",
    "metadata",
    "want",
    "framework",
    "talk",
    "work",
    "read",
    "well",
    "seen",
    "many",
    "spam",
    "reason",
    "folder",
    "model",
    "end",
    "looks",
    "verbatim",
    "sense",
    "without",
    "right",
    "working",
    "frameworks",
    "third",
    "relatively",
    "depth",
    "textbook",
    "along",
    "dot",
    "stuff",
    "cover",
    "goes",
    "would",
    "recommend",
    "pass",
    "everything",
    "space",
    "separate",
    "follow",
    "encourage",
    "install",
    "windows",
    "pip",
    "english",
    "terminal",
    "pause",
    "ahead",
    "jupyter",
    "notebook",
    "gpu",
    "requires",
    "installed",
    "correctly",
    "selecting",
    "download",
    "n",
    "core",
    "web",
    "sm",
    "small",
    "thing",
    "cell",
    "command",
    "look",
    "downloaded",
    "got",
    "sure",
    "import",
    "familiar",
    "bunch",
    "something",
    "imported",
    "create",
    "object",
    "chapter",
    "containers",
    "doc",
    "span",
    "group",
    "token",
    "container",
    "dock",
    "created",
    "around",
    "contains",
    "practice",
    "attributes",
    "individual",
    "tokens",
    "words",
    "sequence",
    "open"
  ]
}