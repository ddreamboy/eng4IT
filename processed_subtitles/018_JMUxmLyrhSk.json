{
  "text": "Hi everyone,\nthis is Zulaikha from Edureka,\nand I welcome you to this session\non Artificial Intelligence full course.\nIn this video, I'll be covering\nall the domains and the concepts\ninvolved under the umbrella\nof artificial intelligence,\nand I will also be showing\nyou a couple of use cases\nand practical implementations\nby using Python.\nSo there's a lot to cover in this session,\nand let me quickly run you\nthrough today's agenda.\nSo we're gonna begin the session\nby understanding the history\nof artificial intelligence\nand how it cam into existence.\nWe'll follow this by looking at\nwhy we're talking about\nartificial intelligence now,\nwhy has it gotten so famous right now.\nThen we'll look at what exactly\nis artificial intelligence.\nWe'll discuss the applications\nof artificial intelligence,\nafter which we'll discuss the basics of AI\nwhere in we'll understand\nthe different types of\nartificial intelligence.\nWe'll follow this by understanding\nthe different programming languages\nthat can be used to study AI.\nAnd we'll understand why\nwe're gonna choose Python.\nAlright, I'll introduce you to Python.\nAnd then we'll move on and\ndiscuss machine learning.\nHere we'll discuss the different\ntypes of machine learning,\nthe different algorithms\ninvolved in machine learning,\nwhich include classification algorithms,\nregression algorithms, clustering,\nand association algorithms.\nTo make you understand\nmachine learning better,\nwe'll run a couple of demos\nwherein we'll see how\nmachine learning algorithms\nare used to solve real world problems.\nAfter that, we'll discuss\nthe limitations of machine learning\nand why deep learning is needed.\nI'll introduce you to the\ndeep learning concept,\nwhat are neurons, perceptrons,\nmultiple layer perceptrons and so on.\nWe'll discuss the different\ntypes of neural networks,\nand we'll also look at what\nexactly back propagation is.\nApart from this, we'll be running a demo\nto understand deep learning in more depth.\nAnd finally we'll move\nonto the next module,\nwhich is natural language processing.\nOn the natural language processing,\nwe'll try to understand\nwhat is text mining,\nthe difference between text mining in NLP,\nwhat are the different\nterminologies in NLP,\nand we'll end the session by looking at\nthe practical implementation\nof NLP using Python, alright.\nSo guys, there's a lot to\ncover in today's session.\nAlso, if you want to stay updated\nabout the recent technologies,\nand would like to learn more\nabout the training technology,\nmake sure you subscribe\nto our YouTube channel\nto never miss out on such sessions.\nSo let's move ahead and take\na look at our first topic\nwhich is history of\nartificial intelligence.\nSo guys, the concept of\nartificial intelligence\ngoes back to the classical ages.\nUnder Greek mythology,\nthe concept of machines and mechanical men\nwere well thought of.\nSo, an example of this is Talos.\nI don't know how many of\nyou have heard of this.\nTalos was a giant animated bronze warrior\nwho was programmed to\nguard the island of Crete.\nNow these are just ideas.\nNobody knows if this was\nactually implemented,\nbut machine learning and AI\nwere thought of long ago.\nNow let's get back to the 19th century.\nNow 1950 was speculated to be\none of the most important years\nfor the introduction of\nartificial intelligence.\nIn 1950, Alan Turing published a paper\nin which he speculated\nabout the possibility\nof creating machines that think.\nSo he created what is\nknown as the Turing test.\nThis test is basically used to determine\nwhether or not a computer\ncan think intelligently\nlike a human being.\nHe noted that thinking\nis difficult to define\nand devised his famous Turing test.\nSo, basically, if a machine\ncan carry out a conversation\nthat was indistinguishable\nfrom a conversation with a human being,\nit was reasonable to say\nthat the machine is thinking,\nmeaning that the machine\nwill pass the Turing test.\nNow, unfortunately, up to this date,\nwe haven't found a machine\nthat has fully cleared\nthe Turing test.\nSo, the Turing test was actually\nthe first serious proposal\nin the philosophy of\nartificial intelligence.\nFollowed by this was the era of 1951.\nThis was also known as the game AI.\nSo in 1951, by using the\nFerranti Mark 1 machine\nof the University of Manchester,\na computer scientist known\nas Christopher Strachey\nwrote a checkers program.\nAnd at the same time,\na program was written for chess as well.\nNow, these programs were\nlater improved and redone,\nbut this was the first attempt\nat creating programs that could play chess\nor that would compete with\nhumans in playing chess.\nThis is followed by the year 1956.\nNow, this is probably\nthe most important year\nin the invention of AI.\nBecause in 1956, for the firs time,\nthe term artificial\nintelligence was coined.\nAlright.\nSo the term artificial intelligence\nwas coined by John McCarthy\nat the Dartmouth Conference in 1956.\nComing to the year 1959,\nthe first AI laboratory was established.\nThis period marked the\nresearch era for AI.\nSo the first AI lab where\nresearch was performed\nis the MIT lab,\nwhich is still running til date.\nIn 1960, the first robot was introduced\nto the General Motors assembly line.\nIn 1961, the first chatbot was invented.\nNow we have Siri, we have Alexa.\nBut in 1961,\nthere was a chatbot known as Eliza,\nwhich was introduced.\nThis is followed by the\nfamous IBM Deep Blue.\nIn 1997, the news broke down\nthat IBM's Deep Blue\nbeats the world champion,\nGarry Kasparov, in the game of chess.\nSo this was kind of the\nfirst accomplishment of AI.\nIt was able to beat the\nworld champion at chess.\nSo in 2005, when the DARPA\nGrand Challenge was held,\na robotic car named Stanley,\nwhich was built by Stanford's racing team,\nwon the DARPA Grand Challenge.\nThat was another big accomplish of AI.\nIn 2011, IBM's question\nanswering system, Watson,\ndefeated the two greatest\nJeopardy champions,\nBrad Rutter and Ken Jennings.\nSo guys, this was how AI evolved.\nIt started off as a\nhypothetical situation.\nRight now it's the most\nimportant technology\nin today's world.\nIf you look around every where,\neverything around us is run\nthrough AI deep learning\nor machine learning.\nSo since the emergence of AI in the 1950s,\nwe have actually seen\nan exponential growth\nand its potential.\nSo AI covers domains\nsuch as machine learning,\ndeep learning, neural networks,\nnatural language processing,\nknowledge based, expert systems and so on.\nIt is also made its way\ninto computer vision\nand image processing.\nNow the question here\nis if AI has been here\nfor over half a century,\nwhy has it suddenly\ngain so much importance?\nWhy are we talking about\nartificial intelligence now?\nLet me tell you the main\nreasons for the demand of AI.\nThe first reason is what we have\nmore computation power now.\nSo, artificial intelligence requires\na lot of computing power.\nRecently, many advances have been made\nand complex deep learning\nmodels are deployed.\nAnd one of the greatest technology\nthat made this possible are GPUs.\nSince we have more\ncomputational power now,\nit is possible for us to implement AI\nin our daily aspects.\nSecond most important reason is that\nwe have a lot of data at present.\nWe're generating data\nat an immeasurable pace.\nWe are generating data\nthrough social media,\nthrough IoT devices.\nEvery possible way, there's a lot of data.\nSo we need to find a method or a solution\nthat can help us process this much data,\nand help us derive useful insight,\nso that we can grow business\nwith the help of data.\nAlright, so, that process\nis basically artificial intelligence.\nSo, in order to have a useful AI agent\nto make smart decisions\nlike telling which item to recommend\nnext when you shop online,\nor how to classify an\nobject from an image.\nAI are trained on large data sets,\nand big data enables us to\ndo this more efficiently.\nNext reason is now we\nhave better algorithms.\nRight now we have very\neffective algorithms\nwhich are based on the\nidea of neural networks.\nNeural networks is nothing but\nthe concept behind deep learning.\nSince we have better algorithms\nwhich can do better computations\nand quicker computations\nwith more accuracy,\nthe demand for AI has increased.\nAnother reason is that\nuniversities, governments,\nstartup, and tech giants\nare all investing in AI.\nOkay, so companies like Google, Amazon,\nFacebook, Microsoft,\nall of these companies\nhave heavily invested\nin artificial intelligence\nbecause they believe\nthat AI is the future.\nSo AI is rapidly growing\nboth as a field of study\nand also as an economy.\nSo, actually, this is the right time\nfor you to understand what\nis AI and how it works.\nSo let's move on and understand\nwhat exactly artificial intelligence is.\nThe term artificial intelligence\nwas first coined in the\nyear 1956 by John McCarthy\nat the Dartmouth Conference.\nI already mentioned this before.\nIt was the birth of AI in the 1956.\nNow, how did he define\nartificial intelligence?\nJohn McCarthy defined AI as\nthe science and engineering\nof making intelligent machines.\nIn other words, artificial intelligence\nis the theory and development\nof computer systems\nable to perform task\nthat normally require human intelligence,\nsuch as visual perception,\nspeech recognition,\ndecision making, and\ntranslation between languages.\nSo guys, in a sense, AI is a\ntechnique of getting machines\nto work and behave like humans.\nIn the rest past, artificial intelligence\nhas been able to accomplish this\nby creating machines and robots\nthat have been used in\nwide range of fields,\nincluding healthcare, robotics, marketing,\nbusiness analytics, and many more.\nWith this in mind,\nlet's discuss a couple of\nreal world application of AI,\nso that you understand how\nimportant artificial intelligence\nis in today's world.\nNow, one of the most famous applications\nof artificial intelligence\nis the Google predictive search engine.\nWhen you begin typing a search term\nand Google makes recommendations\nfor you to choose from,\nthat is artificial intelligence in action.\nSo predictive searches are based on data\nthat Google collects about you,\nsuch as your browser\nhistory, your location,\nyour age, and other personal details.\nSo by using artificial intelligence,\nGoogle attempts to guess what\nyou might be trying to find.\nNow behind this,\nthere's a lot of natural\nlanguage processing,\ndeep learning, and\nmachine learning involved.\nWe'll be discussing all of those concepts\nin the further slides.\nIt's not very simple to\ncreate a search engine,\nbut the logic behind Google search engine\nis artificial intelligence.\nMoving on, in the finance sector,\nJP Morgan Chase's Contract\nIntelligence Platform\nuses machine learning,\nartificial intelligence,\nand image recognition software\nto analyze legal documents.\nNow let me tell you\nthat manually reviewing\naround 12,000 agreements\ntook over 36,000 hours.\nThat's a lot of time.\nBut as soon as this task\nwas replaced by AI machine,\nit was able to do this\nin a matter of seconds.\nSo that's the difference\nbetween artificial intelligence\nand manual or human work.\nEven though AI cannot think\nand reason like humans,\nbut their computational\npower is very strong\ncompared to humans,\nbecause the machine learning algorithm,\ndeep learning concepts, and\nnatural language processing,\nAI has reach a stage\nwherein it can compute\nthe most complex of complex problems\nin a matter of seconds.\nComing to healthcare, IBM\nis one of the pioneers\nthat has developed AI software,\nspecifically for medicine.\nLet me tell you that more than\n230 healthcare organizations\nuse IBM AI technology,\nwhich is basically IBM Watson.\nIn 2016, IBM Watson technology\nwas able to cross reference\n20 million oncology records quickly\nand correctly diagnose a rare leukemia\ncondition in a patient.\nSo, it basically went\nthrough 20 million records,\nwhich it probably did in a\nmatter of second or minutes,\nmax to max.\nAnd then it correctly diagnosed a patient\nwith a rare leukemia.\nKnowing that machines are now used\nin medical fields as well,\nit shows how important AI has become.\nIt has reached every domains of our lives.\nLet me give you another example.\nThe Google's AI Eye Doctor\nis another initiative,\nwhich is taken by Google,\nwhere they're working with\nan Indian eye care chain\nto develop artificial intelligence system\nwhich can examine retinal scans\nand identify a condition called\ndiabetic retinopathy\nwhich can cause blindness.\nNow in social media\nplatforms like Facebook,\nartificial intelligence is\nused for face verification\nwherein you make use of machine learning\nand deep learning concept\nin order to detect facial\nfeatures and tag your friends.\nAll the auto tagging feature\nthat you see in Facebook,\nbehind that there's machine learning,\ndeep learning, neural networks.\nThere's only AI behind it.\nSo we're actually unaware\nthat we use AI very regularly in our life.\nAll the social media platforms\nlike Instagram, Facebook, Twitter,\nthey heavily rely on\nartificial intelligence.\nAnother such example is Twitter's AI\nwhich is being used to identify\nany sort of hate speech\nand terroristic languages in tweets.\nSo again, it makes use of machine leaning,\ndeep learning, natural language processing\nin order to filter out any offensive\nor any reportable content.\nNow recently, the company discovered\naround 300,000 terroristic link accounts\nand 95% of these were found by non-human\nartificially intelligent machines.\nComing to virtual assistants,\nwe have virtual assistants\nlike Siri and Alexa right now.\nLet me tell you about\nanother newly released\nGoogle's virtual assistant\ncalled the Google Duplex,\nwhich has astonished millions\nof people around the world.\nNot only can it respond to calls\nand book appointments for you,\nit also adds a human touch.\nSo it adds human filters and all of that.\nIt makes it sound very realistic.\nIt's actually very hard\nto distinguish between\nhuman and the AI speaking over the phone.\nAnother famous application\nis AI is self-driving cars.\nSo, artificial intelligence\nimplements computer vision,\nimage detection, deep learning,\nin order to build cars\nthat can automatically detect\nany objects or any obstacles\nand drive around without\nhuman intervention.\nSo these are fully\nautomated self-driving cars.\nAlso, Elon Musk talks a lot\nabout how AI is implemented\nin Tesla's self-driving cars.\nHe quoted that Tesla will\nhave fully self-driving cars\nready by the end of the year,\nand robo taxi version\nthat can ferry passengers\nwithout anyone behind the wheel.\nSo if you look at it, AI is actually used\nby the tech giants.\nA lot of tech giant companies\nlike Google, Tesla, Facebook,\nall of these data-driven companies.\nIn fact, Netflix also makes use of AI,.\nSo, coming to Netflix.\nSo with the help of\nartificial intelligence\nand machine learning,\nNetflix has developed a\npersonalized movie recommendation\nfor each of its users.\nSo if each of you opened up Netflix\nand if you look at the type of movies\nthat are recommended to\nyou, they are different.\nThis is because Netflix studies\neach user's personal details,\nand tries to understand what\neach user is interested in\nand what sort of movie\npatterns each user has,\nand then it recommends movies to them.\nSo Netflix uses the watching\nhistory of other users\nwith similar taste to recommend\nwhat you may be most\ninterested in watching next,\nso that you can stay engaged\nand continue your monthly subscription.\nAlso, there's a known fact\nthat over 75% of what you watch\nis recommended by Netflix.\nSo their recommendation\nengine is brilliant.\nAnd the logic behind their\nrecommendation engine\nis machine learning and\nartificial intelligence.\nApart from Netflix, Gmail also\nuses AI on a everyday basis.\nIf you open up your inbox right now,\nyou will notice that there\nare separate sections.\nFor example, we have primary section,\nsocial section, and all of that.\nGmail has a separate section\ncalled the spam mails also.\nSo, what Gmail does is it makes use of\nconcepts of artificial intelligence\nand machine learning algorithms\nto classify emails as spam and non-spam.\nMany times certain words or phrases\nare frequently used in spam emails.\nIf notice your spam emails,\nthey have words like\nlottery, earn, full refund.\nAll of this denotes that the email\nis more likely to be a spam one.\nSo such words and\ncorrelations are understood\nby using machine learning and\nnatural language processing\nand a few other aspects of\nartificial intelligence.\nSo, guys, these were\nthe common applications\nof artificial intelligence.\nNow let's discuss the\ndifferent types of AI.\nSo, AI is divided into three\ndifferent evolutionary stages,\nor you can say that there are three stages\nof artificial intelligence.\nOf course, we have artificial\nnarrow intelligence\nfollowed by artificial\ngeneral intelligence,\nand that is followed by\nartificial super intelligence.\nArtificial narrow intelligence,\nwhich is also known as weak AI,\nit involves applying\nartificial intelligence\nonly to specific task.\nSo, many currently existing systems\nthat claim to use artificial intelligence\nare actually operating as weak AI\nfocused on a narrowly\ndefined specific problem\nLet me give you an example\nof artificial narrow intelligence.\nAlexa is a very good example of weak AI.\nIt operates within unlimited\npre-defined range of functions.\nThere's no genuine intelligence\nor there is no self awareness,\ndespite being a sophisticated\nexample of weak AI.\nThe Google search engine,\nSophia the humanoid,\nself-driving cars, and\neven the famous AlphaGo\nfall under the category of weak AI.\nSo guys, right now we're at the stage\nof artificial narrow\nintelligence or weak AI.\nWe actually haven't reached\nartificial general intelligence\nor artificial super intelligence,\nbut let's look at what\nexactly it would be like\nif we reach artificial\ngeneral intelligence.\nNow artificial general intelligence\nwhich is also known as strong AI,\nit involves machines\nthat posses the ability\nto perform any intelligent\ntask that a human being can.\nNow this is actually something\nthat a lot of people don't realize.\nMachines don't posses\nhuman-like abilities.\nThey have a very strong processing unit\nthat can perform high-level computations,\nbut they're not yet\ncapable of doing the simple\nand the most reasonable\nthings that a human being can.\nIf you tell a machine to process\nlike a million documents,\nit'll probably do that in\na matter of 10 seconds,\nor a minute, or even 10 minutes.\nBut if you ask a machine to\nwalk up to your living room\nand switch on the TV,\na machine will take forever to learn that,\nbecause machines don't have\nthe reasonable way of thinking.\nThey have a very strong processing unit,\nbut they're not yet capable\nof thinking and reasoning\nlike a human being.\nSo that's exactly why we're still stuck\non artificial narrow intelligence.\nSo far we haven't developed any machine\nthat can fully be called strong AI,\neven though there are\nexamples of AlphaGo Zero\nwhich defeated AlphaGo in the game of Go.\nAlphaGo Zero basically learned\nin a span of four months.\nIt learned on its own without\nany human intervention.\nBut even then, it was not classified\nas a fully strong artificial intelligence,\nbecause it cannot reason\nlike a human being.\nMoving onto artificial super intelligence.\nNow this is a term referring to the time\nwhen the capabilities of a computer\nwill surpass that of a human being.\nIn all actuality, I'll take a while for us\nto achieve artificial super intelligence.\nPresently, it's seen as\na hypothetical situation\nas depicted in movies and\nany science fiction books\nwherein machines have\ntaken over the world,\nmovies like Terminator and all of that\ndepict artificial super intelligence.\nThese don't exist yet,\nwhich we should be thankful for,\nbut there are a lot of people\nwho speculate that\nartificial super intelligence\nwill take over the world by the year 2040.\nSo guys, these were the different types\nor different stages of\nartificial intelligence.\nTo summarize everything,\nlike I said before,\nnarrow intelligence is the\nonly thing that exist for now.\nWe have only weak AI or weak\nartificial intelligence.\nAll the major AI technologies that you see\nare artificial narrow intelligence.\nWe don't have any machines\nwhich are capable of thinking\nlike human beings or\nreasoning like a human being.\nNow let's move on and discuss\nthe different programming language for AI.\nSo there are actually N number of language\nthat can be used for\nartificial intelligence.\nI'm gonna mention a few of them.\nSo, first, we have Python.\nPython is probably the\nmost famous language\nfor artificial intelligence.\nIt's also known as the most\neffective language for AI,\nbecause a lot of developers\nprefer to use Python.\nAnd a lot of scientists\nare also comfortable\nwith the Python language.\nThis is partly because the syntaxes\nwhich belong to Python are very simple\nand they can be learned very easily.\nIt's considered to be one of the most\neasiest language to learn.\nAnd also many other AI algorithms\nand machine learning algorithms\ncan be easily implemented in Python,\nbecause there are a lot of libraries\nwhich are predefined functions\nfor these algorithms.\nSo all you have to do is you\nhave to call that function.\nYou don't actually have\nto call your algorithm.\nSo, Python is considered the best choice\nfor artificial intelligence.\nWith Python stands R,\nwhich is a statistical\nprogramming language.\nNow R is one of the\nmost effective language\nand environment for analyzing\nand manipulating the data\nfor statistical purpose.\nIt is a statistical programming language.\nSo using R we can easily produce\nwell designed publication quality plots,\nincluding mathematical symbol\nand formula, wherever needed.\nIf you ask me, I think\nR is also one of the\neasiest programming language to learn.\nThe syntax is very similar\nto English language,\nand it also has N number of libraries\nthat support statistics, data science,\nAI, machine learning, and so on.\nIt also has predefined functions\nfor machine learning algorithms,\nnatural language processing, and so on.\nSo R is also a very good choice\nif you want to get started\nwith programming languages\nfor machine learning or AI.\nApart from this, we have Java.\nNow Java can also be\nconsidered as a good choice\nfor AI development.\nArtificial intelligence has a lot to do\nwith search algorithms,\nartificial neural networks,\nand genetic programming,\nand Java provides many benefits.\nIt's easy to use.\nDebugging is very easy, package services.\nThere is simplified work\nwith large scale projects.\nThere's a good user interaction,\nand graphical representation of data.\nIt has something known as\nthe standard widget toolkit,\nwhich can be used for making\ngraphs and interfaces.\nSo, graphic virtualization is actually\na very important part of AI,\nor data science, or machine\nlearning for that matter.\nLet me list out a few more languages.\nWe also have something known as Lisp.\nNow shockingly, a lot\nof people have not heard\nof this language.\nThis is actually the oldest\nand the most suited language\nfor the development of\nartificial intelligence.\nIt is considered to be a language\nwhich is very suited for the development\nof artificial intelligence.\nNow let me tell you that this language\nwas invented by John McCarthy\nwho's also known as the father\nof artificial intelligence.\nHe was the person who coined the term\nartificial intelligence.\nIt has the capability of\nprocessing symbolic information.\nIt has excellent prototyping capabilities.\nIt is easy,\nand it creates dynamic\nobjects with a lot of ease.\nThere's automatic garbage\ncollection in all of that.\nBut over the years,\nbecause of advancements,\nmany of these features\nhave migrated into many other languages.\nAnd that's why a lot of\npeople don't go for Lisp.\nThere are a lot of new languages\nwhich have more effective features\nor which have better packages you can see.\nAnother language I like\nto talk about is Prolog.\nProlog is frequently\nused in knowledge base\nand expert systems.\nThe features provided by Prolog\ninclude pattern matching,\nfreebase data structuring,\nautomatic back tracking and so on.\nAll of these features provide\na very powerful and flexible\nprogramming framework.\nProlog is actually widely\nused in medical projects\nand also for designing expert AI systems.\nApart from this, we also have C++,\nwe have SaaS, we have JavaScript\nwhich can also be used for AI.\nWe have MATLAB, we have Julia.\nAll of these languages\nare actually considered\npretty good languages for\nartificial intelligence.\nBut for now, if you ask me\nwhich programming\nlanguage should I go for,\nI would say Python.\nPython has all the possible packages,\nand it is very easy to\nunderstand and easy to learn.\nSo let's look at a couple\nof features of Python.\nWe can see why we should go for Python.\nFirst of all, Python was created\nin the year 1989.\nIt is actually a very\neasy programming language.\nThat's one of the reasons why\na lot of people prefer Python.\nIt's very easy to understand.\nIt's very easy to grasp this language.\nSo Python is an interpreted,\nobject-oriented,\nhigh-level programming language,\nand it can be very easily implemented.\nNow let me tell you a\nfew features of Python.\nIt's very simple and easy to learn.\nLike I mentioned,\nit is one of the easiest\nprogramming language,\nand it also free and open source.\nApart from that, it is\na high-level language.\nYou don't have to worry about\nanything like memory allocation.\nIt is portable,\nmeaning that you can\nuse it on any platform\nlike Linux, Windows,\nMacintosh, Solaris, and so on.\nIt support different programming paradigms\nlike object-oriented and\nprocedure oriented programming,\nand it is extensible,\nmeaning that it can invoke\nC and C++ libraries.\nApart from this, let\nme tell you that Python\nis actually gaining unbelievable\nhuge momentum in AI.\nThe language is used to develop\ndata science algorithms,\nmachine learning algorithms,\nand IoT projects.\nThe other advantages to Python also,\nthe fact that you don't have to code much\nwhen it comes to Python\nfor AI or machine learning.\nThis is because there\nare ready-made packages.\nThere are predefined packages\nthat have all the function\nand algorithm stored.\nFor example, there is\nsomething known as PiBrain,\nwhich can be used for machine learning,\nNumPy which can be used\nfor scientific computation,\nPandas and so on.\nThere are N number of libraries in Python.\nSo guys, I'm now going to\ngo into depth of Python.\nI'm now going to explain Python to you,\nsince this session is about\nartificial intelligence.\nSo, those of you who don't\nknow much about Python\nor who are new to Python,\nI will leave a couple of\nlinks in the description box.\nYou all can get started with programming\nand any other concepts or any other doubts\nthat you have on Python.\nWe have a lot of content\naround programming with Python\nor Python for machine learning and so on.\nNow let's move on and talk about\none of the most important aspects\nof artificial intelligence,\nwhich is machine learning.\nNow a lot of people always\nask me this question.\nIs machine learning and\nartificial intelligence\nthe same thing?\nWell, both of them are not the same thing.\nThe difference between\nAI and machine learning\nis that machine learning is\nused in artificial intelligence.\nMachine learning is a method\nthrough which you can feed\na lot of data to a machine\nand make it learn.\nNow AI is a vast of field.\nUnder AI, we have machine\nlearning, we have NLP,\nwe have expert systems,\nwe have image recognition,\nobject detection, and so on.\nWe have deep learning also.\nSo, AI is sort of a process\nor it's a methodology\nin which you make machines\nmimic the behavior of human beings.\nMachine learning is a way\nin which you feed a lot\nof data to a machine,\nso that it can make it's own decisions.\nLet's get into depth\nabout machine learning.\nSo first, we'll understand\nthe need for machine learning\nor why machine learning\ncame into existence.\nNow the need for machine learning\nbegins since the technical\nrevolution itself.\nSo, guys, since technology\nbecame the center of everything,\nwe've been generating an\nimmeasurable amount of data.\nAs per research, we generate around\n2.5 quintillion bytes of\ndata every single data\nevery single day.\nAnd it is estimated\nthat by this year, 2020,\n1.7 mb of data will be\ncreated every second\nfor every person on earth.\nSo as I'm speaking to you right now,\nI'm generating a lot of data.\nNow your watching this video on YouTube\nalso accounts for data generation.\nSo there's data everywhere.\nSo with the availability of so much data,\nit is finally possible to\nbuild predictive models\nthat can study and analyze complex data\nto find useful insights and\ndeliver more accurate results.\nSo, top tier companies\nlike Netflix and Amazon\nbuild such machine learning models\nby using tons of data\nin order to identify any\nprofitable opportunity\nand avoid any unwanted risk.\nSo guys, one thing you\nall need to know is that\nthe most important thing\nfor artificial intelligence\nis data.\nFor artificial intelligence\nor whether it's machine\nlearning or deep learning,\nit's always data.\nAnd now that we have a lot of data,\nwe can find a way to analyze, process,\nand draw useful insights from this data\nin order to help us grow businesses\nor to find solutions to some problems.\nData is the solution.\nWe just need to know\nhow to handle the data.\nAnd the way to handle data\nis through machine\nlearning, deep learning,\nand artificial intelligence.\nA few reasons why machine\nlearning is so important\nis, number one, due to\nincrease in data generation.\nSo due to excessive production of data,\nwe need to find a method that can be used\nto structure, analyze, and\ndraw useful insights from data,\nthis is where machine learning comes in.\nIt is used to solve\nproblems and find solutions\nthrough the most complex\ntask faced by organizations.\nApart form this, we also needed\nto improve decision making.\nSo by making use of various algorithms,\nmachine learning can be used to make\nbetter business decisions.\nFor example, machine learning\nis used to focus sales.\nIt is used to predict any\ndownfalls n the stock market\nor identify any sort\nof risk and anomalies.\nOther reasons include that\nmachine learning helps us\nuncover patterns and trends in data.\nSo finding hidden patterns\nand extracting key insights fro data\nis the most important\npart of machine learning.\nSo by building predictive models\nand using statistical techniques,\nmachine learning allows you\nto dig beneath the surface\nand explode the data at a minute scale.\nUnderstanding data and\nextracting patterns manually\ntakes a lot of time.\nIt'll take several days for us\nto extract any useful\ninformation from data.\nBut if you use machine\nlearning algorithms,\nyou can perform similar\ncomputations in less than a second.\nAnother reason is we need\nto solve complex problems.\nSo from detecting the genes\nlinked to the deadly ALS disease,\nto building self-driving cars,\nmachine learning can be used\nto solve the most complex problems.\nAt present, we also\nfound a way to spot stars\nwhich are 2,400 light\nyears away from our planet.\nOkay, all of this is possible through AI,\nmachine learning, deep\nlearning, and these techniques.\nSo to sum it up,\nmachine learning is very\nimportant at present\nbecause we're facing a\nlot of issues with data.\nWe're generating a lot of data,\nand we have to handle this data\nin such a way that in benefits us.\nSo that's why machine learning comes in.\nMoving on, what exactly\nis machine learning?\nSo let me give you a short\nhistory of machine learning.\nSo machine learning was\nfirst coined by Arthur Samuel\nin the year 1959,\nwhich is just three years from\nwhen artificial intelligence was coined.\nSo, looking back, that year was probably\nthe most significant in terms\nof technological advancement,\nbecause most of the technologies today\nare based on the concept\nof machine learning.\nMost of the AI technologies itself\nare based on the concept of\nmachine learning and deep learning.\nDon't get confused about\nmachine learning and deep learning.\nWe'll discuss about deep\nlearning in the further slides,\nwhere we'll also see the difference\nbetween AI, machine\nlearning, and deep learning.\nSo coming back to what\nexactly machine learning is,\nif we browse through the internet,\nyou'll find a lot of definitions about\nwhat exactly machine learning is.\nOne of the definitions I found was\na computer program is said\nto learn from experience E\nwith respect to some class of task T\nand performance measure P if\nits performance at task in T,\nas measured by P, improves\nwith experience E.\nThat's very confusing, so let\nme just narrow it down to you.\nIn simple terms, machine\nlearning is a subset\nof artificial intelligence\nwhich provides machines the ability\nto learn automatically and\nimprove with experience\nwithout being explicitly\nprogrammed to do so.\nIn the sense, it is the practice\nof getting machines to solve problems\nby gaining the ability to think.\nBut now you might be thinking\nhow can a machine think or make decisions.\nNow machines are very similar to humans.\nOkay, if you feed a machine\na good amount of data,\nit will learn how to interpret, process,\nand analyze this data by using\nmachine learning algorithms,\nand it will help you solve world problems.\nSo what happens here is a lot of data\nis fed to the machine.\nThe machine will train on this data\nand it'll build a predictive model\nwith the help of machine\nlearning algorithms\nin order to predict some outcome\nor in order to find some\nsolution to a problem.\nSo it involves data.\nYou're gonna train the machine\nand build a model by using\nmachine learning algorithms\nin order to predict some outcome\nor to find a solution to a problem.\nSo that is a simple way of understanding\nwhat exactly machine learning is.\nI'll be going into more\ndepth about machine learning,\nso don't worry if you have\nunderstood anything as of now.\nNow let's discuss a couple terms\nwhich are frequently\nused in machine learning.\nSo, the first definition that\nwe come across very often\nis an algorithm.\nSo, basically, a machine\nlearning algorithm\nis a set of rules and\nstatistical techniques\nthat is used to learn patterns from data\nand draw significant information from it.\nOkay.\nSo, guys, the logic behind\na machine learning model\nis basically the machine\nlearning algorithm.\nOkay, an example of a\nmachine learning algorithm\nis linear regression, or decision\ntree, or a random forest.\nAll of these are machine\nlearning algorithms.\nWe'll define the logic behind\na machine learning model.\nNow what is a machine learning model?\nA model is actually the main component\nof a machine learning process.\nOkay, so a model is trained by using\nthe machine learning algorithm.\nThe difference between an\nalgorithm and a model is that\nan algorithm maps all the decisions\nthat a model is supposed to take\nbased on the given input\nin order to get the correct output.\nSo the model will use\nthe machine learning algorithm\nin order to draw useful\ninsights from the input\nand give you an outcome\nthat is very precise.\nThat's the machine learning model.\nThe next definition we\nhave is predictor variable.\nNow a predictor variable\nis any feature of the data\nthat can be used to predict the output.\nOkay, let me give you an example\nto make you understand what\na predictor variable is.\nLet's say you're trying to\npredict the height of a person,\ndepending on his weight.\nSo here your predictor\nvariable becomes your weight,\nbecause you're using\nthe weight of a person\nto predict the person's height.\nSo your predictor variable\nbecomes your weight.\nThe next definition is response variable.\nNow in the same example,\nheight would be the response variable.\nResponse variable is also known as\nthe target variable or\nthe output variable.\nThis is the variable that\nyou're trying to predict\nby using the predictor variables.\nSo a response variable is the feature\nor the output variable\nthat needs to be predicted\nby using the predictor variables.\nNext, we have something\nknown as training data.\nNow training and testing\ndata are terminologies\nthat you'll come across very often\nin a machine learning process.\nSo training data is basically\nthe data that I used\nto create the machine learning model.\nSo, basically in a\nmachine learning process,\nwhen you feed data into the machine,\nit'll be divided into two parts.\nSo splitting the data into two parts\nis also known as data splicing.\nSo you'll take your input data,\nyou'll divide it into two sections.\nOne you'll call the training data,\nand the other you'll\ncall the testing data.\nSo then you have something\nknown as the testing data.\nThe training data is basically used\nto create the machine learning model.\nThe training data helps\nthe model to identify\nkey trends and patterns\nwhich are essential to predict the output.\nNow the testing data is,\nafter the model is trained,\nit must be tested in order\nto evaluate how accurately\nit can predict an outcome.\nNow this is done by\nusing the testing data.\nSo, basically, the training\ndata is used to train the model.\nThe testing data is used to test\nthe efficiency of the model.\nNow let's move on and get our next topic,\nwhich is machine learning process.\nSo what is the machine learning process?\nNow the machine learning process\ninvolves building a predictive model\nthat can be used to find a solution\nfor a problem statement.\nNow in order to solve any\nproblem in machine learning,\nthere are a couple of steps\nthat you need to follow.\nLet's look at the steps.\nThe first step is you define\nthe objective of your problem.\nAnd the second step is data gathering,\nwhich is followed by preparing your data,\ndata exploration, building a model,\nmodel evaluation, and\nfinally making predictions.\nNow, in order to understand\nthe machine learning process,\nlet's assume that you've\nbeen given a problem\nthat needs to be solved\nby using machine learning.\nSo the problem that you need to solve is\nwe need to predict the occurrence of rain\nin your local area by\nusing machine learning.\nSo, basically, you need to predict\nthe possibility of rain by\nstudying the weather conditions.\nSo what we did here is we\nbasically looked at step number one,\nwhich is define the\nobjective of the problem.\nNow here you need to\nanswer questions such as\nwhat are we trying to predict.\nIs that output going to\nbe a continuous variable,\nor is it going to be a discreet variable?\nThese are the kinds of questions\nthat you need to answer\nin the first page,\nwhich is defining the objective\nof the problem, right?\nSo yeah, exactly what\nare the target feature.\nSo here you need to understand\nwhich is your target variable\nand what are the different\npredictor variables\nthat you need in order\nto predict this outcome.\nSo here our target\nvariable will be basically\na variable that can tell us\nwhether it's going to rain or not.\nInput data is we'll\nneed data such as maybe\nthe temperature on a particular day\nor the humidity level, the\nprecipitation, and so on.\nSo you need to define the\nobjective at this stage.\nSo basically, you have to\nform an idea of the problem\nat this storage.\nAnother question that\nyou need to ask yourself\nis what kind of problem are you solving.\nIs this a binary classification problem,\nor is this a clustering problem,\nor is this a regression problem?\nNow, a lo of you might not be familiar\nwith the terms classification clustering\nand regression in terms\nof machine learning.\nDon't worry, I'll explain\nall of these terms\nin the upcoming slides.\nAll you need to understand at step one\nis you need to define how you're\ngoing to solve the problem.\nYou need to understand what sort of data\nyou need to solve the problem,\nhow you're going to approach the problem,\nwhat are you trying to predict,\nwhat variables you'll need in\norder to predict the outcome,\nand so on.\nLet's move on and look at step number two,\nwhich is data gather.\nNow in this stage, you must\nbe asking questions such as,\nwhat kind of data is needed\nto solve this problem?\nAnd is this data available?\nAnd if it is available, from\nwhere can I get this data\nand how can I get the data?\nData gathering is one of\nthe most time-consuming\nsteps in machine learning process.\nIf you have to go manually\nand collect the data,\nit's going to take a lot of time.\nBut lucky for us, there are\na lot of resources online,\nwhich were wide data sets.\nAll you need to do is web scraping\nwhere you just have to go\nahead and download data.\nOne of the websites I can\ntell you all about is Cargill.\nSo if you're a beginner\nin machine learning,\ndon't worry about data\ngathering and all of that.\nAll you have to do is go\nto websites such as cargill\nand just download the data set.\nSo coming back to the problem\nthat we are discussing,\nwhich is predicting the weather,\nthe data needed for weather forecasting\nincludes measures like humidity level,\nthe temperature, the\npressure, the locality,\nwhether or not you live in a hill station,\nsuch data has to be collected\nor stored for analysis.\nSo all the data is collected\nduring the data gathering stage.\nThis step is followed by data preparation,\nor also known as data cleaning.\nSo if you're going around collecting data,\nit's almost never in the right format.\nAnd eve if you are taking data\nfrom online resources from any website,\neven then, the data will require\ncleaning and preparation.\nThe data is never in the right format.\nYou have to do some sort of preparation\nand some sort of cleaning\nin order to make the\ndata ready for analysis.\nSo what you'll encounter\nwhile cleaning data\nis you'll encounter a\nlot of inconsistencies\nin the data set,\nlike you'll encounter som missing values,\nredundant variables, duplicate\nvalues, and all of that.\nSo removing such inconsistencies\nis very important,\nbecause they might lead to any wrongful\ncomputations and predictions.\nOkay, so at this stage\nyou can scan the data set\nfor any inconsistencies,\nand you can fix them then and there.\nNow let me give you a small\nfact about data cleaning.\nSo there was a survey that\nwas ran last year or so.\nI'm not sure.\nAnd a lot of data scientists were asked\nwhich step was the most\ndifficult or the most\nannoying and time-consuming of all.\nAnd 80% of the data scientist said\nit was data cleaning.\nData cleaning takes up 80% of their time.\nSo it's not very easy to\nget rid of missing values\nand corrupted data.\nAnd even if you get rid of missing values,\nsometimes your data\nset might get affected.\nIt might get biased\nbecause maybe one variable\nhas too many missing values,\nand this will affect your outcome.\nSo you'll have to fix such issue,\nwe'll have to deal with\nall of this missing data\nand corrupted data.\nSo data cleaning is actually\none of the hardest steps\nin machine learning process.\nOkay, now let's move on\nand look at our next step,\nwhich is exploratory data analysis.\nSo here what you do is basically become\na detective in the stage.\nSo this stage, which is EDA\nor exploratory data analysis,\nis like the brainstorming\nstage of machine learning.\nData exploration involves\nunderstanding the patterns\nand the trends in your data.\nSo at this stage, all the\nuseful insights are drawn\nand any correlations between\nthe various variables\nare understood.\nWhat do I mean by trends and\npatterns and correlations?\nNow let's consider our example\nwhich is we have to predict the rainfall\non a particular day.\nSo we know that there is a\nstrong possibility of rain\nif the temperature has fallen law.\nSo we know that our output will depend on\nvariables such as temperature,\nhumidity, and so on.\nNow to what level it\ndepends on these variables,\nwe'll have to find out that.\nWe'll have to find out the patterns,\nand we'll find out the correlations\nbetween such variables.\nSo such patterns and trends\nhave to be understood\nand mapped at this stage.\nSo this is what exploratory\ndata analysis is about.\nIt's the most important\npart of machine learning.\nThis is where you'll understand\nwhat exactly your data is\nand how you can form the\nsolution to your problem.\nThe next step in a\nmachine learning process\nis building a machine learning module.\nSo all the insights and the patterns\nthat you derive during\nthe data exploration\nare used to build a\nmachine learning model.\nSo this stage always begins\nby splitting the data set\ninto two parts, which is\ntraining data and testing data.\nI've already discussed with you\nthat the data that you used\nin a machine learning process\nis always split into two parts.\nWe have the training data\nand we have the testing data.\nNow when you're building a model,\nyou always use the training data.\nSo you always make use\nof the training data\nin order to build the model.\nNow a lot of you might be\nasking what is training data.\nIs it different from the input data\nthat you're feeding with the machine\nor is it different from the testing data?\nNow training data is the same input data\nthat you're feeding to the machine.\nThe only difference is that you're\nsplitting the data set into two.\nYou're randomly picking 80% of your data\nand you're assigning for training purpose.\nAnd the rest 20%, probably,\nyou'll assign it for testing purpose.\nSo guys, always remember\nanother thing that\nthe training data is always much more\nthan your testing data,\nobviously because you need\nto train your machine.\nAnd the more data you feed the machine\nduring the training phase,\nthe better it will be\nduring the testing phase.\nObviously, it'll predict better outcomes\nif it is being trained on more data.\nCorrect?\nSo the model is basically using\nthe machine learning algorithm\nthat predicts the output\nby using the data fed to it.\nNow in the case of predicting rainfall,\nthe output will be a categorical variable,\nbecause we'll be predicting\nwhether it's going to rain or not.\nOkay, so let's say we have an\noutput variable called rain.\nThe two possible values\nthat this variable can take\nis yes it's going to rain\nand no it won't rain.\nCorrect, so that is out come.\nOur outcome is a classification\nor a categorical variable.\nSo for such cases where your outcome\nis a categorical variable,\nyou'll be using classification algorithms.\nAgain, example of a\nclassification algorithm\nis logistic regression\nor you can also support vector machines,\nyou can use K nearest neighbor,\nand you can also use\nnaive Bayes, and so on.\nNow don't worry about these terms,\nI'll be discussing all\nthese algorithms with you.\nBut just remember that\nwhile you're building\na machine learning model,\nyou'll make use of the training data.\nYou'll train the model by\nusing the training data\nand the machine learning algorithm.\nNow like I said, choosing the\nmachine learning algorithm,\ndepends on the problem statement\nthat you're trying to solve\nbecause of N number of\nmachine learning algorithms.\nWe'll have to choose the algorithm\nthat is the most suitable\nfor your problem statement.\nSo step number six is model evaluation\nand optimization.\nNow after you've done building a model\nby using the training data set,\nit is finally time to\nput the model road test.\nThe testing data set is used to check\nthe efficiency of the model\nand how accurately it\ncan predict the outcome.\nSo once the accuracy is calculated,\nany further improvements in the model\ncan be implemented during this stage.\nThe various methods that can help you\nimprove the performance of the model,\nlike you can use parameter tuning\nand cross validation methods\nin order to improve the\nperformance of the model.\nNow the main things you need to remember\nduring model evaluation and optimization\nis that model evaluation is nothing but\nyou're testing how well your\nmodel can predict the outcome.\nSo at this stage, you will be\nusing the testing data set.\nIn the previous stage,\nwhich is building a model,\nyou'll be using the training data set.\nBut in the model evaluation stage,\nyou'll be using the testing data set.\nNow once you've tested your model,\nyou need to calculate the accuracy.\nYou need to calculate how accurately\nyour model is predicting the outcome.\nAfter that, if you find that you need to\nimprove your model in\nsome way or the other,\nbecause the accuracy is not very good,\nthen you'll use methods\nsuch as parameter tuning.\nDon't worry about these terms,\nI'll discuss all of this with you,\nbut I'm just trying to make sure\nthat you're understanding the concept\nbehind each of the phases\nand machine learning.\nIt's very important you\nunderstand each step.\nOkay, now let's move on and look at\nthe last stage of machine\nlearning, which is predictions.\nNow, once a model is evaluated\nand once you've improved it,\nit is finally used to make predictions.\nThe final output can either\nbe a categorical variable\nor a continuous variable.\nNow all of this depends\non your problem statement.\nDon't get confused about\ncontinuous variables,\ncategorical variables.\nI'll be discussing all of this.\nNow in our case, because we're predicting\nthe occurrence of rainfall,\nthe output will be categorical variable.\nIt's obvious because we're predicting\nwhether it's going to rain or not.\nThe result, we understand\nthat this is a classification problem\nbecause we have a categorical variable.\nSo that was the entire\nmachine learning process.\nNow it's time to learn\nabout the different ways\nin which machines can learn.\nSo let's move ahead\nand look at the types of machine learning.\nNow this is one of the most\ninteresting concepts in machine learning,\nthe three different ways\nin which machines learn.\nThere is something known\nas supervised learning,\nunsupervised learning, and\nreinforcement learning.\nSo we'll go through this one by one.\nWe'll understand what\nsupervised learning is first,\nand then we'll look at\nthe other two types.\nSo defined supervised learning,\nit is basically a\ntechnique in which we teach\nor train the machine by using the data,\nwhich is well labeled.\nNow, in order to understand\nsupervised learning,\nlet's consider a small example.\nSo, as kids, we all needed\nguidance to solve math problems.\nA lot of us had trouble\nsolving math problems.\nSo our teachers always help\nus understand what addition is\nan dhow it is done.\nSimilarly, you can think\nof supervised learning\nas a type of machine learning\nthat involves a guide.\nThe label data set is a teacher\nthat will train you to understand\nthe patterns in the data.\nSo the label data set is nothing\nbut the training data set.\nI'll explain more about this in a while.\nSo, to understand\nsupervised learning better,\nlet's look at the figure on the screen.\nRight here we're feeding the machine\nimage of Tom and Jerry,\nand the goal is for\nthe machine to identify\nand classify the images into two classes.\nOne will contain images of Tom\nand the the other will\ncontain images of Jerry.\nNow the main thing that you need to note\nin supervised learning\nis a training data set.\nThe training data set is\ngoing to be very well labeled.\nNow what do I mean when I say that\ntraining data set is labeled.\nBasically, what we're doing\nis we're telling the machine\nthis how Tom looks and\nthis is how Jerry looks.\nBy doing this, you're training the machine\nby using label data.\nSo the main thing that you're\ndoing is you're labeling\nevery input data that\nyou're feeding to the model.\nSo, basically, you're entire\ntraining data set is labeled.\nWhenever you're giving an image of Tom,\nthere's gonna be a label\nthere saying this is Tom.\nAnd when you're giving an image of Jerry,\nyou're saying that this\nis how Jerry looks.\nSo, basically, you're guiding the machine\nand you're telling that,\n\"Listen, this is how Tom looks,\n\"this is how Jerry looks,\n\"and now you need to classify them\n\"into two different classes.\"\nThat's how supervised learning works.\nApart from that, it's\nthe same old process.\nAfter getting the input data,\nyou're gonna perform data cleaning.\nThen there's exploratory data analysis,\nfollowed by creating the model\nby using the machine learning algorithm,\nand then this is followed\nby model evaluation,\nand finally, your predictions.\nNow, one more thing to note here is that\nthe output that you get by\nusing supervised learning\nis also labeled output.\nSo, basically, you'll\nget two different classes\nof name Tom and one of name Jerry,\nand you'll get them labeled.\nThat is how supervised learning works.\nThe most important thing\nin supervised learning\nis that you're training the model by using\nlabeled data set.\nNow let's move on and look\nat unsupervised learning.\nWe look at the same example and understand\nhow unsupervised learning works.\nSo what exactly is unsupervised learning?\nNow this involves training\nby using unlabeled data\nand allowing the model to\nact on that information\nwithout any guidance.\nAlright.\nLike the name suggest itself,\nthere is no supervision here.\nIt's unsupervised learning.\nSo think of unsupervised\nlearning as a smart kid\nthat learns without any guidance.\nOkay, in this type of machine learning,\nthe model is not fed with any label data,\nas in the model has no clue that this is\nthe image of Tom and this is Jerry.\nIt figures out patterns\nand the difference between\nTom and Jerry on its own\nby taking in tons and tons of data.\nNow how do you think the\nmachine identifies this as Tom,\nand then finally gives us the output like\nyes this is Tom, this is Jerry.\nFor example, it identifies\nprominent features of Tom,\nsuch as pointy ears,\nbigger in size, and so on,\nto understand that this\nimage is of type one.\nSimilarly, it finds out features in Jerry,\nand knows that this image is of type two,\nmeaning that the first image\nis different from the second image.\nSo what the unsupervised\nlearning algorithm\nor the model does is it'll\nform two different clusters.\nIt'll form one cluster\nwhich are very similar,\nand the other cluster\nwhich is very different\nfrom the first cluster.\nThat's how unsupervised learning works.\nSo the important things\nthat you need to know\nin unsupervised learning\nis that you're gonna feed\nthe machine unlabeled data.\nThe machine has to understand the patterns\nand discover the output on its own.\nAnd finally, the machine\nwill form clusters\nbased on feature similarity.\nNow let's move on and locate\nthe last type of machine learning,\nwhich is reinforcement learning.\nReinforcement learning is quite different\nwhen compared to supervised\nand unsupervised learning.\nWhat exactly is reinforcement learning?\nIt is a part of machine\nlearning where an agent\nis put in an environment,\nand he learns to behave\nin this environment\nby performing certain actions,\nand observing the rewards which\nis gets from those actions.\nTo understand what\nreinforcement learning is,\nimagine that you were dropped\noff at an isolate island.\nWhat would you do?\nNow panic.\nYes, of course, initially,\nwe'll all panic.\nBut as time passes by, you will learn\nhow to live on the island.\nYou will explode the environment,\nyou will understand\nthe climate conditions,\nthe type of food that grows there,\nthe dangers of the island so on.\nThis is exactly how\nreinforcement learning works.\nIt basically involves an agent,\nwhich is you stuck on the island,\nthat is put in an unknown\nenvironment, which is the island,\nwhere he must learn by\nobserving and performing\nactions that result in rewards.\nSo reinforcement learning is mainly used\nin advanced machine learning areas\nsuch as self-driving cars and AlphaGo.\nI'm sure a lot of you\nhave heard of AlphaGo.\nSo, the logic behind AlphaGo\nis nothing but reinforcement\nlearning and deep learning.\nAnd in reinforcement learning,\nthere is not really any input\ndata given to the agent.\nAll he has to do is he has to explore\neverything from scratch\nit's like a newborn baby with\nno information about anything.\nHe has to go around\nexploring the environment,\nand getting rewards, and\nperforming some actions\nwhich results in either rewards\nor in some sort of punishment.\nOkay.\nSo that sums up the types\nof machine learning.\nBefore we move ahead,\nI'd like to discuss the difference\nbetween the three types\nof machine learning,\njust to make the concept clear to you all.\nSo let's start by looking\nat the definitions of each.\nIn supervised learning,\nthe machine will learn\nby using the label data.\nIn unsupervised learning,\nthey'll be unlabeled data,\nand the machine has to learn\nwithout any supervision.\nIn reinforcement learning,\nthere'll be an agent\nwhich interacts with the environment\nby producing actions and\ndiscover errors or rewards\nbased on his actions.\nNow what are the type of problems\nthat can be solved by using\nsupervised, unsupervised,\nand reinforcement learning.\nWhen it comes to supervised learning,\nthe two main types of\nproblems that are solved\nis regression problems and\nclassification problems.\nWhen it comes to unsupervised learning,\nit is association and clustering problems.\nWhen it comes to reinforcement learning,\nit's reward-based problems.\nI'll be discussing\nregression, classification,\nclustering, and all of this\nin the upcoming slides,\nso don't worry if you\ndon't understand this.\nNow the type of data which is\nused in supervised learning\nis labeled data.\nIn unsupervised learning, it unlabeled.\nAnd in reinforcement learning,\nwe have no predefined data set.\nThe agent has to do\neverything from scratch.\nNow the type of training involved\nin each of these learnings.\nIn supervised learning, there\nis external supervision,\nas in there is the labeled data set\nwhich acts as a guide\nfor the machine to learn.\nIn unsupervised learning,\nthere's no supervision.\nAgain, in reinforcement learning,\nthere's no supervision at all.\nNow what is the approach to solve problems\nby using supervised, unsupervised,\nand reinforcement learning?\nIn supervised learning, it is simple.\nYou have to mal the labeled\ninput to the known output.\nThe machine knows what\nthe output looks like.\nSo you're just labeling\nthe input to the output.\nIn unsupervised learning,\nyou're going to understand the patterns\nand discover the output.\nHere you have no clue\nabout what the input is.\nIt's not labeled.\nYou just have to understand the patterns\nand you'll have to form clusters\nand discover the output.\nIn reinforcement learning,\nthere is no clue at all.\nYou'll have to follow the\ntrial and error method.\nYou'll have to go around your environment.\nYou'll have to explore the environment,\nand you'll have to try some actions.\nAnd only once you perform those actions,\nyou'll know that whether\nthis is a reward-based action\nor whether this is a\npunishment-based action.\nSo, reinforcement\nlearning is totally based\non the concept of trial and error.\nOkay.\nA popular algorithm on the\nsupervised learning include\nlinear regression, logistic regressions,\nsupport vector machines\nK nearest neighbor,\nnaive Bayes, and so on.\nUnder unsupervised learning,\nwe have the famous K-means\nclustering method, C-means\nand all of that.\nUnder reinforcement learning,\nwe have the famous learning\nQ-learning algorithm.\nI'll be discussing these\nalgorithms in the upcoming slides.\nSo let's move on and\nlook at the next topic,\nwhich is the types of problems solved\nusing machine learning.\nNow this is what we were\ntalking about earlier\nwhen I said regression, classification,\nand clustering problems.\nOkay, so let's discuss what\nexactly I mean by that.\nIn machine learning,\nall the problems can be\nclassified into three types.\nEvery problem that is\napproached in machine learning\ncan be put interest one\nof these three categories.\nOkay, so the first type\nis known as a regression,\nthen we have classification\nand clustering.\nSo, first, let's look at\nregression type of problems.\nSo in this type problem,\nthe output is always\na continuous quantity.\nFor example, if you want to predict\nthe speed of a car, given the distance,\nit is a regression problem.\nNow a lot of you might not be very aware\nof what exactly a continuous quantity is.\nA continuous quantity is\nany quantity that can have\nan infinite range of values.\nFor example, The weight of a person,\nit is a continuous quantity,\nbecause our weight can be 50, 50.1,\n50.001,\n5.0021,\n50.0321 and so on.\nIt can have an infinite\nrange of values, correct?\nSo the type of problem\nthat you have to predict\na continuous quantity to make\nuse of regression algorithms.\nSo, regression problems can be solved\nby using supervised learning algorithms\nlike linear regression.\nNext, we have classification.\nNow in this type of problem,\nthe output is always a categorical value.\nNow when I say categorical value,\nit can be value such as\nthe gender of a person\nis a categorical value.\nNow classifying emails\ninto two two classes\nlike spam and non-spam is\na classification problem\nthat can be solved by using\nsupervised learning\nclassification algorithms,\nlike support vector machines, naive Bayes,\nlogistic regression, K\nnearest neighbor, and so on.\nSo, again, the main aim in classification\nis to compute the category of the data.\nComing to clustering problems.\nThis type of problem involves\nassigned input into two or more clusters\nbased on feature similarity.\nThus when I read this sentence,\nyou should understand that\nthis is unsupervised learning,\nbecause you don't have\nenough data about your input,\nand the only option that\nyou have is to form clusters\nCategories are formed\nonly when you know that\nyour data is of two type.\nYour input data is labeled\nand it's of two types,\nso it's gonna be a classification problem.\nBut when a clustering problem happens,\nwhen you don't have much\ninformation about your input,\nall you have to do is\nyou have to find patterns\nand you have to understand that\ndata points which are similar\nare clustered into one group,\nand data points which are\ndifferent from the first group\nare clustered into another group.\nThat's what clustering is.\nAn example is in Netflix what happens is\nNetflix clusters their\nusers into similar groups\nbased on their interest,\nbased on their age,\ngeography, and so on.\nThis can be done by using\nunsupervised learning algorithms\nlike K-means.\nOkay.\nSo guys, there were the\nthree categories of problems\nthat can be solved by\nusing machine learning.\nSo, basically, what I'm trying to say\nis all the problems will fall\ninto one of these categories.\nSo any problem that you give\nto a machine learning model,\nit'll fall into one of these categories.\nOkay.\nNow to make things a\nlittle more interesting,\nI have collected real world data sets\nfrom online resources.\nAnd what we're gonna do is we're\ngoing to try and understand\nif this is a regression problem,\nor a clustering problem, or\na classification problem.\nOkay.\nNow the problem statement in here\nis to study the house sales data set,\nand build a machine learning model\nthat predicts the house pricing index.\nNow the most important\nthing you need to understand\nwhen you read a problem statement\nis you need to understand\nwhat is your target variable,\nwhat are the possible predictor\nvariable that you'll need.\nThe first thing you should\nlook at is your targe variable.\nIf you want to understand\nif this a classification,\nregression, or clustering problem,\nlook at your target variable\nor your output variable\nthat you're supposed to predict.\nHere you're supposed to predict\nthe house pricing index.\nOur house pricing index is obviously\na continuous quantity.\nSo as soon as you understand that,\nyou'll know that this\nis a regression problem.\nSo for this, you can make use of\nthe linear regression algorithm,\nand you can predict the\nhouse pricing index.\nLinear regression is the\nregression algorithm.\nIt is a supervised learning algorithm.\nWe'll discuss more about\nit in the further slides.\nLet's look at our next problem statement.\nHere you have to study\na bank credit data set,\nand make a decision about whether\nto approve the loan of an applicant\nbased on his profile.\nNow what is your output\nvariable over here?\nYour output variable is\nto predict whether you can\napprove the loan of a applicant or not.\nSo, obviously, your output\nis going to be categorical.\nIt's either going to be yes or no.\nYes is basically approved loan.\nNo is reject loan.\nSo here, you understand that\nthis is a classification problem.\nOkay.\nSo you can make use of\nalgorithms like KNN algorithm\nor you can make use of\nsupport vector machines\nin order to do this.\nSo, support vector machine and KNN\nwhich is K nearest neighbor algorithms\nare basically supervised\nlearning algorithm.\nWe'll talk more about that\nin the upcoming slides.\nMoving on to our next problem statement.\nHere the problem statement is to cluster\na set of movies as either good or average\nbased on the social media outreach.\nNow if you look properly,\nyour clue is in the question itself.\nThe first line it says is\nto cluster a set of movies\nas either good or average.\nNow guys, whenever you\nhave a problem statement\nthat is asking you to group the data set\ninto different groups\nor to form different, different clusters,\nit's obviously a clustering problem.\nRight here you can make use\nof the K-means clustering algorithm,\nand you can form two clusters.\nOne will contain the popular movies\nand the other will contain\nthe non-popular movies.\nThese alright small\nexamples of how you can use\nmachine learning to\nsolve clustering problem,\nthe regression, and\nclassification problems.\nThe key is you need to identify\nthe type of problem first.\nNow let's move on and\ndiscuss the different types\nof machine learning algorithms.\nSo we're gonna start by\ndiscussing the different\nsupervised learning algorithms.\nSo to give you a quick overview,\nwe'll be discussing the linear regression,\nlogistic regression, and decision tree,\nrandom forest, naive Bayes classifier,\nsupport vector machines,\nand K nearest neighbor.\nWe'll be discussing\nthese seven algorithms.\nSo without any further delay,\nlet's look at linear regression first.\nNow what exactly is a\nlinear regression algorithm?\nSo guys, linear regression is basically\na supervised learning algorithm\nthat is used to predict a\ncontinuous dependent variable y\nbased on the values of\nindependent variable x.\nOkay.\nThe important thing to note here\nis that the dependent variable y,\nthe variable that you're\ntrying to predict,\nis always going to be\na continuous variable.\nBut the independent variable x,\nwhich is basically the\npredictor variables,\nthese are the variables\nthat you'll be using\nto predict your output variable,\nwhich is nothing but\nyour dependent variable.\nSo your independent variables\nor your predictive variables\ncan either be continuous or discreet.\nOkay, there is not such\na restriction over here.\nOkay, they can be either\ncontinuous variables\nor they can be discreet variables.\nNow, again, I'll tell you\nwhat a continuous variable is,\nin case you've forgotten.\nIt is a vary that has infinite\nnumber of possibilities.\nSo I'll give you an example\nof a person's weight.\nIt can be 160 pounds, or\nthey can weigh 160.11 pounds,\nor 160.1134 pounds and so on.\nSo the number of possibilities\nfor weight is limitless,\nand this is exactly what\na continuous variable is.\nNow in order to understand\nlinear regression,\nlet's assume that you want to predict the\nprice of a stock over a period of time.\nOkay.\nFor such a problem, you can\nmake use of linear regression\nby starting the relationship\nbetween the dependent variable,\nwhich is the stock price,\nand the independent\nvariable, which is the time.\nYou're trying to predict the stock price\nover a period of time.\nSo basically, you're gonna\ncheck how the price of a stock\nvaries over a period of time.\nSo your stock price is going to be\nyour dependent variable\nor your output variable,\nand the time is going to\nbe your predictor variable\nor your independent variable.\nLet's not confuse it anymore.\nYour dependent variable\nis your output variable.\nOkay, your independent\nvariable is your input variable\nor your predictor variable.\nSo in our case, the\nstock price is obviously\na continuous quantity,\nbecause the stock price can have\nan infinite number of values.\nNow the first step in linear regression\nis always to draw out a relationship\nbetween your dependent and\nyour independent variable\nby using the best fitting linear length.\nWe make an assumption that your dependent\nand independent variable\nis linearly related to each other.\nWe call it linear regression because\nboth the variables vary linearly,\nwhich means that by\nplotting the relationship\nbetween these two variables,\nwe'll get more of a straight\nline, instead of a curve.\nLet's discuss the math\nbehind linear regression.\nSo, this equation over here,\nit denotes the relationship between your\nindependent variable x, which is here,\nand your dependent variable y.\nThis is the variable\nyou're trying to predict.\nHopefully, we all know that the equation\nfor a linear line in math\nis y equals mx plus c.\nI hope all of you remember math.\nSo the equation for a linear line in math\nis y equals to mx plus c.\nSimilarly, the linear regression equation\nis represented along the same line.\nOkay, y equals to mx plus c.\nThere's just a little bit of changes,\nwhich I'll tell you what they are.\nLet's understand this equation properly.\nSo y basically stands for\nyour dependent variable\nthat you're going to predict.\nB naught is the y intercept.\nNow y intercept is nothing\nbut this point here.\nNow in this graph, you're basically\nshowing the relationship between\nyour dependent variable y\nand your independent variable x.\nNow this is the linear relationship\nbetween these two variables.\nOkay, now your y intercept is basically\nthe point on the line\nwhich starts at the y-axis.\nThis is y interceptor,\nwhich is represented by B naught.\nNow B one or beta is\nthe slope of this line\nnow the slope can either\nbe negative or positive,\ndepending on the relationship\nbetween the dependent\nand independent variable.\nThe next variable that we have is x.\nX here represents the independent variable\nthat is used to predict our\nresulting output variable.\nBasically, x is used to\npredict the value of y.\nOkay.\nE here denotes the error\nin the computation.\nFor example, this is the actual line,\nand these dots here represent\nthe predicted values.\nNow the distance between these two\nis denoted by the error\nin the computation.\nSo this is the entire equation.\nIt's quite simple, right?\nLinear regression will basically draw\na relationship between your\ninput and your input variable.\nThat's how simple linear regression was.\nNow to better understand\nlinear regression,\nI'll be running a demo in Python.\nSo guys, before I get started\nwith our practical demo,\nI'm assuming that most of you\nhave a good understanding of Python,\nbecause explaining Python is going to be\nout of the scope of today's session.\nBut if some of you are not familiar\nwith the Python language,\nI'll leave a couple of links\nin the description box.\nThose will be related\nto Python programming.\nYou can go through those\nlinks, understand Python,\nand then maybe try to understand the demo.\nBut I'd be explaining the logic\npart of the demo in depth.\nSo the main thing that\nwe're going to do here\nis try and understand linear regression.\nSo it's okay if you do not\nunderstand Python for now.\nI'll try to explain as much as I can.\nBut if you still want to\nunderstand this in a better way,\nI'll leave a couple of\nlinks in the description box\nyou can go to those videos.\nLet me just zoom in for you.\nI hope all of you can see the screen.\nNow in this linear regression demo,\nwhat we're going to do is\nwe're going to form a linear relationship\nbetween the maximum temperature\nand minimum temperature\non a particular date.\nWe're just going to do\nweather forecasting here.\nSo our task is to predict\nthe maximum temperature,\ntaking input feature\nas minimum temperature.\nSo I'm just going to try\nand make you understand\nlinear regression through this demo.\nOkay, we'll see how it\nactually works practically.\nBefore I get started with the demo,\nlet me tell you something\nabout the data set.\nOur data set is stored\nin this path basically.\nThe name of the data set is weather.csv.\nOkay, now, this contains\ndata on whether conditions\nrecorded on each day\nat various weather\nstations around the world.\nOkay, the information\ninclude precipitation,\nsnowfall, temperatures, wind speeds,\nand whether the day\nincluded any thunderstorm\nor other poor weather conditions.\nSo our first step in\nany demo for that matter\nwill be to import all the\nlibraries that are needed.\nSo we're gonna begin our demo\nby importing all the required libraries.\nAfter that, we're going\nto read in our data.\nOur data will be stored\nin this variable called data set,\nand we're going to use a read.csv function\nsince our data set is in the CSV format.\nAfter that, I'll be showing you\nhow the data set looks.\nWe'll also look at the data set in depth.\nNow let me just show you the output first.\nLet's run this demo and see first.\nWe're getting a couple of plots which I'll\ntalk about in a while.\nSo we can ignore this warning.\nIt has nothing to do with...\nSo, first of all, we're printing\nthe shape of our data set.\nSo, when we print the\nshape of our data set,\nThis is the output that we get.\nSo, basically, this\nshows that we have around\n12,000 rows and 31\ncolumns in our data set.\nThe 31 columns basically represent\nthe predictor variables.\nSo you can say that we\nhave 31 predictor variables\nin order to protect the weather conditions\non a particular date.\nSo guys, the main aim\nin this problem segment\nis weather forecast.\nWe're going to predict the weather\nby using a set of predictor variables.\nSo these are the different types\nof predictor variables that we have.\nOkay, we have something\nknown as maximum temperature.\nSo this is what our data set looks like.\nNow what I'm doing in\nthis block of code is...\nWhat we're doing is we're\nplotting our data points\non a 2D graph in order to\nunderstand our data set\nand see if we can manually\nfind any relationship\nbetween the variables.\nHere we've taken minimum temperature\nand maximum temperature\nfor doing our analysis.\nSo let's just look at this plot.\nBefore that, let me just comment\nall of these other plots,\nso that you see on either\ngraph that I'm talking about.\nSo, when you look at this graph,\nthis is basically the graph\nbetween your minimum temperature\nand your maximum temperature.\nMaximum temperature are dependent variable\nthat you're going to predict.\nThis is y.\nAnd your minim temperature is your x.\nIt's basically your independent variable.\nSo if you look at this graph,\nyou can see that there is a sort of\nlinear relationship between the two,\nexcept there are a little bit\nof outliers here and there.\nThere are a few data points\nwhich are a little bit random.\nBut apart from that, there is\na pretty linear relationship\nbetween your minimum temperature\nand your maximum temperature.\nSo by this graphic, you can understand\nthat you can easily solve this problem\nusing linear regression,\nbecause our data is very linear.\nI can see a clear straight line over here.\nThis is our first graph.\nNext, what I'm doing is I'm just checking\nthe average and maximum\ntemperature that we have.\nI'm just looking at the\naverage of our output variable.\nOkay.\nSo guys, what we're doing here right now\nis just exploratory data analysis.\nWe're trying to understand our data.\nWe're trying to see the relationship\nbetween our input variable\nand our output variable.\nWe're trying to see\nthe mean or the average\nof the output variable.\nAll of this is necessary\nto understand our data set.\nSo, this is what our average\nmaximum temperature looks like.\nSo if we try to understand\nwhere exactly this is,\nso our average maximum temperature\nis somewhere between 28\nand I would say between 30.\n28 and 32, somewhere there.\nSo you can say that\naverage maximum temperature\nlies between 25 and 35.\nAnd so that is our average\nmaximum temperature.\nNow that you know a little\nbit about the data set,\nyou know that there is a\nvery good linear relationship\nbetween your input variable\nand your output variable.\nNow what you're going\nto do is you're going to\nperform something known as data splicing.\nLet me just comment that for you.\nThis section is nothing but data splicing.\nSo for those of you who\nare paying attention,\nknow that data splicing is nothing but\nsplitting your data set into\ntraining and testing data.\nNow before we do that,\nI mentioned earlier that we'll\nbe only using two variables,\nbecause we're trying to understand\nthe relationship between\nthe minimum temperature\nand maximum temperature.\nI'm doing this because\nI want you to understand\nlinear regression in the\nsimplest way possible.\nSo guys, in order to make\nunderstand linear regression,\nI have just derived only two\nvariables from a data set.\nEven though when we check\nthe structure of a data set,\nwe had around 31 features,\nmeaning that we had 31 variables\nwhich include my predictor\nvariable and my target variable.\nSo, basically, we had\n30 predictor variables\nand we had one target variable,\nwhich is your maximum temperature.\nSo, what I'm doing here\nis I'm only considering\nthese two variables,\nbecause I want to show you exactly\nhow linear regression works.\nSo, here what I'm doing is I'm basically\nextracting only these two variables\nfrom our data set, storing it in x and y.\nAfter that, I'm performing data splicing.\nSo here, I'm basically splitting the data\ninto training and testing data,\nand remember one point that I am assigning\n20% of the data to our testing data set,\nand the remaining 80% is\nassigned for training.\nThat's how training works.\nWe assign maximum data set for training.\nWe do this because we want\nthe machine learning model\nor the machine learning algorithm\nto train better on data.\nWe wanted to take as\nmuch data as possible,\nso that it can predict\nthe outcome properly.\nSo, to repeat it again for you,\nso here we're just splitting the data\ninto training and testing data set.\nSo, one more thing to note here is that\nwe're splitting 80% of\nthe data from training,\nand we're assigning the 20%\nof the data to test data.\nThe test size variable,\nthis variable that you see,\nis what is used to specify\nthe proportion of the test set.\nNow after splitting the data\ninto training and testing set,\nfinally, the time is\nto train our algorithm.\nFor that, we need to import\nthe linear regression class.\nWe need to instantiate it\nand call the fit method\nalong with the training data.\nThis is our linear regression class,\nand we're just creating an instance\nof the linear regression class.\nSo guys, a good thing about Python is that\nyou have pre-defined\nclasses for your algorithms,\nand you don't have call your algorithms.\nInstead, all you have to do,\nis you call this class\nlinear regression class,\nand you have to create an instance of it.\nHere I'm basically creating\nsomething known as a regressor.\nAnd all you have to do is you\nhave to call the fit method\nalong with your training data.\nSo this is my training\ndata, x train and y train\ncontains my training data,\nand I'm calling our linear\nregression instance,\nwhich is regressor,\nalong with this data set.\nSo here, basically,\nwe're building the model.\nWe're doing nothing\nbut building the model.\nNow, one of the major things that\nlinear regression model does is\nit finds the best value for\nthe intercept and the slope,\nwhich results in a line\nthat best fits the data.\nI've discussed what\nintercept and slope is.\nSo if you want to see the\nintercept and the slope\ncalculated by our linear regression model,\nwe just have to run this line of code.\nAnd let's looks at the output for that.\nSo, our intercept is around 10.66\nand our coefficient,\nthese are also known as beta coefficients,\ncoefficient are nothing but\nwhat we discussed, beta naught.\nThese are beta values.\nNow this will just help you understand\nthe significance of your input variables.\nNow what this coefficient value means is,\nsee, the coefficient value is around 0.92.\nThis means that for every one unit changed\nof your minimum temperature,\nthe change in the maximum\ntemperature is around 0.92.\nThis will just show you how significant\nyour input variable is.\nSo, for every one unit change\nin your minimum temperature,\nthe change in the maximum temperature\nwill be around 0.92.\nI hope you've understood this part.\nNow that we've trained our algorithm,\nit's trying to make some predictions.\nTo do so, what we'll use is\nwe'll use our test data set,\nand we'll see how accurately our algorithm\npredicts the percentage score.\nNow to make predictions,\nwe have this line of code.\nPredict is basically a\npredefined function in Python.\nAnd all you're going to\ndo is you're going to pass\nyour testing data set to this.\nNow what you'll do is you'll compare\nthe actual output values,\nwhich is basically stored in your y test.\nAnd you'll compare these\nto the predicted values,\nwhich is in y prediction.\nAnd you'll store these\ncomparisons in our data frame\ncalled df.\nAnd all I'm doing here is\nI'm printing the data frame.\nSo if you look at the output,\nthis is what it looks like.\nThese are your actual values\nand these are the values\nthat you predicted\nby building that model.\nSo, if your actual value is 28,\nyou predicted around 33,\nhere your actual value is 31,\nmeaning that your maximum\ntemperature is 31.\nAnd you predicted a\nmaximum temperature of 30.\nNow, these values are\nactually pretty close.\nI feel like the accuracy\nis pretty good over here.\nNow in some cases, you see\na lot of variance, like 23.\nHere it's 15.\nRight here it's 22.\nHere it's 11.\nBut such cases are very often.\nAnd the best way to improve\nyour accuracy I would say\nis by training a model with more data.\nAlright.\nYou can also view this\ncomparison in the form of a plot.\nLet's see how that looks.\nSo, basically, this is a bar graph\nthat shows our actual values\nand our predicted values.\nBlue is represented by your actual values,\nand orange is represented\nby your predicted values.\nAt places you can see that\nwe've predicted pretty well,\nlike the predictions are pretty close\nto the actual values.\nIn some cases, the predictions\nare varying a little bit.\nSo in a few places, it\nis actually varying,\nbut all of this depends on\nyour input data as well.\nWhen we saw the input data,\nalso we saw a lot of variation.\nWe saw a couple of outliers.\nSo, all that also might\neffect your output.\nBut then this is how you\nbuild machine learning models.\nInitially, you're never going to get\na really good accuracy.\nWhat you should do is you have to improve\nyour training process.\nThat's the best way\nyou can predict better,\neither you use a lot of data,\ntrain your model with a lot of data,\nor you use other methods\nlike parameter tuning,\nor basically you try and find\nanother predictor variable\nthat'll help you more in\npredicting your output.\nTo me, this looks pretty good.\nNow let me show you another plot.\nWhat we're doing is we're\ndrawing a straight line plot.\nOkay, let's see how it looks.\nSo guys, this straight line\nrepresents a linear relationship.\nNow let's say you get a new data point.\nOkay, let's say the\nvalue of x is around 20.\nSo by using this line,\nyou can predict that four a\nminimum temperature of 20,\nyour maximum temperature\nwould be around 25\nor something like that.\nSo, we basically drew\na linear relationship\nbetween our input and\noutput variable over here.\nAnd the final step is to evaluate\nthe performance of the algorithm.\nThis step is particularly\nimportant to compare\nhow well different algorithms perform\non a particular data set.\nNow for regression algorithms,\nthree evaluation metrics are used.\nWe have something known\nas mean absolute error,\nmean squared error, and\nroot mean square error.\nNow mean absolute error is nothing but\nthe absolute value of the errors.\nYour mean squared error is a\nmean of the squared errors.\nThat's all.\nIt's basically you read\nthis and you understand\nwhat the error means.\nA root mean squared\nerror is the square root\nof the mean of the squared errors.\nOkay.\nSo these are pretty simple to understand\nyour mean absolute error,\nyour mean squared errors,\nyour root mean squared error.\nNow, luckily, we don't\nhave to perform these\ncalculations manually.\nWe don't have to code each\nof these calculations.\nThe cycle on library comes\nwith prebuilt functions\nthat can be used to find out these values.\nOkay.\nSo, when you run this code, you will get\nthese values for each of the errors.\nYou'll get around 3.19 as\nthe mean absolute error.\nYour mean squared error is around 17.63.\nYour root mean squared\nerror is around 4.19.\nNow these error values basically show that\nour model accuracy is not very precise,\nbut it's still able to\nmake a lot of predictions.\nWe can draw a good linear relationship.\nNow in order to improve\nthe efficiency at all,\nthere are a lot of methods like this,\nparameter tuning and all of that,\nor basically you can train your\nmodel with a lot more data.\nApart from that, you can use\nother predictor variables,\nor maybe you can study\nthe relationship between\nother predictor variables\nand your maximum temperature variable.\nThere area lot of ways\nto improve the efficiency of the model.\nBut for now, I just wanted\nto make you understand\nhow linear regression works,\nand I hope all of you have\na good idea about this.\nI hope all of you have\na good understanding\nof how linear regression works.\nThis is a small demo about it.\nIf any of you still have any doubts,\nregarding linear regression,\nplease leave that in the comment section.\nWe'll try and solve all your errors.\nSo, if you look at this equation,\nwe calculated everything here.\nwe drew a relationship between y and x,\nwhich is basically x was\nour minimum temperature,\ny was our maximum temperature.\nWe also calculated the\nslope and the intercept.\nAnd we also calculated\nthe error in the end.\nWe calculated mean squared error\nwe calculated the root mean squared error.\nWe also calculate the mean absolute error.\nSo that was everything\nabout linear regression.\nThis was a simple linear regression model.\nNow let's move on and look\nat our next algorithm,\nwhich is a logistic regression.\nNow, in order to understand\nwhy we use logistic regression,\nlet's consider a small scenarios.\nLet's say that your little sister\nis trying to get into grad school\nand you want to predict\nwhether she'll get admitted\nin her dream school or not.\nOkay, so based on her\nCGPA and the past data,\nyou can use logistic regression\nto foresee the outcome.\nSo logistic regression\nwill allow you to analyze\nthe set of variables and\npredict a categorical outcome.\nSince here we need to\npredict whether she will\nget into a school or not,\nwhich is a classification problem,\nlogistic regression will be used.\nNow I know the first\nquestion in your head is,\nwhy are we not using linear\nregression in this case?\nThe reason is that linear regression\nis used to predict a continuous quantity,\nrather than a categorical one.\nHere we're going to predict\nwhether or not your sister is\ngoing to get into grad school.\nSo that is clearly a categorical outcome.\nSo when the result in outcome\ncan take only classes of values,\nlike two classes of values,\nit is sensible to have a\nmodel that predicts the value\nas either zero or one,\nor in a probability form that\nranges between zero and one.\nOkay.\nSo linear regression does\nnot have this ability.\nIf you use linear regression\nto model a binary outcome,\nthe resulting model will\nnot predict y values\nin the range of zero and one,\nbecause linear regression works on\ncontinuous dependent variables,\nand not on categorical variables.\nThat's why we make use\nof logistic regression.\nSo understand that linear\nregression was used\nto predict continuous quantities,\nand logistic regression is used to\npredict categorical quantities.\nOkay, now one major\nconfusion that everybody has\nis people keep asking me\nwhy is logistic regression\ncalled logistic regression\nwhen it is used for classification.\nThe reason it is named logistic regression\nis because its primary technique\nis very similar to logistic regression.\nThere's no other reason behind the naming.\nIt belongs to the general linear models.\nIt belongs to the same\nclass as linear regression,\nbut that is not the other reason\nbehind the name logistic regression.\nLogistic regression is mainly used\nfor classification purpose,\nbecause here you'll have to\npredict a dependent variable\nwhich is categorical in nature.\nSo this is mainly used for classification.\nSo, to define logistic regression for you,\nlogistic regression is\na method used to predict\na dependent variable y,\ngiven an independent variable x,\nsuch that the dependent\nvariable is categorical,\nmeaning that your output\nis a categorical variable.\nSo, obviously, this is\nclassification algorithm.\nSo guys, again, to clear your confusion,\nwhen I say categorical variable,\nI mean that it can hold\nvalues like one or zero,\nyes or no, true or false, and so on.\nSo, basically, in logistic regression,\nthe outcome is always categorical.\nNow, how does logistic regression work?\nSo guys, before I tell you\nhow logistic regression works,\ntake a look at this graph.\nNow I told you that the outcome\nin a logistic regression is categorical.\nYour outcome will either be zero or one,\nor it'll be a probability that\nranges between zero and one.\nSo, that's why we have this S curve.\nNow some of you might think\nthat why do we have an S curve.\nWe can obviously have a straight line.\nWe have something known\nas a sigmoid curve,\nbecause we can have values\nranging between zero and one,\nwhich will basically show the probability.\nSo, maybe your output will be 0.7,\nwhich is a probability value.\nIf it is 0.7,\nit means that your\noutcome is basically one.\nSo that's why we have this\nsigmoid curve like this.\nOkay.\nNow I'll explain more about this\nin depth in a while.\nNow, in order to understand\nhow logistic regression works,\nfirst, let's take a look at\nthe linear regression equation.\nThis was the logistic regression equation\nthat we discussed.\nY here stands for the dependent variable\nthat needs to be predicted\nbeta naught is nothing by the y intercept.\nBeta one is nothing but the slope.\nAnd X here represents\nthe independent variable\nthat is used to predict y.\nThat E denotes the error\non the computation.\nSo, given the fact that x\nis the independent variable\nand y is the dependent variable,\nhow can we represent a\nrelationship between x an y\nso that y ranges only\nbetween zero and one?\nHere this value basically denotes\nprobably of y equal to one,\ngiven some value of x.\nSo here, because this\nPr, denotes probability\nand this value basically\ndenotes that the probability\nof y equal to one, given some value of x,\nthis is what we need to find out.\nNow, if you wanted to\ncalculate the probability\nusing the linear regression model,\nthen the probability\nwill look something like\nP of X equal to beta naught\nplus beta one into X.\nP of X will be equal to beta\nnaught plus beta one into X,\nwhere P of X nothing but\nyour probability of\ngetting y equal to one,\ngiven some value of x.\nSo the logistic regression equation\nis derived from the same equation,\nexcept we need to make a few alterations,\nbecause the output is only categorical.\nSo, logistic regression does\nnot necessarily calculate\nthe outcome as zero or one.\nI mentioned this before.\nInstead, it calculates the\nprobability of a variable\nfalling in the class zero or class one.\nSo that's how we can conclude that\nthe resulting variable must be positive,\nand it should lie between zero and one,\nwhich means that it must be less than one.\nSo to meet these conditions,\nwe have to do two things.\nFirst, we can take the\nexponent of the equation,\nbecause taking an exponential of any value\nwill make sure that you\nget a positive number.\nCorrect?\nSecondly, you have to make sure\nthat your output is less than one.\nSo, a number divided by itself plus one\nwill always be less than one.\nSo that's how we get this formula\nFirst, we take the\nexponent of the equation,\nbeta naught plus beta one plus x\nand then we divide it\nby that number plus one.\nSo this is how we get this formula.\nNow the next step is to calculate\nsomething known as a logic function.\nNow the logic function is nothing,\nbut it is a link function\nthat is represented as an S curve\nor as a sigmoid curve\nthat ranges between\nthe value zero and one.\nIt basically calculates the probability\nof the output variable.\nSo if you look at this\nequation, it's quite simple.\nWhat we have done here\nis we just cross multiply\nand take each of our beta naught\nplus beta one into x as common.\nThe RHS denotes the linear equation for\nthe independent variables.\nThe LHS represents the odd ratio.\nSo if you compute this entire thing,\nyou'll get this final value,\nwhich is basically your\nlogistic regression equation.\nYour RHS here denotes the linear equation\nfor independent variables,\nand your LHS represents the odd ratio\nwhich is also known as the logic function.\nSo I told you that logic function\nis basically a function\nthat represents an S curve\nthat bring zero and one.\nthis will make sure that our value\nranges between zero and one.\nSo in logistic regression,\non increasing this X by one measure,\nit changes the logic by\na factor of beta naught.\nIt's the same thing as I showed\nyou in logistic regression.\nSo guys, that's how you derive\nthe logistic regression equation.\nSo if you have any doubts\nregarding these equations,\nplease leave them in the comment section,\nand I'll get back to you,\nand I'll clear that out.\nSo to sum it up, logistic\nregression is used\nfor classification.\nThe output variable will always\nbe a categorical variable.\nWe also saw how you derive the\nlogistic regression equation.\nAnd one more important thing is that\nthe relationship between the variables\nand a logistic regression is denoted as\nan S curve which is also\nknows as a sigmoid curve,\nand also the outcome does not\nnecessarily have to be\ncalculated as zero or one.\nIt can be calculate as a probability\nthat the output lies in\nclass one or class zero.\nSo your output can be a probability\nranging between zero and one.\nThat's why we have a sigmoid curve.\nSo I hope all of you are clear\nwith logistic regression.\nNow I won't be showing\nyou the demo right away.\nI'll explain a couple of more\nclassification algorithms.\nThen I'll show you a practical demo\nwhere we'll use multiple\nclassification algorithms\nto solve the same problem.\nAgain, we'll also calculate the accuracy\nand se which classification\nalgorithm is doing the best.\nNow the next algorithm\nI'm gonna talk about\nis decision tree.\nDecision tree is one of\nmy favorite algorithms,\nbecause it's very simple to understand\nhow a decision tree works.\nSo guys, before this, we\ndiscussed linear regression,\nwhich was a regression algorithm.\nThen we discussed logistic regression,\nwhich is a classification algorithm.\nRemember, don't get confused just because\nit has the name logistic regression.\nOkay, it is a classification algorithm.\nNow we're discussing decision tree,\nwhich is again a classification algorithm.\nOkay.\nSo what exactly is a decision tree?\nNow a decision tree is, again,\na supervised machine learning algorithm\nwhich looks like an inverted tree\nwherein each node represents\na predictor variable,\nand the link between the\nnode represents a decision,\nand each leaf node represents an outcome.\nNow I know that's a little confusing,\nso let me make you understand\nwhat a decision tree is\nwith the help of an example.\nLet's say that you hosted a huge party,\nand you want to know\nhow many of your gusts\nare non-vegetarians.\nSo to solve this problem,\nyou can create a simple decision tree.\nNow if you look at this figure over here,\nI've created a decision\ntree that classifies a guest\nas either vegetarian or non-vegetarian.\nOur last outcome here is non-veg or veg.\nSo here you understand\nthat this is a classification algorithm,\nbecause here you're predicting\na categorical value.\nEach node over here represents\na predictor variable.\nSo eat chicken is one variable,\neat mutton is one variable,\nseafood is another variable.\nSo each node represents\na predictor variable\nthat will help you conclude whether or not\na guest is a non-vegetarian.\nNow as you traverse down the tree,\nyou'll make decisions that each node\nuntil you reach the dead end.\nOkay, that's how it works.\nSo, let's say we got a new data point.\nNow we'll pass it through\nthe decision tree.\nThe first variable is did the guest\neat the chicken?\nIf yes, then he's a non-vegetarian.\nIf no, then you'll pass\nit to the next variable,\nwhich is did the guest eat mutton?\nIf yes, then he's a non-vegetarian.\nIf no, then you'll pass\nit to the next variable,\nwhich is seafood.\nIf he ate seafood, then\nhe is a non-vegetarian.\nIf no, then he's a vegetarian.\nthis is how a decision tree works.\nIt's a very simple algorithm\nthat you can easily understand.\nIt has drawn out letters, which\nis very easy to understand.\nNow let's understand the\nstructure of a decision tree.\nI just showed you an example\nof how the decision tree works.\nNow let me take the same example\nand tell you the structure\nfor decision tree.\nSo, first of all, we have\nsomething known as the root node.\nOkay.\nThe root node is the starting point\nof a decision tree.\nHere you'll perform the first split\nand split it into two other nodes\nor three other nodes, depending\non your problem statement.\nSo the top most node is\nknown as your root node.\nNow guys, about the root node,\nthe root node is assigned to a variable\nthat is very significant,\nmeaning that that\nvariable is very important\nin predicting the output.\nOkay, so you assign a variable\nthat you think is the most\nsignificant at the root node.\nAfter that, we have something\nknown as internal nodes.\nSo each internal node\nrepresents a decision point\nthat eventually leads to the output.\nInternal nodes will have\nother predictor variables.\nEach of these are nothing\npredictor variables.\nI just made it into a question\notherwise these are just\npredictor variables.\nThose are internal nodes.\nTerminal nodes, also\nknown as the leaf node,\nrepresent the final class\nof the output variable,\nbecause these are basically your outcomes,\nnon-veg and vegetarian.\nBranches are nothing but\nconnections between nodes.\nOkay, these connections are links between\neach node is known as a branch,\nand they're represented by arrows.\nSo each branch will have\nsome response to it,\neither yes or no, true or\nfalse, one or zero, and so on.\nOkay.\nSo, guys, this is the\nstructure of a decision tree.\nIt's pretty understandable.\nNow let's move on and\nwe'll understand how the\ndecision tree algorithm works.\nNow there are many ways\nto build a decision tree,\nbut I'll be focusing on something known\nas the ID3 algorithm.\nOkay, this is something\nknown as the ID3 algorithm.\nThat is one of the ways\nin which you can build\nthe decision tree.\nID3 stands for Iterative\nDichotomiser 3 algorithm,\nwhich is one of the most\neffective algorithms\nused to build a decision tree.\nIt uses the concepts of\nentropy and information gain\nin order to build a decision tree.\nNow you don't have to know what exactly\nthe ID3 algorithm is.\nIt's just a concept behind\nbuilding a decision tree.\nNow the ID3 algorithm has\naround six defined steps\nin order to build a decision tree.\nSo the first step is you will\nselect the best attribute.\nNow what do you mean\nby the best attribute?\nSo, attribute is nothing but\nthe predictor variable over here.\nSo you'll select the\nbest predictor variable.\nLet's call it A.\nAfter that, you'll assign this A\nas a decision variable for the root node.\nBasically, you'll assign\nthis predictor variable A\nat the root node.\nNext, what you'll do\nis for each value of A,\nyou'll build a descendant of the node.\nNow these three steps, let's look at it\nwith the previous example.\nNow here the best\nattribute is eat chicken.\nOkay, this is my best\nattribute variable over here.\nSo I selected that attribute.\nAnd what is the next step?\nStep two was assigned that\nas a decision variable.\nSo I assigned eat chick\nas the decision variable\nat the root node.\nNow you might be wondering how do I know\nwhich is the best attribute.\nI'll explain all of that in a while.\nSo what we did is we assigned\nthis other root node.\nAfter that, step number three\nsays for each value of A,\nbuild a descendant of the node.\nSo for each value of this variable,\nbuild a descendant node.\nSo this variable can take\ntwo values, yes and no.\nSo for each of these values,\nI build a descendant node.\nStep number four, assign\nclassification labels\nto the leaf node.\nTo your leaf node, I have assigned\nclassification one as\nnon-veg, and the other is veg.\nThat is step number four.\nStep number five is if data\nis correctly classified,\nthen you stop at that.\nHowever, if it is not,\nthen you keep iterating over the tree,\nand keep changing the position of\nthe predictor variables in the tree,\nor you change the root node also\nin order to get the correct output.\nSo now let me answer this question.\nWhat is the best attribute?\nWhat do you mean by the best attribute\nor the best predictor variable?\nNow the best attribute is the one\nthat separates the data\ninto different classes,\nmost effectively, or it is basically\na feature that best splits the data set.\nNow the next question in your\nhead must be how do I decide\nwhich variable or which\nfeature best splits the data.\nTo do this, there are\ntwo important measures.\nThere's something known\nas information gain\nand there's something known as entropy.\nNow guys, in order to understand\ninformation gain and entropy,\nwe look at a simple problem statement.\nThis data represents the speed of a car\nbased on certain parameters.\nSo our problem statement\nhere is to study the data set\nand create a decision tree that classifies\nthe speed of the car\nas either slow or fast.\nSo our predictor variables\nhere are road type,\nobstruction, and speed limit,\nand or response variable, or\nour output variable is speed.\nSo we'll be building a decision\ntree using these variables\nin order to predict the speed of car.\nNow like I mentioned earlier,\nwe must first begin by deciding a variable\nthat best splits the data set\nand assign that particular\nvariable to the root node\nand repeat the same thing\nfor other nodes as well.\nSo step one, like we discussed earlier,\nis to select the best attribute A.\nNow, how do you know which\nvariable best separates the data?\nThe variable with the\nhighest information gain\nbest derives the data into\nthe desired output classes.\nFirst of all, we'll\ncalculate two measures.\nWe'll calculate the entropy\nand the information gain.\nNow this is where it ell\nyou what exactly entropy is,\nand what exactly information gain is.\nNow entropy is basically used to measure\nthe impurity or the uncertainty\npresent in the data.\nIt is used to decide how a\ndecision tree can split the data.\nInformation gain, on the other hand,\nis the most significant measure\nwhich is used to build a decision tree.\nIt indicates how much\ninformation a particular variable\ngives us a bout the final outcome.\nSo information gain is important,\nbecause it is used to choose a variable\nthat best splits the data at each node\nfor a decision tree.\nNow the variable with the\nhighest information gain\nwill be used to split the\ndata at the root node.\nNow in our data set, there\nare are four observations.\nSo what we're gonna do is\nwe'll start by calculating\nthe entropy and information gain\nfor each of the predictor variable.\nSo we're gonna start by\ncalculating the information gain\nand entropy for the road type variable.\nIn our data set, you can see that\nthere are four observations.\nThere are four observations\nin the road type column,\nwhich corresponds to the four\nlabels in the speed column.\nSo we're gonna begin by\ncalculating the information gain\nof the parent node.\nThe parent node is nothing but\nthe speed of the care node.\nThis is our output variable, correct?\nIt'll be used to show\nwhether the speed of the car\nis slow or fast.\nSo to find out the information gain of the\nspeed of the car variable,\nwe'll go through a couple of steps.\nNow we know that there\nare four observations\nin this parent node.\nFirst, we have slow.\nThen again we have slow, fast, and fast.\nNow, out of these four\nobservations, we have two classes.\nSo two observations\nbelong to the class slow,\nand two observations\nbelong to the class fast.\nSo that's how you calculate\nP slow and P fast.\nP slow is nothing by the fraction\nof slow outcomes in the parent node,\nand P fast is the\nfraction of fast outcomes\nin the parent node.\nAnd the formula to calculate P slow\nis the number of slow\noutcomes in the parent node\ndivided by the total number of outcomes.\nSo the number of slow outcomes\nin the parent node is two,\nand the total number of outcomes is four.\nWe have four observations in total.\nSo that's how we get P of slow as 0.5.\nSimilarly, for P of fast, you'll calculate\nthe number of fast outcomes\ndivided by the total number of outcomes.\nSo again, two by four, you'll get 0.5.\nThe next thing you'll\ndo is you'll calculate\nthe entropy of this node.\nSo to calculate the entropy,\nthis is the formula.\nAll you have to do is you\nhave to substitute the,\nyou'll have to substitute\nthe value in this formula.\nSo P of slow we're substituting as 0.5.\nSimilarly, P of fast as 0.5.\nNow when you substitute the value,\nyou'll get a answer of one.\nSo the entropy of your parent node is one.\nSo after calculating the\nentropy of the parent node,\nwe'll calculate the information\ngain of the child node.\nNow guys, remember that\nif the information gain\nof the road type variable is\ngreat than the information gain\nof all the other predictor variables,\nonly then the root node\ncan be split by using\nthe road type variable.\nSo, to calculate the information\ngain of road type variable,\nwe first need to split the root node\nby sing the road type variable.\nWe're just doing this in order to check\nif the road type variable\nis giving us maximum\ninformation about a data.\nOkay, so if you notice that\nroad type has two outcomes,\nit has two values, either steep or flat.\nNow go back to our data set.\nSo here what you can notice is\nwhenever the road type is steep,\nso first what we'll do is we'll check\nthe value of speed that we get\nwhen the road type is steep.\nSo, first, observation.\nYou see that whenever\nthe road type is steep,\nyou're getting a speed of slow.\nSimilarly, in the second observation,\nwhen the road type is steep,\nyou'll get a value of slow again.\nIf the road type is flat, you'll\nget an observation of fast.\nAnd again, if it is steep,\nthere is a value of fast.\nSo for three steep values,\nwe have slow, slow, and fast.\nAnd when the road type is flat,\nwe'll get an output of fast.\nThat's exactly what I've\ndone in this decision tree.\nSo whenever the road type is steep,\nyou'll get slow, slow or fast.\nAnd whenever the road type is flat,\nyou'll get fast.\nNow the entropy of the\nright-hand side is zero.\nEntropy is nothing but the uncertainty.\nThere's no uncertainty over here.\nBecause as soon as you see\nthat the road type is flat,\nyour output is fast.\nSo there's no uncertainty.\nBut when the road type is steep,\nyou can have any one of\nthe following outcomes,\neither your speed will be slow\nor it can be fast.\nSo you'll start by calculating the entropy\nof both RHS and LHS of the decision tree.\nSo the entropy for the right\nside child node will be zero,\nbecause there's no uncertainty here.\nImmediately, if you see\nthat the road type is flat,\nyour speed of the car will be fast.\nOkay, so there's no uncertainty here,\nand therefore your entropy becomes zero.\nNow entropy for the left-hand side\nis we'll again have to calculate\nthe fraction of P slow and\nthe fraction of P fast.\nSo out of three observations,\nin two observations we have slow.\nThat's why we have two by three over here.\nSimilarly for P fast,\nwe have one P fast\ndivided by the total number of\nobservation which are three.\nSo out of these three, we\nhave two slows and one fast.\nWhen you calculate P slow and P fast,\nyou'll get these two values.\nAnd then when you substitute\nthe entropy in this formula,\nyou'll get the entropy as 0.9\nfor the road type variable.\nI hope you all are understanding this.\nI'll go through this again.\nSo, basically, here we are calculating\nthe information gain and\nentropy for road type variable.\nWhenever you consider road type variable,\nthere are two values, steep and flat.\nAnd whenever the value\nfor road type is steep,\nyou'll get anyone of these three outcomes,\neither you'll get slow, slow, or fast.\nAnd when the road type is flat,\nyour outcome will be fast.\nNow because there is no uncertainty\nwhenever the road type is flat,\nyou'll always get an outcome of fast.\nThis means that the entropy here is zero,\nor the uncertainty value here is zero.\nBut here, there is a lot of uncertainty.\nSo whenever your road type is steep,\nyour output can either be\nslow or it can be fast.\nSo, finally, you get the Python as 0.9.\nSo in order to calculate\nthe information gain\nof the road type variable.\nYou need to calculate\nthe weighted average.\nI'll tell you why.\nIn order to calculate\nthe information gain,\nyou need to know the\nentropy of the parent,\nwhich we calculate as one,\nminus the weighted\naverage into the entropy\nof the children.\nOkay.\nSo for this formula, you need to calculate\nall of these values.\nSo, first of all, you need\nto calculate the entropy\nof the weighted average.\nNow the total number of\noutcomes in the parent node\nwe saw were four.\nThe total number of outcomes\nin the left child node were three.\nAnd the total number of\noutcomes in the right child node\nwas one.\nCorrect?\nIn order to verify this with you,\nthe total number of outcomes\nin the parent node are four.\nOne, two, three, and four.\nComing to the child node,\nwhich is the road type,\nthe total number of outcomes\non the right-hand side\nof the child node is one.\nAnd the total number of outcomes\non the left-hand side of\nthe child node is three.\nThat's exactly what\nI've written over here.\nAlright, I hope you all\nunderstood these three values.\nAfter that, all you have to do is\nyou have to substitute these\nvalues in this formula.\nSo when you do that, you'll get\nthe entropy of the children\nwith weighted average\nwill be around 0.675.\nNow just substitute the\nvalue in this formula.\nSo if you calculate the information gain\nof the road type variable,\nyou'll get a value of 0.325.\nNow by using the same method,\nyou're going to calculate\nthe information gain\nfor each of the predictor variable,\nfor road type, for obstruction,\nand for speed limit.\nNow when you follow the same method\nand you calculate the information gain,\nyou'll get these values.\nNow what does this\ninformation gain for road type\nequal to 0.325 denote?\nNow the value 0.325 for\nroad type denotes that\nwe're getting very little information gain\nfrom this road type variable.\nAnd for obstruction, we literally have\ninformation gain of zero.\nSimilarly, information gained\nfor speed limit is one.\nThis is the highest value\nwe've got for information gain.\nThis means that we'll have to\nuse the speed limit variable\nat our root node in order\nto split the data set.\nSo guys, don't get\nconfused whichever variable\ngives you the maximum information gain.\nThat variable has to be\nchosen at the root node.\nSo that's why we have the\nroot node as speed limit.\nSo if you've maintained the speed limit,\nthen you're going to go slow.\nBut if you haven't\nmaintained the speed limit,\nthen the speed of your\ncar is going to be fast.\nYour entropy is literally zero,\nand your information is one,\nmeaning that you can use this\nvariable at your root node\nin order to split the data set,\nbecause speed limit gives you\nthe maximum information gain.\nSo guys, I hope this use\ncase is clear to all of you.\nTo sum everything up,\nI'll just repeat the entire\nthing to you all once more.\nSo basically, here you were\ngiven a problem statement\nin order to create a decision tree\nthat classifies the speed of\na car as either slow or fast.\nSo you were given three\npredictor variables\nand this was your output variable.\nInformation gained in entropy\nare basically two measures\nthat are used to decide which variable\nwill be assigned to the root\nnode of a decision tree.\nOkay.\nSo guys, as soon as you\nlook at the data set,\nif you compare these two columns,\nthat is speed limit and speed,\nyou'll get an output easily.\nMeaning that if you're\nmaintaining speed limit,\nyou're going to go slow.\nBut if you aren't maintaining speed limit,\nyou're going to a fast.\nSo here itself we can\nunderstand the speed limit\nhas no uncertainty.\nSo every time you've\nmaintained your speed limit,\nyou will be going slow,\nand every time your\noutside or speed limit,\nyou will be going fast.\nIt's as simple as that.\nSo how did you start?\nSo you started by calculating\nthe entropy of the parent node.\nYou calculated the entropy\nof the parent node,\nwhich came down to one.\nOkay.\nAfter that, you calculated\nthe information gain\nof each of the child nodes.\nIn order to calculate\nthe information gain of the child node,\nyou stat by calculating the entropy\nof the right-hand side\nand the left-hand side\nof the decision tree.\nOkay.\nThen you calculate the entropy\nalong with the weighted average.\nYou substitute these values in\nthe information gain formula,\nand you get the information gain\nfor each of the predictor variables.\nSo after you get the information gain\nof each of the predictor variables,\nyou check which variable gives you\nthe maximum information gain,\nand you assign that\nvariable to your root node.\nIt's as simple as that.\nSo guys, that was all\nabout decision trees.\nNow let's look at our next\nclassification algorithm\nwhich is random forest.\nNow first of all, what is a random forest?\nRandom forest basically\nbuilds multiple decision trees\nand glues them together\nto get a more accurate\nand stable prediction.\nNow if already have decision trees\nand random forest is nothing but\na collection of decision tree,\nwhy do we have to use a random forest\nwhen we already have decision tree?\nThere are three main reasons\nwhy random forest is used.\nNow even though decision\ntrees are convenient\nand easily implemented,\nthey are not as accurate as random forest.\nDecision trees work very effectively\nwith the training data,\nbackup they're not flexible\nwhen it comes to classifying anew sample.\nNow this happens because of\nsomething known as overfitting.\nNow overfitting is a problem\nthat is seen with decision trees.\nIt's something that commonly occurs\nwhen we use decision trees.\nNow overfitting occurs\nwhen a model studies\na training data to such an extent\nthat it negatively influences\nthe performance of the\nmodel on a new data.\nNow this means that the disturbance\nin the training data is recorded,\nand it is learned as concept by the model.\nIf there's any disturbance\nor any thought of noise\nin the training data\nor any error in the training data,\nthat is also studied by the model.\nThe problem here is that these concepts\ndo not apply to the testing data,\nand it negatively impacts\nthe model's ability\nto classify new data.\nSo to sum it up,\noverfitting occurs whenever your model\nlearns the training data,\nalong with all the disturbance\nin the training data.\nSo it basically memorized\nthe training data.\nAnd whenever a new data\nwill be given to your model,\nit will not predict the\noutcome very accurately.\nnow this is a problem\nseen in decision trees.\nOkay.\nBut in random forest, there's\nsomething known as bagging.\nNow the basic idea behind bagging is\nto reduce the variations\nand the predictions\nby combining the result\nof multiple decision trees\non different samples of the data set.\nSo your data set will be\ndivided into different samples,\nand you'll be building a decision tree\non each of these samples.\nThis way, each decision\ntree will be studying\none subset of your data.\nSo this way over fitting will get reduced\nbecause one decision tree is not studying\nthe entire data set.\nNow let's focus on random forest.\nNow in order to understand random forest,\nwe look at a small example.\nWe can consider this data set.\nIn this data, we have\nfour predictor variables.\nWe have blood flow, blocked arteries,\nchest pain, and weight.\nNow these variables are used to predict\nwhether or not a person\nhas a heart disease.\nSo we're going to use this data set\nto create a random forest that predicts\nif a person has a heart disease or not.\nNow the first step in\ncreating a random forest\nis that you create a bootstrap data set.\nNow in bootstrapping, all you have to do\nis you have to randomly select samples\nfrom your original data set.\nOkay.\nAnd a point to note is that\nyou can select the same sample\nmore than once.\nSo if you look at the original data set,\nwe have a abnormal, normal,\nnormal, and abnormal.\nLook at the blood flow section.\nNow here I've randomly selected samples,\nnormal, abnormal,\nand I've selected one sample twice.\nYou can do this in a bootstrap data set.\nNow all I did here is\nI created a bootstrap data set.\nBoot strapping is nothing\nbut an estimation method\nused to make predictions on a data\nby re-sampling the data.\nThis is a bootstrap data set.\nNow even though this seems very simple,\nin real world problems,\nyou'll never get such small data set.\nOkay, so bootstrapping\nis actually a little\nmore complex than this.\nUsually in real world problems,\nyou'll have a huge data set,\nand bootstrapping that\ndata set is actually\na pretty complex problem.\nI'm here because I'm making you understand\nhow random forest works,\nso that's why I've\nconsidered a small data set.\nNow you're going to use\nthe bootstrap data set\nthat you created,\nand you're going to build\ndecision trees from it.\nNow one more thing to\nnote in random forest is\nyou will not be using\nyour entire data set.\nOkay, so you'll only be\nusing few other variables\nat each node.\nSo, for example, we'll\nonly consider two variables\nat each step.\nSo if you begin at the root node here,\nwe will randomly select two variables\nas candidates for the root node.\nOkay, let's say that\nwe selected blood flow\nand blocked arteries.\nOut of these two variables we\nhave to select the variable\nthat best separates the sample.\nOkay.\nSo for the sake of this example,\nlet's say that blocked arteries\nis the most significant predictor,\nand that's why we'll\nassign it to the root node.\nNow our next step is to\nrepeat the same process\nfor each of these upcoming branch nodes.\nHere we'll again select\ntwo variables at random\nas candidates for each\nof these branch nodes,\nand then choose a variable\nthat best separates the samples, right?\nSo let me just repeat this entire process.\nSo you know that you start\ncreating a decision tree\nby selecting the root node.\nIn random forest, you'll randomly select\na couple of variables for each node,\nand then you'll calculate which variable\nbest splits the data at that node.\nSo for each node, we'll randomly select\ntwo or three variables.\nAnd out of those two, three variables,\nwe'll see which variable\nbest separates the data.\nOkay, so at each node,\nwe'll because calculating\ninformation gain an entropy.\nBasically, that's what I mean.\nAt every node, you'll\ncalculate information gain\nand entropy of two or three variables,\nand you'll see which variable\nhas the highest information gain,\nand you'll keep descending downwards.\nThat's how you create a decision tree.\nSo we just created our\nfirst decision tree.\nNow what you do is you'll\ngo back to step one,\nand you'll repeat the entire process.\nSo each decision tree will\npredict the output class\nbased on the predictor variables\nthat you've assigned\nto each decision tree.\nNow let's say for this decision tree,\nyou've assigned blood flow.\nHere we have blocked\narteries at the root node.\nHere we might have blood flow\nat the root node and so on.\nSo your output will depend\non which predictor variable\nis at the root node.\nSo each decision tree will\npredict the output class\nbased on the predictor variable\nthat you assigned in that tree.\nNow what you do is you'll\ngo back to step one,\nyou'll create a new bootstrap data set,\nand then again you'll\nbuild a new decision tree.\nAnd for that decision tree,\nyou'll consider only\na subset of variables,\nand you'll choose the\nbest predictor variable\nby calculating the information gain.\nSo you will keep repeating this process.\nSo you just keep repeating\nstep two and step one.\nOkay.\nAnd you'll keep creating\nmultiple decision trees.\nOkay.\nSo having a variety of decision\ntrees in a random forest\nis what makes it more effective than\nan individual decision tree.\nSo instead of having an\nindividual decision tree,\nwhich is created using all the features,\nyou can build a random forest\nthat uses multiple decision trees\nwherein each decision\ntree has a random set\nof predictor variables.\nNow step number four is\npredicting the outcome\nof a new data point.\nSo now that you've\ncreated a random forest,\nlet's see how it can be used\nto predict whether a new patient\nhas a heart disease or not.\nOkay, now this diagram\nbasically has a data\nabout the new patient.\nOkay, this is the data\nabout the new patient.\nHe doesn't have blocked arteries.\nHe has chest pain, and his\nweight is around 185 kgs.\nNow all you have to do is\nyou have to run this data\ndown each of the decision\ntrees that you made.\nSo, the first decision tree shows that\nyes, this person has heart disease.\nSimilarly, you'll run the\ninformation of this new patient\nthrough every decision\ntree that you created.\nThen depending on how many\nvotes you get for yes and no,\nyou'll classify that patient\nas either having heart disease or not.\nAll you have to do is you have to run\nthe information of the new patient\nthrough all the decision\ntrees that you created\nin the previous step,\nand the final output is\nbased on the number of votes\neach of the class is getting.\nOkay, let's say that three decision trees\nsaid that yes the patient\nhas heart disease,\nand one decision tree said\nthat no it doesn't have.\nSo this means you will obviously classify\nthe patient as having a heart disease\nbecause three of them voted for yes.\nIt's based on majority.\nSo guys, I hope the concept\nbehind random forest\nis understandable.\nNow the next step is you will evaluate\nthe efficiency of the model.\nNow earlier when we created\nthe bootstrap data set\nwe left out one entry sample.\nThis is the entry sample we left out,\nbecause we repeated one sample twice.\nIf you'll remember in\nthe bootstrap data set,\nhere we repeated an entry twice,\nand we missed out on one of the entries.\nWe missed out on one of the entries.\nSo what we're gonna do is...\nSo for evaluating the model,\nwe'll be using the data\nentry that we missed out on.\nNow in a real world problem,\nabout 1/3 of the original\ndata set is not included\nin the bootstrap dataset.\nBecause there's a huge amount of data\nin a real world problem,\nso 1/3 of the original data set\nis not included in the bootstrap data set.\nSo guys, the sample data set\nwhich is not there in\nyour bootstrap data set\nis known as out-of-bag data set,\nbecause basically this is\nour out-of-bag data set.\nNow the out-of-bag data set\nis used to check the\naccuracy of the model.\nBecause the model was not created\nby using the out-of-bag data set,\nit will give us a good understanding\nof whether the model is effective or not.\nNow the out-of-bag data set\nis nothing but your testing data set.\nRemember, in machine\nlearning, there's training\nand testing data set.\nSo your out-of-bag data set\nis nothing but your testing data set.\nThis is used to evaluate the\nefficiency of your model.\nSo eventually, you can\nmeasure the accuracy\nof a random forest by the proportion\nof out-of-bag samples that\nare correctly classified,\nbecause the out-of-bag data set\nis used to evaluate the\nefficiency of your model.\nSo you can calculate the accuracy\nby understanding how many samples\nor was this out-of-bag data set\ncorrectly able to classify it.\nSo guys, that was an explanation about\nhow random forest works.\nTo give you an overview,\nlet me just run you through\nall the steps that we took.\nSo basically, this was our data set,\nand all we have to do\nis we have to predict\nwhether a patient has\nheart disease or not.\nSo, our first step was to\ncreate a bootstrap data set.\nA bootstrap data set is\nnothing but randomly selected\nobservations from your original data set,\nand you can also have duplicate values\nin your bootstrap data set.\nOkay.\nThe next step is you're going\nto create a decision tree\nby considering a random\nset of predictor variables\nfor each decision tree.\nOkay.\nSo, the third step is\nyou'll go back to step one,\ncreate a bootstrap data set.\nAgain, create a decision tree.\nSo this iteration is\nperformed hundreds of times\nuntil you are multiple decision trees.\nNow that you've created a random forest,\nyou'll use this random forest\nto predict the outcome.\nSo if you're given a new data point\nand you have to classify it\ninto one of the two classes,\nwe'll just run this new information\nthrough all the decision trees.\nAnd you'll just take the majority\nof the output that you're\ngetting from the decision trees\nas your outcome.\nNow in order to evaluate\nthe efficiency of the model,\nyou'll use the out of\nthe bag sample data set.\nNow the out-of-bag sample\nis basically the sample\nthat was not included in\nyour bootstrap data set,\nbut this sample is coming\nfrom your original data set, guys.\nThis is not something\nthat you randomly create.\nThis data set was there\nin your original data set,\nbut it was just not mentioned\nin your bootstrap data set.\nSo you'll use your out-of-bag sample\nin order to calculate the accuracy\nof your random forest.\nSo the proportion of out-of-bag samples\nthat are correctly classified\nwill give you the accuracy\nof your model.\nSo that is all for random forest.\nSo guys, I'll discuss other\nclassification algorithms with you,\nand only then I'll show you a demo on\nthe classification algorithms.\nNow our next algorithm is\nsomething known as naive Bayes.\nNaive Bayes is, again,\na supervised classification algorithm,\nwhich is based on the Bayes Theorem.\nNow the Bayes Theorem basically follows\na probabilistic approach.\nThe main idea behind naive Bayes is that\nthe predictor variables in\na machine learning model\nare independent of each other,\nmeaning that the outcome of a model\ndepends on a set of independent variables\nthat have nothing to do with each other.\nNow a lot of you might\nask why is naive Bayes\ncalled naive.\nNow usually, when I tell\nanybody why naive Bayes,\nthey keep asking me why is\nnaive Bayes called naive.\nSo in real world problems\npredictor variables\naren't always independent of each other.\nThere is always some correlation\nbetween the independent variables.\nNow because naive Bayes\nconsiders each predictor variable\nto be independent of any\nother variable in the model,\nit is called naive.\nThis is an assumption\nthat naive Bayes states.\nNow let's understand the math\nbehind the naive Bayes algorithm.\nSo like I mentioned, the\nprinciple behind naive Bayes\nis the Bayes Theorem,\nwhich is also known as the Bayes Rule.\nThe Bayes Theorem is used to calculate\nthe conditional probability,\nwhich is nothing but the\nprobability of an event occurring\nbased on information about\nthe events in the past.\nThis is the mathematical\nequation for the Bayes Theorem.\nNow, in this equation, the LHS is nothing\nbut the conditional probability\nof event A occurring,\ngiven the event B.\nP of A is nothing but\nprobability of event A occurring\nP of B is probability of event B.\nAnd PB of A is nothing but\nthe conditional probability\nof event B occurring, given the event A.\nNow let's try to understand\nhow naive Bayes works.\nNow consider this data set of\naround thousand 500 observations.\nOkay, here we have the\nfollowing output classes.\nWe have either cat, parrot, or turtle.\nThese are our output classes,\nand the predictor variables are\nswim, wings, green color, and sharp teeth.\nOkay.\nSo, basically, your type\nis your output variable,\nand swim, wings, green, and sharp teeth\nare your predictor variables.\nYour output variables has three classes,\ncat, parrot, and turtle.\nOkay.\nNow I've summarized this table\nI've shown on the screen.\nThe first thing you can see\nis the class of type cats\nshows that out of 500 cats,\n450 can swim,\nmeaning that 90% of them can.\nAnd zero number of cats have wings,\nand zero number of cats\nare green in color,\nand 500 out of 500 cats have sharp teeth.\nOkay.\nNow, coming to parrot, it\nsays 50 out of 500 parrots\nhave true value for swim.\nNow guys, obviously,\nthis does not hold true\nin real world.\nI don't think there are\nany parrots who can swim,\nbut I've just created this data set\nso that we can understand naive Bayes.\nSo, meaning that 10% of parrots\nhave true value for swim.\nNow all 500 parrots have wings,\nand 400 out of 500 parrots\nare green in color,\nand zero parrots have sharp teeth.\nComing to the turtle class,\nall 500 turtles can swim.\nZero number of turtles have wings.\nAnd out of 500, hundred\nturtles are green in color,\nmeaning that 20% of the\nturtles are green in color.\nAnd 50 out of 500\nturtles have sharp teeth.\nSo that's what we understand\nfrom this data set.\nNow the problem here is\nwe are given our observation over here,\ngiven some value for swim,\nwings, green, and sharp teeth.\nWhat we need to do is we need to predict\nwhether the animal is a\ncat, parrot, or a turtle,\nbased on these values.\nSo the goal here to predict\nwhether it is a cat,\nparrot, or a turtle\nbased on all these defined parameters.\nOkay.\nBased on the value of swim,\nwings, green, and sharp teeth,\nwe'll understand whether\nthe animal is a cat,\nor is it a parrot, or is it a turtle.\nSo, if you look at the observation,\nthe variables swim and\ngreen have a value of true,\nand the outcome can be\nanyone of the types.\nIt can either be a cat,\nit can be a parrot,\nor it can be a turtle.\nSo in order to check\nif the animal is a cat,\nall you have to do is\nyou have to calculate\nthe conditional probability at each step.\nSo here what we're doing is\nwe need to calculate the probability that\nthis is a cat,\ngiven that it can swim\nand it is green in color.\nFirst, we'll calculate the\nprobability that it can swim,\ngiven that it's a cat.\nAnd two, the probability that it is green\nand the probability of it being green,\ngiven that it is a cat,\nand then we'll multiply it\nwith the probability of it being a cat\ndivided by the probability\nof swim and green.\nOkay.\nSo, guys, I know you all can\ncalculate the probability.\nIt's quite simple.\nSo once you calculate\nthe probability here,\nyou'll get a direct value of zero.\nOkay, you'll get a value of zero,\nmeaning that this animal\nis definitely not a cat.\nSimilarly, if you do this for parrots,\nyou calculate a conditional probability,\nyou'll get a value of 0.0264\ndivided by probability\nof swim comma green.\nWe don't know this probability.\nSimilarly, if you check\nthis for the turtle,\nyou'll get a probability of 0.066\ndivided by P swim comma green.\nOkay.\nNow for these calculations,\nthe denominator is the same.\nThe value of the denominator is the same,\nand the value of and the probability of it\nbeing a turtle is greater\nthan that of a parrot.\nSo that's how we can correctly predict\nthat the animal is actually a turtle.\nSo guys, this is how naive Bayes works.\nYou basically calculate\nthe conditional probability at each step.\nWhatever classification needs to be done,\nthat has to be calculated\nthrough probability.\nThere's a lot of statistic\nthat comes into naive Bayes.\nAnd if you all want to\nlearn more about statistics\nand probability,\nI'll leave a link in the description.\nYou all can watch that video as well.\nThere I've explain exactly\nwhat conditional probability is,\nand the Bayes Theorem is\nalso explained very well.\nSo you all can check out that video also.\nAnd apart from this, if\nyou all have any doubts\nregarding any of the algorithms,\nplease leave them in the comment section.\nOkay, I'll solve your doubts.\nAnd apart from that, I'll\nalso leave a couple of links\nfor each of the algorithms\nin the description box.\nBecause if you want more\nin-depth understanding\nof each of the algorithms,\nyou can check out that content.\nSince this is a full course video,\nI have to cover all the topics,\nand it is hard for me\nto make you understand\nin-depth of each topic.\nSo I'll leave a couple of\nlinks in the description box.\nYou can watch those videos as well.\nMake sure you checkout the probability\nand statistics video.\nSo now let's move on and\nlocate our next algorithm,\nwhich is the K nearest neighbor algorithm.\nNow KNN, which basically\nstands for K nearest neighbor,\nis, again, a supervised\nclassification algorithm\nthat classifies a new data\npoint into the target class\nor the output class,\ndepending on the features\nof its neighboring data points.\nThat's why it's called K nearest neighbor.\nSo let's try to understand\nKNN with a small analogy.\nOkay, let's say that we want a machine\nto distinguish between the\nimages of cats and dogs.\nSo to do this, we must input our data set\nof cat and dog images,\nand we have to train our\nmodel to detect the animal\nbased on certain features.\nFor example, features such as pointy ears\ncan be used to identify cats.\nSimilarly, we can identify dogs\nbased on their long ears.\nSo after starting the data set\nduring the training phase,\nwhen a new image is given to the model,\nthe KNN algorithm will classify it\ninto either cats or dogs,\ndepending on the similarity\nin their features.\nOkay, let's say that a\nnew image has pointy ears,\nit will classify that image as cat,\nbecause it is similar to the cat images,\nbecause it's similar to its neighbors.\nIn this manner, the KNN\nalgorithm classifies\nthe data point based\non how similar they are\nto their neighboring data points.\nSo this is a small example.\nWe'll discuss more about\nit in the further slides.\nNow let me tell you a couple of\nfeatures of KNN algorithm.\nSo, first of all, we know that\nit is a supervised learning algorithm.\nIt uses labeled input data set\nto predict the output of the data points.\nThen it is also one of the simplest\nmachine learning algorithms,\nand it can be easily implemented\nfor a varied set of problems.\nAnother feature is that\nit is non-parametric,\nmeaning that it does not\ntake in any assumptions.\nFor example, naive Bayes\nis a parametric model,\nbecause it assumes that all\nthe independent variables\nare in no way related to each other.\nIt has assumptions about the model.\nK nearest neighbor has\nno such assumptions.\nThat's why it's considered\na non-parametric model.\nAnother feature is that\nit is a lazy algorithm.\nNow, lazy algorithm\nbasically is any algorithm\nthat memorizes the training set,\ninstead of learning a\ndiscriminative function\nfrom the training data.\nNow, even though KNN is mainly\na classification algorithm,\nit can also be used for regression cases.\nSo KNN is actually both a classification\nand a regression algorithm.\nBut mostly, you'll see that it'll be used\non the four classification problems.\nThe most important feature about\na K nearest neighbor is that\nit's based on feature similarity\nwith its neighboring data points.\nYou'll understand this\nin the example that I'm gonna tell you.\nNow, in this image, we\nhave two classes of data.\nWe have class A which is squares\nand class B which are triangles.\nNow the problem statement is to assign\nthe new input data point\nto one of the two classes\nby using the KNN algorithm.\nSo the first step in the KNN algorithm\nis to define the value of K.\nBut what is the K in the\nKNN algorithm stand for?\nNow the K stands for the\nnumber of nearest neighbors,\nand that's why it's got the\nname K nearest neighbors.\nNow, in this image, I've\ndefined the value of K as three.\nThis means that the algorithm\nwill consider the three neighbors\nthat are closest to the new data point\nin order to decide the\nclass of the new data point.\nSo the closest between the data point\nis calculated by using measure\nsuch as Euclidean distance\nand Manhattan distance,\nwhich I'll be explaining in a while.\nSo our K is equal to three.\nThe neighbors include two\nsquares and one triangle.\nSo, if I were to classify\nthe new data point\nbased on K equal to three,\nthen it should be assigned\nto class A, correct?\nIt should be assigned to squares.\nBut what if the K value is set to seven.\nHere I'm basically telling my algorithm\nto look for the seven nearest neighbors\nand classify the new data point\ninto the class it is most similar to.\nSo our K equal to seven.\nThe neighbors include three\nsquares and four triangles.\nSo if I were to classify\nthe new data point\nbased on K equal to seven,\nthen it would be assigned to class B,\nsince majority of its\nneighbors are from class B.\nNow this is where a\nlot of us get confused.\nSo how do we know which K\nvalues is the most suitable\nfor K nearest neighbor.\nNow there are a couple methods\nused to calculate the K value.\nOne of them is known as the elbow method.\nWe'll be discussing the elbow method\nin the upcoming slides.\nSo for now let me just show you\nthe measures that are involved behind KNN.\nOkay, there's very simple math\nbehind the K nearest neighbor algorithm.\nSo I'll be discussing the\nEuclidean distance with you.\nNow in this figure, we have\nto measure the distance\nbetween P one and P two by\nusing Euclidean distance.\nI'm sure a lot of you\nalready know what Euclidean distance is.\nIt is something that we learned\nin eighth or 10th grade.\nI'm not sure.\nSo all you're doing is\nyou're extracting X one.\nSo the formula is\nbasically x two minus x one\nthe whole square\nplus y two minus y one the whole square,\nand the root of that is\nthe Euclidean distance.\nIt's as simple as that.\nSo Euclidean distance is used\nas a measure to check the\ncloseness of data points.\nSo basically, KNN uses\nthe Euclidean distance\nto check the closeness of a new data point\nwith its neighbors.\nSo guys, it's as simple as that.\nKNN makes use of simple measures\nin order to solve very complex problems.\nOkay, and this is one of the reasons why\nKNN is such a commonly used algorithm.\nComing to support vector machine.\nNow, this is our last algorithm\nunder classification algorithms.\nNow guys, don't get paranoid\nbecause of the name.\nSupport vector machine actually\nis one of the simplest algorithms\nin supervised learning.\nOkay, it is basically\nused to classify data\ninto different classes.\nIt's a classification algorithm.\nNow unlike most algorithms,\nSVM makes use of something\nknown as a hyperplane\nwhich acts like a decision boundary\nbetween the separate classes.\nOkay.\nNow SVM can be used to generate multiple\nseparating hyperplane,\nsuch that the data is\ndivided into segments,\nand each segment contains\nonly one kind of data.\nSo, a few features of SVM include that\nit is a supervised learning algorithm,\nmeaning that it's going to\nstudy a labeled training data.\nAnother feature is that it is again\na regression and a\nclassification algorithm.\nEven though SVM is mainly\nused for classification,\nthere is something known as\nthe support vector regressor.\nThat is useful regression problems.\nNow, SVM can also be used\nto classify non-linear data\nby using kernel tricks.\nNon-linear data is basically data\nthat cannot be separated\nby using a single linear line.\nI'll be talking more about this\nin the upcoming slides.\nNow let's move on and\ndiscuss how SVM works.\nNow again, in order to make you understand\nhow support vector machine works,\nyou look at a small scenario.\nFor a second, pretend that you own a farm\nand you have a problem.\nYou need to set up a fence\nto protect your rabbits\nfrom a pack of wolves.\nOkay, now, you need to decide\nwhere you want to build your fence.\nSo one way to solve\nthe problem is by using\nsupport vector machines.\nSo if I do that and if I try\nto draw a decision boundary\nbetween the rabbits and the wolves,\nit looks something like this.\nNow you can clearly build\na fence along this line.\nSo in simple terms, this is exactly how\nyour support vector machines work.\nIt draws a decision boundary,\nwhich is nothing but a hyperplane\nbetween any two classes\nin order to separate them\nor classify them.\nNow I know that you're\nthinking how do you know\nwhere to draw a hyperplane.\nThe basic principle behind SVM\nis to draw a hyperplane\nthat best separates the two classes.\nIn our case, the two classes\nare the rabbits and the wolves.\nNow before we move any further,\nlet's discuss the different terminologies\nthat are there in support vector machine.\nSo that is basically a hyperplane.\nIt is a decision boundary\nthat best separates\nthe two classes.\nNow, support vectors, what\nexactly are support vectors.\nSo when you start with the\nsupport vector machine,\nyou start by drawing a random hyperplane.\nAnd then you check the distance\nbetween the hyperplane\nand the closest data point\nfrom each of the class.\nThese closest data\npoints to the hyperplane\nare known as support vectors.\nNow these two data points\nare the closest to your hyperplane.\nSo these are known as support vectors,\nand that's where the name comes from,\nsupport vector machines.\nNow the hyperplane is drawn\nbased on these support vectors.\nAnd optimum hyperplane will be\nthe one which has a maximum distance\nfrom each of the support vectors,\nmeaning that the distance\nbetween the hyperplane\nand the support vectors has to be maximum.\nSo, to sum it up, SVM\nis used to classify data\nby using a hyperplane,\nsuch that the distance\nbetween the hyperplane\nand the support vector is maximum.\nNow this distance is\nnothing but the margin.\nNow let's try to solve a problem.\nLet's say that I input a new data point\nand I want to draw a hyperplane\nsuch that it best separates\nthese two classes.\nSo what do I do?\nI start out by drawing a hyperplane,\nand then I check the distance\nbetween the hyperplane\nand the support vectors.\nSo, basically here, I'm trying to check\nif the margin is maximum\nfor this hyperplane.\nBut what if I drew the\nhyperplane like this?\nThe margin for this hyperplane\nis clearly being more\nthan the previous one.\nSo this is my optimal hyperplane.\nThis is exactly how you understand\nwhich hyperplane needs to be chosen,\nbecause you can draw multiple hyperplanes.\nNow, the best hyperplane is the one\nthat has a maximum module.\nSo, this is my optimal hyperplane.\nNow so far it was quite easy.\nOur data was linearly separable,\nwhich means that you\ncould draw a straight line\nto separate the two classes.\nBut what will you do if\nthe data looks like this?\nYou possibly cannot draw\na hyperplane like this.\nYou possibly cannot draw\na hyperplane like this.\nIt doesn't separate the two classes.\nWe can clearly see rabbits and wolves\nin both of the classes.\nNow this is exactly where non-linear SVM\ncomes into the picture.\nOkay, this is what the\nkernel trick is all about.\nNow, kernel is basically\nsomething that can be used\nto transform data into another dimension\nthat has a clear dividing\nmargin between classes of data.\nSo, basically the kernel function\noffers the user the option of transforming\nnon-linear spaces into linear ones.\nUntil this point, if you notice that\nwe were plotting our data\non two dimensional space.\nWe had x and y-axis.\nA simple trick is transforming\nthe two variables,\nx and y, into a new feature space,\nwhich involves a new variable z.\nSo, basically, what we're doing\nis we're visualizing the data\non a three dimensional space.\nSo when you transform the\n2D space into a 3D space,\nyou can clearly see a dividing margin\nbetween the two classes of data.\nYou can clearly draw a line in the middle\nthat separates these two data sets.\nSo guys, this sums up\nthe whole idea behind\nsupport vector machines.\nSupport vector machines are\nvery easy to understand.\nNow, this was all for our\nsupervised learning algorithms.\nNow, before I move on to\nunsupervised learning algorithms,\nI'll be running a demo.\nWe'll be running a demo\nin order to understand all\nthe classification algorithms\nthat we studied so far.\nEarlier in the session, we ran a demo\nfor the regression algorithms.\nNow we'll run for the\nclassification algorithms.\nSo, enough of theory.\nLet's open up Python,\nand let's start looking at how\nthese classification algorithms work.\nNow, here what we'll be doing\nis we'll implement multiple\nclassification algorithms\nby using the scikit-learn.\nOkay, it's one of the most popular\nmachine learning tool for Python.\nNow we'll be using a simple data set\nfor the task of training a\nclassifier to distinguish\nbetween the different types of fruits.\nThe purpose of this demo is to implement\nmultiple classification algorithms\nfor the same set of problem.\nSo as usual, you start by importing\nall your libraries in Python.\nAgain, guys, if you don't know Python,\ncheck the description box,\nI'll leave a link there.\nYou can go through that video as well.\nNext, what we're doing is\nwe're reading the fruit data\nin the form of table.\nYou stored it in a variable called fruits.\nNow if you wanna see the\nfirst few rows of the data,\nlet's print the first few\nobservations in our data set.\nSo, this is our data set.\nThese are the fruit labels.\nSo we have around four\nfruits in our data set.\nWe have apple, we have mandarin,\norange, and lemon.\nOkay.\nNow, fruit label denotes\nnothing but the label\nof apple, which is one.\nMandarin has two.\nSimilarly, orange is labeled as three.\nAnd lemon is labeled as four.\nThen a fruit subtype is basically\nthe family of fruit it belongs to.\nMass is the mass of the fruit,\nwidth, height, and color score.\nThese are all our predictor variables.\nWe have to identify the type of fruit,\ndepending on these predictor variables.\nSo, first, we saw a couple\nof observations over here.\nNext, if you want to see\nthe shape of your data set,\nthis is what it looks like.\nThere are around 59 observations with\nseven predictor variables,\nwhich is one, two, three,\nfour, five, six, and seven.\nWe have seven variables in total.\nSorry, not predictor variables.\nThis seven denotes both your predictor\nand your target variable.\nNext, I'm just showing you\nthe four fruits that we have\nin our data set,\nwhich is apple, mandarin,\norange, and lemon.\nNext, I'm just grouping\nfruits by their names.\nOkay.\nSo we have 19 apples in our data set.\nWe have 16 lemons.\nWe have only five mandarins,\nand we have 19 oranges.\nEven though the number of\nmandarin samples is low,\nwe'll have to work with it,\nbecause right now I'm\njust trying to make you\nunderstand the classification algorithms.\nThe main aim for me\nbehind doing these demos\nis so that you understand\nhow classification algorithms work.\nNow what you can do is\nyou can also plot a graph\nin order to see the frequency\nof each of these fruits.\nOkay, I'll show you what\nthe plot looks like.\nThe number of apples\nand oranges is the same.\nWe have I think around\n19 apples and oranges.\nAnd similarly, this is\nthe count for lemons.\nOkay.\nSo this is a small visualization.\nGuys, visualization is\nactually very important\nwhen it comes to machine learning,\nbecause you can see most of the relations\nand correlations by plotting graphs.\nYou can't see those correlations\nby just running code and all of that.\nOnly when you plot different\nvariables on your graph,\nyou'll understand how they are related.\nOne of the main task in machine learning\nis to visualize data.\nIt ensures that you understand\nthe correlation between data.\nNext, what we're gonna do is we'll graph\nsomething known as a box plot.\nOkay, a box plot basically\nhelps you understand\nthe distribution of your data.\nLet me run the box plot,\nand I'll show you what exactly I mean.\nSo this is our box plot.\nSo, box plot will basically give you\na clearer idea of the distribution\nof your input variables.\nIt is mainly used in\nexploratory data analysis,\nand it represents the\ndistribution of the data\nand its variability.\nNow, the box plot contains\nupper quartile and lower quartile.\nSo the box plot basically\nspanned your interquartile range\nor something known as IQR.\nIQR is nothing but your third quartile\nsubtracted from your first quartile.\nNow again, this involves\nstatistics and probability.\nSo I'll be leaving a link\nin the description box.\nYou can go through that video.\nI've explained statistics\nprobability, IQR,\nrange, and all of that in there.\nSo, one of the main reasons\nwhy box plots are used\nis to detect any sort\nof outliers in the data.\nSince the box plot spans the IQR,\nit detects the data point\nthat lie outside the average range.\nSo if you see in the colored space,\nmost of the data is\ndistributed around the IQR,\nwhereas here the data are\nnot that well distributed.\nHeight also is not very well distributed,\nbut color space is\npretty well distributed.\nThis is what the box plot shows you.\nSo guys, this involves a lot of math.\nALl of these, each and every\nfunction in machine learning\ninvolves a lot of math.\nSo you know it's necessary\nto have a good understanding\nof statistics, probability,\nand all of that.\nNow, next, what we'll do\nis we'll plot a histogram.\nHistogram will basically show you\nthe frequency of occurrence.\nLet me just plot this, and\nthen we'll try and understand.\nSo here you can understand\na few correlations.\nOkay, some pairs of these\nattributes are correlated.\nFor example, mass and width,\nthey're somehow correlated\nalong the same ranges.\nSo this suggests a high correlation\nand a predictable relationship.\nLike if you look at the\ngraphs, they're quite similar.\nSo for each of the predictor variables,\nI've drawn a histogram.\nFor each of that input data,\nwe've drawn a histogram.\nNow guys, again, like i said,\nplotting graphs is very important\nbecause you understand\na lot of correlations\nthat you cannot understand\nby just looking at your data,\nor just running operations on your data.\nRepeat, or just running code on your data.\nOkay.\nNow, next, what we're\ndoing here is we're just\ndividing the data set into\ntarget and predictor variables.\nSo, basically, I've created\nan array of feature names\nwhich has your predictor variables.\nIt has mass, width, height, color space.\nAnd you have assigned that as X,\nsince this is your input,\nand y is your output\nwhich is your fruit label.\nThat'll show whether it is an apple,\norange, lemon, and so on.\nNow, the next step that\nwe'll perform over here\nis pretty evident.\nAgain, this is data splicing.\nSo data splicing, by now,\nI'm sure all of you know what it is.\nIt is splitting your data into\ntraining and testing data.\nSo that's what we've done over here.\nNext, we're importing something\nknown as the MinMaxScaler.\nScaling or normalizing your data\nis very important in machine learning.\nNow, I'm seeing this because your raw data\ncan be very biased.\nSo it's very important\nto normalize your data.\nNow when I say normalize your data,\nso if you look at the value of mass\nand if you look at the\nvalue of height and color,\nyou see that mass is ranging\nin hundreds and double digits,\nwhereas height is in single digit,\nand color score is not\neven in single digits.\nSo, if some of your variables\nhave a very high range,\nyou know they have a very high scale,\nlike they're in two\ndigits or three digits,\nwhereas other variables are\nsingle digits and lesser,\nthen your output is\ngoing to be very biased.\nIt's obvious that it's\ngonna be very biased.\nThat's why you have to scale your data\nin such a way that all of these values\nwill have a similar range.\nSo that's exactly what\nthe scaler function does.\nOkay.\nNow since we have already divided our data\ninto training and testing data,\nour next step is to build the model.\nSo, first, we're gonna be using\nthe logistic regression algorithm.\nI've already discussed logistic\nregression with you all.\nIt's a classification algorithm,\nwhich is basically used\nto predict the outcome\nof a categorical variable.\nSo we already have the logistic\nregression class in Python.\nAll you have to do is you have to\ngive an instance for this function,\nwhich is logreg over here.\nAnd I'm fitting this instance\nwith a training data set,\nmeaning that I'm running the algorithm\nwith the training data set.\nOnce you do that, you can calculate\nthe accuracy by using this function.\nSo here I'm calculate the accuracy\non the training data set\nand on the testing data set.\nOkay, so let's look at the output of this.\nNow guys, ignore this future warning.\nWarnings are ignored in Python.\nNow, accuracy of the logistic\nregression classifier\non the training data set is around 70%.\nIt was pretty good on\nthe training data set.\nBut when it comes to classifying\non the test data set,\nit's only 40%,\nwhich is not that good for a classifier.\nNow again, this can depend\non the problem statement,\nfor which problem statement\nis logistic regression more suitable.\nNext, we'll do the same thing\nusing the decision tree.\nSo again, we just call the\ndecision tree function,\nand we'll fit it with\nthe training data set,\nand we'll calculate the accuracy\nof the decision tree on the training,\nand the testing data set.\nSo if you do that for a decision tree\non the training data set,\nyou get 100% accuracy.\nBut on the testing data set,\nyou have around 87% of accuracy.\nThis is something that I\ndiscussed with you all earlier,\nthat this is decision trees are very good\nwith training data set,\nbecause of a process known as overfitting.\nBut when it comes to classifying\nthe outcome on the testing data set,\nthe accuracy reduces.\nNow, this is very good compared\nto logistic regression.\nFor this problem statement, decision trees\nworks better that logistic regression.\nComing to KNN classifier.\nAgain, all you have to do is you have to\ncall the K neighbor\nclassifier, this function.\nAnd you have to fit this\nwith the training data set.\nIf you calculate the accuracy\nfor a KNN classifier,\nwe get a good accuracy actually.\nOn the training data set,\nwe get an accuracy of 95%.\nAnd on the testing data set, it's 100%.\nThat is really good,\nbecause our testing data set\nactually achieved more of an accuracy\nthan on a training data set.\nNow all of this depends on the value of K\nthat you've chosen for KNN.\nNow, I mentioned that\nyou use the elbow method\nto choose the K value in\nthe K nearest neighbor.\nI'll be discussing the elbow\nmethod in the next section.\nSo, don't worry if you\nhaven't understood that yet.\nNow, we're also using a\nnaive Bayes classifier.\nHere we're using a Gaussian\nnaive Bayes classifier.\nGaussian is basically a type\nof naive Bayes classifier.\nI'm not going to go into depth of this,\nbecause it'll just extend our\nsession too much more longer.\nOkay.\nAnd if you want to know more about this,\nI'll leave a link in the description box.\nYou can read all about the\ncaution naive Bayes classifier.\nNow, the math behind this is the same.\nIt uses naive Bayes, it uses\nthe Bayes Theorem itself.\nNow again, we're gonna call this class,\nand then we're going to run our data,\ntraining data on it.\nSo using the naive Bayes classifier,\nwe're getting an accuracy of 0.86\non the training data set.\nAnd on the testing data set,\nwe're getting 67% accuracy.\nOkay.\nNow let's do the same thing\nwith support vector machines.\nImporting the support vector classifier.\nAnd we are fitting the training\ndata into the algorithm.\nWe're getting an accuracy of around 61%\non the training data set and\n33% on the testing data set.\nNow guys, this accuracy and all\ndepends also on the problem statement.\nIt depends on the type of data\nthat support vector machines get.\nUsually, SVM is very\ngood on large data sets.\nNow since we have a very\nsmall data set over here,\nit's sort of obvious by\nthe accuracy, so less.\nSo guys, these were a couple\nof classification algorithms\nthat I showed you here.\nNow, because our KNN classifier\nclassified our data set more accurately\nwe'll look at the predictions\nthat the KNN classifier mean.\nOkay\nNow we're storing all our predicted values\nin the predict variable.\nnow in order to show you the accuracy\nof the KNN model,\nwe're going to us something\nknown as the confusion matrix.\nSo, a confusion matrix is a table\nthat is often used to describe\nthe performance of a classification model.\nSo, confusion matrix actually\nrepresents a tabular representation\nof actual versus predicted values.\nSo when you draw a confusion matrix\non the actual versus predicted values\nfor the KNN classifier,\nthis is what the confusion\nmatrix looks like.\nNow, we have four rows over here.\nIf you see, we have four rows.\nThe first row represents apples,\nsecond, mandarin, third represents lemons,\nand fourth, oranges.\nSo this four value corresponds\nto zero comma zero,\nmeaning that it was\ncorrectly able to classify\nall the four apples.\nOkay.\nThis one value represents one comma one,\nmeaning that our classifier\ncorrectly classified\nthis as mandarins.\nThis matrix is drawn on actual values\nversus predicted values.\nNow, if you look at the summary\nof the confusion matrix,\nwe'll get something known\nas precision recall,\nf1-score and support.\nPrecision is basically the ratio\nof the correctly predicted\npositive observations\nto the total predicted\npositive observations.\nSo the correctly predicted\npositive observations are four,\nand there are total of four apples\nin the testing data set.\nSo that's where I get a precision of one.\nOkay.\nRecall on the other hand\nis the ratio of correctly\npredicted positive observations\nto all the observations in the class.\nAgain, we've correctly\nclassified four apples,\nand there are a total of four apples.\nF1-score is nothing but\nthe weighted average\nof your precision and your recall.\nOkay, and your support basically denotes\nthe number of data points\nthat were correctly classified.\nSo, in our KNN algorithm,\nsince we got 100% accuracy,\nall our data points were\ncorrectly classified.\nSo, 15 out of 15 were correctly classified\nbecause we have 100% accuracy.\nSo that's how you read a confusion matrix.\nOkay, you have four important measures,\nprecision, recall, f1-score, and support.\nF1-score is just the ratio\nor the weighted average\nof your precision and your recall.\nSo precision is basically\nthe correctly predicted\npositive observations\nto the total predicted\npositive observations.\nRecall is a ratio of the predicted\npositive observations to\nall your observations.\nSo guys, that was it for the demo\nof classification algorithms,\nwe discuss regression algorithms\nand we discussed\nclassification algorithms.\nNow it's time to talk about unsupervised\nlearning algorithms.\nUnder unsupervised learning algorithms\nmay try to solve clustering problems.\nAnd the most important\nclustering algorithm there is,\nknown as K-means clustering.\nSo we're going to discuss\nthe K-means algorithm,\nand also show you a demo\nwhere we'll be executing\nthe clustering algorithm,\nand you're seeing how it\nimplemented to solve a problem.\nNow, the main aim of the K-means algorithm\nis to group similar elements\nor data points in to a cluster.\nSo it is basically the process by which\nobjects are classified\ninterest a predefined number of groups,\nso that they are much\ndissimilar as possible\nfrom one group to another group,\nbut as much similar as\npossible within each group.\nNow what I mean is let's\nsay you're trying to cluster\nthis population into\nfour different groups,\nsuch that each group has people within\na specified range of age.\nLet's say group one is of people\nbetween the age 18 and 22.\nSimilarly, group two is between 23 and 35.\nGroup three is 36 and 39\nor something like that.\nSo let's say you're trying to cluster\npeople into different\ngroups based on their age.\nSo for such problems, you can make use\nof the K-means clustering algorithm.\nOne of the major applications\nof the clustering algorithm\nis seen in targeted marketing.\nI don't know how many of you are aware\nof targeted marketing.\nTargeted marketing is all about\nmarketing a specific product\nto a specific audience.\nLet's say you're trying\nto sell fancy clothes\nor a fancy set of bags and all of that.\nAnd the perfect audience for such product\nwould be teenagers.\nIt would be people around\nthe age of 16 to 21 or 18.\nSo that is what target\nmarketing is all about.\nYour product is marketed\nto a specific audience\nthat might be interested in it.\nThat is what targeted marketing is.\nSo K means clustering is use\nmajorly in targeted marketing.\nA lot of eCommerce websites\nlike Amazon, Flipkart, eBay.\nAll of these make use\nof clustering algorithms\nin order to target the right audience.\nNow let's see how the\nK-means clustering works.\nNow the K in K-means denotes\nthe number of clusters.\nLet's say I give you a data\nset containing 20 points,\nand you want to cluster this\ndata set into four clusters.\nThat means your K will be equal to four.\nSo K basically stands for\nthe number of clusters\nin your data set,\nor the number of clusters\nyou want to form.\nYou start by defining the number K.\nNow for each of these clusters,\nyou're going to choose a centroid.\nSo for every cluster,\nthere are four cluster in our data set.\nFor each of these clusters,\nyou'll randomly select\none of the data points\nas a centroid.\nNow what you'll do is you'll start\ncomputing the distance from that centroid\nto every other point in that cluster.\nAs you keep computing the centroid\nand the distance between the centroid\nand other data points in that cluster,\nyour centroid keep shifting,\nbecause you're trying to get\nto the average of that cluster.\nWhenever you're trying to get\nto the average of the cluster,\nthe centroid keeps shifting,\nbecause the centroid keeps\nconverging and it keeps shifting.\nLet's try to understand how K-means works.\nLet's say that this data\nset, this is given to us.\nLet's say if you're given\nrandom points like these\nand you're asked to us\nK-means algorithm on this.\nSo your first step will be\nto decide the number of\nclusters you want to create.\nSo let's say I wanna create\nthree different clusters.\nSo my K value will be equal to three.\nThe next step will be to provide\ncentroids of all the clusters.\nWhat you'll do is initially\nyou'll randomly pick\nthree data points as your centroids\nfor your three different clusters.\nSo basically, this red denotes\nthe centroid for one cluster.\nBlue denotes a centroid\nfor another cluster.\nAnd this green dot denotes the centroid\nfor another cluster.\nNow what happens in K-means,\nthe algorithm will calculate\nthe Euclidean distance of\nthe points from each centroid\nand assign the points\nto the closest cluster.\nNow since we had three centroids here,\nnow what you're gonna do is\nyou're going to calculate the distance\nfrom each and every data point\nto all the centroids,\nand you're going to check which data point\nis closest to which centroid.\nSo let's say your data point A\nis closest to the blue centroid.\nSo you're going to assign the data point A\nto the blue cluster.\nSo based on the distance\nbetween the centroid and the cluster,\nyou're going to form\nthree different clusters.\nNow again, you're going\nto calculate the centroid\nand you're going to form a new cluster\nwhich is from better clusters,\nbecause you're recomputing\nall those centroids.\nBasically, your centroids represent\nthe mean of each of your cluster.\nSo you need to make sure\nthat your mean is actually\nthe centroid of each cluster.\nSo you'll keep recomputing this centroids\nuntil the position of your\ncentroid does not change.\nThat means that your\ncentroid is actually the main\nor the average of that particular cluster.\nSo that's how K-means works.\nIt's very simple.\nAll you have to do is you have to start\nby defining the K value.\nAfter that, you have to randomly\npick the number of case centroids.\nThen you're going to\ncalculate the average distance\nof each of the data\npoints from the centroids,\nand you're going to assign a data point\nto the centroid it is closest to.\nThat's how K-means works.\nIt's a very simple process.\nAll you have to do is us\nhave to keep iterating,\nand you have to recompute\nthe centroid value\nuntil the centroid value does not change,\nuntil you get a constant centroid value.\nNow guys, again, in K-means,\nyou make use of distance\nmeasures like Euclidean.\nI've already discussed what\nEuclidean is all about.\nSo, to summarize how K-means works,\nyou start by picking\nthe number of clusters.\nThen you pick a centroid.\nAfter that, you calculate the distance\nof the objects to the centroid.\nThen you group the data\npoints into specific clusters\nbased on their distance.\nYou have to keep computing the centroid\nuntil each data point is\nassigned to the closest cluster,\nso that's how K-means works.\nNow let's look at the elbow method.\nThe elbow method is basically\nused in order to find out\nthe most optimum k value\nfor a particular problem.\nSo the elbow method is\nquite simple actually.\nYou start off by computing\nthe sum of squared errors\nfor some values of K.\nNow sum of squared error is basically\nthe sum of the squared distance\nbetween each member of the\ncluster and its centroid.\nSo you basically calculate\nthe sum of squared errors\nfor different values of K.\nFor example, you can consider K value\nas two, four, six, eight, 10, 12.\nConsider all these values,\ncompute the sum of squared\nerrors for each of these values.\nNow if you plot your K value\nagainst your sum of squared errors,\nyou will see that the error\ndecreases as K gets larger.\nThis is because the number\nof clusters increase.\nIf the number of clusters increases,\nit means that the distortion gets smaller.\nThe distortion keeps decreasing\nas the number of clusters increase.\nThat's because the more clusters you have,\nthe closer each centroid\nwill be with its data points.\nSo as you keep increasing\nthe number of clusters,\nyour distortion will also decrease.\nSo the idea of the elbow\nmethod is to choose the K\nat which the distortion\ndecreases abruptly.\nSo if you look at this\ngraph at K equal to four,\nthe distortion is abruptly decreasing.\nSo this is how you find the value of K.\nWhen your distortion drops abruptly,\nthat is the most optimal K value\nyou should be choosing for\nyour problem statement.\nSo let me repeat the idea\nbehind the elbow method.\nYou're just going to graph the\nnumber of clusters you have\nversus the squared sum of errors.\nThis graph will basically\ngive you the distortion.\nNow the distortion\nobviously going to decrease\nif you increase the number of clusters,\nand there is gonna be\none point in this graph\nwherein the distortion\ndecreases very abruptly.\nNow for that point, you need\nto find out the value of K,\nand that'll be your most optimal K value.\nThat's how you choose your K-means K value\nand your KNN K value as well.\nSo guys, this is how the elbow method is.\nIt's very simple and it\ncan be easily implemented.\nNow we're gonna look at a small demo\nwhich involves K-means.\nThis is actually a very interesting demo.\nNow guys, one interesting application\nof clustering is in color\ncompression with images.\nFor example, imagine you have an image\nwith millions of colors in it.\nIn most images, a large number\nof colors will be unused,\nand many of the pixels in the image\nwill have similar or\neven identical colors.\nNow having too many colors in your image\nmakes it very hard for image\nprocessing an image analysis.\nSo this is one area where\nK-means is applied very often.\nIt's applied in image\nsegmentation, image analysis,\nimage compression, and so on.\nSo what we're gonna do in this demo\nis we are going to use an image\nfrom the scikit-learn data set.\nOkay, it is a prebuilt image,\nand you will require to install\nthe pillow package for this.\nWe're going to use an image\nform the scikit-learn data set module.\nSo we'll begin by importing\nthe libraries as usual,\nand we'll be loading our image as china.\nThe image is china.jpg,\nand we'll be loading this\nin a variable called china.\nSo if you wanna look at\nthe shape of our image,\nyou can run this command.\nSo we're gonna get a\nthree-dimensional value.\nSo we're getting 427\ncomma 640 comma three.\nNow this is basically a\nthree dimensional array\nof size, height, width, and RGB.\nIt contains red, blue,\ngreen contributions,\nas integers from zero to 255.\nSo, your pixel values\nrange between zero and 255,\nand I think zero stands for your black,\nand 255 represents white if I'm not wrong.\nAnd basically, that's what\nthis array shape denotes.\nNow one way we can view this set of pixels\nis as a cloud of points in a\nthree dimensional color space.\nSo what we'll do is we\nwill reshape the data\nand rescale the color,\nso that they lie between zero and one.\nSo the output of this will be\na two dimensional array now.\nSo basically, we can\nvisualize these pixels\nin this color space.\nNow what we're gonna do is we're gonna try\nand plot our pixels.\nWe have a really huge data set\nwhich contains around 16\nmillion possible colors.\nSo this denotes a very,\nvery large data set.\nSo, let me show you what it looks like.\nWe have red against green\nand red against blue.\nThese are our RGB value,\nand we can have around 16 million possible\ncombination of colors.\nThe data set is way too\nlarge or us to compute.\nSo what we'll do is we will\nreduce these 16 million colors\nto just 16 colors.\nWe can do that by using\nK-means clustering,\nbecause we can cluster similar\ncolors into similar groups.\nSo this is exactly where\nwe'll be importing K-means.\nNow, one thing to note here is\nbecause we're dealing with\na very large data set,\nwe will use the MinibatchKMeans.\nThis operates on subsets of the data\nto compute the results more\nquickly and more accurately,\njust like the K-means algorithm,\nbecause I told you this\ndata set is really huge.\nEven though this is a single image,\nthe number of pixel combinations\ncan come up to 16 million,\nwhich is a lot.\nNow each pixel is\nconsidered as a data point\nwhen you've taken image\ninto consideration.\nWhen you have data points and data values,\nthat's different.\nWhen you're starting an image\nfor image classification\nor image segmentation,\neach and every pixel is considered.\nSo, basically, you're building matrices\nof all of these pixel values.\nSo having 16 million pixels\nis a very huge data set.\nSo, for that reason, we'll\nbe using the MinibatchKMeans.\nIt's very similar to K-means.\nThe only difference is that it'll operate\non subsets of the data.\nBecause the data set is too\nhuge, it'll operate on subsets.\nSo, basically, we're making use of K-means\nin order to cluster these 16 million\ncolor combinations into just 16 colors.\nSo basically, we're gonna form 16 clusters\nin this data set.\nNow, the result is the\nrecoloring of the original pixel\nwhere every pixel is assigned the color\nof its closest cluster center.\nLet's say that there\nare a couple of colors\nwhich are very close to green.\nSo we're going to cluster\nall of these similar colors\ninto one cluster.\nWe'll keep doing this\nuntil we get 16 clusters.\nSo, obviously, to do this, we'll be using\nthe clustering method, K-means.\nLet me show you what\nthe output looks like.\nSo, basically, this was the original image\nfrom the scikit data set,\nand this is the 16-color segmented image.\nBasically, we have only 16 colors here.\nHere we can have around 16 million colors.\nHere there are only 16 colors.\nIf you can't also, you can\nonly see particular colors.\nNow obviously there's a lot\nof distortion over here,\nbut this is how you study an image.\nRemove all the extra contrast\nthat is there in an image.\nYou try to reduce the pixel\nto a smaller set of data as possible.\nThe more varied pixels you have,\nthe harder it is going to be for you\nto study the image for analysis.\nNow, obviously, there are some details\nwhich are lost in this.\nBut overall, the image\nis still recognizable.\nSo here, basically, we've compressed this\nwith a compression factor\nof around one million,\nbecause each cluster will have around\none million data points in it,\nor pixel values in it, or pixels in it.\nNow this is an interesting\napplication of K-means.\nThere are actually better ways\nyou can compress information on image.\nSo, basically, I showed you this example\nbecause I want you to understand\nthe power of K-means algorithm.\nYou can cluster a data\nset that is this huge\ninto just 16 colors.\nInitially, there were 16 million,\nand now you can cluster it to 16 colors.\nSo guys, K-means plays a very huge role\nin computer vision image processing,\nobject detection, and so on.\nIt's a very important algorithm\nwhen it comes to detecting objects.\nSo in self-driving cars and all\ncan make use of such algorithms.\nSo guys, that was all\nabout unsupervised learning\nand supervised learning.\nNow it's the last type\nof machine learning,\nwhich is reinforcement learning.\nNow this is actually\na very interesting part\nof machine learning,\nand it is quite difference from\nsupervised and unsupervised.\nSo we'll be discussing all the concepts\nthat are involved in\nreinforcement learning.\nAnd also reinforcement learning\nis a little more advanced.\nWhen I say advanced, I\nmean that it's been used\nin applications such as self-driving cars\nand is also a part of\na lot of deep learning applications,\nsuch as AlphaGo and so on.\nSo, reinforcement learning\nhas a different concept to it itself.\nSo we'll be discussing\nall the concepts under it.\nSo just to brush up your information\nabout reinforcement learning,\nreinforcement learning is\na part of machine learning\nwhere an agent is put in\nan unknown environment,\nand he learns how to\nbehave in this environment\nby performing certain actions\nand observing the rewards\nwhich it gets from these actions.\nReinforcement learning is all about taking\nan appropriate action in\norder to maximize the reward\nin a particular situation.\nNow let's understand\nreinforcement learning\nwith an analogy.\nLet's consider a scenario\nwherein a baby is learning how to walk.\nThis scenario can go about\nin two different ways.\nThe first is baby starts walking\nand it makes it to the candy.\nAnd since the candy is the end goal,\nthe baby is very happy and it's positive.\nMeaning, the baby is happy\nand it received a positive reward.\nNow, the second way this can go in\nis that the baby starts walking,\nbut it falls due to some hurdle between.\nThat's really cute.\nSo the baby gets hurt and\nit doesn't get to the candy.\nIt's negative because the baby is sad\nand it receives a negative reward.\nSo just like how we humans\nlearn from our mistakes\nby trial and error,\nreinforcement learning is also similar.\nHere we have an agent,\nand in this case, the agent is the baby,\nand the reward is the candy\nwith many hurdles in between.\nThe agent is supposed to find\nthe best possible path\nto reach the reward.\nThat is the main goal of\nreinforcement learning.\nNow the reinforcement learning process\nhas two important components.\nIt has something known as an agent\nand something known as an environment.\nNow the environment is\nthe setting that the agent is acting on,\nand the agent represents the\nreinforcement learning algorithm.\nThe whole reinforcement\nlearning is basically the agent.\nThe environment is the setting\nin which you place the agent,\nand it is the setting\nwherein the agent takes various action.\nThe reinforcement learning process\nstarts when the environment\nsends a state to the agent.\nNow the agent, based on\nthe observations it makes,\nit takes an action in\nresponse to that state.\nNow, in turn, the environment\nwill send the next state\nand the respective\nreward back to the agent.\nNow the agent will update its knowledge\nwith the reward returned\nby the environment\nto evaluate its last actions.\nThe loop continues until the environment\nsends a terminal state\nwhich means that the\nagent has accomplished\nall of its task.\nTo understand this better,\nlet's suppose that our agent\nis playing Counter Strike.\nThe reinforcement learning process\ncan be broken down into a couple of steps.\nThe first step is the\nreinforcement learning agent,\nwhich is basically the player,\nhe collects a state, S\nnaught, from the environment.\nSo whenever you're playing Counter Strike,\nyou start off with\nstage zero or stage one.\nYou start off from the first level.\nNow based on this state, S naught,\nthe reinforcement learning agent\nwill take an action, A naught.\nSo guys, action can be\nanything that causes a result.\nNow if the agent moves\nleft or right in the game,\nthat is also considered as an action.\nSo initially, the action will be random,\nbecause the agent has no\nclue about the environment.\nLet's suppose that you're\nplaying Counter Strike\nfor the first time.\nYou have no idea about how to play it,\nso you'll just start randomly.\nYou'll just go with whatever,\nwhichever action you think is right.\nNow the environment is now in a stage one.\nAfter passing stage zero,\nthe environment will go into stage one.\nOnce the environment updates\nthe stage to stage on,\nthe reinforcement learning agent\nwill get a reward R one\nfrom the environment.\nThis reward can be anything\nlike additional points\nor you'll get additional weapons\nwhen you're playing Counter Strike.\nNow this reinforcement\nlearning loop will go on\nuntil the agent is dead or\nreaches the destination,\nand it continuously outputs\na sequence of state action and rewards.\nThis exactly how\nreinforcement learning works.\nIt starts with the agent\nbeing put in an environment,\nand the agent will randomly take\nsome action in state zero.\nAfter taking an action,\ndepending on his action,\nhe'll either get a reward\nand move on to state number one,\nor he will either die and\ngo back to the same state.\nSo this will keep happening\nuntil the agent reaches the last stage,\nor he dies or reaches his destination.\nThat's exactly how\nreinforcement learning works.\nNow reinforcement learning is the logic\nbehind a lot of games these days.\nIt's being implemented in\nvarious games, such as Dota.\nA lot of you who play\nDota might know this.\nNow let's talk about a couple of\nreinforcement learning\ndefinitions or terminologies.\nSo, first, we have something\nknown as the agent.\nLike I mentioned, an agent\nis the reinforcement learning algorithm\nthat learns from trial and error.\nAn agent is the one\nthat takes actions like,\nfor example, a solider in Counter Strike\nnavigating through the game,\ngoing right, left, and all of that.\nIs the agent taking some action?\nThe environment is because the world\nthrough which the agent moves.\nNow the environment, basically,\ntakes the agent's current\nstate and action as input,\nand returns the agent's reward\nand its next state as the output.\nNext, we have something known as action.\nAll the possible steps\nthat an agent can take\nis considered as an action.\nNext, we have something known as state.\nNow the current condition\nreturned by the environment\nis known as a state.\nReward is an instant\nreturn from the environment\nto apprise the last action\nof the reinforcement learning agent.\nAll of these terms are\npretty understandable.\nNext, we have something known as policy.\nNow, policy is the approach\nthat the agent uses\nto determine the next action\nbased on the current state.\nPolicy is basically the approach\nwith which you go around\nin the environment.\nNext, we have something known as value.\nNow, the expected long-term\nreturn with a discount,\nas opposed to the short-term rewards R,\nis known as value.\nNow, terms like discount and value,\nI'll be discussing in the upcoming slides.\nAction-value is also very\nsimilar to the value,\nexcept it takes an extra parameter\nknown as the current action.\nDon't worry about action and Q value.\nWe'll talk about all of\nthis in the upcoming slides.\nSo make yourself familiar\nwith these terms,\nbecause we'll be seeing a\nwhole lot of them this session.\nSo, before we move any further,\nlet's discuss a couple of more\nreinforcement learning concepts.\nNow we have something known\nas the reward maximization.\nSo if you haven't realized it already,\nthe basic aim of\nreinforcement learning agent\nis to maximize the report.\nHow does this happen?\nLet's try to understand this\nin a little more detail.\nSo, basically the agent\nworks based on the theory\nof reward maximization.\nNow that's exactly why\nthe agent must be trained\nin such a way that he\ntakes the best action,\nso that the reward is maximal.\nNow let me explain a reward maximization\nwith a small example.\nNow in this figure, you\ncan see there is a fox,\nthere is some meat, and there is a tiger.\nOur reinforcement\nlearning agent is the fox.\nHis end goal is to eat\nthe maximum amount of meat\nbefore being eaten by the tiger.\nNow because the fox is a very clever guy,\nhe eats the meat that is closer to him,\nrather than the meat which\nis close to the tiger,\nbecause the closer he gets to the tiger,\nthe higher are his\nchances of getting killed.\nThat's pretty obvious.\nEven if the reward near the\ntiger are bigger meat chunks,\nthat'll be discounted.\nThis is exactly what discount is.\nWe just discussed it\nin the previous slide.\nThis is done because of\nthe uncertainty factor\nthat the tiger might\nactually kill the fox.\nNow the next thing to\nunderstand is how discounting\nof a reward works.\nNow, in order to understand discounting,\nwe define a discount rate called gamma.\nThe value of gamma is\nbetween zero and one.\nAnd the smaller the gamma,\nthe larger the discount and so on.\nNow don't worry about these concepts,\ngamma and all of that.\nWe'll be seeing that in\nour practical demo today.\nSo let's move on and\ndiscuss another concept\nknown as exploration and\nexploitation trade-off.\nNow guys, before that, I\nhope all of you understood\nreward maximization.\nBasically, the main aim\nbehind reinforcement learning\nis to maximize the rewards\nthat an agent can get.\nNow, one of the most important concepts\nin reinforcement learning is\nthe exploration and\nexploitation trade-off.\nNow, exploration, like the name suggests,\nit's about exploring and capturing\nmore information about an environment.\nOn the other hand, exploitation is about\nusing the already known\nexploited information\nto heighten your reward.\nNow consider the same example\nthat we saw previously.\nSo here the fox eats only the meat chunks\nwhich are close to him.\nHe doesn't eat the bigger meat chunks\nwhich are at the top,\neven though the bigger meat chunks\nwould get him more reward.\nSo if the fox only focuses\non the closest reward,\nhe will never reach\nthe big chunks of meat.\nThis process is known as exploitation.\nBut if the fox decide to explore a bit,\nit can find the bigger reward,\nwhich is the big chunk of meat.\nThis is known as exploration.\nSo this is the difference\nbetween exploitation\nand exploration.\nIt's always best if the agent\nexplores the environment,\ntries to figure out a\nway in which we can get\nthe maximum number of rewards.\nNow let's discuss\nanother important concept\nin reinforcement learning,\nwhich is known as the\nMarkov's decision process.\nBasically, the mathematical\napproach for mapping\na solution in reinforcement learning\nis called Markov's decision process.\nIt's the mathematics behind\nreinforcement learning.\nNow, in a way, the purpose\nof reinforcement learning\nis to solve a Markov's decision process.\nNow in order to get a solution,\nthere are a set of parameters\nin a Markov's decision process.\nThere's a set of actions A,\nthere's a set of states S,\na reward R, policy pi, and value V.\nAlso, this image represents\nhow a reinforcement learning works.\nThere's an agent.\nThe agent take some\naction on the environment.\nThe environment, in turn,\nwill reward the agent,\nand it will give him the next state.\nThat's how reinforcement learning works\nso to sum everything up,\nwhat happens in Markov's decision process\nand reinforcement learning is\nthe agent has to take an action A\nto transition from the start state\nto the end state S.\nWhile doing so, the agent\nwill receive some reward R\nfor each action he takes.\nNow the series of action\nthat are taken by the agent\ndefine the policy and\nthe rewards collected\nto find the value.\nThe main goal here is\nto maximize the rewards\nby choosing the optimum policy.\nSo you're gonna choose\nthe best possible approach\nin order to maximize the rewards.\nThat's the main aim of\nMarkov's decision process.\nTo understand Markov's decision process,\nlet's look at a small example.\nI'm sure all of you already know\nabout the shortest path problem.\nWe all had such problems\nand concepts in math\nto find the shortest path.\nNow consider this representation\nover here, this figure.\nHere, our goal is to\nfind the shortest path\nbetween two nodes.\nLet's say we're trying to find\nthe shortest path between\nnode A and node D.\nNow each edge, as you can see,\nhas a number linked with it.\nThis number denotes the cost to traverse\nthrough that edge.\nSo we need to choose a\npolicy to travel from A to D\nin such a way that our cost is minimum.\nSo in this problem, the set of states are\ndenoted by the nodes A, B, C, D.\nThe action is to traverse\nfrom one node to the other.\nFor example, if you're going from to A C,\nthere is an action.\nC to B is an action.\nB to D is another action.\nThe reward is the cost\nrepresented by each edge.\nPolicy is the path taken\nto reach the destination.\nSo we need to make sure\nthat we choose a policy\nin such a way that our cost is minimal.\nSo what you can do is you\ncan start off at node A,\nand you can take baby steps\nto reach your destination.\nInitially, only the next\npossible node is visible to you.\nSo from A, you can either go to B\nor you can go to C.\nSo if you follow the greedy approach\nand take the most optimum step,\nwhich is choosing A to C,\ninstead of choosing A to B to C.\nNow you're at node C\nand you want to traverse to node D.\nAgain, you must choose\nyour path very wisely.\nSo if you traverse from A to C,\nand C to B, and B to D,\nyour cost is the lest.\nBut if you traverse from A to C to D,\nyour cost will actually increase.\nNow you need to choose a policy\nthat will minimize your cost over here.\nSo let's say, for example, the agent\nchose A to C to D.\nIt came to node C, and\nthen it directly chose D.\nNow the policy followed by\nour agent in this problem\nis exploitation type,\nbecause we didn't explore the other notes.\nWe just selected three nodes\nand we traversed through them.\nAnd the policy we followed is not actually\nan optimal policy.\nWe must always explore more\nto find out the optimal policy.\nEven if the other nodes are\nnot giving us any more reward\nor is actually increasing our cost,\nwe still have to explore and find out\nif those paths are actually better.\nThat policy is actually better.\nThe method that we implemented here\nis known as the policy-based learning.\nNow the aim here is to\nfind the best policy\namong all the possible policies.\nSo guys, apart from policy-based,\nwe also have value-based approach\nand action-based approach.\nValue based emphasizes on\nmaximizing the rewards.\nAnd in action base, we emphasize\non each action taken by the agent.\nNow a point to note is that\nall of these learning approaches\nhave a simple end goal.\nThe end goal is to\neffectively guide the agent\nthrough the environment,\nand acquire the most number of rewards.\nSo this was very simple to understand\nMarkov's decision process,\nexploitation and exploration trade-off,\nand we also discussed\nthe different reinforcement\nlearning definitions.\nI hope all of this was understandable.\nNow let's move on and understand\nan algorithm known as\nQ-learning algorithm.\nSo guys, Q-learning is one of\nthe most important algorithms\nin reinforcement learning.\nAnd we'll discuss this algorithm\nwith the help of a small example.\nWe'll study this example,\nand then we'll implement the\nsame example using Python,\nand we'll see how it works.\nSo this is how our\ndemonstration looks for now.\nNow the problem statement\nis to place an agent\nin any one of the rooms numbered\nzero, one, two, three, and four.\nAnd the goal is for the agent\nto reach outside the building,\nwhich is room number five.\nSo, basically, this zero,\none, two, three, four\nrepresents the building,\nand five represents a room\nwhich is outside the building.\nNow all these rooms\nare connected by those.\nNow these gaps that you\nsee between the rooms\nare basically those,\nand each room is numbered\nfrom zero to four.\nThe outside of the building\ncan be taught of as a big room\nwhich is room number five.\nNow if you've noticed this diagram,\nthe door number one and door number four\nlead directly to room number five.\nFrom one, you can directly go to five,\nand from four, also, you\ncan directly go to five.\nBut if you want to go to\nfive from room number two,\nthen you'll first have to\ngo to room number three,\nroom number one, and\nthen room number five.\nSo these are indirect links.\nDirect links are from room\nnumber one and room number four.\nSo I hope all of you are clear\nwith the problem statement.\nYou're basically going to have\na reinforcement learning agent,\nand than agent has to\ntraverse through all the rooms\nin such a way that he\nreaches room number five.\nTo solve this problem,\nfirst, what we'll do is\nwe'll represent the rooms\non a graph.\nNow each room is denoted as anode,\nand the links that are connecting\nthese nodes are the doors.\nAlright, so we have node one to five,\nand the links between each of these nodes\nrepresent the doors.\nSo, for example, if you look\nat this graph over here,\nyou can see that there\nis a direct connection\nfrom one to five,\nmeaning that you can directly\ngo from room number one\nto your goal, which is room number five.\nSo if you want to go from\nroom number three to five,\nyou can either go to room number one,\nand then go to five,\nor you can go from room\nnumber three to four,\nand then to five.\nSo guys, remember, end goal\nis to reach room number five.\nNow to set the room number\nfive as the goal state,\nwhat we'll do is we'll\nassociate a reward value\nto each door.\nThe doors that lead\nimmediately to the goal\nwill have an instant reward of 100.\nSo, basically, one to five\nwill have a reward of hundred,\nand four to five will also\nhave a reward of hundred.\nNow other doors that are not directly\nconnected to the target room\nwill have a zero reward,\nbecause they do not directly\nlead us to that goal.\nSo let's say you placed the\nagent in room number three.\nSo to go from room number three to one,\nthe agent will get a reward of zero.\nAnd to go from one to five,\nthe agent will get a reward of hundred.\nNow because the doors are two-way,\nthe two arrows are assigned to each room.\nYou can see an arrow\ngoing towards the room\nand one coming from the room.\nSo each arrow contains an instant reward\nas shown in this figure.\nNow of course room number five\nwill loop back to itself\nwith a reward of hundred,\nand all other direct\nconnections to the goal room\nwill carry a reward of hundred.\nNow in Q-learning, the\ngoal is to reach the state\nwith the highest reward.\nSo that if the agent arrives at the goal,\nit will remain there forever.\nSo I hope all of you are\nclear with this diagram.\nNow, the terminologies in Q-learning\ninclude two terms, state and action.\nOkay, your room basically\nrepresents the state.\nSo if you're in state two,\nit basically means that\nyou're in room number two.\nNow the action is basically\nthe moment of the agent\nfrom one room to the other room.\nLet's say you're going\nfrom room number two\nto room number three.\nThat is basically an action.\nNow let's consider some more example.\nLet's say you place the\nagent in room number two\nand he has to get to the goal.\nSo your initial state\nwill be state number two\nor room number two.\nThen from room number two,\nyou'll go to room number three,\nwhich is state three.\nThen from state three, you can\neither go back to state two\nor go to state one or state four.\nIf you go to state four, from\nthere you can directly go to\nyour goal room, which is five.\nThis is how the agent\nis going to traverse.\nNow in order to depict the\nrewards that you're going to get,\nwe're going to create a matrix\nknown as the reward matrix.\nOkay, this is represented by R\nor also known as the R matrix.\nNow the minus one in this\ntable represents null values.\nThat is basically where there isn't a link\nbetween the nodes that is\nrepresented as minus one.\nNow there is no link\nbetween zero and zero.\nThat's why it's minus one.\nNow if you look at this diagram,\nthere is no direct link from zero to one.\nThat's why I've put minus\none over here as well.\nBut if you look at zero comma four,\nwe have a value of zero over here,\nwhich means that you can\ntraverse from zero to four,\nbut your reward is going to be zero,\nbecause four is not your goal state.\nHowever, if you look at the matrix,\nlook at one comma five.\nIn one comma five, we have\na reward value of hundred.\nThis is because you can directly go\nfrom room number one to five,\nand five is the end goal.\nThat's why we've assigned\na reward of hundred.\nSimilarly, for four comma five,\nwe have a reward of hundred.\nAnd for five comma five,\nwe have a reward of hundred.\nZeroes basically represent other links,\nbut they are zero because they\ndo not lead to the end goal.\nSo I hope you all understood\nthe reward matrix.\nIt's very simple.\nNow before we move any further,\nwe'll be creating another matrix\nknown as the equitable Q matrix.\nNow the Q matrix basically\nrepresents the memory\nof what the agent has\nlearned through experience.\nThe rules of the Q matrix\nwill represent the current\nstate of the agent.\nThe columns will represent\nthe next possible actions\nleading to the next state,\nand the formula to calculate the Q matrix\nis this formula, right?\nHere we have Q state comma action,\nR state comma action,\nwhich is nothing but the reward matrix.\nThen we have a parameter\nknown as the Gamma parameter,\nwhich I'll explain shortly.\nAnd then we are multiplying\nthis with a maximum\nof Q next state comma all actions.\nNow don't worry if you haven't\nunderstood this formula.\nI'll explain this with a small example.\nFor now, let's understand\nwhat a Gamma parameter is.\nSo, basically, the value of Gamma\nwill be between zero and one.\nIf Gamma is closer to zero,\nit means that the agent\nwill tend to consider\nonly immediate rewards.\nNow, if the Gamma is closer to one,\nit means that the agent\nwill consider future rewards\nwith greater weight.\nNow what exactly I'm trying to say is\nif Gamma is closer to one,\nthen we'll be performing\nsomething known as exploitation.\nI hope you all remember what exploitation\nand exploration trade-off is.\nSo, if your gamma is closer to zero,\nit means that the agent\nis not going to explore the environment.\nInstead, it'll just\nchoose a couple of states,\nand it'll just traverse\nthrough those states.\nBut if your gamma\nparameter is closer to one,\nit means that the agent will traverse\nthrough all possible states,\nmeaning that it'll perform exploration,\nnot exploitation.\nSo the closer your gamma\nparameter is to one,\nthe more your agent will explore.\nThis is exactly what Gamma parameter is.\nIf you want to get the best policy,\nit's always practical that\nyou choose a Gamma parameter\nwhich is closer to one.\nWe want the agent to\nexplore the environment\nas much as possible\nso that it can get the best\npolicy and the maximum rewards.\nI hope this is clear.\nNow let me just tell you\nwhat a Q-learning\nalgorithm is step by step.\nSo you begin the Q-learning algorithm\nby setting the Gamma parameter\nand the environment rewards in matrix R.\nOkay, so, first, you'll\nhave set these two values.\nWe've already calculated\nthe reward matrix.\nWe need to set the Gamma parameter.\nNext, you'll initialize\nthe matrix Q to zero.\nNow why do you do this?\nNow, if you remember, I said that\nQ matrix is basically\nthe memory of the agent.\nInitially, obviously,\nthe agent has no memory\nof the environment.\nIt's new to the environment\nand you're placing it randomly anywhere.\nSo it has zero memory.\nThat's why you initialize\nthe matrix Q to zero.\nAfter that, you'll select\na random initial state,\nand you place your agent\nin that initial state.\nThen you'll set this initial\nstate as your current state.\nNow from the current state,\nyou'll select some action\nthat will lead you to the next state.\nThen you'll basically\nget the maximum Q value\nfor this next state,\nbased on all the possible\nactions that we take.\nThen you'll keep computing the skew value\nuntil you reach the goals state.\nNow that might be a little bit confusing,\nso let's look at this entire\nthing with a small example.\nLet's say that first, you're gonna begin\nwith setting your Gamma parameter.\nSo I'm setting my Gamma parameter to 0.8\nwhich is pretty close to one.\nThis means that our agent\nwill explore the environment\nas much as possible.\nAnd also, I'm setting the\ninitial state as room one.\nMeaning, I'm in state\none or I'm in room one.\nSo basically, your agent is\ngoing to be in room number one.\nThe next step is to initialize\nthe Q matrix as zero matrix.\nSo this is a Q matrix.\nYou can see that\neverything is set to zero,\nbecause the agent has no memory at all.\nHe hasn't traversed to any node,\nso he has no memory.\nNow since the agent is in room one\nhe can either go to room number three\nor he can go to room number five.\nLet's randomly select room number five.\nSo, from room number five,\nyou're going to calculate\nthe maximum Q value\nfor the next state based\non all possible actions.\nSo all the possible actions\nfrom room number five\nis one, four, and five.\nSo, basically, the traversing\nfrom Q one comma five,\nthat's why I put one comma five over here,\nstate comma action.\nYour reward matrix will\nhave R one comma five.\nNow R one comma five is basically hundred.\nThat's why I put hundred over here.\nNow your comma parameter is 0.8.\nSo, guys, what I'm doing here\nis I'm just substituting\nthe values in this formula.\nSo let me just repeat this whole thing.\nQ state comma action.\nSo you're in state number one, correct?\nAnd your action is you're\ngoing to room number five.\nSo your Q state comma\naction is one comma five.\nAgain, your reward matrix R\none comma five is hundred.\nSo here's you're gonna put hundred,\nplus your Gamma parameter.\nYour Gamma parameter is 0.8.\nThen you're going to\ncalculate the maximum Q value\nfor the next state based\non all possible actions.\nSo let's look at the next state.\nFrom room number five,\nyou can go to either one.\nYou can go to four or you can go to five.\nSo your actions are five\ncomma one, five comma four,\nand five comma five.\nThat's exactly what I mentioned over here.\nQ five comma one, Q five comma\nfour, and Q five comma five.\nYou're basically putting all\nthe next possible actions\nfrom state number five.\nFrom here, you'll calculate the maximum\nQ value that you're\ngetting for each of these.\nNow your Q value is zero,\nbecause, initially, your\nQ matrix is set to zero.\nSo you're going to get\nzero for Q five comma one,\nfive comma four, and five comma five.\nSo that's why you'll get 0.8 and zero,\nand hence your Q one comma\nfive becomes hundred.\nThis hundred comes from R one comma five.\nI hope all of you understood this.\nSo next, what you'll do is you'll update\nthis one comma five\nvalue in your Q matrix,\nbecause you just calculated\nQ one comma five.\nSo I've updated it over here.\nNow for the next episode,\nwe'll start with a randomly\nchosen initial state.\nAgain, let's say that we randomly\nchose state number three.\nNow from room number three,\nyou can either go to room\nnumber one, two or four.\nLet's randomly select room number one.\nNow, from room number five,\nyou'll calculate the maximum Q value\nfor the next possible actions.\nSo let's calculate the Q formula for this.\nSo your Q state comma action\nbecomes three comma one,\nbecause you're in state number three\nand your action is you're\ngoing to room number one.\nSo your R three comma one,\nlet's see what R three comma one is.\nR three comma one is zero.\nSo you're going to put zero over here,\nplus your Gamma parameter, which is 0.8,\nand then you're going to check\nthe next possible actions\nfrom room number one,\nand you're going to\nchoose the maximum value\nfrom these two.\nSo Q one comma three and Q one comma five\ndenote your next possible\nactions from room number one.\nSo Q one comma three is zero,\nbut Q one comma five is hundred.\nSo we just calculated this\nhundred in the previous step.\nSo, out of zero and hundred,\nhundred is your maximum value,\nso you're going to choose hundred.\nNow 0.8 into hundred is nothing but 80.\nSo again, your Q matrix gets updated.\nYou see an 80 over here.\nSo, basically what you're doing\nis as you're taking actions,\nyou're updating your Q value,\nyou're just calculating\nthe Q value at every step,\nyou're putting it in your Q matrix\nso that your agent remembers that,\nokay, when I went from room\nnumber one to room number five,\nI had a Q value of hundred.\nSimilarly, three to one\ngave me a Q value of 80.\nSo basically, this Q matrix represents\nthe memory of your agent.\nI hope all of you are clear with this.\nSo basically, what we're gonna do\nis we're gonna keep\niterating through this loop\nuntil we've gone through\nall possible states\nand reach the goal state, which is five.\nAlso, our main aim here is to\nfind the most optimum policy\nto get to room number five.\nNow let's implement the exact\nsame thing using Python.\nSo that was a lot of theory.\nNow let's understand how\nthis is done practically.\nAlright, so we begin by\nimporting your library.\nWe're gonna be using the\nNumPy library over here.\nAfter that, we'll import the R matrix.\nWe've already created the R matrix.\nThis is the exact matrix that I showed you\na couple of minutes ago.\nSo I've created a matrix called R\nand I've basically stored\nall the rewards in it.\nIf you want to see the R\nmatrix, let me print it.\nSo, basically, this is your R matrix.\nIf you remember, node one to five,\nyou have a reward of hundred.\nNode four to five, you\nhave a reward of hundred,\nand five to five, you\nhave a reward of hundred,\nbecause all of these nodes\ndirectly lead us to the reward.\nCorrect?\nNext, what we're doing is\nwe're creating a Q matrix\nwhich is basically a six into six matrix.\nWhich represents all the\nstates, zero to five.\nAnd this matrix is basically zero.\nAfter, that we're setting\nthe Gamma parameter.\nNow guys, you can play\naround with this code,\nand you know you can\nchange the comma parameter\nto 0.7 or 0.9\nand see how much more\nthe agent will explore\nor whether you perform exploitation.\nHere I've set the Gamma parameter 0.8\nwhich is a pretty good number.\nNow what I'm doing is I'm\nsetting the initial state as one.\nYou can randomly choose this state\naccording to your needs.\nI've set the initial state as one.\nNow, this function will basically give me\nall the available actions\nfrom my initial state.\nSince I've set my initial state as one,\nIt'll give me all the possible actions.\nHere what I'm doing is since\nmy initial state is one,\nI'm checking in my row number one,\nwhich value is equal to\nzero or greater than zero.\nThose denote my available actions.\nSo look at our row number one.\nHere we have one zero and\nwe have a hundred over here.\nThis is one comma four and\nthis is one comma five.\nSo if you look at the row number one,\nsince I've selected the\ninitial state as one,\nwe'll consider row number one.\nOkay, what I'm doing is in row number one,\nI have two numbers which\nare either equal to zero\nor greater than zero.\nThese denote my possible actions.\nOne comma three has the value of zero\nand one comma five has\nthe value of hundred,\nwhich means that the agent\ncan either go to room number three\nor it can go to room number five.\nWhat I'm trying to say\nis from room number one,\nyou can basically go to room number three\nor room number five.\nThis is exactly what I've coded over here.\nIf you remember the reward matrix,\nfrom one you can traverse to\nonly room number three directly\nand room number five directly.\nOkay, that's exactly what I've mentioned\nin my code over here.\nSo this will basically give\nme the available actions\nfrom my current state.\nNow once I've moved to me next state,\nI need to check the available\nactions from that state.\nWhat I'm doing over\nhere is basically this.\nIf you're remember,\nfrom room number one, we can\ngo to three and five, correct?\nAnd from three and five,\nI'll randomly select the state.\nAnd from that state, I need to find out\nall possible actions.\nThat's exactly what I've done over here.\nOkay.\nNow this will randomly\nchoose an action for me\nfrom all my available actions.\nNext, we need to update our Q matrix,\ndepending on the actions that we took,\nif you remember.\nSo that's exactly what this\nupdate function is four.\nNow guys, this entire is\nfor calculating the Q value.\nI hope all of you remember the formula,\nwhich is Q state comma action,\nR state comma action plus\nGamma into max value.\nMax value will basically\ngive me the maximum value\nout of the all possible actions.\nI'm basically computing this formula.\nNow this will just update the Q matrix.\nComing to the training phase,\nwhat we're gonna do is we\nare going to set a range.\nHere I've set a range of 10,000,\nmeaning that my agent will\nperform 10,000 iterations.\nYou can set this depending\non your own needs,\nand 10,000 iteration is\na pretty huge number.\nSo, basically, my agent\nis going to go through\n10,000 possible iterations\nin order to find the best policy.\nNow this is the exact same\nthing that we did earlier.\nWe're setting the current state,\nand then we're choosing\nthe available action\nfrom the current state.\nThe from there, we'll\nchoose an action at random.\nHere we'll calculate a Q value\nand we'll update the\nQ value in the matrix.\nAlright.\nAnd here I'm doing nothing,\nbut I'm printing the trained Q matrix.\nThis was the training phase.\nNow the testing phase, basically,\nyou're going to randomly\nchoose a current state.\nYou're gonna choose a current state,\nand you're going to keep looping\nthrough this entire code,\nuntil you reach the goal state,\nwhich is room number five.\nThat's exactly what I'm\ndoing in this whole thing.\nAlso, in the end, I'm\nprinting the selected part.\nThat is basically the\npolicy that the agent took\nto reach room number five.\nNow if I set the current state as one,\nit should give me the best policy\nto reach to room number\nfive from room number one.\nAlright, let's run this code,\nand let's see if it's giving us that.\nNow before that happens, I\nwant you to check and tell me\nwhich is the best possible way\nto get from room number\none to room number five.\nIt's obviously directly like this.\nOne to five is the best policy\nto get from room number one\nto room number five.\nSo we should get an\noutput of one comma five.\nThat's exactly what we're getting\nthis is a Q matrix with all the Q values,\nand here we are getting the selected path.\nSo if your current state is one,\nyour best policy is to\ngo from one to five.\nNow, if you want to\nchange your current state,\nlet's say we set the current state to two.\nAnd before we run the code,\nlet's see which is the best possible way\nto get to room number\nfive from room number two.\nFrom room number two, you can go to three,\nthen you can go to one, and\nthen you can go to five.\nThis will give you a reward of hundred,\nor you can go to room number three,\nthen go to four, and then go to five.\nThis will also give you\na reward of hundred.\nOur path should be something like that.\nLet's save it and let's run the file.\nSo, basically, from stage two,\nyou're going to say three, then to four,\nand then to five.\nThis is our best possible path\nfrom two to room number five.\nSo, guys, this is exactly how\nthe Q learning algorithm works,\nand this was a simple implementation\nof the entire example\nthat I just told you.\nNow if any of you still have doubts\nregarding Q learning or\nreinforcement learning,\nmake sure you comment them\nin the comment section,\nand I'll try to answer all of your doubts.\nNo we're done with machine learning.\nWe've completed the whole\nmachine learning model.\nWe've understood reinforcement learning,\nsupervised learning,\nunsupervised learning, and so on.\nBefore I'll get to deep learning,\nI want to clear a very\ncommon misconception.\nA lot of people get confused\nbetween AI machine\nlearning and deep learning,\nbecause, you know,\nartificial intelligence,\nmachine learning and deep learning\nare very common applications.\nFor example, Siri is an application\nof artificial intelligence,\nmachine learning, and deep learning.\nSo how are these three connected?\nAre they the same thing or how exactly\nis the relationship between\nartificial intelligence,\nmachine learning, and deep learning?\nThis is what I'll be discussing.\nnow artificial intelligence\nis basically the science\nof getting machines to mimic\nthe behavior of human beings.\nBut when it comes to machine learning,\nmachine learning is a subset\nof artificial intelligence\nthat focuses on getting\nmachines to make decisions\nby feeding them data.\nThat's exactly what machine learning is.\nIt is a subset of artificial intelligence.\nDeep learning, on the other hand,\nis a subset of machine learning\nthat uses the concept of neural networks\nto solve complex problems.\nSo, to sum it up, artificial intelligence,\nmachine learning, and deep learning,\nare interconnected fields.\nMachine learning and deep learning\naids artificial intelligence\nby providing a set of\nalgorithms and neural networks\nto solve data-driven problems.\nThat's how AI, machine\nlearning, and deep learning\nare related.\nI hope all of you have\ncleared your misconceptions\nand doubts about AI,\nML, and deep learning.\nNow let's look at our next topic,\nwhich is limitations of machine learning.\nNow the first limitation\nis machine learning\nis not capable enough to\nhandle high dimensional data.\nThis is where the input and\nthe output is very large.\nSo handling and processing\nsuch type of data\nbecomes very complex\nand it takes up a lot of resources.\nThis is also sometimes known\nas the curse of dimensionality.\nSo, to understand this in simpler terms,\nlook at the image shown on this slide.\nConsider a line of hundred yards\nand let's say that you dropped\na coin somewhere on the line.\nNow it's quite convenient\nfor you to find the coin\nby simply walking along the line.\nThis is very simple because\nthis line is considered\nas single dimensional entity.\nNow next, you consider that you have\na square of hundred yards,\nand let's say you dropped a\ncoin somewhere in between.\nNow it's quite evident that\nyou're going to take more time\nto find the coin within that square\nas compared to the previous scenario.\nThe square is, let's say,\na two dimensional entity.\nLet's take it a step ahead\nand let's consider a cube.\nOkay, let's say there's\na cube of 500 yards\nand you have dropped a coin\nsomewhere in between this cube.\nNow it becomes even more difficult\nfor you to find the coin this time,\nbecause this is a three\ndimensional entity.\nSo, as your dimension increases,\nthe problem becomes more complex.\nSo if you observe that the complexity\nis increasing the increase\nin your dimensions,\nand in real life, the\nhigh dimensional data\nthat we're talking about\nhas thousands of dimensions\nthat makes it very complex\nto handle and process.\nand a high dimensional data\ncan easily be found in used\ncases like image processing,\nnatural language processing,\nimage translation, and so on.\nNow in K-means itself,\nwe saw that we had 16\nmillion possible colors.\nThat is a lot of data.\nSo this is why machine\nlearning is restricted.\nIt cannot be used in the\nprocess of image recognition\nbecause image recognition and\nimages have a lot of pixels\nand they have a lot of\nhigh dimensional data.\nThat's why machine learning\nbecomes very restrictive\nwhen it comes to such uses cases.\nNow the second major challenge\nis to tell the computer\nwhat are the features it should look for\nthat will play an important role\nin predicted the outcome and\nin getting a good accuracy.\nNow this process is something\nknown as feature extraction.\nNow feeding raw data to\nthe algorithm rarely works,\nand this is the reason\nwhy feature extraction\nis a critical part of\nmachine learning workflow.\nNow the challenge for the\nprogrammer here increases\nbecause the effectiveness of the algorithm\ndepends on how insightful\nthe programmer is.\nAs a programmer,\nyou have to tell the machine\nthat these are the features.\nAnd depending on these features,\nyou have to predict the outcome.\nThat's how machine learning works.\nSo far, in all our demos,\nwe saw that we were providing\npredictor variables.\nwe were providing input variables\nthat will help us predict the outcome.\nWe were trying to find\ncorrelations between variables,\nand we're trying to find out the variable\nthat is very important in\npredicting the output variable.\nSo this becomes a challenge\nfor the programmer.\nThat's why it's very difficult to apply\nmachine learning model to complex problems\nlike object recognition,\nhandwriting recognition,\nnatural language processing, and so on.\nNow all these problems\nand all these limitations\nin machine learning\nled to the introduction of deep learning.\nNow we're gonna discuss\nabout deep learning.\nNow deep learning is\none of the only methods\nby which we can overcome the challenges\nof feature extraction.\nThis is because deep learning models\nare capable of learning to focus\non the right features by themselves,\nwhich requires very little\nguidance from the programmer.\nBasically, deep learning mimics\nthe way our brain functions.\nThat is it learns from experience.\nSo in deep learning, what happens is\nfeature extraction happens automatically.\nYou need very little\nguidance by the programmer.\nSo deep learning will learn the model,\nand it will understand which\nfeature or which variable\nis important in predicting the outcome.\nLet's say you have millions\nof predictor variables\nfor a particular problem statement.\nHow are you going to sit down and\nunderstand the significance\nof each of these predictor variables\nit's going to be almost impossible\nto sit down with so many features.\nThat's why we have deep learning.\nWhenever there's high dimensionality data\nor whenever the data is really large\nand it has a lot of features\nand a lot of predictor\nvariables, we use deep learning.\nDeep learning will extract\nfeatures on its own\nand understand which\nfeatures are important\nin predicting your output.\nSo that's the main idea\nbehind deep learning.\nLet me give you a small example also.\nSuppose we want to make a system\nthat can recognize the\nface of different people\nin an image.\nOkay, so, basically,\nwe're creating a system\nthat can identify the faces of\ndifferent people in in image.\nIf we solve this by using\nthe typical machine learning algorithms,\nwe'll have to define\nfacial features like eyes,\nnose, ears, et cetera.\nOkay, and then the system will identify\nwhich features are more\nimportant for which person.\nNow, if you consider deep\nlearning for the same example,\ndeep learning will automatically\nfind out the features\nwhich are important for classification,\nbecause it uses the\nconcept of neural networks,\nwhereas in machine learning we have to\nmanually define these features on our own.\nThat's the main difference\nbetween deep learning\nand machine learning.\nNow the next question is\nhow does deep learning work?\nNow when people started\ncoming up with deep learning,\ntheir main aim was to\nre-engineer the human brain.\nOkay, deep learning studies\nthe basic unit of a brain\ncalled the brain cell or a neuron.\nAll of you biology students\nwill know what I'm talking about.\nSo, basically, deep learning is inspired\nfrom our brain structure.\nOkay, in our brains, we have\nsomething known as neurons,\nand these neurons are\nreplicated in deep learning\nas artificial neurons,\nwhich are also called perceptrons.\nNow, before we understand how\nartificial neural networks\nor artificial neurons work,\nlet's understand how these\nbiological neurons work,\nbecause I'm not sure how many of you\nare bio students over here.\nSo let's understand the\nfunctionality of biological neurons\nand how we can mimic this functionality\nin a perceptron or in\nan artificial neuron.\nSo, guys, if you loo at this image,\nthis is basically an image\nof a biological neuron.\nIf you focus on the structure\nof the biological neuron,\nit has something known dendrites.\nThese dendrites are basically\nused to receive inputs.\nNow the inputs are basically\nfound in the cell body,\nand it's passed on the\nnext biological neuron.\nSo, through dendrites, you're\ngoing to receive signals\nfrom other neurons, basically, input.\nThen the cell body will\nsum up all these inputs,\nand the axon will transmit\nthis input to other neurons.\nThe axon will fire up\nthrough some threshold,\nand it will get passed\nonto the next neuron.\nSo similar to this, a perceptron\nor an artificial neuron\nreceives multiple inputs,\nand applies various\ntransformations and functions\nand provides us an output.\nThese multiple inputs are\nnothing but your input variables\nor your predictor variables.\nYou're feeding input data\nto an artificial neuron\nor to a perceptron,\nand this perceptron will apply\nvarious functions and transformations,\nand it will give you an output.\nNow just like our brain consists of\nmultiple connected neurons\ncalled neural networks,\nwe also build something known as\na network of artificial neurons\ncalled artificial neural networks.\nSo that's the basic concept\nbehind deep learning.\nTo sum it up, what\nexactly is deep learning?\nNow deep learning is a collection of\nstatistical machine learning techniques\nused to learn feature\nhierarchies based on the concept\nof artificial neural networks.\nSo the main idea behind deep learning\nis artificial neural networks\nwhich work exactly like\nhow our brain works.\nNow in this diagram, you can see that\nthere are a couple of layers.\nThe first layer is known\nas the input layer.\nThis is where you'll\nreceive all the inputs.\nThe last layer is known\nas the output layer\nwhich provides your desired output.\nNow, all the layers which are\nthere between your input layer\nand your output layer are\nknown as the hidden layers.\nNow, they can be any\nnumber of hidden layers,\nthanks to all the resources\nthat we have these days.\nSo you can have hundreds of\nhidden layers in between.\nNow, the number of hidden layers\nand the number of perceptrons\nin each of these layers\nwill entirely depend on the problem\nor on the use case that\nyou're trying to solve.\nSo this is basically\nhow deep learning works.\nSo let's look at the\nexample that we saw earlier.\nHere what we want to do\nis we want to perform\nimage recognition using deep networks.\nFirst, what we're gonna\ndo is we are going to pass\nthis high dimensional\ndata to the input layer.\nTo mach the dimensionality\nof the input data,\nthe input layer will contain\nmultiple sub layers of perceptrons\nso that it consume the entire input.\nOkay, so you'll have multiple\nsub layers of perceptrons.\nNow, the output received\nfrom the input layer\nwill contain patterns and\nwill only be able to identify\nthe edges of the images,\nbased on the contrast levels.\nThis output will then be fed\nto hidden layer number one\nwhere it'll be able to\nidentify facial features\nlike your eyes, nose,\nears, and all of that.\nNow from here, the output will be fed\nto hidden layer number two,\nwhere it will be able to form entire faces\nit'll go deeper into face recognition,\nand this output of the hidden layer\nwill be sent to the output layer\nor any other hidden layer that is there\nbefore the output layer.\nNow, finally, the output layer\nwill perform classification,\nbased on the result that you'd get\nfrom your previous layers.\nSo, this is exactly how\ndeep learning works.\nThis is a small analogy that I use\nto make you understand\nwhat deep learning is.\nNow let's understand what a\nsingle layer perceptron is.\nSo like I said, perceptron is basically\nan artificial neuron.\nFor something known as single layer\nand multiple layer perceptron,\nwe'll first focus on\nsingle layer perceptron.\nNow before I explain what\na perceptron really is,\nyou should known that perceptrons\nare linear classifiers.\nA single layer perceptron\nis a linear or a binary classifier.\nIt is used mainly in supervised learning,\nand it helps to classify\nthe given input data\ninto separate classes.\nSo this diagram basically\nrepresents a perceptron.\nA perceptron has multiple inputs.\nIt has a set of inputs\nlabeled X one, X two,\nuntil X n.\nNow each of these input is\ngiven a specific weight.\nOkay, so W one represents\nthe weight of input X one.\nW two represents the weight\nof input X two, and so on.\nNow how you assign these weights\nis a different thing altogether.\nBut for now, you need\nto know that each input\nis assigned a particular weightage.\nNow what a perceptron does\nis it computes some functions\non these weighted inputs, and\nit will give you the output.\nSo, basically, these weighted inputs\ngo through something known as summation.\nOkay, summation is nothing but the product\nof each of your input with\nits respective weight.\nNow after the summation is done,\nthis passed onto transfer function.\nA transfer function is nothing\nbut an activation function.\nI'll be discussing more\nabout this in a minute.\nThe activation function.\nAnd from the activation function,\nyou'll get the outputs\nY one, Y two, and so on.\nSo guys, you need to\nunderstand four important parts\nin a perceptron.\nSo, firstly, you have the input values.\nYou have X one, X two, X three.\nYou have something known\nas weights and bias,\nand then you have something\nknown as the net sum\nand finally the activation function.\nNow, all the inputs X\nare multiplied with\nthe respective weights.\nSo, X one will be multiplied with W one.\nThis is known as the summation.\nAfter this, you'll add\nall the multiplied values,\nand we'll call them as the weighted sum.\nThis is done using the summation function.\nNow we'll apply the weighted sum\nto a correct activation function.\nNow, a lot of people have a confusion\nabout activation function.\nActivation function is also\nknown as the transfer function.\nNow, in order to understand\nactivation function,\nthis word stems from the way neurons\nin a human brain work.\nThe neuron becomes activate\nonly after a certain potential is reached.\nThat threshold is known as\nthe activation protection.\nTherefore, mathematically,\nit can be represented by a function\nthat reaches saturation after a threshold.\nOkay, we have a lot of\nactivation functions\nlike signum, sigmoid,\ntan, hedge, and so on.\nYou can think of activation function\nas a function that maps the input\nto the respective output.\nAnd now I also spoke\nabout weights and bias.\nNow why do we assign weights\nto each of these inputs?\nWhat weights do is they show a strength\nof a particular input,\nor how important a particular input\nis for predicting the final output.\nSo, basically, the weightage of an input\ndenotes the importance of that input.\nNow, our bias basically allows us\nto shift the activation function\nin order to get a precise output.\nSo that was all about perceptrons.\nNow in order to make you\nunderstand perceptrons better,\nlet's look at a small analogy.\nSuppose that you wanna go to a party\nhappening near your hose.\nNow your decision will\ndepend on a set of factors.\nFirst is how is the weather.\nSecond probably is your\nwife, or your girlfriend,\nor your boyfriend going with you.\nAnd third, is there any\npublic transport available?\nLet's say these are the three factors\nthat you're going to consider\nbefore you go to a party.\nSo, depending on these predictor variables\nor these features,\nyou're going to decide whether\nyou're going to stay at home\nor go and party.\nNow, how is the weather is\ngoing to be your first input.\nWe'll represent this with a value X one.\nIs your wife going with\nyou is another input X two.\nAny public transport is available\nis your another input X three.\nNow, X one will have two\nvalues, one and zero.\nOne represents that the weather is good.\nZero represents weather is bad.\nSimilarly, one represents\nthat your wife is going,\nand zero represents that\nyour wife is not going.\nAnd in X three, again, one represents that\nthere is public transport,\nand zero represents that\nthere is no public transport.\nNow your output will\neither be one or zero.\nOne means you are going to the party,\nand zero means you will\nbe sitting at home.\nNow in order to understand weightage,\nlet's say that the most\nimportant factor for you\nis your weather.\nIf the weather is good,\nit means that you will\n100% go to the party.\nNow if you weather is not good,\nyou've decided that you'll sit at home.\nSo the maximum weightage is\nfor your weather variable.\nSo if your weather is really good,\nyou will go to the party.\nIt is a very important\nfactor in order to understand\nwhether you're going to sit at home\nor you're going to go to the party.\nSo, basically, if X one equal to one,\nyour output will be one.\nMeaning that if your weather is good,\nyou'll go to the party.\nNow let's randomly assign\nweights to each of our input.\nW one is the weight\nassociated with input X one.\nW two is the weight with X two\nand W three is the weight\nassociated with X three.\nLet's say that your W one is six,\nyour W two is two, and W three is two.\nNow by using the activation function,\nyou're going to set a threshold of five.\nNow this means that it will fire\nwhen the weather is good\nand won't fire if the weather is bad,\nirrespective of the other inputs.\nNow here, because your weightage is six,\nso, basically, if you\nconsider your first input\nwhich has a weightage of six,\nthat means you're 100% going to go.\nLet's say you're considering\nonly the second input.\nThis means that you're not going to go,\nbecause your weightage is two\nand your threshold is five.\nSo if your weightage is\nbelow your threshold,\nit means that you're not going to go.\nNow let's consider another scenario\nwhere our threshold is three.\nThis means that it'll fire\nwhen either X one is high\nor the other two inputs are high.\nNow W two is associated with\nyour wife is going or not.\nLet's say the weather is bad\nand you have no public transportation,\nmeaning that your x one\nand x three is zero,\nand only your x two is one.\nNow if your x two is one,\nyour weightage is going to be two.\nIf your weightage is two,\nyou will not go because the\nthreshold value is set to three.\nThe threshold value is\nset in such a way that\nif X two and X three\nare combined together,\nonly then you'll go,\nor only if x one is true, then you'll go.\nSo you're assigning\nthreshold in such a way that\nyou will go for sure\nif the weather is good.\nThis is how you assign threshold.\nThis is nothing but your\nactivation function.\nSo guys, I hope all of you understood,\nthe most amount of weightage\nis associated with the\ninput that is very important\nin predicting your output.\nThis is exactly how a perceptron works.\nNow let's look at the\nlimitations of a perceptron.\nNow in a perceptron, there\nare no hidden layers.\nThere's only an input layer,\nand there is an output layer.\nWe have no hidden layers in between.\nAnd because of this, you cannot classify\nnon-linearly separable data points.\nOkay, if you have data,\nlike in this figure,\nhow will you separate this.\nYou cannot use a perceptron to do this.\nAlright, so complex problems that involve\na lot of parameters cannot be solved\nby a single layer perceptron.\nThat's why we need something known as\nmultiple layer perceptron.\nSo now we'll discuss something known as\nmultilayer perceptron.\nA multilayer perceptron\nhas the same structure\nof a single layer perceptron,\nbut with one or more hidden layer.\nOkay, and that's why it's\nconsider as a deep neural network.\nSo in a single layer perceptron,\nwe had only input layer, output layer.\nWe didn't have any hidden layer.\nNow when it comes to\nmulti-layer perceptron,\nthere are hidden layers in between,\nand then there is the output layer.\nIt was in this similar\nmanner, like I said,\nfirst, you'll have the\ninput X one, X two, X three,\nand so on.\nAnd each of these inputs\nwill be assigned some weight.\nW one, W two, W three, and so on.\nThen you'll calculate\nthe weighted summation\nof each of these inputs and their weights.\nAfter that, you'll send\nthem to the transformation\nor the activation function,\nand you'll finally get the output.\nNow, the only thing is\nthat you'll have multiple\nhidden layers in between,\none or more than one hidden layers.\nSo, guys, this is how a\nmultilayer perceptron works.\nIt works on the concept of\nfeed forward neural networks.\nFeed forward means\nevery node at each level\nor each layer is connected\nto every other node.\nSo that's what feed forward networks are.\nNow when it comes to assigning weights,\nwhat we do is we randomly assign weights.\nInitially we have input\nX one, X two, X three.\nWe randomly assign some\nweight W one, W two, W three,\nand so on.\nNow it's always necessary\nthat whatever weights\nwe assign to our input,\nthose weights are actually correct,\nmeaning that those weights\nare company significant\nin predicting your output.\nSo how a multilayer perceptron works is\na set of inputs are passed\nto the first hidden layer.\nNow the activations from\nthat layer are passed\nthrough the next layer.\nAnd from that layer, it's\npassed to the next hidden layer,\nuntil you reach the output layer.\nFrom the output layer,\nyou'll form the two classes,\nclass one and class two.\nBasically, you'll classify your input into\none of the two classes.\nSo that's how a multilayer\nperceptron works.\nA very important concept the\nmultiple layer perceptron\nis back propagation.\nNow what is back propagation.\nBack propagation algorithm is\na supervised learning method\nfor multilayer perceptrons.\nOkay, now why do we need back propagation?\nSo guys, when we are\ndesigning a neural network\nin the beginning, we initialize weights\nwith some random values, or\nany variable for that fact.\nNow, obviously, we need to\nmake sure that these weights\nactually are correct,\nmeaning that these weights\nshow the significance\nof each predictor variable.\nThese weights have to fit our model\nin such a way that our\noutput is very precise.\nSo let's say that we randomly selected\nsome weights in the beginning,\nbut our model output\nis much more different\nthan our actual output,\nmeaning that our error value is very huge.\nSo how will you reduce this error.\nBasically, what you need to do is\nwe need to somehow explain to the model\nthat we need to change the weight\nin such a way that the\nerror becomes minimum.\nSo the main thing is the\nweight and your error\nis very highly related.\nThe weightage that you give to each input\nwill show how much error\nis there in your output,\nbecause the most significant variables\nwill have the highest weightage.\nAnd if the weightage is not correct,\nthen your output is also not correct.\nNow, back propagation is a\nway to update your weights\nin such a way that your outcome is precise\nand your error is reduced.\nSo, in short back\npropagation is used to train\na multilayer perceptron.\nIt's basically use to update your weights\nin such a way that your\noutput is more precise,\nand that your error is reduced.\nSo training a neural network\nis all about back propagation.\nSo the most common deep learning algorithm\nfor supervised training of\nthe multilayer perceptron\nis known as back propagation.\nSo, after calculating the\nweighted sum of inputs\nand passing them through\nthe activation function,\nwe propagate backwards\nand update the weights\nto reduce the error.\nIt's as simple as that.\nSo in the beginning, you're\ngoing to assign some weights\nto each of your input.\nNow these inputs will go\nthrough the activation function\nand it'll go through all the hidden layers\nand give us an output.\nNow when you get the output,\nthe output is not very precise,\nor it is not the desired output.\nSo what you'll do is\nyou'll propagate backwards,\nand you start updating your weights\nin such a way that your error\nis as minimum as possible.\nSo, I'm going to repeat this once more.\nSo the idea behind back propagation\nis to choose weights in such a way\nthat your error gets minimized.\nTo understand this, we'll\nlook at a small example.\nLet's say that we have a data\nset which has these labels.\nOkay, your input is zero, one, two,\nbut your desired output\nis zero, one, and four\nnow the output of your model\nwhen W equal to three is like this.\nNotice the difference\nbetween your model output\nand your desired output.\nSo, your model output is three,\nbut your desired output is two.\nSimilarly, when your model output is six,\nyour desired output is\nsupposed to be four.\nNow let's calculate the error\nwhen weight is equal to three.\nThe error is zero over here\nbecause your desired output is zero,\nand your model output is also zero.\nNow the error in the second case is one.\nBasically, your model output\nminus your desired output.\nThree minus two, your error is one.\nSimilarly, your error for\nthe third input is two,\nwhich is six minus four.\nWhen you take the square,\nthis is actually a very huge difference,\nyour error becomes larger.\nNow what we need to do\nis we need to update the weight value\nin such a way that our error decreases.\nNow here we've considered\nthe weight as four.\nSo when you consider the weight as four,\nyour model output becomes\nzero, four, and eight.\nYour desired output is\nzero, two, and four.\nSo your model output becomes\nzero, four, and eight,\nwhich is a lot.\nSo guys, I hope you all know\nhow to calculate the output over here.\nWhat I'm doing is I'm\nmultiplying the input\nwith your weightage.\nThe weightage is four,\nso zero into four will give me zero.\nOne into four will give me four,\nand two into four will give me eight.\nThat's how I'm getting my\nmodel output over here.\nFor now, this is how I'm\ngetting the output over here.\nThat's how you calculate your weightage.\nNow, here, if you see\nthat our desire output\nis supposed to be zero, two, and four,\nbut we're getting an output\nof zero, four, and eight.\nSo our error is actually increasing\nas we increase our weight.\nOur error four W equal to four\nhave become zero, four, and 16,\nwhereas the error for W equal to three,\nzero, one, and four.\nI mean the square error.\nSo if you look at this, as\nwe increase our weightage,\nour error is increasing.\nSo, obviously, we know that\nthere is no point in increasing\nthe value of W further.\nBut if we decrease the value of W,\nour error actually decreases.\nAlright, if we give a weightage of two,\nour error decreases.\nIf we can find a relationship\nbetween our weight and error,\nbasically, if you increase the weight,\nyour error also increases.\nIf you decrease the weight,\nyour error also decreases.\nNow what we did here\nis we first initialize\nsome random value to W,\nand then we propagated forward.\nThen we notice that there is some error.\nAnd to reduce that error,\nwe propagated backwards\nand increase the value of W.\nAfter that, we notice that\nthe error has increased,\nand we came to know that we\ncan't increase the w value.\nObviously, if your error is increasing\nwith increasing your weight,\nyou will not increase the weight.\nSo again, we propagated backwards,\nand we decreased the W value.\nSo, after that, we noticed\nthat the error has reduced.\nSo what we're trying\nis we're trying to get\nthe value of weight in such a way\nthat the error becomes\nas minimum as possible\nso we need to figure out whether we need\nto increase or decrease thew eight value.\nOnce we know that, we keep\non updating the weight value\nin that direction,\nuntil the error becomes minimum.\nNow you might reach a point where\nif you further update the weight,\nthe error will again increase.\nAt that point, you need to stop.\nOkay, at that point\nis where your final weight value is there.\nSo, basically, this\ngraph denotes that point.\nNow this point is nothing\nbut the global loss minimum.\nIf you update the weights further,\nyour error will also increase.\nNow you need to find out where\nyour global loss minimum is,\nand that is where your\noptimum weight lies.\nSo let me summarize the steps for you.\nFirst, you'll calculate the error.\nThis is how far your model output is\nfrom your actual output.\nThen you'll check whether the error\nis minimized or not.\nAfter that, if the error is very huge,\nthen you'll update the weight,\nand you'll check the error again.\nYou'll repeat the process\nuntil the error becomes minimum\nnow once you reach the\nglobal loss minimum,\nyou'll stop updating the weights,\nand we'll finalize your weight value.\nThis is exactly how\nback propagation works.\nNow in order to tell you\nmathematically what we're doing\nis we're using a method\nknown as gradient descent.\nOkay, this method is used\nto adjust all the weights in the network\nwith an aim of reducing the\nerror at the output layer.\nSo how gradient descent\noptimize our works is\nthe first step is you\nwill calculate the error\nby considering the below equation.\nHere you're subtracting the\nsummation of your actual output\nfrom your network output.\nStep two is based on the error you get,\nyou will calculate the\nrate of change of error\nwith respect to the change in the weight.\nThe learning rate is\nsomething that you set\nin the beginning itself.\nStep three is based on\nthis change in weight,\nyou will calculate the new weight.\nAlright, your updated\nweight will be your weight\nplus the rate of change of weight.\nSo guys, that was all about\nback propagation and weight update.\nNow let's look at the limitations\nof feed forward network.\nSo far, we were discussing\nthe multiple layer perceptron,\nwhich uses the feed forward network.\nLet's discuss the limitations of these\nfeed forward networks.\nNow let's consider an example\nof image classification.\nOkay, let's say you've\ntrained the neural network\nto classify images of various animals.\nNow let's consider an example.\nHere the first output is an elephant.\nWe have an elephant.\nAnd this output will have nothing to do\nwith the previous output, which is a dog.\nThis means that the output at time T\nis independent of the\noutput at time T minus one.\nNow consider this scenario\nwhere you will require the use\nof previously obtained output.\nOkay, the concept is very\nsimilarly to reading a book.\nAs you turn every page, you need\nan understanding of the previous pages\nif you want to make\nsense of the information,\nthen you need to know\nwhat you learned before.\nThat's exactly what\nyou're doing right now.\nIn order to understand deep learning,\nyou have to understand machine learning.\nSo, basically, with the\nfeed forward network\nthe new output at time T plus one\nhas nothing to do with\nthe output at time T,\nor T minus one, or T minus two.\nSo feed forward networks cannot be used\nwhile predicting a word in a sentence,\nas it will have absolutely no relationship\nwith the previous set of words.\nSo, a feed forward\nnetwork cannot be used in\nuse cases wherein you have\nto predict the outcome\nbased on your previous outcome.\nSo, in a lot of use cases,\nyour previous output will also\ndetermine your next output.\nSo, for such cases, you may not make use\nof feed forward network.\nNow, what modification can you make\nso that your network can learn\nfrom your previous mistakes.\nFor this, we have solution.\nSo, a solution to this is\nrecurrent neural networks.\nSo, basically, let's say you have an input\nat time T minus one,\nand you'll get some output when\nyou feed it to the network.\nNow, some information from\nthis input at T minus one\nis fed to the next input,\nwhich is input at time T.\nSome information from this output\nis fed into the next input,\nwhich is input at T plus one.\nSo, basically, you keep\nfeeding information\nfrom the previous input to the next input.\nThat's how recurrent neural\nnetworks really work.\nSo recurrent networks\nare a type of artificial neural networks\ndesigned to recognize\npatterns in sequence of data,\nsuch as text, genomes,\nhandwriting, spoken words,\ntime series data, sensors, stock markets,\nand government agencies.\nSo, guys, recurrent neural\nnetworks are actually\na very important part of deep learning,\nbecause recurring neural networks have\napplications in a lot of domains.\nOkay, in time series and in stock markets,\nthe main network that I use\nare recurrent neural networks,\nbecause each of your inputs are correlated\nnow to better understand\nrecurrent neural networks,\nlet's consider a small example\nlet's say that you go\nto the gym regularly,\nand the trainer has given you\na schedule for your workout.\nSo basically, the exercises are repeated\nafter every third day.\nOkay, this is what your\nschedule looks like.\nSo, make a note that all\nthese exercises are repeated\nin a proper order or in\na sequence every week\nfirst, let us use a feedforward network\nto try and predict the type of exercises\nthat we're going to do.\nThe inputs here are Day\nof the week, the month,\nand your health status.\nOkay, so, neural network has to be trained\nusing these inputs to provide\nus with the prediction\nof the exercise that we should do.\nNow let's try and understand\nthe same thing using\nrecurrent neural networks.\nIn recurrent neural networks,\nwhat we'll do is we'll consider the inputs\nof the previous day.\nOkay, so if you did a\nshoulder workout yesterday,\nthen you can do a bicep exercise today,\nand this goes on for the rest of the week.\nHowever, if you happen\nto miss a day at the gym,\nthe data from the previously\nattended time stamps\ncan be considered.\nIt can be done like this.\nSo, if a model is\ntrained based on the data\nit can obtain from the previous exercise,\nthe output on the model\nwill be extremely accurate.\nIn such cases, if you\nneed to do know the output\nat T minus one in order to\npredict the output at T.\nIn such cases, recurrent neural\nnetworks are very essential.\nSo, basically, I'm feeding some inputs\nthrough the neural networks.\nYou'll go through a few functions,\nand you'll get the output.\nSo, basically, you're\npredicting the output\nbased on past information\nor based on your past input.\nSo that's how recurrent\nneural networks work.\nNow let's look at another\ntype of neural network\nknown as convolutional neural network.\nTo understand why we need\nconvolutional neural networks,\nlet's look at an analogy.\nHow do you think a\ncomputer reads an image?\nConsider this image.\nThis is a New York skyline image.\nOn the first glance,\nyou'll see a lot of buildings\nand a lot of colors.\nHow does a computer process this image?\nThe image is actually broken\ndown into three color channels,\nwhich is the red, green, and blue.\nIt reads in the form of RGB values.\nNow each of these color\nchannels are mapped\nwith the image's pixel\nthen the computer will recognize the value\nassociated with each pixel,\nand determine the size of the image.\nNow for the black and white images,\nthere is only one channel,\nbut the concept is still the same.\nThe thing is we cannot make use of\nfully connected networks when it comes to\nconvolutional neural networks.\nI'll tell you why.\nNow consider the first input image.\nOkay, first image has size about\n28 into 28 into three pixels.\nAnd if we input this to a neural network,\nwe'll get about 2,352 weights\nin the first hidden layer itself.\nNow consider another example.\nOkay, let's say we have an image\nof 200 into 200 into three pixels.\nSo the size of your first hidden layer\nbecomes around 120,000.\nNow if this is just\nthe first hidden layer,\nimagine the number of\nneurons that you need\nto process an entire complex image set.\nThis leads to something\nknown as overfitting,\nbecause all of the hidden\nlayers are connected.\nThey're massively connected.\nThere's connection between\neach and every node.\nBecause of this, we face overfitting.\nWe have way too much of data.\nWe have to use way too many neurons,\nwhich is not practical.\nSo that's why we have something known as\nconvolutional neural networks.\nNow convolutional neural networks,\nlike any other neural network\nare made up of neurons with\nlearnable weights and basis.\nSo each neuron receives several input.\nIt takes a weighted sum over them,\nand it gets passed on through\nsome activation function,\nand finally responds with an output.\nSo, the concept in\nconvolutional neural networks\nis that the neuron in a particular layer\nwill only be connected to a small region\nof the layer before it.\nNot all the neurons will be connected\nin a fully-connected manner,\nwhich leads to overfitting\nbecause we need way too many neurons\nto solve this problem.\nOnly the regions, which are significant\nare connected to each other.\nThere is no full connection\nin convolutional neural networks.\nSo gus, what we did so far is we discussed\nwhat a perceptron is.\nWe discussed the different types\nof neural networks that are there.\nWe discussed a feedforward neural network.\nWe discuss multi layer perceptrons\nwe discussed recurrent neural networks,\nand convolutional neural networks.\nI'm not going to go too much in depth\nwith these concepts\nnow I'll be executing a demo.\nIf you you haven't understood any\ntheoretical concept of deep learning,\nplease let me know in the comment section.\nApart from this, I'll also leave\na couple of links in the description box,\nso that you understand the\nwhole download in a better way.\nOkay, if you want a more\nin-depth explanation,\nI'll leave a couple of links\nin the description box.\nFor now, what I'm gonna\ndo is I'll be running\na practical demonstration to show you\nwhat exactly download does\nso, basically, what we're\ngoing to do in this demo\nis we're going to predict stock prices.\nLike I said, stock price prediction\nis one of the very good applications\nof deep neural networks.\nYou can easily predict the stock price\nof a particular stock for the next minute\nor the next day by using\ndeep neural networks.\nSo that's exactly what\nwe're gonna do in this demo\nnow, before I discuss the code,\nlet me tell you a few\nthings about our data set.\nThe data set contains\naround 42,000 minutes\nof data ranging from April to August 2017\non 500 stocks,\nas well as the total S&P 500 Index price.\nSo the index and stocks are arranged\nin a wide format.\nSo, this is my data set, data_stocks.\nIt's in the CSV format.\nSo what I'm gonna do is I'm going to use\nthe read CSV function in\norder to import this data set.\nThis is just the part of\nwhere my data set is stored.\nThis data set was actually\ncleaned and prepared,\nmeaning that we don't\nhave any missing stock\nand index prices.\nSo the file does not\ncontain any missing values.\nNow what we're gonna do first\nis we'll drop the data valuable\nwe have a variable known as date,\nwhich is not really necessary\nin predicting our outcome over here.\nSo that's exactly what I'm doing here.\nI'm just dropping the date variable.\nSo here, I'm checking the\ndimensions of the data set.\nThis is pretty understandable,\nusing the shape function to do that.\nNow, always you make the\ndata as a NymPy array.\nThis makes computation much easier.\nThe next process is the data splicing.\nI've already discussed data\nthe data splicing with you all.\nHere we're just preparing the training\nand the testing data.\nSo the training data will contain\n80% of the total data set.\nOkay, and also we are not\nshuffling the data set.\nWe're just slicing the\ndata set sequentially.\nThat's why we have a test start start\nand the test end variable.\nIn sequence, I'll be selecting the data.\nThere's no need of\nshuffling this data set.\nThese are stock prices\nit does not make sense\nto shuffle this data.\nNow in the next step, we're going to do is\nwe're going to scale the data\nnow, scaling data and data normalization\nis one of the most important steps.\nYou cannot miss this step\nI already mentioned earlier\nwhat normalization and scaling is.\nNow most neural networks\nbenefit from scaling inputs.\nThis is because most\ncommon activation function\nof the networks neuron such\nas tan, hedge, and sigmoid.\nTan, hedge, and sigmoid are\nbasically activation functions,\nand these are defined in the\nrange of minus one to one\nor zero and one.\nSo that's why scaling\nis an important thing\nin deep neural networks\nfor scaling, again, we'll\nuse the MinMaxScaler.\nSo we're just importing\nthat function over here.\nAnd also one point to note is that\nyou have to be very cautious\nabout what part of data you're scaling\nand when you're doing it.\nA very common mistake is\nto scale the whole data set\nbefore training and test\nsplits are being applied.\nSo before data splicing itself,\nyou shouldn't be scaling your data.\nNow this is a mistake because\nscaling invokes the\ncalculation of statistics.\nFor example, minimum or\nmaximum range of the variable\ngets affected.\nSo when performing time series\nforecasting in real life,\nyou do not have information\nfrom future observations\nat the time of forecasting.\nThat's why calculation\nof scaling statistics\nhas to be conducted on training data,\nand only then it has to be\napplied to the test data.\nOtherwise, you're basically\nusing the future information\nat the time of forecasting,\nwhich obviously going to lead to biasness\nso that's why you need to make sure\nyou do scaling very accurately.\nSo, basically, what we're\ndoing is the number of features\nin the training data are stored\nin a variable known as n stocks.\nAfter this, we'll import\nthe infamous TensorFlow.\nSo guys, TensorFlow is\nactually a very good\npiece of software and it\nis currently the leading\ndeep learning and neural\nnetwork computation framework.\nIt is based on a C++ low-level backend,\nbut it's usually\ncontrolled through Python.\nSo TensorFlow actually operates as\na graphical representation\nof your computations.\nAnd this is important\nbecause neural networks\nare actually graphs of data\nand mathematical operation.\nSo that's why TensorFlow is just perfect\nfor neural networks and deep learning.\nSo the next thing after\nimporting the TensorFlow library\nis something known as placeholders.\nPlaceholders are used to\nstore, import, and target data.\nWe need two placeholders\nin order to fit our model.\nSo basically, X will\ncontain the network's input,\nwhich is the stock\nprices of all the stocks\nat time T equal to T.\nAnd y will contain the network's output,\nwhich is the stock price at\ntime T is equal to T plus one.\nNow the shape of the X placeholder\nmeans that the inputs are\ntwo-dimensional matrix.\nAnd the outputs are a\none-dimensional vector.\nSo guys, basically, the\nnon-argument indicates\nthat at this point we do not yet know\nthe number of observations\nthat'll flow through the neural network.\nWe just keep it as a\nflexible array for now.\nWe'll later define the variable batch size\nthat controls the number of observations\nin each training batch.\nNow, apart form this, we also have\nsomething know as initializers.\nNow, before I tell you what\nthese initializers are,\nyou need to understand that\nthere's something known as variables\nthat are used as flexible containers\nthat are allowed to change\nduring the execution.\nWeights and bias are\nrepresented as variables\nin order to adapt during training.\nI already discuss weights\nand bias with you earlier.\nNow weights and bias is something\nthat you need to initialize\nbefore you train the model.\nThat's how we discussed it\neven while I was explaining\nneural networks to you.\nSo here, basically, we make\nuse of something known as\nvariant scaling initializer\nand for bias initializer,\nwe make use of zeros initializers.\nThese are some predefined\nfunctions in our TensorFlow model.\nWe'll not get into the\ndepth of those things.\nNow let's look at our model\narchitecture parameters.\nSo the next thing we have to discuss\nis the model architecture parameters.\nNow the model that we build,\nit consists of four hidden layers.\nFor the first layer, we've\nassigned 1,024 neurons\nwhich is likely more than\ndouble the size of the inputs.\nThe subsequent hidden layers are always\nhalf the size of the previous layer,\nwhich means that in the\nhidden layer number two,\nwe'll have 512 neurons.\nHidden layer three will have 256.\nAnd similarly, hidden layer number four\nwill have 128 neurons.\nNow why do we keep reducing\nthe number of neurons\nas we go through each hidden layer.\nWe do this because the number of neurons\nfor each subsequent layer\ncompresses the information\nthat the network identifies\nin the previous layer.\nOf course there are other\npossible network architectures\nthat you can apply for\nthis problem statement,\nbut I'm trying to keep\nit as simple as possible,\nbecause I'm introducing\ndeep learning to you all.\nSo I can't build a model architecture\nthat's very complex and hard to explain.\nAnd of course, we have output over here\nwhich will be assigned a single neuron.\nNow it is very important to understand\nthat variable dimensions\nbetween your input,\nhidden, and output layers.\nSo, as a rule of thumb in\nmultilayer perceptrons,\nthe second dimension of the previous layer\nis the first dimension\nin the current layer.\nSo the second dimension\nin my first hidden layer\nis going to be my first dimension\nin my second hidden layer.\nNow the reason behind\nthis is pretty logical.\nIt's because the output\nfrom the first hidden layer\nis passed on as an input\nto the second hidden layer.\nThat's why the second\ndimension of the previous layer\nis the same as the first dimension\nof the next layer or the current layer.\nI hope this is understandable.\nNow coming to the bias\ndimension over here,\nthe bias dimension is always\nequal to the second dimension\nof your current layer,\nmeaning that you're just going to pass\nthe number of neurons in\nthat particular hidden layer\nas your dimension in your bias.\nSo here, the number of neurons, 1,024,\nyou're passing the same number\nas a parameter to your bias.\nSimilarly, even for\nhidden layer number two,\nif you see a second dimension here\nis n_neurons_2.\nI'm passing the same\nparameter over here as well.\nSimilarly, for hidden layer three\nand hidden layer number four.\nAlright, I hope this is understandable\nnow we come to the output layer.\nThe output layer will obviously have\nthe output from hidden layer number four.\nThis is our output from hidden layer four\nthat's passed as the first\ndimension in our output layer,\nand it'll finally have your n target,\nwhich is set to one over here.\nThis is our output.\nYour bias will basically have\nthe current layer's dimension,\nwhich is n target.\nYou're passing that same\nparameter over here.\nNow after you define the required weight\nand the bias variables,\nthe architecture of the\nnetwork has to be specified.\nWhat you do is placeholders and variables\nneed to be combined into a system of\nsequential matrix multiplication.\nSo that's exactly what's\nhappening over here.\nApart from this, all the hidden layers\nneed to be transformed by\nusing the activation function.\nSo, activation functions are important\ncomponents of the network\nbecause they introduce\nnon-linearity to the system.\nThis means that high dimensional data\ncan be dealt with with the help\nof the activation functions.\nObviously, we have very\nhigh dimensional data\nwhen it comes to neural networks.\nWe don't have a single dimension\nor we don't have two or three inputs.\nWe have thousands and thousands of inputs.\nSo, in order for a\nneural network to process\nthat much of high dimensional data,\nwe need something known\nas activation functions.\nThat's why we make use\nof activation functions.\nNow, there are dozens\nof activation functions,\nand one of the most common one\nis the rectified linear unit,\nrectified linear unit.\nRELU is nothing but rectified linear unit,\nwhich is what we're gonna\nbe using in this model.\nSo, after, you applied the\ntransformation function\nto your hidden layer, you\nneed to make sure that\nyour output is transposed.\nThis is followed by a very\nimportant function known as\ncost function.\nSo the cost function of a network\nis used to generate a measure of deviation\nbetween the network's prediction\nand the actual observed training targets.\nSo this is basically your actual output\nminus your model output.\nIt basically calculates the\nerror between your actual output\nand your predicted output.\nSo, for regression problems,\nthe mean squared error function\nis commonly used.\nI have discussed MSC, mean\nsquared error, before.\nSo, basically, we are just measuring\nthe deviation over here.\nMSC is nothing bot your deviation\nfrom your actual output.\nThat's exactly what we're doing here.\nSo after you've computed your error,\nthe next step is obviously to update\nyour weight and your bias.\nSo, we have something\nknown as the optimizers.\nThey basically take care of\nall the necessary computations\nthat are needed to adapt\nthe network's weight\nand bias variables during\nthe training phase.\nThat's exactly what's happening over here.\nNow the main function of\nthis optimizer is that\nit invoke something known as a gradient.\nNow if you all remember, we\ndiscussed gradient before\nit basically indicates the direction\nin which the weights and the bias\nhas to be changed during the training\nin order to minimize the\nnetwork's cost function\nor the network's error.\nSo you need to figure out\nwhether you need to increase\nthe weight and the bias in\norder to decrease the error,\nor is it the other way around?\nYou need to understand the relationship\nbetween your error and\nyour weight variable.\nThat's exactly what the optimizer does.\nIt invokes the gradient.\nWe will give you the\ndirection in which the weights\nand the bias have to be changed.\nSo now that you know\nwhat an optimizer does,\nin our model, we'll be using\nsomething known as the AdamOptimizer.\nThis is one of the\ncurrent default optimizers\nin deep learning.\nAdam basically stands for\nadaptive moment estimation,\nand it can be considered\nas a combination between\nvery two popular optimizers\ncalled Adagrad and RMSprop.\nNow let's not get into the\ndepth of the optimizers.\nThe main agenda here\nis for you to understand the\nlogic behind deep learning.\nWe don't have to go into the functions.\nI know these are predefined functions\nwhich TensorFlow takes care of.\nNext we have something\nknown as initializers.\nNow, initializers are used to initialize\nthe network's variables before training.\nWe already discussed this before.\nI'll define the initializer here again.\nI've already done it\nearlier in this session.\nInitializers are already defined.\nSo I just removed that line of code.\nNext step would be fitting\nthe neural network.\nSo after we've defined the\nplace holders, the variables,\nvariables which are\nbasically weights and bias,\nthe initializers, the cost functions,\nand the optimizers of the network,\nthe model has to be trained.\nNow, this is usually done by using\nthe mini batch training method,\nbecause we have very huge data set.\nSo it's always best to use the\nmini batch training method.\nNow what happens during\nmini batch training\nis random data samples of any batch size\nare drawn from the training data,\nand they are fed into the network.\nSo the training data set gets divided into\nN divided by your batch size batches\nthat are sequentially\nfed into the network.\nSo, one after the other,\neach of these batches will\nbe fed into the network.\nAt this point, the placeholder\nwhich are your X and Y,\nthey come into play.\nThey store the input and the target data\nand present them to the\nnetwork as inputs and targets.\nThat's the main functionality\nof placeholders.\nWhat they do is they store\nthe input and the target data,\nand they provide this to the network\nas inputs and targets.\nThat's exactly what your placeholders do.\nSo let's say that a\nsample data batch of X.\nNow this data batch\nflows through the network\nuntil it reaches the output layer.\nThere the TensorFlow compares\nthe model's predictions\nagainst the actual observed targets,\nwhich is stored in Y.\nIf you all remember,\nwe stored our actual\nobserved targets in Y.\nAfter this, TensorFlow will conduct\nsomething known as optimization step,\nand it'll update the network's parameters\nlike the weight of the\nnetwork and the bias.\nSo after having update\nyour weight and the bias,\nthe next batch is sampled and\nthe process gets repeated.\nSo this procedure will continue\nuntil all the batches have\npresented to the network.\nAnd one full sweep over all batches\nis known as an epoch.\nSo I've defined this\nentire thing over here.\nSo we're gonna go through 10 epochs,\nmeaning that all the batches\nare going to go through training,\nmeaning you're going to\ninput each batch that is X,\nand it'll flow through the network\nuntil it reaches the output layer.\nThere what happens is TensorFlow\nwill compare your predictions.\nThat is basically what\nyour model predicted\nagainst the actual observed targets\nwhich is stored in Y.\nAfter this, TensorFlow\nwill perform optimization\nwherein it'll update the network paramters\nlike your weight and your bias.\nAfter you update the weight and the bias,\nthe next batch will get sampled\nand the process will keep repeating.\nThis happens until all the batches are\nimplemented in the network.\nSo what I just told you was one epoch.\nWe're going to repeat this 10 times.\nSo a batch size is 256,\nmeaning that we have 256 batches.\nSo here we're going to assign x and y,\nwhat I just spoke to you about.\nThe mini batch training starts over here\nso, basically, your first batch\nwill start flowing through the network\nuntil it reaches the output layer.\nAfter this, TensorFlow will\ncompare your model's prediction.\nThis is where predictions happen.\nIt'll compare your model's prediction\nto the actual observed targets\nwhich is stored in y.\nThen TensorFlow will\nstart doing optimization,\nand it'll update the network paramters\nlike your weight and your bias.\nSo after you update the\nweight and the biases,\nthe next batch will get\ninput into the network,\nand this process will keep repeating.\nThis process will repeat 10 times\nbecause we've defined 10 epochs.\nNow, also during the training,\nwe evaluate the network's\nprediction on the test set,\nwhich is basically the data\nwhich we haven't learned,\nbut this data is set aside\nfor every fifth batch,\nand this is visualized.\nSo in our problem statement,\nwhat a network is going to do\nis it's going to predict the stock price\ncontinuously over a time\nperiod of T plus one.\nWe're feeding it data about\na stock price at time T.\nIt's going to give us an\noutput of time T plus one.\nNow let me run this code\nand let's see how close\nour predicted values are\nto the actual values.\nWe're going to visualize\nthis entire thing,\nand we've also exported this\nin order to combine it\ninto a video animation.\nI'll show you what the video looks like.\nSo now let's look at our visualization.\nWe'll look at our output.\nSo the orange basically\nshows our model's prediction.\nSo the model quickly learns the shape\nand the location of the\ntime series in the test data\nand showing us an accurate prediction.\nIt's pretty close to\nthe actual prediction.\nNow as I'm explaining this to you,\neach batch is running here.\nWe are at epoch two.\nWe have 10 epochs to go over here.\nSo you can see that the\nnetwork is actually adapting\nto the basic shape of the time series,\nand it's learning finer\npatterns in the data.\nYou see it keeps learning patterns\nand the production is\ngetting closer and closer\nafter every epoch.\nSo let just wait til we reach epoch 10\nand we complete the entire process.\nSo guys, I think the\npredictions are pretty close,\nlike the pattern and the\nshape is learned very well\nby our neural network.\nIt is actually mimicking this network.\nThe only deviation is in the values.\nApart from that, it's learning the shape\nof the time series data\nin almost the same way.\nThe shape is exactly the same.\nIt looks very similar to me.\nNow, also remember that\nthere are a lot of ways\nof improving your result.\nYou can change the design of your layers\nor you can change the number of neurons.\nYou can choose different\ninitialization functions\nand activation functions.\nYou can introduce something\nknown as dropout layers\nwhich basically help you\nto get rid of overfitting,\nand there's also something\nknown as early stopping.\nEarly stopping helps you understand\nwhere you must stop your batch training.\nThat's also another method\nthat you can implement\nfor improving your model.\nNow there are also different\ntypes of deep learning model\nthat you can use for this problem.\nHere we use the feedforward network,\nwhich basically means that the batches\nwill flow from left to right.\nOkay, so our 10 epochs are over.\nNow the final thing that's\ngetting calculate is our error,\nMSC or mean squared error.\nSo guys, don't worry about this warning.\nIt's just a warning.\nSo our mean square error\ncomes down to 0.0029\nwhich is pretty low because\nthe target is scaled.\nAnd this means that our\naccuracy is pretty good.\nSo guys, like I mentioned,\nif you want to improve\nthe accuracy of the model,\nyou can use different schemes,\nyou can use different\ninitialization functions,\nor you can try out different\ntransformation functions.\nYou can use something\nknown as dropout technique\nand early stopping in order\nto make the training phase\neven more better.\nSo guys, that was the end\nof our deep learning demo.\nI hope all of you understood\nthe deep learning demo.\nFor those of you who are just learning\ndeep learning for the first time,\nit might be a little confusing.\nSo if you have any doubts\nregarding the demo,\nlet me know in the comment section.\nI'll also leave a couple of\nlinks in the description box,\nso that you can understand deep learning\nin a little more depth.\nNow let's look at our\nfinal topic for today,\nwhich is natural language processing.\nNow before we understand\nwhat text mining is\nand what natural language processing is,\nwe have to understand\nthe need for text mining\nand natural language processing.\nSo guys, the number one reason why we need\ntext mining and natural\nlanguage processing\nis because of the amount of data\nthat we're generating during this time.\nLike I mentioned earlier,\nthere are around 2.5\nquintillion bytes of data\nthat is created every day,\nand this number is only going to grow.\nWith the evolution of communication\nthrough social media,\nwe generate tons and tons of data.\nThe numbers are on your screen.\nThese numbers are\nliterally for every minute.\nOn Instagram, every minute, 1.7\nmillion pictures are posted.\nOkay, 1.7 or more than 1.7\nmillion pictures are posted.\nSimilarly, we have tweets.\nWe have around 347,000 tweets\nevery minute on Twitter.\nThis is actually a lot and lot of data.\nSo, every time we're using a phone,\nwe're generating way too much data.\nJust watching a video on YouTube\nis generating a lot of data.\nWhen sending text messages from WhatsApp,\nthat is also generating\ntons and tons of data.\nNow the only problem is\nnot our data generation.\nThe problem is that out of all the data\nthat we're generating,\nonly 21% of the data\nis structured and well-formatted.\nThe remaining of the data is unstructured,\nand the major source of\nunstructured data include\ntext messages from\nWhatsApp, Facebook likes,\ncomments on Instagram, bulk emails\nthat we send out ever single day.\nAll of this accounts for\nthe unstructured data\nthat we have today.\nNow the question here is what can be done\nwith so much data.\nNow the data that we generate\ncan be used to grow businesses.\nBy analyzing and mining the data,\nwe can add more value to a business.\nThis exactly what text\nmining is all about.\nSo text mining or text analytics\nis the analysis of data available to us\nin a day-to-day spoken\nor written language.\nIt is amazing so much\ndata that we generate\ncan actually be used in text mining.\nWe have data from word Word documents,\nPowerPoints, chat messages, emails.\nAll of this is used to\nadd value to a business\nnow the data that we get from sources\nlike social media, IoT,\nthey are mainly unstructured,\nand unstructured data cannot be used\nto draw useful insights\nto grow a business.\nThat's exactly why we need to text mining.\nText mining or text analytics\nis the process of deriving\nmeaningful information\nfrom natural language text.\nSo, all the data that we\ngenerate through text messages,\nemails, documents, files,\nare written in natural language text.\nAnd we are going to use text mining\nand natural language processing\nto draw useful insights or\npatterns from such data.\nNow let's look at a few examples\nto show you how natural\nlanguage processing\nand text mining is used.\nSo now before I move any further,\nI want to compare text mining and NLP.\nA lot of you might be confused\nabout what exactly text mining is\nand how is it related to\nnatural language processing.\nA lot of people have also asked me\nwhy is NLP and text mining\nconsidered as one and the same\nand are they the same thing.\nSo, basically, text mining is a vast field\nthat makes use of natural\nlanguage processing\nto derive high quality\ninformation from the text.\nSo, basically, text mining is a process,\nand natural language\nprocessing is a method\nused to carry out text mining.\nSo, in a way, you can say that text mining\nis a vast field which uses and NLP\nin order perform text\nanalysis and text mining.\nSo, NLP is a part of text mining.\nNow let's understand what exactly\nnatural language processing is.\nNow, natural language processing\nis a component of text mining\nwhich basically helps a\nmachine in reading the text.\nObviously, machines don't\nactually known English or French,\nthey interpret data in the\nform of zeroes and ones.\nSo this is where natural\nlanguage processing comes in.\nNLP is what computers and smart phones\nuse to understand our language,\nboth spoken and written language.\nNow because use language to\ninteract with our device,\nNLP became an integral part of our life.\nNLP uses concepts of computer science\nand artificial intelligence\nto study the data and derive\nuseful information from it.\nNow before we move any further,\nlet's look at a few applications\nof NLP and text mining.\nNow we all spend a lot\nof time surfing the webs.\nHave you ever notice that\nif you start typing a word on Google,\nyou immediately get\nsuggestions like these.\nThese feature is also\nknown as auto complete.\nIt'll basically suggest the\nrest of the word for you.\nAnd we also have something\nknown as spam detection.\nHere is an example of\nhow Google recognizes\nthe misspelling Netflix\nand shows results for keywords\nthat match your misspelling.\nSo, the spam detection is also based\non the concepts of text mining\nand natural language processing.\nNext we have predictive\ntyping and spell checkers.\nFeatures like auto correct,\nemail classification\nare all applications\nof text mining and NLP.\nNow we look at a couple\nof more applications\nof natural language processing.\nWe have something known\nas sentimental analysis.\nSentimental analysis is extremely useful\nin social media monitoring,\nbecause it allows us to gain an overview\nof the wider public opinion\nbehind certain topics.\nSo, basically, sentimental analysis\nis used to understand the public's opinion\nor customer's opinion on a certain product\nor on a certain topic.\nSentimental analysis is\nactually a very huge part\nof a lot of social media platforms\nlike Twitter, Facebook.\nThey use sentimental\nanalysis very frequently.\nThen we have something known as chatbot.\nChatbots are basically the solutions\nfor all the consumer frustration,\nregarding customer call assistance.\nSo we have companies like Pizza Hut, Uber\nwho have started using chatbots\nto provide good customer service,\napart form that speech recognition.\nNLP has widely been used\nin speech recognition.\nWe're all aware of Alexa,\nSiri, Google Assistant,\nand Cortana.\nThese are all applications of\nnatural language processing.\nMachine translation is another\nimportant application of NLP.\nAn example of this is\nthe Google Translator\nthat uses NLP to process and translate\none language to the other.\nOther application include spell checkers,\nkeywords search, information extraction,\nand NLP can be used to\nget useful information\nfrom various website, from word documents,\nfrom files, and et cetera.\nIt can also be used in\nadvertisement matching.\nThis basically means a\nrecommendation of ads\nbased on your history.\nSo now that you have a\nbasic understanding of where\nnatural language processing is used\nand what exactly it is,\nlet's take a look at\nsome important concepts.\nSo, firstly, we're gonna\ndiscuss tokenization.\nNow tokenization is the mos\nbasic step in text mining.\nTokenization basically\nmeans breaking down data\ninto smaller chunks or tokens\nso that they can be easily analyzed.\nNow how tokenization works is\nit works by breaking a\ncomplex sentence into words.\nSo you're breaking a\nhuge sentence into words.\nYou'll understand the\nimportance of each of the word\nwith respect to the whole sentence,\nafter which will produce a description\non an input sentence.\nSo, for example, let's\nsay we have this sentence,\ntokens are simple.\nIf we apply tokenization on this sentence,\nwhat we get is this.\nWe're just breaking a sentence into words.\nThen we're understanding the importance\nof each of these words.\nWe'll perform NLP process\non each of these words\nto understand how important each word\nis in this entire sentence.\nFor me, I think tokens and\nsimple are important words,\nare is basically another stop word.\nWe'll be discussing about stop\nwords in our further slides.\nBut for now, you eed to\nunderstand that tokenization\nis a very simple process that involves\nbreaking sentences into words.\nNext, we have something known as stemming.\nStemming is basically normalizing words\ninto its base form or into its root form.\nTake a look at this example.\nWe have words like detection,\ndetecting, detected, and detections.\nNow we all know that the root word\nfor all these words is detect.\nBasically, all these words mean detect.\nSo the stemming algorithm\nworks by cutting off the end\nor the beginning of the word\nand taking into account\na list of common prefixes\nand suffixes that can\nbe found on any word.\nSo guys, stemming can be\nsuccessful in some cases,\nbut not always.\nThat is why a lot of people affirm that\nstemming has a lot of limitations.\nSo, in order to overcome\nthe limitations of stemming,\nwe have something known as lemmatization.\nNow what lemmatization does is\nit takes into consideration\nthe morphological analysis\nof the words.\nTo do so, it is necessary to\nhave a detailed dictionary\nwhich the algorithm can look\nthrough to link the form\nback to its lemma.\nSo, basically lemmatization\nis also quite similar to stemming.\nIt maps different words\ninto one common root.\nSometimes what happens in stemming is that\nmost of the words gets cut off.\nLet's say we wanted to\ncut detection into detect.\nSometimes it becomes\ndet or it becomes tect,\nor something like that.\nSo because of this, the grammar\nor the importance of the word goes away.\nYou don't know what\nthe words mean anymore.\nDue to the indiscriminate\ncutting of the word,\nsometimes the grammar the\nunderstanding of the word\nis not there anymore.\nSo that's why lemmatization\nwas introduced.\nThe output of lemmatization\nis always going to be\na proper word.\nOkay, it's not going to be\nsomething that is half cut\nor anything like that.\nYou're going to understand\nthe morphological analysis\nand then only you're going\nto perform lemmatization.\nAn example of a lemmatizer\nis you're going to convert\ngone, going, and went into go.\nAll the three words anyway\nmean the same thing.\nSo you're going to convert it into go.\nWe are not removing the first\nand the last part of the word.\nWhat we're doing is we're understanding\nthe grammar behind the word.\nWe're understanding the English\nor the morphological analysis of the word,\nand only then we're going\nto perform lemmatization.\nThat's what lemmatization is all about.\nNow stop words are basically a set of\ncommonly used words in any\nlanguage, not just English.\nNow the reason why stop words\nare critical to many applications is that\nif we remove the words\nthat are very commonly used\nin a given language,\nwe can finally focus\non the important words.\nFor example, in the\ncontext of a search engine,\nlet's say you open up Google\nand you try how to make\nstrawberry milkshake.\nWhat the search engine is going to do is\nit's going to find a lot more pages\nthat contain the terms how to make,\nrather than pages which contain the recipe\nfor your strawberry milkshake.\nThat's why you have to\ndisregard these terms.\nThe search engine can actually focus\non the strawberry milkshake recipe,\ninstead of looking for pages\nthat have how to and so on.\nSo that's why you need to\nremove these stop words.\nStop words are how to, begin,\ngone, various, and, the,\nall of these are stop words.\nThey are not necessarily important\nto understand the\nimportance of the sentence.\nSo you get rid of these\ncommonly used words,\nso that you can focus\non the actual keywords.\nAnother term you need to understand\nis document term matrix.\nA document term matrix\nis basically a matrix\nwith documents designated by\nroles and words by columns.\nSo if your document one has\nthis sentence, this is fun,\nor has these word, this is fun,\nthen you're going to get\none, one, one over here.\nIn document two, if you see\nwe have this and we have is,\nbut we do not have fun.\nSo that's what a document term matrix is.\nIt is basically to understand\nwhether your document\ncontains each of these words.\nIt is a frequency matrix.\nThat is what a document term matrix is.\nNow let's move on and look at\na natural language processing demo.\nSo what we're gonna do\nis we're gonna perform\nsentimental analysis.\nNow like I said, sentimental analysis\nis one of the most popular applications\nof natural language processing.\nIt refers to the processing of determining\nwhether a given piece of text\nor a given sentence of text\nis positive or negative.\nSo, in some variations, we consider\na sentence to also be neutral.\nThat's a third option.\nAnd this technique is\ncommonly used to discover\nhow people feel about a particular topic\nor what are people's opinion\nabout a particular topic.\nSo this is mainly used to\nanalyze the sentiments of users\nin various forms,\nsuch as in marketing\ncampaigns, in social media,\nin e-commerce websites, and so on.\nSo now we'll be performing\nsentimental analysis\nusing Python.\nSo we are going to perform\nnatural language processing\nby using the NaiveBayesClassifier.\nThat's why we are importing\nthe NaiveBayesClassifier.\nSo guys, Python provides a library known\nas natural language toolkit.\nThis library contains all\nthe functions that are needed\nto perform natural language processing.\nAlso in this library,\nwe have a predefined data\nset called movie reviews.\nWhat we're gonna do is\nwe're going to download that\nfrom our NLTK, which is\nnatural language toolkit.\nWe're basically going to run our analysis\non this movie review data set.\nAnd that's exactly what\nwe're doing over here.\nNow what we're doing is\nwe're defining a function\nin order to extract features.\nSo this is our function.\nIt's just going to extract all our words.\nNow that we've extracted the data,\nwe need to train it,\nso we'll do that by using\nour movie reviews data set\nthat we just downloaded.\nWe're going to understand\nthe positive words and the negative words.\nSo what we're doing here is\nwe're just loading our positive\nand our negative reviews.\nWe're loading both of them.\nAfter that, we'll separate each of these\ninto positive features\nand negative features.\nThis is pretty understandable.\nNext, we'll split the data\ninto our training and testing set.\nNow this is something\nthat we've been doing\nfor all our demos.\nThis is also known as data splicing.\nWe've also set a threshold factor of 0.8\nwhich basically means\nthat 80% of your data set\nwill belong to your training,\nand 20% will be for your testing.\nYou're going to do this\neven for your positive\nand your negative words.\nAfter that, you're just\nextracting the features again,\nand you're just printing\nthe number of training\ndata points that you have.\nYou're just printing the length\nof your training features\nand you're printing the length\nof your testing features.\nWe can see the output,\nlet's run this program.\nSo if you see that we're getting\nthe number of training\ndata points as 1,600\nand your number of testing\ndata points are 400,\nthere's an 80 to 20% ration over here.\nAfter this, we'll be using\nthe NaiveBayesClassifier\nand we'll define the object\nfor the NaiveBayesClassifier\nwith basically classifier,\nand we'll train this using\nour training data set.\nWe'll also look at the\naccuracy of our model.\nThe accuracy of our\nclassifier is around 73%,\nwhich is a really good number.\nNow this classifier object\nwill actually contain\nthe most informative words\nthat are obtained during analysis.\nThese words are basically\nessential in understanding\nwhich word is classified as positive\nand which is classified as negative.\nWhat we're doing here is\nwe're going to review movies.\nWe're going to see which\nmovie review is positive\nor which movie review is negative.\nNow this classifier will basically have\nall the informative words\nthat will help us decide\nwhich is a positive review\nor a negative review.\nThen we're just printing these\n10 most informative words,\nand we have outstanding, insulting,\nvulnerable, ludicrous, uninvolving,\navoids, fascination, and so on.\nThese are the most\nimportant words in our text.\nNow what we're gonna do is\nwe're gonna test our model.\nI've randomly given some reviews.\nIf you want, let's add another review.\nWe'll say\nI loved the\nmovie.\nSo I've added another review over here.\nHere we're just printing the review,\nand we're checking if\nthis is a positive review\nor a negative review.\nNow let's look at our predictions.\nWe'll save this and...\nI forgot to put a comma over here.\nSave it and let's run the file again.\nSo these were our randomly\nwritten movie reviews.\nThe predicted sentiment is positive.\nOur probability score was 0.61.\nIt's pretty accurate here.\nThis is a dull movie and I\nwould never recommend it,\nis a negative sentiment.\nThe cinematography is pretty great,\nthat's a positive review.\nThe movie is pathetic is\nobviously a negative review.\nThe direction was terrible,\nand the story was all over the place.\nThis is also considered\nas a negative review.\nSimilarly, I love the movie\nis what I just inputted,\nand I've got a positive review on that.\nSo our classifier actually\nworks really well.\nIt's giving us good accuracy\nand it's classifying the\nsentiments very accurately.\nSo, guys, this was all\nabout sentimental analysis.\nHere we basically saw if a movie review\nwas positive or negative.\nSo guys, that was all for our NLP demo.\nI hope all of you understood this.\nIt was a simple sentimental analysis\nthat we saw through Python.\nSo again, if you have doubts,\nplease leave them in the comment section,\nand I'll help you with all of the queries.\nSo guys, that was our last module,\nwhich was on natural language processing.\nNow before I end today's session,\nI would like to discuss with you\nthe machine learning engineers program\nthat we have Edureka.\nSo we all are aware of\nthe demand of the machine\nlearning engineer.\nSo, at Edureka, we have a master's program\nthat involves 200-plus hours\nof interactive training.\nSo the machine learning\nmaster's program at Edureka\nhas around nine modules and 200-plus hours\nof interactive learning.\nSo let me tell you the curriculum\nthat this course provides.\nSo your first module will basically cover\nPython programming.\nIt'll have all the basics and\nall your data visualization,\nyour GUI programming, your functions,\nand your object-oriented concepts.\nThe second module will cover\nmachine learning with Python.\nSo you'll supervise algorithms\nand unsupervised algorithms\nalong with statistics and time series\nin Python will be covered\nin your second module.\nYour third module will\nhave graphical modeling.\nThis is quite important when\nti comes to machine learning.\nHere you'll be taught\nabout decision making,\ngraph theory, inference, and\nBayesian and Markov's network,\nand module number four will cover\nreinforcement learning in depth.\nHere you'll understanding\ndynamic programming,\ntemporal difference, Bellman equations,\nall the concepts of\nreinforcement learning in depth.\nAll the detail in advance concepts\nof reinforcement learning.\nSo, module number five\nwill cover NLP with Python.\nYou'll understand tokenization,\nstemming lemmatization,\nsyntax, tree parsing, and so on.\nAnd module number six will\nhave module six will have\nartificial intelligence and\ndeep learning with TensorFlow.\nThis module is a very advanced version\nof all your machine learning\nand reinforcement learning\nthat you'll learn.\nDeep learning will be in depth over here.\nYou'll be using TensorFlow throughout.\nThey'll cover all the concepts\nthat we saw, CNN, RNN.\nit'll cover the various\ntype of neural networks,\nlike convolutional neural networks,\nrecurrent neural networks,\nlong, short-term memory, neural networks,\nand auto encoders and so on.\nThe seventh module is all about PySpark.\nIt'll show you how Spark SQL works\nand all the features and\nfunctions of Spark ML library.\nAnd the last module will finally cover\nabout Python Spark using PySpark.\nAppropriate from this seven modules,\nyou'll also get two\nfree self-paced courses.\nLet's actually take a look at the course.\nSo this is your machine learning\nengineer master's program.\nYou'll have nine courses, 200-plus hours\nof interactive learning.\nThis is the whole course curriculum,\nwhich we just discussed.\nHere there are seven modules.\nApart from these seven modules,\nyou'll be given two\nfree self-paced courses,\nwhich I'll discuss shortly.\nYou can also get to know\nthe average annual salary\nfor a machine learning engineer,\nwhich is over $134,000.\nAnd there are also a lot of job openings\nin the field of machine\nlearning AI and data science.\nSo the job titles that you might get\nare machine learning\nengineer, AI engineer,\ndata scientist, data and analytics manger,\nNLP engineer, and data engineer.\nSo this is basically the curriculum.\nYour first will by Python\nprogramming certification,\nmachine learning\ncertification using Python,\ngraphical modeling,\nreinforcement learning,\nnatural language processing,\nAI and deep learning with TensorFlow.\nPython Spark certification\ntraining using PySpark.\nIf you want to learn more\nabout each of these modules,\nyou can just go and view the curriculum.\nThey'll explain each and every concept\nthat they'll be showing in this module.\nAll of this is going to be covered here.\nThis is just the first module.\nNow at the end of this project,\nyou will be given a verified\ncertificate of completion\nwith your name on it,\nand these are the free elective courses\nthat you're going to get.\nOne is your Python scripting\ncertification training.\nAnd the other is your Python Statistics\nfor Data Science Course.\nBoth of these courses\nexplain Python in depth.\nThe second course on statistics\nwill explain all the concepts\nof statistics probability,\ndescriptive statistics,\ninferential statistics,\ntime series, testing data,\ndata clustering, regression\nmodeling, and so on.\nSo each of the module is\ndesigned in such a way that\nyou'll have a practical demo\nor a practical implementation\nafter each and every model.\nSo all the concept that I\ntheoretically taught to you\nwill be explained through practical demos.\nThis way you'll get a\ngood understanding of\nthe entire machine\nlearning and AI concepts.\nSo, if any of you are interested\nin enrolling for this program\nor if you want to learn more about\nthe machine learning\ncourse offered by Edureka,\nplease leave your email\nIDs in the comment section,\nand we'll get back to you\nwith all the details of the course.\nSo guys, with this, we come to the end\nof this AI full course session.\nI hope all of you have\nunderstood the basic concepts\nand the idea behind AI machine\nlearning, deep learning,\nand natural language processing.\nSo if you still have doubts\nregarding any of these topics,\nmention them in the comment section,\nand I'll try to answer all your queries.\nSo guys, thank you so much for\njoining me in this session.\nHave a great day.\nI hope you have enjoyed\nlistening to this video.\nPlease be kind enough to like it,\nand you can comment any of\nyour doubts and queries,\nand we will reply them at the earliest.\nDo look out for more\nvideos in our playlist\nand subscribe to Edureka\nchannel to learn more.\nHappy learning.\n",
  "words": [
    "hi",
    "everyone",
    "zulaikha",
    "edureka",
    "welcome",
    "session",
    "artificial",
    "intelligence",
    "full",
    "course",
    "video",
    "covering",
    "domains",
    "concepts",
    "involved",
    "umbrella",
    "artificial",
    "intelligence",
    "also",
    "showing",
    "couple",
    "use",
    "cases",
    "practical",
    "implementations",
    "using",
    "python",
    "lot",
    "cover",
    "session",
    "let",
    "quickly",
    "run",
    "today",
    "agenda",
    "gon",
    "na",
    "begin",
    "session",
    "understanding",
    "history",
    "artificial",
    "intelligence",
    "cam",
    "existence",
    "follow",
    "looking",
    "talking",
    "artificial",
    "intelligence",
    "gotten",
    "famous",
    "right",
    "look",
    "exactly",
    "artificial",
    "intelligence",
    "discuss",
    "applications",
    "artificial",
    "intelligence",
    "discuss",
    "basics",
    "ai",
    "understand",
    "different",
    "types",
    "artificial",
    "intelligence",
    "follow",
    "understanding",
    "different",
    "programming",
    "languages",
    "used",
    "study",
    "ai",
    "understand",
    "gon",
    "na",
    "choose",
    "python",
    "alright",
    "introduce",
    "python",
    "move",
    "discuss",
    "machine",
    "learning",
    "discuss",
    "different",
    "types",
    "machine",
    "learning",
    "different",
    "algorithms",
    "involved",
    "machine",
    "learning",
    "include",
    "classification",
    "algorithms",
    "regression",
    "algorithms",
    "clustering",
    "association",
    "algorithms",
    "make",
    "understand",
    "machine",
    "learning",
    "better",
    "run",
    "couple",
    "demos",
    "wherein",
    "see",
    "machine",
    "learning",
    "algorithms",
    "used",
    "solve",
    "real",
    "world",
    "problems",
    "discuss",
    "limitations",
    "machine",
    "learning",
    "deep",
    "learning",
    "needed",
    "introduce",
    "deep",
    "learning",
    "concept",
    "neurons",
    "perceptrons",
    "multiple",
    "layer",
    "perceptrons",
    "discuss",
    "different",
    "types",
    "neural",
    "networks",
    "also",
    "look",
    "exactly",
    "back",
    "propagation",
    "apart",
    "running",
    "demo",
    "understand",
    "deep",
    "learning",
    "depth",
    "finally",
    "move",
    "onto",
    "next",
    "module",
    "natural",
    "language",
    "processing",
    "natural",
    "language",
    "processing",
    "try",
    "understand",
    "text",
    "mining",
    "difference",
    "text",
    "mining",
    "nlp",
    "different",
    "terminologies",
    "nlp",
    "end",
    "session",
    "looking",
    "practical",
    "implementation",
    "nlp",
    "using",
    "python",
    "alright",
    "guys",
    "lot",
    "cover",
    "today",
    "session",
    "also",
    "want",
    "stay",
    "updated",
    "recent",
    "technologies",
    "would",
    "like",
    "learn",
    "training",
    "technology",
    "make",
    "sure",
    "subscribe",
    "youtube",
    "channel",
    "never",
    "miss",
    "sessions",
    "let",
    "move",
    "ahead",
    "take",
    "look",
    "first",
    "topic",
    "history",
    "artificial",
    "intelligence",
    "guys",
    "concept",
    "artificial",
    "intelligence",
    "goes",
    "back",
    "classical",
    "ages",
    "greek",
    "mythology",
    "concept",
    "machines",
    "mechanical",
    "men",
    "well",
    "thought",
    "example",
    "talos",
    "know",
    "many",
    "heard",
    "talos",
    "giant",
    "animated",
    "bronze",
    "warrior",
    "programmed",
    "guard",
    "island",
    "crete",
    "ideas",
    "nobody",
    "knows",
    "actually",
    "implemented",
    "machine",
    "learning",
    "ai",
    "thought",
    "long",
    "ago",
    "let",
    "get",
    "back",
    "19th",
    "century",
    "1950",
    "speculated",
    "one",
    "important",
    "years",
    "introduction",
    "artificial",
    "intelligence",
    "1950",
    "alan",
    "turing",
    "published",
    "paper",
    "speculated",
    "possibility",
    "creating",
    "machines",
    "think",
    "created",
    "known",
    "turing",
    "test",
    "test",
    "basically",
    "used",
    "determine",
    "whether",
    "computer",
    "think",
    "intelligently",
    "like",
    "human",
    "noted",
    "thinking",
    "difficult",
    "define",
    "devised",
    "famous",
    "turing",
    "test",
    "basically",
    "machine",
    "carry",
    "conversation",
    "indistinguishable",
    "conversation",
    "human",
    "reasonable",
    "say",
    "machine",
    "thinking",
    "meaning",
    "machine",
    "pass",
    "turing",
    "test",
    "unfortunately",
    "date",
    "found",
    "machine",
    "fully",
    "cleared",
    "turing",
    "test",
    "turing",
    "test",
    "actually",
    "first",
    "serious",
    "proposal",
    "philosophy",
    "artificial",
    "intelligence",
    "followed",
    "era",
    "also",
    "known",
    "game",
    "ai",
    "1951",
    "using",
    "ferranti",
    "mark",
    "1",
    "machine",
    "university",
    "manchester",
    "computer",
    "scientist",
    "known",
    "christopher",
    "strachey",
    "wrote",
    "checkers",
    "program",
    "time",
    "program",
    "written",
    "chess",
    "well",
    "programs",
    "later",
    "improved",
    "redone",
    "first",
    "attempt",
    "creating",
    "programs",
    "could",
    "play",
    "chess",
    "would",
    "compete",
    "humans",
    "playing",
    "chess",
    "followed",
    "year",
    "probably",
    "important",
    "year",
    "invention",
    "ai",
    "1956",
    "firs",
    "time",
    "term",
    "artificial",
    "intelligence",
    "coined",
    "alright",
    "term",
    "artificial",
    "intelligence",
    "coined",
    "john",
    "mccarthy",
    "dartmouth",
    "conference",
    "coming",
    "year",
    "1959",
    "first",
    "ai",
    "laboratory",
    "established",
    "period",
    "marked",
    "research",
    "era",
    "ai",
    "first",
    "ai",
    "lab",
    "research",
    "performed",
    "mit",
    "lab",
    "still",
    "running",
    "til",
    "date",
    "1960",
    "first",
    "robot",
    "introduced",
    "general",
    "motors",
    "assembly",
    "line",
    "1961",
    "first",
    "chatbot",
    "invented",
    "siri",
    "alexa",
    "1961",
    "chatbot",
    "known",
    "eliza",
    "introduced",
    "followed",
    "famous",
    "ibm",
    "deep",
    "blue",
    "1997",
    "news",
    "broke",
    "ibm",
    "deep",
    "blue",
    "beats",
    "world",
    "champion",
    "garry",
    "kasparov",
    "game",
    "chess",
    "kind",
    "first",
    "accomplishment",
    "ai",
    "able",
    "beat",
    "world",
    "champion",
    "chess",
    "2005",
    "darpa",
    "grand",
    "challenge",
    "held",
    "robotic",
    "car",
    "named",
    "stanley",
    "built",
    "stanford",
    "racing",
    "team",
    "darpa",
    "grand",
    "challenge",
    "another",
    "big",
    "accomplish",
    "ai",
    "2011",
    "ibm",
    "question",
    "answering",
    "system",
    "watson",
    "defeated",
    "two",
    "greatest",
    "jeopardy",
    "champions",
    "brad",
    "rutter",
    "ken",
    "jennings",
    "guys",
    "ai",
    "evolved",
    "started",
    "hypothetical",
    "situation",
    "right",
    "important",
    "technology",
    "today",
    "world",
    "look",
    "around",
    "every",
    "everything",
    "around",
    "us",
    "run",
    "ai",
    "deep",
    "learning",
    "machine",
    "learning",
    "since",
    "emergence",
    "ai",
    "1950s",
    "actually",
    "seen",
    "exponential",
    "growth",
    "potential",
    "ai",
    "covers",
    "domains",
    "machine",
    "learning",
    "deep",
    "learning",
    "neural",
    "networks",
    "natural",
    "language",
    "processing",
    "knowledge",
    "based",
    "expert",
    "systems",
    "also",
    "made",
    "way",
    "computer",
    "vision",
    "image",
    "processing",
    "question",
    "ai",
    "half",
    "century",
    "suddenly",
    "gain",
    "much",
    "importance",
    "talking",
    "artificial",
    "intelligence",
    "let",
    "tell",
    "main",
    "reasons",
    "demand",
    "ai",
    "first",
    "reason",
    "computation",
    "power",
    "artificial",
    "intelligence",
    "requires",
    "lot",
    "computing",
    "power",
    "recently",
    "many",
    "advances",
    "made",
    "complex",
    "deep",
    "learning",
    "models",
    "deployed",
    "one",
    "greatest",
    "technology",
    "made",
    "possible",
    "gpus",
    "since",
    "computational",
    "power",
    "possible",
    "us",
    "implement",
    "ai",
    "daily",
    "aspects",
    "second",
    "important",
    "reason",
    "lot",
    "data",
    "present",
    "generating",
    "data",
    "immeasurable",
    "pace",
    "generating",
    "data",
    "social",
    "media",
    "iot",
    "devices",
    "every",
    "possible",
    "way",
    "lot",
    "data",
    "need",
    "find",
    "method",
    "solution",
    "help",
    "us",
    "process",
    "much",
    "data",
    "help",
    "us",
    "derive",
    "useful",
    "insight",
    "grow",
    "business",
    "help",
    "data",
    "alright",
    "process",
    "basically",
    "artificial",
    "intelligence",
    "order",
    "useful",
    "ai",
    "agent",
    "make",
    "smart",
    "decisions",
    "like",
    "telling",
    "item",
    "recommend",
    "next",
    "shop",
    "online",
    "classify",
    "object",
    "image",
    "ai",
    "trained",
    "large",
    "data",
    "sets",
    "big",
    "data",
    "enables",
    "us",
    "efficiently",
    "next",
    "reason",
    "better",
    "algorithms",
    "right",
    "effective",
    "algorithms",
    "based",
    "idea",
    "neural",
    "networks",
    "neural",
    "networks",
    "nothing",
    "concept",
    "behind",
    "deep",
    "learning",
    "since",
    "better",
    "algorithms",
    "better",
    "computations",
    "quicker",
    "computations",
    "accuracy",
    "demand",
    "ai",
    "increased",
    "another",
    "reason",
    "universities",
    "governments",
    "startup",
    "tech",
    "giants",
    "investing",
    "ai",
    "okay",
    "companies",
    "like",
    "google",
    "amazon",
    "facebook",
    "microsoft",
    "companies",
    "heavily",
    "invested",
    "artificial",
    "intelligence",
    "believe",
    "ai",
    "future",
    "ai",
    "rapidly",
    "growing",
    "field",
    "study",
    "also",
    "economy",
    "actually",
    "right",
    "time",
    "understand",
    "ai",
    "works",
    "let",
    "move",
    "understand",
    "exactly",
    "artificial",
    "intelligence",
    "term",
    "artificial",
    "intelligence",
    "first",
    "coined",
    "year",
    "1956",
    "john",
    "mccarthy",
    "dartmouth",
    "conference",
    "already",
    "mentioned",
    "birth",
    "ai",
    "define",
    "artificial",
    "intelligence",
    "john",
    "mccarthy",
    "defined",
    "ai",
    "science",
    "engineering",
    "making",
    "intelligent",
    "machines",
    "words",
    "artificial",
    "intelligence",
    "theory",
    "development",
    "computer",
    "systems",
    "able",
    "perform",
    "task",
    "normally",
    "require",
    "human",
    "intelligence",
    "visual",
    "perception",
    "speech",
    "recognition",
    "decision",
    "making",
    "translation",
    "languages",
    "guys",
    "sense",
    "ai",
    "technique",
    "getting",
    "machines",
    "work",
    "behave",
    "like",
    "humans",
    "rest",
    "past",
    "artificial",
    "intelligence",
    "able",
    "accomplish",
    "creating",
    "machines",
    "robots",
    "used",
    "wide",
    "range",
    "fields",
    "including",
    "healthcare",
    "robotics",
    "marketing",
    "business",
    "analytics",
    "many",
    "mind",
    "let",
    "discuss",
    "couple",
    "real",
    "world",
    "application",
    "ai",
    "understand",
    "important",
    "artificial",
    "intelligence",
    "today",
    "world",
    "one",
    "famous",
    "applications",
    "artificial",
    "intelligence",
    "google",
    "predictive",
    "search",
    "engine",
    "begin",
    "typing",
    "search",
    "term",
    "google",
    "makes",
    "recommendations",
    "choose",
    "artificial",
    "intelligence",
    "action",
    "predictive",
    "searches",
    "based",
    "data",
    "google",
    "collects",
    "browser",
    "history",
    "location",
    "age",
    "personal",
    "details",
    "using",
    "artificial",
    "intelligence",
    "google",
    "attempts",
    "guess",
    "might",
    "trying",
    "find",
    "behind",
    "lot",
    "natural",
    "language",
    "processing",
    "deep",
    "learning",
    "machine",
    "learning",
    "involved",
    "discussing",
    "concepts",
    "slides",
    "simple",
    "create",
    "search",
    "engine",
    "logic",
    "behind",
    "google",
    "search",
    "engine",
    "artificial",
    "intelligence",
    "moving",
    "finance",
    "sector",
    "jp",
    "morgan",
    "chase",
    "contract",
    "intelligence",
    "platform",
    "uses",
    "machine",
    "learning",
    "artificial",
    "intelligence",
    "image",
    "recognition",
    "software",
    "analyze",
    "legal",
    "documents",
    "let",
    "tell",
    "manually",
    "reviewing",
    "around",
    "agreements",
    "took",
    "hours",
    "lot",
    "time",
    "soon",
    "task",
    "replaced",
    "ai",
    "machine",
    "able",
    "matter",
    "seconds",
    "difference",
    "artificial",
    "intelligence",
    "manual",
    "human",
    "work",
    "even",
    "though",
    "ai",
    "think",
    "reason",
    "like",
    "humans",
    "computational",
    "power",
    "strong",
    "compared",
    "humans",
    "machine",
    "learning",
    "algorithm",
    "deep",
    "learning",
    "concepts",
    "natural",
    "language",
    "processing",
    "ai",
    "reach",
    "stage",
    "wherein",
    "compute",
    "complex",
    "complex",
    "problems",
    "matter",
    "seconds",
    "coming",
    "healthcare",
    "ibm",
    "one",
    "pioneers",
    "developed",
    "ai",
    "software",
    "specifically",
    "medicine",
    "let",
    "tell",
    "230",
    "healthcare",
    "organizations",
    "use",
    "ibm",
    "ai",
    "technology",
    "basically",
    "ibm",
    "watson",
    "2016",
    "ibm",
    "watson",
    "technology",
    "able",
    "cross",
    "reference",
    "20",
    "million",
    "oncology",
    "records",
    "quickly",
    "correctly",
    "diagnose",
    "rare",
    "leukemia",
    "condition",
    "patient",
    "basically",
    "went",
    "20",
    "million",
    "records",
    "probably",
    "matter",
    "second",
    "minutes",
    "max",
    "max",
    "correctly",
    "diagnosed",
    "patient",
    "rare",
    "leukemia",
    "knowing",
    "machines",
    "used",
    "medical",
    "fields",
    "well",
    "shows",
    "important",
    "ai",
    "become",
    "reached",
    "every",
    "domains",
    "lives",
    "let",
    "give",
    "another",
    "example",
    "google",
    "ai",
    "eye",
    "doctor",
    "another",
    "initiative",
    "taken",
    "google",
    "working",
    "indian",
    "eye",
    "care",
    "chain",
    "develop",
    "artificial",
    "intelligence",
    "system",
    "examine",
    "retinal",
    "scans",
    "identify",
    "condition",
    "called",
    "diabetic",
    "retinopathy",
    "cause",
    "blindness",
    "social",
    "media",
    "platforms",
    "like",
    "facebook",
    "artificial",
    "intelligence",
    "used",
    "face",
    "verification",
    "wherein",
    "make",
    "use",
    "machine",
    "learning",
    "deep",
    "learning",
    "concept",
    "order",
    "detect",
    "facial",
    "features",
    "tag",
    "friends",
    "auto",
    "tagging",
    "feature",
    "see",
    "facebook",
    "behind",
    "machine",
    "learning",
    "deep",
    "learning",
    "neural",
    "networks",
    "ai",
    "behind",
    "actually",
    "unaware",
    "use",
    "ai",
    "regularly",
    "life",
    "social",
    "media",
    "platforms",
    "like",
    "instagram",
    "facebook",
    "twitter",
    "heavily",
    "rely",
    "artificial",
    "intelligence",
    "another",
    "example",
    "twitter",
    "ai",
    "used",
    "identify",
    "sort",
    "hate",
    "speech",
    "terroristic",
    "languages",
    "tweets",
    "makes",
    "use",
    "machine",
    "leaning",
    "deep",
    "learning",
    "natural",
    "language",
    "processing",
    "order",
    "filter",
    "offensive",
    "reportable",
    "content",
    "recently",
    "company",
    "discovered",
    "around",
    "terroristic",
    "link",
    "accounts",
    "95",
    "found",
    "artificially",
    "intelligent",
    "machines",
    "coming",
    "virtual",
    "assistants",
    "virtual",
    "assistants",
    "like",
    "siri",
    "alexa",
    "right",
    "let",
    "tell",
    "another",
    "newly",
    "released",
    "google",
    "virtual",
    "assistant",
    "called",
    "google",
    "duplex",
    "astonished",
    "millions",
    "people",
    "around",
    "world",
    "respond",
    "calls",
    "book",
    "appointments",
    "also",
    "adds",
    "human",
    "touch",
    "adds",
    "human",
    "filters",
    "makes",
    "sound",
    "realistic",
    "actually",
    "hard",
    "distinguish",
    "human",
    "ai",
    "speaking",
    "phone",
    "another",
    "famous",
    "application",
    "ai",
    "cars",
    "artificial",
    "intelligence",
    "implements",
    "computer",
    "vision",
    "image",
    "detection",
    "deep",
    "learning",
    "order",
    "build",
    "cars",
    "automatically",
    "detect",
    "objects",
    "obstacles",
    "drive",
    "around",
    "without",
    "human",
    "intervention",
    "fully",
    "automated",
    "cars",
    "also",
    "elon",
    "musk",
    "talks",
    "lot",
    "ai",
    "implemented",
    "tesla",
    "cars",
    "quoted",
    "tesla",
    "fully",
    "cars",
    "ready",
    "end",
    "year",
    "robo",
    "taxi",
    "version",
    "ferry",
    "passengers",
    "without",
    "anyone",
    "behind",
    "wheel",
    "look",
    "ai",
    "actually",
    "used",
    "tech",
    "giants",
    "lot",
    "tech",
    "giant",
    "companies",
    "like",
    "google",
    "tesla",
    "facebook",
    "companies",
    "fact",
    "netflix",
    "also",
    "makes",
    "use",
    "ai",
    "coming",
    "netflix",
    "help",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "netflix",
    "developed",
    "personalized",
    "movie",
    "recommendation",
    "users",
    "opened",
    "netflix",
    "look",
    "type",
    "movies",
    "recommended",
    "different",
    "netflix",
    "studies",
    "user",
    "personal",
    "details",
    "tries",
    "understand",
    "user",
    "interested",
    "sort",
    "movie",
    "patterns",
    "user",
    "recommends",
    "movies",
    "netflix",
    "uses",
    "watching",
    "history",
    "users",
    "similar",
    "taste",
    "recommend",
    "may",
    "interested",
    "watching",
    "next",
    "stay",
    "engaged",
    "continue",
    "monthly",
    "subscription",
    "also",
    "known",
    "fact",
    "75",
    "watch",
    "recommended",
    "netflix",
    "recommendation",
    "engine",
    "brilliant",
    "logic",
    "behind",
    "recommendation",
    "engine",
    "machine",
    "learning",
    "artificial",
    "intelligence",
    "apart",
    "netflix",
    "gmail",
    "also",
    "uses",
    "ai",
    "everyday",
    "basis",
    "open",
    "inbox",
    "right",
    "notice",
    "separate",
    "sections",
    "example",
    "primary",
    "section",
    "social",
    "section",
    "gmail",
    "separate",
    "section",
    "called",
    "spam",
    "mails",
    "also",
    "gmail",
    "makes",
    "use",
    "concepts",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "algorithms",
    "classify",
    "emails",
    "spam",
    "many",
    "times",
    "certain",
    "words",
    "phrases",
    "frequently",
    "used",
    "spam",
    "emails",
    "notice",
    "spam",
    "emails",
    "words",
    "like",
    "lottery",
    "earn",
    "full",
    "refund",
    "denotes",
    "email",
    "likely",
    "spam",
    "one",
    "words",
    "correlations",
    "understood",
    "using",
    "machine",
    "learning",
    "natural",
    "language",
    "processing",
    "aspects",
    "artificial",
    "intelligence",
    "guys",
    "common",
    "applications",
    "artificial",
    "intelligence",
    "let",
    "discuss",
    "different",
    "types",
    "ai",
    "ai",
    "divided",
    "three",
    "different",
    "evolutionary",
    "stages",
    "say",
    "three",
    "stages",
    "artificial",
    "intelligence",
    "course",
    "artificial",
    "narrow",
    "intelligence",
    "followed",
    "artificial",
    "general",
    "intelligence",
    "followed",
    "artificial",
    "super",
    "intelligence",
    "artificial",
    "narrow",
    "intelligence",
    "also",
    "known",
    "weak",
    "ai",
    "involves",
    "applying",
    "artificial",
    "intelligence",
    "specific",
    "task",
    "many",
    "currently",
    "existing",
    "systems",
    "claim",
    "use",
    "artificial",
    "intelligence",
    "actually",
    "operating",
    "weak",
    "ai",
    "focused",
    "narrowly",
    "defined",
    "specific",
    "problem",
    "let",
    "give",
    "example",
    "artificial",
    "narrow",
    "intelligence",
    "alexa",
    "good",
    "example",
    "weak",
    "ai",
    "operates",
    "within",
    "unlimited",
    "range",
    "functions",
    "genuine",
    "intelligence",
    "self",
    "awareness",
    "despite",
    "sophisticated",
    "example",
    "weak",
    "ai",
    "google",
    "search",
    "engine",
    "sophia",
    "humanoid",
    "cars",
    "even",
    "famous",
    "alphago",
    "fall",
    "category",
    "weak",
    "ai",
    "guys",
    "right",
    "stage",
    "artificial",
    "narrow",
    "intelligence",
    "weak",
    "ai",
    "actually",
    "reached",
    "artificial",
    "general",
    "intelligence",
    "artificial",
    "super",
    "intelligence",
    "let",
    "look",
    "exactly",
    "would",
    "like",
    "reach",
    "artificial",
    "general",
    "intelligence",
    "artificial",
    "general",
    "intelligence",
    "also",
    "known",
    "strong",
    "ai",
    "involves",
    "machines",
    "posses",
    "ability",
    "perform",
    "intelligent",
    "task",
    "human",
    "actually",
    "something",
    "lot",
    "people",
    "realize",
    "machines",
    "posses",
    "abilities",
    "strong",
    "processing",
    "unit",
    "perform",
    "computations",
    "yet",
    "capable",
    "simple",
    "reasonable",
    "things",
    "human",
    "tell",
    "machine",
    "process",
    "like",
    "million",
    "documents",
    "probably",
    "matter",
    "10",
    "seconds",
    "minute",
    "even",
    "10",
    "minutes",
    "ask",
    "machine",
    "walk",
    "living",
    "room",
    "switch",
    "tv",
    "machine",
    "take",
    "forever",
    "learn",
    "machines",
    "reasonable",
    "way",
    "thinking",
    "strong",
    "processing",
    "unit",
    "yet",
    "capable",
    "thinking",
    "reasoning",
    "like",
    "human",
    "exactly",
    "still",
    "stuck",
    "artificial",
    "narrow",
    "intelligence",
    "far",
    "developed",
    "machine",
    "fully",
    "called",
    "strong",
    "ai",
    "even",
    "though",
    "examples",
    "alphago",
    "zero",
    "defeated",
    "alphago",
    "game",
    "go",
    "alphago",
    "zero",
    "basically",
    "learned",
    "span",
    "four",
    "months",
    "learned",
    "without",
    "human",
    "intervention",
    "even",
    "classified",
    "fully",
    "strong",
    "artificial",
    "intelligence",
    "reason",
    "like",
    "human",
    "moving",
    "onto",
    "artificial",
    "super",
    "intelligence",
    "term",
    "referring",
    "time",
    "capabilities",
    "computer",
    "surpass",
    "human",
    "actuality",
    "take",
    "us",
    "achieve",
    "artificial",
    "super",
    "intelligence",
    "presently",
    "seen",
    "hypothetical",
    "situation",
    "depicted",
    "movies",
    "science",
    "fiction",
    "books",
    "wherein",
    "machines",
    "taken",
    "world",
    "movies",
    "like",
    "terminator",
    "depict",
    "artificial",
    "super",
    "intelligence",
    "exist",
    "yet",
    "thankful",
    "lot",
    "people",
    "speculate",
    "artificial",
    "super",
    "intelligence",
    "take",
    "world",
    "year",
    "guys",
    "different",
    "types",
    "different",
    "stages",
    "artificial",
    "intelligence",
    "summarize",
    "everything",
    "like",
    "said",
    "narrow",
    "intelligence",
    "thing",
    "exist",
    "weak",
    "ai",
    "weak",
    "artificial",
    "intelligence",
    "major",
    "ai",
    "technologies",
    "see",
    "artificial",
    "narrow",
    "intelligence",
    "machines",
    "capable",
    "thinking",
    "like",
    "human",
    "beings",
    "reasoning",
    "like",
    "human",
    "let",
    "move",
    "discuss",
    "different",
    "programming",
    "language",
    "ai",
    "actually",
    "n",
    "number",
    "language",
    "used",
    "artificial",
    "intelligence",
    "gon",
    "na",
    "mention",
    "first",
    "python",
    "python",
    "probably",
    "famous",
    "language",
    "artificial",
    "intelligence",
    "also",
    "known",
    "effective",
    "language",
    "ai",
    "lot",
    "developers",
    "prefer",
    "use",
    "python",
    "lot",
    "scientists",
    "also",
    "comfortable",
    "python",
    "language",
    "partly",
    "syntaxes",
    "belong",
    "python",
    "simple",
    "learned",
    "easily",
    "considered",
    "one",
    "easiest",
    "language",
    "learn",
    "also",
    "many",
    "ai",
    "algorithms",
    "machine",
    "learning",
    "algorithms",
    "easily",
    "implemented",
    "python",
    "lot",
    "libraries",
    "predefined",
    "functions",
    "algorithms",
    "call",
    "function",
    "actually",
    "call",
    "algorithm",
    "python",
    "considered",
    "best",
    "choice",
    "artificial",
    "intelligence",
    "python",
    "stands",
    "r",
    "statistical",
    "programming",
    "language",
    "r",
    "one",
    "effective",
    "language",
    "environment",
    "analyzing",
    "manipulating",
    "data",
    "statistical",
    "purpose",
    "statistical",
    "programming",
    "language",
    "using",
    "r",
    "easily",
    "produce",
    "well",
    "designed",
    "publication",
    "quality",
    "plots",
    "including",
    "mathematical",
    "symbol",
    "formula",
    "wherever",
    "needed",
    "ask",
    "think",
    "r",
    "also",
    "one",
    "easiest",
    "programming",
    "language",
    "learn",
    "syntax",
    "similar",
    "english",
    "language",
    "also",
    "n",
    "number",
    "libraries",
    "support",
    "statistics",
    "data",
    "science",
    "ai",
    "machine",
    "learning",
    "also",
    "predefined",
    "functions",
    "machine",
    "learning",
    "algorithms",
    "natural",
    "language",
    "processing",
    "r",
    "also",
    "good",
    "choice",
    "want",
    "get",
    "started",
    "programming",
    "languages",
    "machine",
    "learning",
    "ai",
    "apart",
    "java",
    "java",
    "also",
    "considered",
    "good",
    "choice",
    "ai",
    "development",
    "artificial",
    "intelligence",
    "lot",
    "search",
    "algorithms",
    "artificial",
    "neural",
    "networks",
    "genetic",
    "programming",
    "java",
    "provides",
    "many",
    "benefits",
    "easy",
    "use",
    "debugging",
    "easy",
    "package",
    "services",
    "simplified",
    "work",
    "large",
    "scale",
    "projects",
    "good",
    "user",
    "interaction",
    "graphical",
    "representation",
    "data",
    "something",
    "known",
    "standard",
    "widget",
    "toolkit",
    "used",
    "making",
    "graphs",
    "interfaces",
    "graphic",
    "virtualization",
    "actually",
    "important",
    "part",
    "ai",
    "data",
    "science",
    "machine",
    "learning",
    "matter",
    "let",
    "list",
    "languages",
    "also",
    "something",
    "known",
    "lisp",
    "shockingly",
    "lot",
    "people",
    "heard",
    "language",
    "actually",
    "oldest",
    "suited",
    "language",
    "development",
    "artificial",
    "intelligence",
    "considered",
    "language",
    "suited",
    "development",
    "artificial",
    "intelligence",
    "let",
    "tell",
    "language",
    "invented",
    "john",
    "mccarthy",
    "also",
    "known",
    "father",
    "artificial",
    "intelligence",
    "person",
    "coined",
    "term",
    "artificial",
    "intelligence",
    "capability",
    "processing",
    "symbolic",
    "information",
    "excellent",
    "prototyping",
    "capabilities",
    "easy",
    "creates",
    "dynamic",
    "objects",
    "lot",
    "ease",
    "automatic",
    "garbage",
    "collection",
    "years",
    "advancements",
    "many",
    "features",
    "migrated",
    "many",
    "languages",
    "lot",
    "people",
    "go",
    "lisp",
    "lot",
    "new",
    "languages",
    "effective",
    "features",
    "better",
    "packages",
    "see",
    "another",
    "language",
    "like",
    "talk",
    "prolog",
    "prolog",
    "frequently",
    "used",
    "knowledge",
    "base",
    "expert",
    "systems",
    "features",
    "provided",
    "prolog",
    "include",
    "pattern",
    "matching",
    "freebase",
    "data",
    "structuring",
    "automatic",
    "back",
    "tracking",
    "features",
    "provide",
    "powerful",
    "flexible",
    "programming",
    "framework",
    "prolog",
    "actually",
    "widely",
    "used",
    "medical",
    "projects",
    "also",
    "designing",
    "expert",
    "ai",
    "systems",
    "apart",
    "also",
    "saas",
    "javascript",
    "also",
    "used",
    "ai",
    "matlab",
    "julia",
    "languages",
    "actually",
    "considered",
    "pretty",
    "good",
    "languages",
    "artificial",
    "intelligence",
    "ask",
    "programming",
    "language",
    "go",
    "would",
    "say",
    "python",
    "python",
    "possible",
    "packages",
    "easy",
    "understand",
    "easy",
    "learn",
    "let",
    "look",
    "couple",
    "features",
    "python",
    "see",
    "go",
    "python",
    "first",
    "python",
    "created",
    "year",
    "actually",
    "easy",
    "programming",
    "language",
    "one",
    "reasons",
    "lot",
    "people",
    "prefer",
    "python",
    "easy",
    "understand",
    "easy",
    "grasp",
    "language",
    "python",
    "interpreted",
    "programming",
    "language",
    "easily",
    "implemented",
    "let",
    "tell",
    "features",
    "python",
    "simple",
    "easy",
    "learn",
    "like",
    "mentioned",
    "one",
    "easiest",
    "programming",
    "language",
    "also",
    "free",
    "open",
    "source",
    "apart",
    "language",
    "worry",
    "anything",
    "like",
    "memory",
    "allocation",
    "portable",
    "meaning",
    "use",
    "platform",
    "like",
    "linux",
    "windows",
    "macintosh",
    "solaris",
    "support",
    "different",
    "programming",
    "paradigms",
    "like",
    "procedure",
    "oriented",
    "programming",
    "extensible",
    "meaning",
    "invoke",
    "c",
    "libraries",
    "apart",
    "let",
    "tell",
    "python",
    "actually",
    "gaining",
    "unbelievable",
    "huge",
    "momentum",
    "ai",
    "language",
    "used",
    "develop",
    "data",
    "science",
    "algorithms",
    "machine",
    "learning",
    "algorithms",
    "iot",
    "projects",
    "advantages",
    "python",
    "also",
    "fact",
    "code",
    "much",
    "comes",
    "python",
    "ai",
    "machine",
    "learning",
    "packages",
    "predefined",
    "packages",
    "function",
    "algorithm",
    "stored",
    "example",
    "something",
    "known",
    "pibrain",
    "used",
    "machine",
    "learning",
    "numpy",
    "used",
    "scientific",
    "computation",
    "pandas",
    "n",
    "number",
    "libraries",
    "python",
    "guys",
    "going",
    "go",
    "depth",
    "python",
    "going",
    "explain",
    "python",
    "since",
    "session",
    "artificial",
    "intelligence",
    "know",
    "much",
    "python",
    "new",
    "python",
    "leave",
    "couple",
    "links",
    "description",
    "box",
    "get",
    "started",
    "programming",
    "concepts",
    "doubts",
    "python",
    "lot",
    "content",
    "around",
    "programming",
    "python",
    "python",
    "machine",
    "learning",
    "let",
    "move",
    "talk",
    "one",
    "important",
    "aspects",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "lot",
    "people",
    "always",
    "ask",
    "question",
    "machine",
    "learning",
    "artificial",
    "intelligence",
    "thing",
    "well",
    "thing",
    "difference",
    "ai",
    "machine",
    "learning",
    "machine",
    "learning",
    "used",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "method",
    "feed",
    "lot",
    "data",
    "machine",
    "make",
    "learn",
    "ai",
    "vast",
    "field",
    "ai",
    "machine",
    "learning",
    "nlp",
    "expert",
    "systems",
    "image",
    "recognition",
    "object",
    "detection",
    "deep",
    "learning",
    "also",
    "ai",
    "sort",
    "process",
    "methodology",
    "make",
    "machines",
    "mimic",
    "behavior",
    "human",
    "beings",
    "machine",
    "learning",
    "way",
    "feed",
    "lot",
    "data",
    "machine",
    "make",
    "decisions",
    "let",
    "get",
    "depth",
    "machine",
    "learning",
    "first",
    "understand",
    "need",
    "machine",
    "learning",
    "machine",
    "learning",
    "came",
    "existence",
    "need",
    "machine",
    "learning",
    "begins",
    "since",
    "technical",
    "revolution",
    "guys",
    "since",
    "technology",
    "became",
    "center",
    "everything",
    "generating",
    "immeasurable",
    "amount",
    "data",
    "per",
    "research",
    "generate",
    "around",
    "quintillion",
    "bytes",
    "data",
    "every",
    "single",
    "data",
    "every",
    "single",
    "day",
    "estimated",
    "year",
    "2020",
    "mb",
    "data",
    "created",
    "every",
    "second",
    "every",
    "person",
    "earth",
    "speaking",
    "right",
    "generating",
    "lot",
    "data",
    "watching",
    "video",
    "youtube",
    "also",
    "accounts",
    "data",
    "generation",
    "data",
    "everywhere",
    "availability",
    "much",
    "data",
    "finally",
    "possible",
    "build",
    "predictive",
    "models",
    "study",
    "analyze",
    "complex",
    "data",
    "find",
    "useful",
    "insights",
    "deliver",
    "accurate",
    "results",
    "top",
    "tier",
    "companies",
    "like",
    "netflix",
    "amazon",
    "build",
    "machine",
    "learning",
    "models",
    "using",
    "tons",
    "data",
    "order",
    "identify",
    "profitable",
    "opportunity",
    "avoid",
    "unwanted",
    "risk",
    "guys",
    "one",
    "thing",
    "need",
    "know",
    "important",
    "thing",
    "artificial",
    "intelligence",
    "data",
    "artificial",
    "intelligence",
    "whether",
    "machine",
    "learning",
    "deep",
    "learning",
    "always",
    "data",
    "lot",
    "data",
    "find",
    "way",
    "analyze",
    "process",
    "draw",
    "useful",
    "insights",
    "data",
    "order",
    "help",
    "us",
    "grow",
    "businesses",
    "find",
    "solutions",
    "problems",
    "data",
    "solution",
    "need",
    "know",
    "handle",
    "data",
    "way",
    "handle",
    "data",
    "machine",
    "learning",
    "deep",
    "learning",
    "artificial",
    "intelligence",
    "reasons",
    "machine",
    "learning",
    "important",
    "number",
    "one",
    "due",
    "increase",
    "data",
    "generation",
    "due",
    "excessive",
    "production",
    "data",
    "need",
    "find",
    "method",
    "used",
    "structure",
    "analyze",
    "draw",
    "useful",
    "insights",
    "data",
    "machine",
    "learning",
    "comes",
    "used",
    "solve",
    "problems",
    "find",
    "solutions",
    "complex",
    "task",
    "faced",
    "organizations",
    "apart",
    "form",
    "also",
    "needed",
    "improve",
    "decision",
    "making",
    "making",
    "use",
    "various",
    "algorithms",
    "machine",
    "learning",
    "used",
    "make",
    "better",
    "business",
    "decisions",
    "example",
    "machine",
    "learning",
    "used",
    "focus",
    "sales",
    "used",
    "predict",
    "downfalls",
    "n",
    "stock",
    "market",
    "identify",
    "sort",
    "risk",
    "anomalies",
    "reasons",
    "include",
    "machine",
    "learning",
    "helps",
    "us",
    "uncover",
    "patterns",
    "trends",
    "data",
    "finding",
    "hidden",
    "patterns",
    "extracting",
    "key",
    "insights",
    "fro",
    "data",
    "important",
    "part",
    "machine",
    "learning",
    "building",
    "predictive",
    "models",
    "using",
    "statistical",
    "techniques",
    "machine",
    "learning",
    "allows",
    "dig",
    "beneath",
    "surface",
    "explode",
    "data",
    "minute",
    "scale",
    "understanding",
    "data",
    "extracting",
    "patterns",
    "manually",
    "takes",
    "lot",
    "time",
    "take",
    "several",
    "days",
    "us",
    "extract",
    "useful",
    "information",
    "data",
    "use",
    "machine",
    "learning",
    "algorithms",
    "perform",
    "similar",
    "computations",
    "less",
    "second",
    "another",
    "reason",
    "need",
    "solve",
    "complex",
    "problems",
    "detecting",
    "genes",
    "linked",
    "deadly",
    "als",
    "disease",
    "building",
    "cars",
    "machine",
    "learning",
    "used",
    "solve",
    "complex",
    "problems",
    "present",
    "also",
    "found",
    "way",
    "spot",
    "stars",
    "light",
    "years",
    "away",
    "planet",
    "okay",
    "possible",
    "ai",
    "machine",
    "learning",
    "deep",
    "learning",
    "techniques",
    "sum",
    "machine",
    "learning",
    "important",
    "present",
    "facing",
    "lot",
    "issues",
    "data",
    "generating",
    "lot",
    "data",
    "handle",
    "data",
    "way",
    "benefits",
    "us",
    "machine",
    "learning",
    "comes",
    "moving",
    "exactly",
    "machine",
    "learning",
    "let",
    "give",
    "short",
    "history",
    "machine",
    "learning",
    "machine",
    "learning",
    "first",
    "coined",
    "arthur",
    "samuel",
    "year",
    "1959",
    "three",
    "years",
    "artificial",
    "intelligence",
    "coined",
    "looking",
    "back",
    "year",
    "probably",
    "significant",
    "terms",
    "technological",
    "advancement",
    "technologies",
    "today",
    "based",
    "concept",
    "machine",
    "learning",
    "ai",
    "technologies",
    "based",
    "concept",
    "machine",
    "learning",
    "deep",
    "learning",
    "get",
    "confused",
    "machine",
    "learning",
    "deep",
    "learning",
    "discuss",
    "deep",
    "learning",
    "slides",
    "also",
    "see",
    "difference",
    "ai",
    "machine",
    "learning",
    "deep",
    "learning",
    "coming",
    "back",
    "exactly",
    "machine",
    "learning",
    "browse",
    "internet",
    "find",
    "lot",
    "definitions",
    "exactly",
    "machine",
    "learning",
    "one",
    "definitions",
    "found",
    "computer",
    "program",
    "said",
    "learn",
    "experience",
    "e",
    "respect",
    "class",
    "task",
    "performance",
    "measure",
    "p",
    "performance",
    "task",
    "measured",
    "p",
    "improves",
    "experience",
    "confusing",
    "let",
    "narrow",
    "simple",
    "terms",
    "machine",
    "learning",
    "subset",
    "artificial",
    "intelligence",
    "provides",
    "machines",
    "ability",
    "learn",
    "automatically",
    "improve",
    "experience",
    "without",
    "explicitly",
    "programmed",
    "sense",
    "practice",
    "getting",
    "machines",
    "solve",
    "problems",
    "gaining",
    "ability",
    "think",
    "might",
    "thinking",
    "machine",
    "think",
    "make",
    "decisions",
    "machines",
    "similar",
    "humans",
    "okay",
    "feed",
    "machine",
    "good",
    "amount",
    "data",
    "learn",
    "interpret",
    "process",
    "analyze",
    "data",
    "using",
    "machine",
    "learning",
    "algorithms",
    "help",
    "solve",
    "world",
    "problems",
    "happens",
    "lot",
    "data",
    "fed",
    "machine",
    "machine",
    "train",
    "data",
    "build",
    "predictive",
    "model",
    "help",
    "machine",
    "learning",
    "algorithms",
    "order",
    "predict",
    "outcome",
    "order",
    "find",
    "solution",
    "problem",
    "involves",
    "data",
    "gon",
    "na",
    "train",
    "machine",
    "build",
    "model",
    "using",
    "machine",
    "learning",
    "algorithms",
    "order",
    "predict",
    "outcome",
    "find",
    "solution",
    "problem",
    "simple",
    "way",
    "understanding",
    "exactly",
    "machine",
    "learning",
    "going",
    "depth",
    "machine",
    "learning",
    "worry",
    "understood",
    "anything",
    "let",
    "discuss",
    "couple",
    "terms",
    "frequently",
    "used",
    "machine",
    "learning",
    "first",
    "definition",
    "come",
    "across",
    "often",
    "algorithm",
    "basically",
    "machine",
    "learning",
    "algorithm",
    "set",
    "rules",
    "statistical",
    "techniques",
    "used",
    "learn",
    "patterns",
    "data",
    "draw",
    "significant",
    "information",
    "okay",
    "guys",
    "logic",
    "behind",
    "machine",
    "learning",
    "model",
    "basically",
    "machine",
    "learning",
    "algorithm",
    "okay",
    "example",
    "machine",
    "learning",
    "algorithm",
    "linear",
    "regression",
    "decision",
    "tree",
    "random",
    "forest",
    "machine",
    "learning",
    "algorithms",
    "define",
    "logic",
    "behind",
    "machine",
    "learning",
    "model",
    "machine",
    "learning",
    "model",
    "model",
    "actually",
    "main",
    "component",
    "machine",
    "learning",
    "process",
    "okay",
    "model",
    "trained",
    "using",
    "machine",
    "learning",
    "algorithm",
    "difference",
    "algorithm",
    "model",
    "algorithm",
    "maps",
    "decisions",
    "model",
    "supposed",
    "take",
    "based",
    "given",
    "input",
    "order",
    "get",
    "correct",
    "output",
    "model",
    "use",
    "machine",
    "learning",
    "algorithm",
    "order",
    "draw",
    "useful",
    "insights",
    "input",
    "give",
    "outcome",
    "precise",
    "machine",
    "learning",
    "model",
    "next",
    "definition",
    "predictor",
    "variable",
    "predictor",
    "variable",
    "feature",
    "data",
    "used",
    "predict",
    "output",
    "okay",
    "let",
    "give",
    "example",
    "make",
    "understand",
    "predictor",
    "variable",
    "let",
    "say",
    "trying",
    "predict",
    "height",
    "person",
    "depending",
    "weight",
    "predictor",
    "variable",
    "becomes",
    "weight",
    "using",
    "weight",
    "person",
    "predict",
    "person",
    "height",
    "predictor",
    "variable",
    "becomes",
    "weight",
    "next",
    "definition",
    "response",
    "variable",
    "example",
    "height",
    "would",
    "response",
    "variable",
    "response",
    "variable",
    "also",
    "known",
    "target",
    "variable",
    "output",
    "variable",
    "variable",
    "trying",
    "predict",
    "using",
    "predictor",
    "variables",
    "response",
    "variable",
    "feature",
    "output",
    "variable",
    "needs",
    "predicted",
    "using",
    "predictor",
    "variables",
    "next",
    "something",
    "known",
    "training",
    "data",
    "training",
    "testing",
    "data",
    "terminologies",
    "come",
    "across",
    "often",
    "machine",
    "learning",
    "process",
    "training",
    "data",
    "basically",
    "data",
    "used",
    "create",
    "machine",
    "learning",
    "model",
    "basically",
    "machine",
    "learning",
    "process",
    "feed",
    "data",
    "machine",
    "divided",
    "two",
    "parts",
    "splitting",
    "data",
    "two",
    "parts",
    "also",
    "known",
    "data",
    "splicing",
    "take",
    "input",
    "data",
    "divide",
    "two",
    "sections",
    "one",
    "call",
    "training",
    "data",
    "call",
    "testing",
    "data",
    "something",
    "known",
    "testing",
    "data",
    "training",
    "data",
    "basically",
    "used",
    "create",
    "machine",
    "learning",
    "model",
    "training",
    "data",
    "helps",
    "model",
    "identify",
    "key",
    "trends",
    "patterns",
    "essential",
    "predict",
    "output",
    "testing",
    "data",
    "model",
    "trained",
    "must",
    "tested",
    "order",
    "evaluate",
    "accurately",
    "predict",
    "outcome",
    "done",
    "using",
    "testing",
    "data",
    "basically",
    "training",
    "data",
    "used",
    "train",
    "model",
    "testing",
    "data",
    "used",
    "test",
    "efficiency",
    "model",
    "let",
    "move",
    "get",
    "next",
    "topic",
    "machine",
    "learning",
    "process",
    "machine",
    "learning",
    "process",
    "machine",
    "learning",
    "process",
    "involves",
    "building",
    "predictive",
    "model",
    "used",
    "find",
    "solution",
    "problem",
    "statement",
    "order",
    "solve",
    "problem",
    "machine",
    "learning",
    "couple",
    "steps",
    "need",
    "follow",
    "let",
    "look",
    "steps",
    "first",
    "step",
    "define",
    "objective",
    "problem",
    "second",
    "step",
    "data",
    "gathering",
    "followed",
    "preparing",
    "data",
    "data",
    "exploration",
    "building",
    "model",
    "model",
    "evaluation",
    "finally",
    "making",
    "predictions",
    "order",
    "understand",
    "machine",
    "learning",
    "process",
    "let",
    "assume",
    "given",
    "problem",
    "needs",
    "solved",
    "using",
    "machine",
    "learning",
    "problem",
    "need",
    "solve",
    "need",
    "predict",
    "occurrence",
    "rain",
    "local",
    "area",
    "using",
    "machine",
    "learning",
    "basically",
    "need",
    "predict",
    "possibility",
    "rain",
    "studying",
    "weather",
    "conditions",
    "basically",
    "looked",
    "step",
    "number",
    "one",
    "define",
    "objective",
    "problem",
    "need",
    "answer",
    "questions",
    "trying",
    "predict",
    "output",
    "going",
    "continuous",
    "variable",
    "going",
    "discreet",
    "variable",
    "kinds",
    "questions",
    "need",
    "answer",
    "first",
    "page",
    "defining",
    "objective",
    "problem",
    "right",
    "yeah",
    "exactly",
    "target",
    "feature",
    "need",
    "understand",
    "target",
    "variable",
    "different",
    "predictor",
    "variables",
    "need",
    "order",
    "predict",
    "outcome",
    "target",
    "variable",
    "basically",
    "variable",
    "tell",
    "us",
    "whether",
    "going",
    "rain",
    "input",
    "data",
    "need",
    "data",
    "maybe",
    "temperature",
    "particular",
    "day",
    "humidity",
    "level",
    "precipitation",
    "need",
    "define",
    "objective",
    "stage",
    "basically",
    "form",
    "idea",
    "problem",
    "storage",
    "another",
    "question",
    "need",
    "ask",
    "kind",
    "problem",
    "solving",
    "binary",
    "classification",
    "problem",
    "clustering",
    "problem",
    "regression",
    "problem",
    "lo",
    "might",
    "familiar",
    "terms",
    "classification",
    "clustering",
    "regression",
    "terms",
    "machine",
    "learning",
    "worry",
    "explain",
    "terms",
    "upcoming",
    "slides",
    "need",
    "understand",
    "step",
    "one",
    "need",
    "define",
    "going",
    "solve",
    "problem",
    "need",
    "understand",
    "sort",
    "data",
    "need",
    "solve",
    "problem",
    "going",
    "approach",
    "problem",
    "trying",
    "predict",
    "variables",
    "need",
    "order",
    "predict",
    "outcome",
    "let",
    "move",
    "look",
    "step",
    "number",
    "two",
    "data",
    "gather",
    "stage",
    "must",
    "asking",
    "questions",
    "kind",
    "data",
    "needed",
    "solve",
    "problem",
    "data",
    "available",
    "available",
    "get",
    "data",
    "get",
    "data",
    "data",
    "gathering",
    "one",
    "steps",
    "machine",
    "learning",
    "process",
    "go",
    "manually",
    "collect",
    "data",
    "going",
    "take",
    "lot",
    "time",
    "lucky",
    "us",
    "lot",
    "resources",
    "online",
    "wide",
    "data",
    "sets",
    "need",
    "web",
    "scraping",
    "go",
    "ahead",
    "download",
    "data",
    "one",
    "websites",
    "tell",
    "cargill",
    "beginner",
    "machine",
    "learning",
    "worry",
    "data",
    "gathering",
    "go",
    "websites",
    "cargill",
    "download",
    "data",
    "set",
    "coming",
    "back",
    "problem",
    "discussing",
    "predicting",
    "weather",
    "data",
    "needed",
    "weather",
    "forecasting",
    "includes",
    "measures",
    "like",
    "humidity",
    "level",
    "temperature",
    "pressure",
    "locality",
    "whether",
    "live",
    "hill",
    "station",
    "data",
    "collected",
    "stored",
    "analysis",
    "data",
    "collected",
    "data",
    "gathering",
    "stage",
    "step",
    "followed",
    "data",
    "preparation",
    "also",
    "known",
    "data",
    "cleaning",
    "going",
    "around",
    "collecting",
    "data",
    "almost",
    "never",
    "right",
    "format",
    "eve",
    "taking",
    "data",
    "online",
    "resources",
    "website",
    "even",
    "data",
    "require",
    "cleaning",
    "preparation",
    "data",
    "never",
    "right",
    "format",
    "sort",
    "preparation",
    "sort",
    "cleaning",
    "order",
    "make",
    "data",
    "ready",
    "analysis",
    "encounter",
    "cleaning",
    "data",
    "encounter",
    "lot",
    "inconsistencies",
    "data",
    "set",
    "like",
    "encounter",
    "som",
    "missing",
    "values",
    "redundant",
    "variables",
    "duplicate",
    "values",
    "removing",
    "inconsistencies",
    "important",
    "might",
    "lead",
    "wrongful",
    "computations",
    "predictions",
    "okay",
    "stage",
    "scan",
    "data",
    "set",
    "inconsistencies",
    "fix",
    "let",
    "give",
    "small",
    "fact",
    "data",
    "cleaning",
    "survey",
    "ran",
    "last",
    "year",
    "sure",
    "lot",
    "data",
    "scientists",
    "asked",
    "step",
    "difficult",
    "annoying",
    "80",
    "data",
    "scientist",
    "said",
    "data",
    "cleaning",
    "data",
    "cleaning",
    "takes",
    "80",
    "time",
    "easy",
    "get",
    "rid",
    "missing",
    "values",
    "corrupted",
    "data",
    "even",
    "get",
    "rid",
    "missing",
    "values",
    "sometimes",
    "data",
    "set",
    "might",
    "get",
    "affected",
    "might",
    "get",
    "biased",
    "maybe",
    "one",
    "variable",
    "many",
    "missing",
    "values",
    "affect",
    "outcome",
    "fix",
    "issue",
    "deal",
    "missing",
    "data",
    "corrupted",
    "data",
    "data",
    "cleaning",
    "actually",
    "one",
    "hardest",
    "steps",
    "machine",
    "learning",
    "process",
    "okay",
    "let",
    "move",
    "look",
    "next",
    "step",
    "exploratory",
    "data",
    "analysis",
    "basically",
    "become",
    "detective",
    "stage",
    "stage",
    "eda",
    "exploratory",
    "data",
    "analysis",
    "like",
    "brainstorming",
    "stage",
    "machine",
    "learning",
    "data",
    "exploration",
    "involves",
    "understanding",
    "patterns",
    "trends",
    "data",
    "stage",
    "useful",
    "insights",
    "drawn",
    "correlations",
    "various",
    "variables",
    "understood",
    "mean",
    "trends",
    "patterns",
    "correlations",
    "let",
    "consider",
    "example",
    "predict",
    "rainfall",
    "particular",
    "day",
    "know",
    "strong",
    "possibility",
    "rain",
    "temperature",
    "fallen",
    "law",
    "know",
    "output",
    "depend",
    "variables",
    "temperature",
    "humidity",
    "level",
    "depends",
    "variables",
    "find",
    "find",
    "patterns",
    "find",
    "correlations",
    "variables",
    "patterns",
    "trends",
    "understood",
    "mapped",
    "stage",
    "exploratory",
    "data",
    "analysis",
    "important",
    "part",
    "machine",
    "learning",
    "understand",
    "exactly",
    "data",
    "form",
    "solution",
    "problem",
    "next",
    "step",
    "machine",
    "learning",
    "process",
    "building",
    "machine",
    "learning",
    "module",
    "insights",
    "patterns",
    "derive",
    "data",
    "exploration",
    "used",
    "build",
    "machine",
    "learning",
    "model",
    "stage",
    "always",
    "begins",
    "splitting",
    "data",
    "set",
    "two",
    "parts",
    "training",
    "data",
    "testing",
    "data",
    "already",
    "discussed",
    "data",
    "used",
    "machine",
    "learning",
    "process",
    "always",
    "split",
    "two",
    "parts",
    "training",
    "data",
    "testing",
    "data",
    "building",
    "model",
    "always",
    "use",
    "training",
    "data",
    "always",
    "make",
    "use",
    "training",
    "data",
    "order",
    "build",
    "model",
    "lot",
    "might",
    "asking",
    "training",
    "data",
    "different",
    "input",
    "data",
    "feeding",
    "machine",
    "different",
    "testing",
    "data",
    "training",
    "data",
    "input",
    "data",
    "feeding",
    "machine",
    "difference",
    "splitting",
    "data",
    "set",
    "two",
    "randomly",
    "picking",
    "80",
    "data",
    "assigning",
    "training",
    "purpose",
    "rest",
    "20",
    "probably",
    "assign",
    "testing",
    "purpose",
    "guys",
    "always",
    "remember",
    "another",
    "thing",
    "training",
    "data",
    "always",
    "much",
    "testing",
    "data",
    "obviously",
    "need",
    "train",
    "machine",
    "data",
    "feed",
    "machine",
    "training",
    "phase",
    "better",
    "testing",
    "phase",
    "obviously",
    "predict",
    "better",
    "outcomes",
    "trained",
    "data",
    "correct",
    "model",
    "basically",
    "using",
    "machine",
    "learning",
    "algorithm",
    "predicts",
    "output",
    "using",
    "data",
    "fed",
    "case",
    "predicting",
    "rainfall",
    "output",
    "categorical",
    "variable",
    "predicting",
    "whether",
    "going",
    "rain",
    "okay",
    "let",
    "say",
    "output",
    "variable",
    "called",
    "rain",
    "two",
    "possible",
    "values",
    "variable",
    "take",
    "yes",
    "going",
    "rain",
    "wo",
    "rain",
    "correct",
    "come",
    "outcome",
    "classification",
    "categorical",
    "variable",
    "cases",
    "outcome",
    "categorical",
    "variable",
    "using",
    "classification",
    "algorithms",
    "example",
    "classification",
    "algorithm",
    "logistic",
    "regression",
    "also",
    "support",
    "vector",
    "machines",
    "use",
    "k",
    "nearest",
    "neighbor",
    "also",
    "use",
    "naive",
    "bayes",
    "worry",
    "terms",
    "discussing",
    "algorithms",
    "remember",
    "building",
    "machine",
    "learning",
    "model",
    "make",
    "use",
    "training",
    "data",
    "train",
    "model",
    "using",
    "training",
    "data",
    "machine",
    "learning",
    "algorithm",
    "like",
    "said",
    "choosing",
    "machine",
    "learning",
    "algorithm",
    "depends",
    "problem",
    "statement",
    "trying",
    "solve",
    "n",
    "number",
    "machine",
    "learning",
    "algorithms",
    "choose",
    "algorithm",
    "suitable",
    "problem",
    "statement",
    "step",
    "number",
    "six",
    "model",
    "evaluation",
    "optimization",
    "done",
    "building",
    "model",
    "using",
    "training",
    "data",
    "set",
    "finally",
    "time",
    "put",
    "model",
    "road",
    "test",
    "testing",
    "data",
    "set",
    "used",
    "check",
    "efficiency",
    "model",
    "accurately",
    "predict",
    "outcome",
    "accuracy",
    "calculated",
    "improvements",
    "model",
    "implemented",
    "stage",
    "various",
    "methods",
    "help",
    "improve",
    "performance",
    "model",
    "like",
    "use",
    "parameter",
    "tuning",
    "cross",
    "validation",
    "methods",
    "order",
    "improve",
    "performance",
    "model",
    "main",
    "things",
    "need",
    "remember",
    "model",
    "evaluation",
    "optimization",
    "model",
    "evaluation",
    "nothing",
    "testing",
    "well",
    "model",
    "predict",
    "outcome",
    "stage",
    "using",
    "testing",
    "data",
    "set",
    "previous",
    "stage",
    "building",
    "model",
    "using",
    "training",
    "data",
    "set",
    "model",
    "evaluation",
    "stage",
    "using",
    "testing",
    "data",
    "set",
    "tested",
    "model",
    "need",
    "calculate",
    "accuracy",
    "need",
    "calculate",
    "accurately",
    "model",
    "predicting",
    "outcome",
    "find",
    "need",
    "improve",
    "model",
    "way",
    "accuracy",
    "good",
    "use",
    "methods",
    "parameter",
    "tuning",
    "worry",
    "terms",
    "discuss",
    "trying",
    "make",
    "sure",
    "understanding",
    "concept",
    "behind",
    "phases",
    "machine",
    "learning",
    "important",
    "understand",
    "step",
    "okay",
    "let",
    "move",
    "look",
    "last",
    "stage",
    "machine",
    "learning",
    "predictions",
    "model",
    "evaluated",
    "improved",
    "finally",
    "used",
    "make",
    "predictions",
    "final",
    "output",
    "either",
    "categorical",
    "variable",
    "continuous",
    "variable",
    "depends",
    "problem",
    "statement",
    "get",
    "confused",
    "continuous",
    "variables",
    "categorical",
    "variables",
    "discussing",
    "case",
    "predicting",
    "occurrence",
    "rainfall",
    "output",
    "categorical",
    "variable",
    "obvious",
    "predicting",
    "whether",
    "going",
    "rain",
    "result",
    "understand",
    "classification",
    "problem",
    "categorical",
    "variable",
    "entire",
    "machine",
    "learning",
    "process",
    "time",
    "learn",
    "different",
    "ways",
    "machines",
    "learn",
    "let",
    "move",
    "ahead",
    "look",
    "types",
    "machine",
    "learning",
    "one",
    "interesting",
    "concepts",
    "machine",
    "learning",
    "three",
    "different",
    "ways",
    "machines",
    "learn",
    "something",
    "known",
    "supervised",
    "learning",
    "unsupervised",
    "learning",
    "reinforcement",
    "learning",
    "go",
    "one",
    "one",
    "understand",
    "supervised",
    "learning",
    "first",
    "look",
    "two",
    "types",
    "defined",
    "supervised",
    "learning",
    "basically",
    "technique",
    "teach",
    "train",
    "machine",
    "using",
    "data",
    "well",
    "labeled",
    "order",
    "understand",
    "supervised",
    "learning",
    "let",
    "consider",
    "small",
    "example",
    "kids",
    "needed",
    "guidance",
    "solve",
    "math",
    "problems",
    "lot",
    "us",
    "trouble",
    "solving",
    "math",
    "problems",
    "teachers",
    "always",
    "help",
    "us",
    "understand",
    "addition",
    "dhow",
    "done",
    "similarly",
    "think",
    "supervised",
    "learning",
    "type",
    "machine",
    "learning",
    "involves",
    "guide",
    "label",
    "data",
    "set",
    "teacher",
    "train",
    "understand",
    "patterns",
    "data",
    "label",
    "data",
    "set",
    "nothing",
    "training",
    "data",
    "set",
    "explain",
    "understand",
    "supervised",
    "learning",
    "better",
    "let",
    "look",
    "figure",
    "screen",
    "right",
    "feeding",
    "machine",
    "image",
    "tom",
    "jerry",
    "goal",
    "machine",
    "identify",
    "classify",
    "images",
    "two",
    "classes",
    "one",
    "contain",
    "images",
    "tom",
    "contain",
    "images",
    "jerry",
    "main",
    "thing",
    "need",
    "note",
    "supervised",
    "learning",
    "training",
    "data",
    "set",
    "training",
    "data",
    "set",
    "going",
    "well",
    "labeled",
    "mean",
    "say",
    "training",
    "data",
    "set",
    "labeled",
    "basically",
    "telling",
    "machine",
    "tom",
    "looks",
    "jerry",
    "looks",
    "training",
    "machine",
    "using",
    "label",
    "data",
    "main",
    "thing",
    "labeling",
    "every",
    "input",
    "data",
    "feeding",
    "model",
    "basically",
    "entire",
    "training",
    "data",
    "set",
    "labeled",
    "whenever",
    "giving",
    "image",
    "tom",
    "gon",
    "na",
    "label",
    "saying",
    "tom",
    "giving",
    "image",
    "jerry",
    "saying",
    "jerry",
    "looks",
    "basically",
    "guiding",
    "machine",
    "telling",
    "listen",
    "tom",
    "looks",
    "jerry",
    "looks",
    "need",
    "classify",
    "two",
    "different",
    "classes",
    "supervised",
    "learning",
    "works",
    "apart",
    "old",
    "process",
    "getting",
    "input",
    "data",
    "gon",
    "na",
    "perform",
    "data",
    "cleaning",
    "exploratory",
    "data",
    "analysis",
    "followed",
    "creating",
    "model",
    "using",
    "machine",
    "learning",
    "algorithm",
    "followed",
    "model",
    "evaluation",
    "finally",
    "predictions",
    "one",
    "thing",
    "note",
    "output",
    "get",
    "using",
    "supervised",
    "learning",
    "also",
    "labeled",
    "output",
    "basically",
    "get",
    "two",
    "different",
    "classes",
    "name",
    "tom",
    "one",
    "name",
    "jerry",
    "get",
    "labeled",
    "supervised",
    "learning",
    "works",
    "important",
    "thing",
    "supervised",
    "learning",
    "training",
    "model",
    "using",
    "labeled",
    "data",
    "set",
    "let",
    "move",
    "look",
    "unsupervised",
    "learning",
    "look",
    "example",
    "understand",
    "unsupervised",
    "learning",
    "works",
    "exactly",
    "unsupervised",
    "learning",
    "involves",
    "training",
    "using",
    "unlabeled",
    "data",
    "allowing",
    "model",
    "act",
    "information",
    "without",
    "guidance",
    "alright",
    "like",
    "name",
    "suggest",
    "supervision",
    "unsupervised",
    "learning",
    "think",
    "unsupervised",
    "learning",
    "smart",
    "kid",
    "learns",
    "without",
    "guidance",
    "okay",
    "type",
    "machine",
    "learning",
    "model",
    "fed",
    "label",
    "data",
    "model",
    "clue",
    "image",
    "tom",
    "jerry",
    "figures",
    "patterns",
    "difference",
    "tom",
    "jerry",
    "taking",
    "tons",
    "tons",
    "data",
    "think",
    "machine",
    "identifies",
    "tom",
    "finally",
    "gives",
    "us",
    "output",
    "like",
    "yes",
    "tom",
    "jerry",
    "example",
    "identifies",
    "prominent",
    "features",
    "tom",
    "pointy",
    "ears",
    "bigger",
    "size",
    "understand",
    "image",
    "type",
    "one",
    "similarly",
    "finds",
    "features",
    "jerry",
    "knows",
    "image",
    "type",
    "two",
    "meaning",
    "first",
    "image",
    "different",
    "second",
    "image",
    "unsupervised",
    "learning",
    "algorithm",
    "model",
    "form",
    "two",
    "different",
    "clusters",
    "form",
    "one",
    "cluster",
    "similar",
    "cluster",
    "different",
    "first",
    "cluster",
    "unsupervised",
    "learning",
    "works",
    "important",
    "things",
    "need",
    "know",
    "unsupervised",
    "learning",
    "gon",
    "na",
    "feed",
    "machine",
    "unlabeled",
    "data",
    "machine",
    "understand",
    "patterns",
    "discover",
    "output",
    "finally",
    "machine",
    "form",
    "clusters",
    "based",
    "feature",
    "similarity",
    "let",
    "move",
    "locate",
    "last",
    "type",
    "machine",
    "learning",
    "reinforcement",
    "learning",
    "reinforcement",
    "learning",
    "quite",
    "different",
    "compared",
    "supervised",
    "unsupervised",
    "learning",
    "exactly",
    "reinforcement",
    "learning",
    "part",
    "machine",
    "learning",
    "agent",
    "put",
    "environment",
    "learns",
    "behave",
    "environment",
    "performing",
    "certain",
    "actions",
    "observing",
    "rewards",
    "gets",
    "actions",
    "understand",
    "reinforcement",
    "learning",
    "imagine",
    "dropped",
    "isolate",
    "island",
    "would",
    "panic",
    "yes",
    "course",
    "initially",
    "panic",
    "time",
    "passes",
    "learn",
    "live",
    "island",
    "explode",
    "environment",
    "understand",
    "climate",
    "conditions",
    "type",
    "food",
    "grows",
    "dangers",
    "island",
    "exactly",
    "reinforcement",
    "learning",
    "works",
    "basically",
    "involves",
    "agent",
    "stuck",
    "island",
    "put",
    "unknown",
    "environment",
    "island",
    "must",
    "learn",
    "observing",
    "performing",
    "actions",
    "result",
    "rewards",
    "reinforcement",
    "learning",
    "mainly",
    "used",
    "advanced",
    "machine",
    "learning",
    "areas",
    "cars",
    "alphago",
    "sure",
    "lot",
    "heard",
    "alphago",
    "logic",
    "behind",
    "alphago",
    "nothing",
    "reinforcement",
    "learning",
    "deep",
    "learning",
    "reinforcement",
    "learning",
    "really",
    "input",
    "data",
    "given",
    "agent",
    "explore",
    "everything",
    "scratch",
    "like",
    "newborn",
    "baby",
    "information",
    "anything",
    "go",
    "around",
    "exploring",
    "environment",
    "getting",
    "rewards",
    "performing",
    "actions",
    "results",
    "either",
    "rewards",
    "sort",
    "punishment",
    "okay",
    "sums",
    "types",
    "machine",
    "learning",
    "move",
    "ahead",
    "like",
    "discuss",
    "difference",
    "three",
    "types",
    "machine",
    "learning",
    "make",
    "concept",
    "clear",
    "let",
    "start",
    "looking",
    "definitions",
    "supervised",
    "learning",
    "machine",
    "learn",
    "using",
    "label",
    "data",
    "unsupervised",
    "learning",
    "unlabeled",
    "data",
    "machine",
    "learn",
    "without",
    "supervision",
    "reinforcement",
    "learning",
    "agent",
    "interacts",
    "environment",
    "producing",
    "actions",
    "discover",
    "errors",
    "rewards",
    "based",
    "actions",
    "type",
    "problems",
    "solved",
    "using",
    "supervised",
    "unsupervised",
    "reinforcement",
    "learning",
    "comes",
    "supervised",
    "learning",
    "two",
    "main",
    "types",
    "problems",
    "solved",
    "regression",
    "problems",
    "classification",
    "problems",
    "comes",
    "unsupervised",
    "learning",
    "association",
    "clustering",
    "problems",
    "comes",
    "reinforcement",
    "learning",
    "problems",
    "discussing",
    "regression",
    "classification",
    "clustering",
    "upcoming",
    "slides",
    "worry",
    "understand",
    "type",
    "data",
    "used",
    "supervised",
    "learning",
    "labeled",
    "data",
    "unsupervised",
    "learning",
    "unlabeled",
    "reinforcement",
    "learning",
    "predefined",
    "data",
    "set",
    "agent",
    "everything",
    "scratch",
    "type",
    "training",
    "involved",
    "learnings",
    "supervised",
    "learning",
    "external",
    "supervision",
    "labeled",
    "data",
    "set",
    "acts",
    "guide",
    "machine",
    "learn",
    "unsupervised",
    "learning",
    "supervision",
    "reinforcement",
    "learning",
    "supervision",
    "approach",
    "solve",
    "problems",
    "using",
    "supervised",
    "unsupervised",
    "reinforcement",
    "learning",
    "supervised",
    "learning",
    "simple",
    "mal",
    "labeled",
    "input",
    "known",
    "output",
    "machine",
    "knows",
    "output",
    "looks",
    "like",
    "labeling",
    "input",
    "output",
    "unsupervised",
    "learning",
    "going",
    "understand",
    "patterns",
    "discover",
    "output",
    "clue",
    "input",
    "labeled",
    "understand",
    "patterns",
    "form",
    "clusters",
    "discover",
    "output",
    "reinforcement",
    "learning",
    "clue",
    "follow",
    "trial",
    "error",
    "method",
    "go",
    "around",
    "environment",
    "explore",
    "environment",
    "try",
    "actions",
    "perform",
    "actions",
    "know",
    "whether",
    "action",
    "whether",
    "action",
    "reinforcement",
    "learning",
    "totally",
    "based",
    "concept",
    "trial",
    "error",
    "okay",
    "popular",
    "algorithm",
    "supervised",
    "learning",
    "include",
    "linear",
    "regression",
    "logistic",
    "regressions",
    "support",
    "vector",
    "machines",
    "k",
    "nearest",
    "neighbor",
    "naive",
    "bayes",
    "unsupervised",
    "learning",
    "famous",
    "clustering",
    "method",
    "reinforcement",
    "learning",
    "famous",
    "learning",
    "algorithm",
    "discussing",
    "algorithms",
    "upcoming",
    "slides",
    "let",
    "move",
    "look",
    "next",
    "topic",
    "types",
    "problems",
    "solved",
    "using",
    "machine",
    "learning",
    "talking",
    "earlier",
    "said",
    "regression",
    "classification",
    "clustering",
    "problems",
    "okay",
    "let",
    "discuss",
    "exactly",
    "mean",
    "machine",
    "learning",
    "problems",
    "classified",
    "three",
    "types",
    "every",
    "problem",
    "approached",
    "machine",
    "learning",
    "put",
    "interest",
    "one",
    "three",
    "categories",
    "okay",
    "first",
    "type",
    "known",
    "regression",
    "classification",
    "clustering",
    "first",
    "let",
    "look",
    "regression",
    "type",
    "problems",
    "type",
    "problem",
    "output",
    "always",
    "continuous",
    "quantity",
    "example",
    "want",
    "predict",
    "speed",
    "car",
    "given",
    "distance",
    "regression",
    "problem",
    "lot",
    "might",
    "aware",
    "exactly",
    "continuous",
    "quantity",
    "continuous",
    "quantity",
    "quantity",
    "infinite",
    "range",
    "values",
    "example",
    "weight",
    "person",
    "continuous",
    "quantity",
    "weight",
    "50",
    "infinite",
    "range",
    "values",
    "correct",
    "type",
    "problem",
    "predict",
    "continuous",
    "quantity",
    "make",
    "use",
    "regression",
    "algorithms",
    "regression",
    "problems",
    "solved",
    "using",
    "supervised",
    "learning",
    "algorithms",
    "like",
    "linear",
    "regression",
    "next",
    "classification",
    "type",
    "problem",
    "output",
    "always",
    "categorical",
    "value",
    "say",
    "categorical",
    "value",
    "value",
    "gender",
    "person",
    "categorical",
    "value",
    "classifying",
    "emails",
    "two",
    "two",
    "classes",
    "like",
    "spam",
    "classification",
    "problem",
    "solved",
    "using",
    "supervised",
    "learning",
    "classification",
    "algorithms",
    "like",
    "support",
    "vector",
    "machines",
    "naive",
    "bayes",
    "logistic",
    "regression",
    "k",
    "nearest",
    "neighbor",
    "main",
    "aim",
    "classification",
    "compute",
    "category",
    "data",
    "coming",
    "clustering",
    "problems",
    "type",
    "problem",
    "involves",
    "assigned",
    "input",
    "two",
    "clusters",
    "based",
    "feature",
    "similarity",
    "thus",
    "read",
    "sentence",
    "understand",
    "unsupervised",
    "learning",
    "enough",
    "data",
    "input",
    "option",
    "form",
    "clusters",
    "categories",
    "formed",
    "know",
    "data",
    "two",
    "type",
    "input",
    "data",
    "labeled",
    "two",
    "types",
    "gon",
    "na",
    "classification",
    "problem",
    "clustering",
    "problem",
    "happens",
    "much",
    "information",
    "input",
    "find",
    "patterns",
    "understand",
    "data",
    "points",
    "similar",
    "clustered",
    "one",
    "group",
    "data",
    "points",
    "different",
    "first",
    "group",
    "clustered",
    "another",
    "group",
    "clustering",
    "example",
    "netflix",
    "happens",
    "netflix",
    "clusters",
    "users",
    "similar",
    "groups",
    "based",
    "interest",
    "based",
    "age",
    "geography",
    "done",
    "using",
    "unsupervised",
    "learning",
    "algorithms",
    "like",
    "okay",
    "guys",
    "three",
    "categories",
    "problems",
    "solved",
    "using",
    "machine",
    "learning",
    "basically",
    "trying",
    "say",
    "problems",
    "fall",
    "one",
    "categories",
    "problem",
    "give",
    "machine",
    "learning",
    "model",
    "fall",
    "one",
    "categories",
    "okay",
    "make",
    "things",
    "little",
    "interesting",
    "collected",
    "real",
    "world",
    "data",
    "sets",
    "online",
    "resources",
    "gon",
    "na",
    "going",
    "try",
    "understand",
    "regression",
    "problem",
    "clustering",
    "problem",
    "classification",
    "problem",
    "okay",
    "problem",
    "statement",
    "study",
    "house",
    "sales",
    "data",
    "set",
    "build",
    "machine",
    "learning",
    "model",
    "predicts",
    "house",
    "pricing",
    "index",
    "important",
    "thing",
    "need",
    "understand",
    "read",
    "problem",
    "statement",
    "need",
    "understand",
    "target",
    "variable",
    "possible",
    "predictor",
    "variable",
    "need",
    "first",
    "thing",
    "look",
    "targe",
    "variable",
    "want",
    "understand",
    "classification",
    "regression",
    "clustering",
    "problem",
    "look",
    "target",
    "variable",
    "output",
    "variable",
    "supposed",
    "predict",
    "supposed",
    "predict",
    "house",
    "pricing",
    "index",
    "house",
    "pricing",
    "index",
    "obviously",
    "continuous",
    "quantity",
    "soon",
    "understand",
    "know",
    "regression",
    "problem",
    "make",
    "use",
    "linear",
    "regression",
    "algorithm",
    "predict",
    "house",
    "pricing",
    "index",
    "linear",
    "regression",
    "regression",
    "algorithm",
    "supervised",
    "learning",
    "algorithm",
    "discuss",
    "slides",
    "let",
    "look",
    "next",
    "problem",
    "statement",
    "study",
    "bank",
    "credit",
    "data",
    "set",
    "make",
    "decision",
    "whether",
    "approve",
    "loan",
    "applicant",
    "based",
    "profile",
    "output",
    "variable",
    "output",
    "variable",
    "predict",
    "whether",
    "approve",
    "loan",
    "applicant",
    "obviously",
    "output",
    "going",
    "categorical",
    "either",
    "going",
    "yes",
    "yes",
    "basically",
    "approved",
    "loan",
    "reject",
    "loan",
    "understand",
    "classification",
    "problem",
    "okay",
    "make",
    "use",
    "algorithms",
    "like",
    "knn",
    "algorithm",
    "make",
    "use",
    "support",
    "vector",
    "machines",
    "order",
    "support",
    "vector",
    "machine",
    "knn",
    "k",
    "nearest",
    "neighbor",
    "algorithms",
    "basically",
    "supervised",
    "learning",
    "algorithm",
    "talk",
    "upcoming",
    "slides",
    "moving",
    "next",
    "problem",
    "statement",
    "problem",
    "statement",
    "cluster",
    "set",
    "movies",
    "either",
    "good",
    "average",
    "based",
    "social",
    "media",
    "outreach",
    "look",
    "properly",
    "clue",
    "question",
    "first",
    "line",
    "says",
    "cluster",
    "set",
    "movies",
    "either",
    "good",
    "average",
    "guys",
    "whenever",
    "problem",
    "statement",
    "asking",
    "group",
    "data",
    "set",
    "different",
    "groups",
    "form",
    "different",
    "different",
    "clusters",
    "obviously",
    "clustering",
    "problem",
    "right",
    "make",
    "use",
    "clustering",
    "algorithm",
    "form",
    "two",
    "clusters",
    "one",
    "contain",
    "popular",
    "movies",
    "contain",
    "movies",
    "alright",
    "small",
    "examples",
    "use",
    "machine",
    "learning",
    "solve",
    "clustering",
    "problem",
    "regression",
    "classification",
    "problems",
    "key",
    "need",
    "identify",
    "type",
    "problem",
    "first",
    "let",
    "move",
    "discuss",
    "different",
    "types",
    "machine",
    "learning",
    "algorithms",
    "gon",
    "na",
    "start",
    "discussing",
    "different",
    "supervised",
    "learning",
    "algorithms",
    "give",
    "quick",
    "overview",
    "discussing",
    "linear",
    "regression",
    "logistic",
    "regression",
    "decision",
    "tree",
    "random",
    "forest",
    "naive",
    "bayes",
    "classifier",
    "support",
    "vector",
    "machines",
    "k",
    "nearest",
    "neighbor",
    "discussing",
    "seven",
    "algorithms",
    "without",
    "delay",
    "let",
    "look",
    "linear",
    "regression",
    "first",
    "exactly",
    "linear",
    "regression",
    "algorithm",
    "guys",
    "linear",
    "regression",
    "basically",
    "supervised",
    "learning",
    "algorithm",
    "used",
    "predict",
    "continuous",
    "dependent",
    "variable",
    "based",
    "values",
    "independent",
    "variable",
    "okay",
    "important",
    "thing",
    "note",
    "dependent",
    "variable",
    "variable",
    "trying",
    "predict",
    "always",
    "going",
    "continuous",
    "variable",
    "independent",
    "variable",
    "x",
    "basically",
    "predictor",
    "variables",
    "variables",
    "using",
    "predict",
    "output",
    "variable",
    "nothing",
    "dependent",
    "variable",
    "independent",
    "variables",
    "predictive",
    "variables",
    "either",
    "continuous",
    "discreet",
    "okay",
    "restriction",
    "okay",
    "either",
    "continuous",
    "variables",
    "discreet",
    "variables",
    "tell",
    "continuous",
    "variable",
    "case",
    "forgotten",
    "vary",
    "infinite",
    "number",
    "possibilities",
    "give",
    "example",
    "person",
    "weight",
    "160",
    "pounds",
    "weigh",
    "pounds",
    "pounds",
    "number",
    "possibilities",
    "weight",
    "limitless",
    "exactly",
    "continuous",
    "variable",
    "order",
    "understand",
    "linear",
    "regression",
    "let",
    "assume",
    "want",
    "predict",
    "price",
    "stock",
    "period",
    "time",
    "okay",
    "problem",
    "make",
    "use",
    "linear",
    "regression",
    "starting",
    "relationship",
    "dependent",
    "variable",
    "stock",
    "price",
    "independent",
    "variable",
    "time",
    "trying",
    "predict",
    "stock",
    "price",
    "period",
    "time",
    "basically",
    "gon",
    "na",
    "check",
    "price",
    "stock",
    "varies",
    "period",
    "time",
    "stock",
    "price",
    "going",
    "dependent",
    "variable",
    "output",
    "variable",
    "time",
    "going",
    "predictor",
    "variable",
    "independent",
    "variable",
    "let",
    "confuse",
    "anymore",
    "dependent",
    "variable",
    "output",
    "variable",
    "okay",
    "independent",
    "variable",
    "input",
    "variable",
    "predictor",
    "variable",
    "case",
    "stock",
    "price",
    "obviously",
    "continuous",
    "quantity",
    "stock",
    "price",
    "infinite",
    "number",
    "values",
    "first",
    "step",
    "linear",
    "regression",
    "always",
    "draw",
    "relationship",
    "dependent",
    "independent",
    "variable",
    "using",
    "best",
    "fitting",
    "linear",
    "length",
    "make",
    "assumption",
    "dependent",
    "independent",
    "variable",
    "linearly",
    "related",
    "call",
    "linear",
    "regression",
    "variables",
    "vary",
    "linearly",
    "means",
    "plotting",
    "relationship",
    "two",
    "variables",
    "get",
    "straight",
    "line",
    "instead",
    "curve",
    "let",
    "discuss",
    "math",
    "behind",
    "linear",
    "regression",
    "equation",
    "denotes",
    "relationship",
    "independent",
    "variable",
    "x",
    "dependent",
    "variable",
    "variable",
    "trying",
    "predict",
    "hopefully",
    "know",
    "equation",
    "linear",
    "line",
    "math",
    "equals",
    "mx",
    "plus",
    "hope",
    "remember",
    "math",
    "equation",
    "linear",
    "line",
    "math",
    "equals",
    "mx",
    "plus",
    "similarly",
    "linear",
    "regression",
    "equation",
    "represented",
    "along",
    "line",
    "okay",
    "equals",
    "mx",
    "plus",
    "little",
    "bit",
    "changes",
    "tell",
    "let",
    "understand",
    "equation",
    "properly",
    "basically",
    "stands",
    "dependent",
    "variable",
    "going",
    "predict",
    "b",
    "naught",
    "intercept",
    "intercept",
    "nothing",
    "point",
    "graph",
    "basically",
    "showing",
    "relationship",
    "dependent",
    "variable",
    "independent",
    "variable",
    "linear",
    "relationship",
    "two",
    "variables",
    "okay",
    "intercept",
    "basically",
    "point",
    "line",
    "starts",
    "interceptor",
    "represented",
    "b",
    "naught",
    "b",
    "one",
    "beta",
    "slope",
    "line",
    "slope",
    "either",
    "negative",
    "positive",
    "depending",
    "relationship",
    "dependent",
    "independent",
    "variable",
    "next",
    "variable",
    "x",
    "represents",
    "independent",
    "variable",
    "used",
    "predict",
    "resulting",
    "output",
    "variable",
    "basically",
    "x",
    "used",
    "predict",
    "value",
    "okay",
    "e",
    "denotes",
    "error",
    "computation",
    "example",
    "actual",
    "line",
    "dots",
    "represent",
    "predicted",
    "values",
    "distance",
    "two",
    "denoted",
    "error",
    "computation",
    "entire",
    "equation",
    "quite",
    "simple",
    "right",
    "linear",
    "regression",
    "basically",
    "draw",
    "relationship",
    "input",
    "input",
    "variable",
    "simple",
    "linear",
    "regression",
    "better",
    "understand",
    "linear",
    "regression",
    "running",
    "demo",
    "python",
    "guys",
    "get",
    "started",
    "practical",
    "demo",
    "assuming",
    "good",
    "understanding",
    "python",
    "explaining",
    "python",
    "going",
    "scope",
    "today",
    "session",
    "familiar",
    "python",
    "language",
    "leave",
    "couple",
    "links",
    "description",
    "box",
    "related",
    "python",
    "programming",
    "go",
    "links",
    "understand",
    "python",
    "maybe",
    "try",
    "understand",
    "demo",
    "explaining",
    "logic",
    "part",
    "demo",
    "depth",
    "main",
    "thing",
    "going",
    "try",
    "understand",
    "linear",
    "regression",
    "okay",
    "understand",
    "python",
    "try",
    "explain",
    "much",
    "still",
    "want",
    "understand",
    "better",
    "way",
    "leave",
    "couple",
    "links",
    "description",
    "box",
    "go",
    "videos",
    "let",
    "zoom",
    "hope",
    "see",
    "screen",
    "linear",
    "regression",
    "demo",
    "going",
    "going",
    "form",
    "linear",
    "relationship",
    "maximum",
    "temperature",
    "minimum",
    "temperature",
    "particular",
    "date",
    "going",
    "weather",
    "forecasting",
    "task",
    "predict",
    "maximum",
    "temperature",
    "taking",
    "input",
    "feature",
    "minimum",
    "temperature",
    "going",
    "try",
    "make",
    "understand",
    "linear",
    "regression",
    "demo",
    "okay",
    "see",
    "actually",
    "works",
    "practically",
    "get",
    "started",
    "demo",
    "let",
    "tell",
    "something",
    "data",
    "set",
    "data",
    "set",
    "stored",
    "path",
    "basically",
    "name",
    "data",
    "set",
    "okay",
    "contains",
    "data",
    "whether",
    "conditions",
    "recorded",
    "day",
    "various",
    "weather",
    "stations",
    "around",
    "world",
    "okay",
    "information",
    "include",
    "precipitation",
    "snowfall",
    "temperatures",
    "wind",
    "speeds",
    "whether",
    "day",
    "included",
    "thunderstorm",
    "poor",
    "weather",
    "conditions",
    "first",
    "step",
    "demo",
    "matter",
    "import",
    "libraries",
    "needed",
    "gon",
    "na",
    "begin",
    "demo",
    "importing",
    "required",
    "libraries",
    "going",
    "read",
    "data",
    "data",
    "stored",
    "variable",
    "called",
    "data",
    "set",
    "going",
    "use",
    "function",
    "since",
    "data",
    "set",
    "csv",
    "format",
    "showing",
    "data",
    "set",
    "looks",
    "also",
    "look",
    "data",
    "set",
    "depth",
    "let",
    "show",
    "output",
    "first",
    "let",
    "run",
    "demo",
    "see",
    "first",
    "getting",
    "couple",
    "plots",
    "talk",
    "ignore",
    "warning",
    "nothing",
    "first",
    "printing",
    "shape",
    "data",
    "set",
    "print",
    "shape",
    "data",
    "set",
    "output",
    "get",
    "basically",
    "shows",
    "around",
    "rows",
    "31",
    "columns",
    "data",
    "set",
    "31",
    "columns",
    "basically",
    "represent",
    "predictor",
    "variables",
    "say",
    "31",
    "predictor",
    "variables",
    "order",
    "protect",
    "weather",
    "conditions",
    "particular",
    "date",
    "guys",
    "main",
    "aim",
    "problem",
    "segment",
    "weather",
    "forecast",
    "going",
    "predict",
    "weather",
    "using",
    "set",
    "predictor",
    "variables",
    "different",
    "types",
    "predictor",
    "variables",
    "okay",
    "something",
    "known",
    "maximum",
    "temperature",
    "data",
    "set",
    "looks",
    "like",
    "block",
    "code",
    "plotting",
    "data",
    "points",
    "2d",
    "graph",
    "order",
    "understand",
    "data",
    "set",
    "see",
    "manually",
    "find",
    "relationship",
    "variables",
    "taken",
    "minimum",
    "temperature",
    "maximum",
    "temperature",
    "analysis",
    "let",
    "look",
    "plot",
    "let",
    "comment",
    "plots",
    "see",
    "either",
    "graph",
    "talking",
    "look",
    "graph",
    "basically",
    "graph",
    "minimum",
    "temperature",
    "maximum",
    "temperature",
    "maximum",
    "temperature",
    "dependent",
    "variable",
    "going",
    "predict",
    "minim",
    "temperature",
    "basically",
    "independent",
    "variable",
    "look",
    "graph",
    "see",
    "sort",
    "linear",
    "relationship",
    "two",
    "except",
    "little",
    "bit",
    "outliers",
    "data",
    "points",
    "little",
    "bit",
    "random",
    "apart",
    "pretty",
    "linear",
    "relationship",
    "minimum",
    "temperature",
    "maximum",
    "temperature",
    "graphic",
    "understand",
    "easily",
    "solve",
    "problem",
    "using",
    "linear",
    "regression",
    "data",
    "linear",
    "see",
    "clear",
    "straight",
    "line",
    "first",
    "graph",
    "next",
    "checking",
    "average",
    "maximum",
    "temperature",
    "looking",
    "average",
    "output",
    "variable",
    "okay",
    "guys",
    "right",
    "exploratory",
    "data",
    "analysis",
    "trying",
    "understand",
    "data",
    "trying",
    "see",
    "relationship",
    "input",
    "variable",
    "output",
    "variable",
    "trying",
    "see",
    "mean",
    "average",
    "output",
    "variable",
    "necessary",
    "understand",
    "data",
    "set",
    "average",
    "maximum",
    "temperature",
    "looks",
    "like",
    "try",
    "understand",
    "exactly",
    "average",
    "maximum",
    "temperature",
    "somewhere",
    "28",
    "would",
    "say",
    "30",
    "28",
    "32",
    "somewhere",
    "say",
    "average",
    "maximum",
    "temperature",
    "lies",
    "25",
    "average",
    "maximum",
    "temperature",
    "know",
    "little",
    "bit",
    "data",
    "set",
    "know",
    "good",
    "linear",
    "relationship",
    "input",
    "variable",
    "output",
    "variable",
    "going",
    "going",
    "perform",
    "something",
    "known",
    "data",
    "splicing",
    "let",
    "comment",
    "section",
    "nothing",
    "data",
    "splicing",
    "paying",
    "attention",
    "know",
    "data",
    "splicing",
    "nothing",
    "splitting",
    "data",
    "set",
    "training",
    "testing",
    "data",
    "mentioned",
    "earlier",
    "using",
    "two",
    "variables",
    "trying",
    "understand",
    "relationship",
    "minimum",
    "temperature",
    "maximum",
    "temperature",
    "want",
    "understand",
    "linear",
    "regression",
    "simplest",
    "way",
    "possible",
    "guys",
    "order",
    "make",
    "understand",
    "linear",
    "regression",
    "derived",
    "two",
    "variables",
    "data",
    "set",
    "even",
    "though",
    "check",
    "structure",
    "data",
    "set",
    "around",
    "31",
    "features",
    "meaning",
    "31",
    "variables",
    "include",
    "predictor",
    "variable",
    "target",
    "variable",
    "basically",
    "30",
    "predictor",
    "variables",
    "one",
    "target",
    "variable",
    "maximum",
    "temperature",
    "considering",
    "two",
    "variables",
    "want",
    "show",
    "exactly",
    "linear",
    "regression",
    "works",
    "basically",
    "extracting",
    "two",
    "variables",
    "data",
    "set",
    "storing",
    "x",
    "performing",
    "data",
    "splicing",
    "basically",
    "splitting",
    "data",
    "training",
    "testing",
    "data",
    "remember",
    "one",
    "point",
    "assigning",
    "20",
    "data",
    "testing",
    "data",
    "set",
    "remaining",
    "80",
    "assigned",
    "training",
    "training",
    "works",
    "assign",
    "maximum",
    "data",
    "set",
    "training",
    "want",
    "machine",
    "learning",
    "model",
    "machine",
    "learning",
    "algorithm",
    "train",
    "better",
    "data",
    "wanted",
    "take",
    "much",
    "data",
    "possible",
    "predict",
    "outcome",
    "properly",
    "repeat",
    "splitting",
    "data",
    "training",
    "testing",
    "data",
    "set",
    "one",
    "thing",
    "note",
    "splitting",
    "80",
    "data",
    "training",
    "assigning",
    "20",
    "data",
    "test",
    "data",
    "test",
    "size",
    "variable",
    "variable",
    "see",
    "used",
    "specify",
    "proportion",
    "test",
    "set",
    "splitting",
    "data",
    "training",
    "testing",
    "set",
    "finally",
    "time",
    "train",
    "algorithm",
    "need",
    "import",
    "linear",
    "regression",
    "class",
    "need",
    "instantiate",
    "call",
    "fit",
    "method",
    "along",
    "training",
    "data",
    "linear",
    "regression",
    "class",
    "creating",
    "instance",
    "linear",
    "regression",
    "class",
    "guys",
    "good",
    "thing",
    "python",
    "classes",
    "algorithms",
    "call",
    "algorithms",
    "instead",
    "call",
    "class",
    "linear",
    "regression",
    "class",
    "create",
    "instance",
    "basically",
    "creating",
    "something",
    "known",
    "regressor",
    "call",
    "fit",
    "method",
    "along",
    "training",
    "data",
    "training",
    "data",
    "x",
    "train",
    "train",
    "contains",
    "training",
    "data",
    "calling",
    "linear",
    "regression",
    "instance",
    "regressor",
    "along",
    "data",
    "set",
    "basically",
    "building",
    "model",
    "nothing",
    "building",
    "model",
    "one",
    "major",
    "things",
    "linear",
    "regression",
    "model",
    "finds",
    "best",
    "value",
    "intercept",
    "slope",
    "results",
    "line",
    "best",
    "fits",
    "data",
    "discussed",
    "intercept",
    "slope",
    "want",
    "see",
    "intercept",
    "slope",
    "calculated",
    "linear",
    "regression",
    "model",
    "run",
    "line",
    "code",
    "let",
    "looks",
    "output",
    "intercept",
    "around",
    "coefficient",
    "also",
    "known",
    "beta",
    "coefficients",
    "coefficient",
    "nothing",
    "discussed",
    "beta",
    "naught",
    "beta",
    "values",
    "help",
    "understand",
    "significance",
    "input",
    "variables",
    "coefficient",
    "value",
    "means",
    "see",
    "coefficient",
    "value",
    "around",
    "means",
    "every",
    "one",
    "unit",
    "changed",
    "minimum",
    "temperature",
    "change",
    "maximum",
    "temperature",
    "around",
    "show",
    "significant",
    "input",
    "variable",
    "every",
    "one",
    "unit",
    "change",
    "minimum",
    "temperature",
    "change",
    "maximum",
    "temperature",
    "around",
    "hope",
    "understood",
    "part",
    "trained",
    "algorithm",
    "trying",
    "make",
    "predictions",
    "use",
    "use",
    "test",
    "data",
    "set",
    "see",
    "accurately",
    "algorithm",
    "predicts",
    "percentage",
    "score",
    "make",
    "predictions",
    "line",
    "code",
    "predict",
    "basically",
    "predefined",
    "function",
    "python",
    "going",
    "going",
    "pass",
    "testing",
    "data",
    "set",
    "compare",
    "actual",
    "output",
    "values",
    "basically",
    "stored",
    "test",
    "compare",
    "predicted",
    "values",
    "prediction",
    "store",
    "comparisons",
    "data",
    "frame",
    "called",
    "df",
    "printing",
    "data",
    "frame",
    "look",
    "output",
    "looks",
    "like",
    "actual",
    "values",
    "values",
    "predicted",
    "building",
    "model",
    "actual",
    "value",
    "28",
    "predicted",
    "around",
    "33",
    "actual",
    "value",
    "31",
    "meaning",
    "maximum",
    "temperature",
    "predicted",
    "maximum",
    "temperature",
    "values",
    "actually",
    "pretty",
    "close",
    "feel",
    "like",
    "accuracy",
    "pretty",
    "good",
    "cases",
    "see",
    "lot",
    "variance",
    "like",
    "right",
    "cases",
    "often",
    "best",
    "way",
    "improve",
    "accuracy",
    "would",
    "say",
    "training",
    "model",
    "data",
    "alright",
    "also",
    "view",
    "comparison",
    "form",
    "plot",
    "let",
    "see",
    "looks",
    "basically",
    "bar",
    "graph",
    "shows",
    "actual",
    "values",
    "predicted",
    "values",
    "blue",
    "represented",
    "actual",
    "values",
    "orange",
    "represented",
    "predicted",
    "values",
    "places",
    "see",
    "predicted",
    "pretty",
    "well",
    "like",
    "predictions",
    "pretty",
    "close",
    "actual",
    "values",
    "cases",
    "predictions",
    "varying",
    "little",
    "bit",
    "places",
    "actually",
    "varying",
    "depends",
    "input",
    "data",
    "well",
    "saw",
    "input",
    "data",
    "also",
    "saw",
    "lot",
    "variation",
    "saw",
    "couple",
    "outliers",
    "also",
    "might",
    "effect",
    "output",
    "build",
    "machine",
    "learning",
    "models",
    "initially",
    "never",
    "going",
    "get",
    "really",
    "good",
    "accuracy",
    "improve",
    "training",
    "process",
    "best",
    "way",
    "predict",
    "better",
    "either",
    "use",
    "lot",
    "data",
    "train",
    "model",
    "lot",
    "data",
    "use",
    "methods",
    "like",
    "parameter",
    "tuning",
    "basically",
    "try",
    "find",
    "another",
    "predictor",
    "variable",
    "help",
    "predicting",
    "output",
    "looks",
    "pretty",
    "good",
    "let",
    "show",
    "another",
    "plot",
    "drawing",
    "straight",
    "line",
    "plot",
    "okay",
    "let",
    "see",
    "looks",
    "guys",
    "straight",
    "line",
    "represents",
    "linear",
    "relationship",
    "let",
    "say",
    "get",
    "new",
    "data",
    "point",
    "okay",
    "let",
    "say",
    "value",
    "x",
    "around",
    "using",
    "line",
    "predict",
    "four",
    "minimum",
    "temperature",
    "20",
    "maximum",
    "temperature",
    "would",
    "around",
    "25",
    "something",
    "like",
    "basically",
    "drew",
    "linear",
    "relationship",
    "input",
    "output",
    "variable",
    "final",
    "step",
    "evaluate",
    "performance",
    "algorithm",
    "step",
    "particularly",
    "important",
    "compare",
    "well",
    "different",
    "algorithms",
    "perform",
    "particular",
    "data",
    "set",
    "regression",
    "algorithms",
    "three",
    "evaluation",
    "metrics",
    "used",
    "something",
    "known",
    "mean",
    "absolute",
    "error",
    "mean",
    "squared",
    "error",
    "root",
    "mean",
    "square",
    "error",
    "mean",
    "absolute",
    "error",
    "nothing",
    "absolute",
    "value",
    "errors",
    "mean",
    "squared",
    "error",
    "mean",
    "squared",
    "errors",
    "basically",
    "read",
    "understand",
    "error",
    "means",
    "root",
    "mean",
    "squared",
    "error",
    "square",
    "root",
    "mean",
    "squared",
    "errors",
    "okay",
    "pretty",
    "simple",
    "understand",
    "mean",
    "absolute",
    "error",
    "mean",
    "squared",
    "errors",
    "root",
    "mean",
    "squared",
    "error",
    "luckily",
    "perform",
    "calculations",
    "manually",
    "code",
    "calculations",
    "cycle",
    "library",
    "comes",
    "prebuilt",
    "functions",
    "used",
    "find",
    "values",
    "okay",
    "run",
    "code",
    "get",
    "values",
    "errors",
    "get",
    "around",
    "mean",
    "absolute",
    "error",
    "mean",
    "squared",
    "error",
    "around",
    "root",
    "mean",
    "squared",
    "error",
    "around",
    "error",
    "values",
    "basically",
    "show",
    "model",
    "accuracy",
    "precise",
    "still",
    "able",
    "make",
    "lot",
    "predictions",
    "draw",
    "good",
    "linear",
    "relationship",
    "order",
    "improve",
    "efficiency",
    "lot",
    "methods",
    "like",
    "parameter",
    "tuning",
    "basically",
    "train",
    "model",
    "lot",
    "data",
    "apart",
    "use",
    "predictor",
    "variables",
    "maybe",
    "study",
    "relationship",
    "predictor",
    "variables",
    "maximum",
    "temperature",
    "variable",
    "area",
    "lot",
    "ways",
    "improve",
    "efficiency",
    "model",
    "wanted",
    "make",
    "understand",
    "linear",
    "regression",
    "works",
    "hope",
    "good",
    "idea",
    "hope",
    "good",
    "understanding",
    "linear",
    "regression",
    "works",
    "small",
    "demo",
    "still",
    "doubts",
    "regarding",
    "linear",
    "regression",
    "please",
    "leave",
    "comment",
    "section",
    "try",
    "solve",
    "errors",
    "look",
    "equation",
    "calculated",
    "everything",
    "drew",
    "relationship",
    "x",
    "basically",
    "x",
    "minimum",
    "temperature",
    "maximum",
    "temperature",
    "also",
    "calculated",
    "slope",
    "intercept",
    "also",
    "calculated",
    "error",
    "end",
    "calculated",
    "mean",
    "squared",
    "error",
    "calculated",
    "root",
    "mean",
    "squared",
    "error",
    "also",
    "calculate",
    "mean",
    "absolute",
    "error",
    "everything",
    "linear",
    "regression",
    "simple",
    "linear",
    "regression",
    "model",
    "let",
    "move",
    "look",
    "next",
    "algorithm",
    "logistic",
    "regression",
    "order",
    "understand",
    "use",
    "logistic",
    "regression",
    "let",
    "consider",
    "small",
    "scenarios",
    "let",
    "say",
    "little",
    "sister",
    "trying",
    "get",
    "grad",
    "school",
    "want",
    "predict",
    "whether",
    "get",
    "admitted",
    "dream",
    "school",
    "okay",
    "based",
    "cgpa",
    "past",
    "data",
    "use",
    "logistic",
    "regression",
    "foresee",
    "outcome",
    "logistic",
    "regression",
    "allow",
    "analyze",
    "set",
    "variables",
    "predict",
    "categorical",
    "outcome",
    "since",
    "need",
    "predict",
    "whether",
    "get",
    "school",
    "classification",
    "problem",
    "logistic",
    "regression",
    "used",
    "know",
    "first",
    "question",
    "head",
    "using",
    "linear",
    "regression",
    "case",
    "reason",
    "linear",
    "regression",
    "used",
    "predict",
    "continuous",
    "quantity",
    "rather",
    "categorical",
    "one",
    "going",
    "predict",
    "whether",
    "sister",
    "going",
    "get",
    "grad",
    "school",
    "clearly",
    "categorical",
    "outcome",
    "result",
    "outcome",
    "take",
    "classes",
    "values",
    "like",
    "two",
    "classes",
    "values",
    "sensible",
    "model",
    "predicts",
    "value",
    "either",
    "zero",
    "one",
    "probability",
    "form",
    "ranges",
    "zero",
    "one",
    "okay",
    "linear",
    "regression",
    "ability",
    "use",
    "linear",
    "regression",
    "model",
    "binary",
    "outcome",
    "resulting",
    "model",
    "predict",
    "values",
    "range",
    "zero",
    "one",
    "linear",
    "regression",
    "works",
    "continuous",
    "dependent",
    "variables",
    "categorical",
    "variables",
    "make",
    "use",
    "logistic",
    "regression",
    "understand",
    "linear",
    "regression",
    "used",
    "predict",
    "continuous",
    "quantities",
    "logistic",
    "regression",
    "used",
    "predict",
    "categorical",
    "quantities",
    "okay",
    "one",
    "major",
    "confusion",
    "everybody",
    "people",
    "keep",
    "asking",
    "logistic",
    "regression",
    "called",
    "logistic",
    "regression",
    "used",
    "classification",
    "reason",
    "named",
    "logistic",
    "regression",
    "primary",
    "technique",
    "similar",
    "logistic",
    "regression",
    "reason",
    "behind",
    "naming",
    "belongs",
    "general",
    "linear",
    "models",
    "belongs",
    "class",
    "linear",
    "regression",
    "reason",
    "behind",
    "name",
    "logistic",
    "regression",
    "logistic",
    "regression",
    "mainly",
    "used",
    "classification",
    "purpose",
    "predict",
    "dependent",
    "variable",
    "categorical",
    "nature",
    "mainly",
    "used",
    "classification",
    "define",
    "logistic",
    "regression",
    "logistic",
    "regression",
    "method",
    "used",
    "predict",
    "dependent",
    "variable",
    "given",
    "independent",
    "variable",
    "x",
    "dependent",
    "variable",
    "categorical",
    "meaning",
    "output",
    "categorical",
    "variable",
    "obviously",
    "classification",
    "algorithm",
    "guys",
    "clear",
    "confusion",
    "say",
    "categorical",
    "variable",
    "mean",
    "hold",
    "values",
    "like",
    "one",
    "zero",
    "yes",
    "true",
    "false",
    "basically",
    "logistic",
    "regression",
    "outcome",
    "always",
    "categorical",
    "logistic",
    "regression",
    "work",
    "guys",
    "tell",
    "logistic",
    "regression",
    "works",
    "take",
    "look",
    "graph",
    "told",
    "outcome",
    "logistic",
    "regression",
    "categorical",
    "outcome",
    "either",
    "zero",
    "one",
    "probability",
    "ranges",
    "zero",
    "one",
    "curve",
    "might",
    "think",
    "curve",
    "obviously",
    "straight",
    "line",
    "something",
    "known",
    "sigmoid",
    "curve",
    "values",
    "ranging",
    "zero",
    "one",
    "basically",
    "show",
    "probability",
    "maybe",
    "output",
    "probability",
    "value",
    "means",
    "outcome",
    "basically",
    "one",
    "sigmoid",
    "curve",
    "like",
    "okay",
    "explain",
    "depth",
    "order",
    "understand",
    "logistic",
    "regression",
    "works",
    "first",
    "let",
    "take",
    "look",
    "linear",
    "regression",
    "equation",
    "logistic",
    "regression",
    "equation",
    "discussed",
    "stands",
    "dependent",
    "variable",
    "needs",
    "predicted",
    "beta",
    "naught",
    "nothing",
    "intercept",
    "beta",
    "one",
    "nothing",
    "slope",
    "x",
    "represents",
    "independent",
    "variable",
    "used",
    "predict",
    "e",
    "denotes",
    "error",
    "computation",
    "given",
    "fact",
    "x",
    "independent",
    "variable",
    "dependent",
    "variable",
    "represent",
    "relationship",
    "x",
    "ranges",
    "zero",
    "one",
    "value",
    "basically",
    "denotes",
    "probably",
    "equal",
    "one",
    "given",
    "value",
    "pr",
    "denotes",
    "probability",
    "value",
    "basically",
    "denotes",
    "probability",
    "equal",
    "one",
    "given",
    "value",
    "x",
    "need",
    "find",
    "wanted",
    "calculate",
    "probability",
    "using",
    "linear",
    "regression",
    "model",
    "probability",
    "look",
    "something",
    "like",
    "p",
    "x",
    "equal",
    "beta",
    "naught",
    "plus",
    "beta",
    "one",
    "p",
    "x",
    "equal",
    "beta",
    "naught",
    "plus",
    "beta",
    "one",
    "x",
    "p",
    "x",
    "nothing",
    "probability",
    "getting",
    "equal",
    "one",
    "given",
    "value",
    "logistic",
    "regression",
    "equation",
    "derived",
    "equation",
    "except",
    "need",
    "make",
    "alterations",
    "output",
    "categorical",
    "logistic",
    "regression",
    "necessarily",
    "calculate",
    "outcome",
    "zero",
    "one",
    "mentioned",
    "instead",
    "calculates",
    "probability",
    "variable",
    "falling",
    "class",
    "zero",
    "class",
    "one",
    "conclude",
    "resulting",
    "variable",
    "must",
    "positive",
    "lie",
    "zero",
    "one",
    "means",
    "must",
    "less",
    "one",
    "meet",
    "conditions",
    "two",
    "things",
    "first",
    "take",
    "exponent",
    "equation",
    "taking",
    "exponential",
    "value",
    "make",
    "sure",
    "get",
    "positive",
    "number",
    "correct",
    "secondly",
    "make",
    "sure",
    "output",
    "less",
    "one",
    "number",
    "divided",
    "plus",
    "one",
    "always",
    "less",
    "one",
    "get",
    "formula",
    "first",
    "take",
    "exponent",
    "equation",
    "beta",
    "naught",
    "plus",
    "beta",
    "one",
    "plus",
    "x",
    "divide",
    "number",
    "plus",
    "one",
    "get",
    "formula",
    "next",
    "step",
    "calculate",
    "something",
    "known",
    "logic",
    "function",
    "logic",
    "function",
    "nothing",
    "link",
    "function",
    "represented",
    "curve",
    "sigmoid",
    "curve",
    "ranges",
    "value",
    "zero",
    "one",
    "basically",
    "calculates",
    "probability",
    "output",
    "variable",
    "look",
    "equation",
    "quite",
    "simple",
    "done",
    "cross",
    "multiply",
    "take",
    "beta",
    "naught",
    "plus",
    "beta",
    "one",
    "x",
    "common",
    "rhs",
    "denotes",
    "linear",
    "equation",
    "independent",
    "variables",
    "lhs",
    "represents",
    "odd",
    "ratio",
    "compute",
    "entire",
    "thing",
    "get",
    "final",
    "value",
    "basically",
    "logistic",
    "regression",
    "equation",
    "rhs",
    "denotes",
    "linear",
    "equation",
    "independent",
    "variables",
    "lhs",
    "represents",
    "odd",
    "ratio",
    "also",
    "known",
    "logic",
    "function",
    "told",
    "logic",
    "function",
    "basically",
    "function",
    "represents",
    "curve",
    "bring",
    "zero",
    "one",
    "make",
    "sure",
    "value",
    "ranges",
    "zero",
    "one",
    "logistic",
    "regression",
    "increasing",
    "x",
    "one",
    "measure",
    "changes",
    "logic",
    "factor",
    "beta",
    "naught",
    "thing",
    "showed",
    "logistic",
    "regression",
    "guys",
    "derive",
    "logistic",
    "regression",
    "equation",
    "doubts",
    "regarding",
    "equations",
    "please",
    "leave",
    "comment",
    "section",
    "get",
    "back",
    "clear",
    "sum",
    "logistic",
    "regression",
    "used",
    "classification",
    "output",
    "variable",
    "always",
    "categorical",
    "variable",
    "also",
    "saw",
    "derive",
    "logistic",
    "regression",
    "equation",
    "one",
    "important",
    "thing",
    "relationship",
    "variables",
    "logistic",
    "regression",
    "denoted",
    "curve",
    "also",
    "knows",
    "sigmoid",
    "curve",
    "also",
    "outcome",
    "necessarily",
    "calculated",
    "zero",
    "one",
    "calculate",
    "probability",
    "output",
    "lies",
    "class",
    "one",
    "class",
    "zero",
    "output",
    "probability",
    "ranging",
    "zero",
    "one",
    "sigmoid",
    "curve",
    "hope",
    "clear",
    "logistic",
    "regression",
    "wo",
    "showing",
    "demo",
    "right",
    "away",
    "explain",
    "couple",
    "classification",
    "algorithms",
    "show",
    "practical",
    "demo",
    "use",
    "multiple",
    "classification",
    "algorithms",
    "solve",
    "problem",
    "also",
    "calculate",
    "accuracy",
    "se",
    "classification",
    "algorithm",
    "best",
    "next",
    "algorithm",
    "gon",
    "na",
    "talk",
    "decision",
    "tree",
    "decision",
    "tree",
    "one",
    "favorite",
    "algorithms",
    "simple",
    "understand",
    "decision",
    "tree",
    "works",
    "guys",
    "discussed",
    "linear",
    "regression",
    "regression",
    "algorithm",
    "discussed",
    "logistic",
    "regression",
    "classification",
    "algorithm",
    "remember",
    "get",
    "confused",
    "name",
    "logistic",
    "regression",
    "okay",
    "classification",
    "algorithm",
    "discussing",
    "decision",
    "tree",
    "classification",
    "algorithm",
    "okay",
    "exactly",
    "decision",
    "tree",
    "decision",
    "tree",
    "supervised",
    "machine",
    "learning",
    "algorithm",
    "looks",
    "like",
    "inverted",
    "tree",
    "wherein",
    "node",
    "represents",
    "predictor",
    "variable",
    "link",
    "node",
    "represents",
    "decision",
    "leaf",
    "node",
    "represents",
    "outcome",
    "know",
    "little",
    "confusing",
    "let",
    "make",
    "understand",
    "decision",
    "tree",
    "help",
    "example",
    "let",
    "say",
    "hosted",
    "huge",
    "party",
    "want",
    "know",
    "many",
    "gusts",
    "solve",
    "problem",
    "create",
    "simple",
    "decision",
    "tree",
    "look",
    "figure",
    "created",
    "decision",
    "tree",
    "classifies",
    "guest",
    "either",
    "vegetarian",
    "last",
    "outcome",
    "veg",
    "understand",
    "classification",
    "algorithm",
    "predicting",
    "categorical",
    "value",
    "node",
    "represents",
    "predictor",
    "variable",
    "eat",
    "chicken",
    "one",
    "variable",
    "eat",
    "mutton",
    "one",
    "variable",
    "seafood",
    "another",
    "variable",
    "node",
    "represents",
    "predictor",
    "variable",
    "help",
    "conclude",
    "whether",
    "guest",
    "traverse",
    "tree",
    "make",
    "decisions",
    "node",
    "reach",
    "dead",
    "end",
    "okay",
    "works",
    "let",
    "say",
    "got",
    "new",
    "data",
    "point",
    "pass",
    "decision",
    "tree",
    "first",
    "variable",
    "guest",
    "eat",
    "chicken",
    "yes",
    "pass",
    "next",
    "variable",
    "guest",
    "eat",
    "mutton",
    "yes",
    "pass",
    "next",
    "variable",
    "seafood",
    "ate",
    "seafood",
    "vegetarian",
    "decision",
    "tree",
    "works",
    "simple",
    "algorithm",
    "easily",
    "understand",
    "drawn",
    "letters",
    "easy",
    "understand",
    "let",
    "understand",
    "structure",
    "decision",
    "tree",
    "showed",
    "example",
    "decision",
    "tree",
    "works",
    "let",
    "take",
    "example",
    "tell",
    "structure",
    "decision",
    "tree",
    "first",
    "something",
    "known",
    "root",
    "node",
    "okay",
    "root",
    "node",
    "starting",
    "point",
    "decision",
    "tree",
    "perform",
    "first",
    "split",
    "split",
    "two",
    "nodes",
    "three",
    "nodes",
    "depending",
    "problem",
    "statement",
    "top",
    "node",
    "known",
    "root",
    "node",
    "guys",
    "root",
    "node",
    "root",
    "node",
    "assigned",
    "variable",
    "significant",
    "meaning",
    "variable",
    "important",
    "predicting",
    "output",
    "okay",
    "assign",
    "variable",
    "think",
    "significant",
    "root",
    "node",
    "something",
    "known",
    "internal",
    "nodes",
    "internal",
    "node",
    "represents",
    "decision",
    "point",
    "eventually",
    "leads",
    "output",
    "internal",
    "nodes",
    "predictor",
    "variables",
    "nothing",
    "predictor",
    "variables",
    "made",
    "question",
    "otherwise",
    "predictor",
    "variables",
    "internal",
    "nodes",
    "terminal",
    "nodes",
    "also",
    "known",
    "leaf",
    "node",
    "represent",
    "final",
    "class",
    "output",
    "variable",
    "basically",
    "outcomes",
    "vegetarian",
    "branches",
    "nothing",
    "connections",
    "nodes",
    "okay",
    "connections",
    "links",
    "node",
    "known",
    "branch",
    "represented",
    "arrows",
    "branch",
    "response",
    "either",
    "yes",
    "true",
    "false",
    "one",
    "zero",
    "okay",
    "guys",
    "structure",
    "decision",
    "tree",
    "pretty",
    "understandable",
    "let",
    "move",
    "understand",
    "decision",
    "tree",
    "algorithm",
    "works",
    "many",
    "ways",
    "build",
    "decision",
    "tree",
    "focusing",
    "something",
    "known",
    "id3",
    "algorithm",
    "okay",
    "something",
    "known",
    "id3",
    "algorithm",
    "one",
    "ways",
    "build",
    "decision",
    "tree",
    "id3",
    "stands",
    "iterative",
    "dichotomiser",
    "3",
    "algorithm",
    "one",
    "effective",
    "algorithms",
    "used",
    "build",
    "decision",
    "tree",
    "uses",
    "concepts",
    "entropy",
    "information",
    "gain",
    "order",
    "build",
    "decision",
    "tree",
    "know",
    "exactly",
    "id3",
    "algorithm",
    "concept",
    "behind",
    "building",
    "decision",
    "tree",
    "id3",
    "algorithm",
    "around",
    "six",
    "defined",
    "steps",
    "order",
    "build",
    "decision",
    "tree",
    "first",
    "step",
    "select",
    "best",
    "attribute",
    "mean",
    "best",
    "attribute",
    "attribute",
    "nothing",
    "predictor",
    "variable",
    "select",
    "best",
    "predictor",
    "variable",
    "let",
    "call",
    "assign",
    "decision",
    "variable",
    "root",
    "node",
    "basically",
    "assign",
    "predictor",
    "variable",
    "root",
    "node",
    "next",
    "value",
    "build",
    "descendant",
    "node",
    "three",
    "steps",
    "let",
    "look",
    "previous",
    "example",
    "best",
    "attribute",
    "eat",
    "chicken",
    "okay",
    "best",
    "attribute",
    "variable",
    "selected",
    "attribute",
    "next",
    "step",
    "step",
    "two",
    "assigned",
    "decision",
    "variable",
    "assigned",
    "eat",
    "chick",
    "decision",
    "variable",
    "root",
    "node",
    "might",
    "wondering",
    "know",
    "best",
    "attribute",
    "explain",
    "assigned",
    "root",
    "node",
    "step",
    "number",
    "three",
    "says",
    "value",
    "build",
    "descendant",
    "node",
    "value",
    "variable",
    "build",
    "descendant",
    "node",
    "variable",
    "take",
    "two",
    "values",
    "yes",
    "values",
    "build",
    "descendant",
    "node",
    "step",
    "number",
    "four",
    "assign",
    "classification",
    "labels",
    "leaf",
    "node",
    "leaf",
    "node",
    "assigned",
    "classification",
    "one",
    "veg",
    "step",
    "number",
    "four",
    "step",
    "number",
    "five",
    "data",
    "correctly",
    "classified",
    "stop",
    "however",
    "keep",
    "iterating",
    "tree",
    "keep",
    "changing",
    "position",
    "predictor",
    "variables",
    "tree",
    "change",
    "root",
    "node",
    "also",
    "order",
    "get",
    "correct",
    "output",
    "let",
    "answer",
    "question",
    "best",
    "attribute",
    "mean",
    "best",
    "attribute",
    "best",
    "predictor",
    "variable",
    "best",
    "attribute",
    "one",
    "separates",
    "data",
    "different",
    "classes",
    "effectively",
    "basically",
    "feature",
    "best",
    "splits",
    "data",
    "set",
    "next",
    "question",
    "head",
    "must",
    "decide",
    "variable",
    "feature",
    "best",
    "splits",
    "data",
    "two",
    "important",
    "measures",
    "something",
    "known",
    "information",
    "gain",
    "something",
    "known",
    "entropy",
    "guys",
    "order",
    "understand",
    "information",
    "gain",
    "entropy",
    "look",
    "simple",
    "problem",
    "statement",
    "data",
    "represents",
    "speed",
    "car",
    "based",
    "certain",
    "parameters",
    "problem",
    "statement",
    "study",
    "data",
    "set",
    "create",
    "decision",
    "tree",
    "classifies",
    "speed",
    "car",
    "either",
    "slow",
    "fast",
    "predictor",
    "variables",
    "road",
    "type",
    "obstruction",
    "speed",
    "limit",
    "response",
    "variable",
    "output",
    "variable",
    "speed",
    "building",
    "decision",
    "tree",
    "using",
    "variables",
    "order",
    "predict",
    "speed",
    "car",
    "like",
    "mentioned",
    "earlier",
    "must",
    "first",
    "begin",
    "deciding",
    "variable",
    "best",
    "splits",
    "data",
    "set",
    "assign",
    "particular",
    "variable",
    "root",
    "node",
    "repeat",
    "thing",
    "nodes",
    "well",
    "step",
    "one",
    "like",
    "discussed",
    "earlier",
    "select",
    "best",
    "attribute",
    "know",
    "variable",
    "best",
    "separates",
    "data",
    "variable",
    "highest",
    "information",
    "gain",
    "best",
    "derives",
    "data",
    "desired",
    "output",
    "classes",
    "first",
    "calculate",
    "two",
    "measures",
    "calculate",
    "entropy",
    "information",
    "gain",
    "ell",
    "exactly",
    "entropy",
    "exactly",
    "information",
    "gain",
    "entropy",
    "basically",
    "used",
    "measure",
    "impurity",
    "uncertainty",
    "present",
    "data",
    "used",
    "decide",
    "decision",
    "tree",
    "split",
    "data",
    "information",
    "gain",
    "hand",
    "significant",
    "measure",
    "used",
    "build",
    "decision",
    "tree",
    "indicates",
    "much",
    "information",
    "particular",
    "variable",
    "gives",
    "us",
    "bout",
    "final",
    "outcome",
    "information",
    "gain",
    "important",
    "used",
    "choose",
    "variable",
    "best",
    "splits",
    "data",
    "node",
    "decision",
    "tree",
    "variable",
    "highest",
    "information",
    "gain",
    "used",
    "split",
    "data",
    "root",
    "node",
    "data",
    "set",
    "four",
    "observations",
    "gon",
    "na",
    "start",
    "calculating",
    "entropy",
    "information",
    "gain",
    "predictor",
    "variable",
    "gon",
    "na",
    "start",
    "calculating",
    "information",
    "gain",
    "entropy",
    "road",
    "type",
    "variable",
    "data",
    "set",
    "see",
    "four",
    "observations",
    "four",
    "observations",
    "road",
    "type",
    "column",
    "corresponds",
    "four",
    "labels",
    "speed",
    "column",
    "gon",
    "na",
    "begin",
    "calculating",
    "information",
    "gain",
    "parent",
    "node",
    "parent",
    "node",
    "nothing",
    "speed",
    "care",
    "node",
    "output",
    "variable",
    "correct",
    "used",
    "show",
    "whether",
    "speed",
    "car",
    "slow",
    "fast",
    "find",
    "information",
    "gain",
    "speed",
    "car",
    "variable",
    "go",
    "couple",
    "steps",
    "know",
    "four",
    "observations",
    "parent",
    "node",
    "first",
    "slow",
    "slow",
    "fast",
    "fast",
    "four",
    "observations",
    "two",
    "classes",
    "two",
    "observations",
    "belong",
    "class",
    "slow",
    "two",
    "observations",
    "belong",
    "class",
    "fast",
    "calculate",
    "p",
    "slow",
    "p",
    "fast",
    "p",
    "slow",
    "nothing",
    "fraction",
    "slow",
    "outcomes",
    "parent",
    "node",
    "p",
    "fast",
    "fraction",
    "fast",
    "outcomes",
    "parent",
    "node",
    "formula",
    "calculate",
    "p",
    "slow",
    "number",
    "slow",
    "outcomes",
    "parent",
    "node",
    "divided",
    "total",
    "number",
    "outcomes",
    "number",
    "slow",
    "outcomes",
    "parent",
    "node",
    "two",
    "total",
    "number",
    "outcomes",
    "four",
    "four",
    "observations",
    "total",
    "get",
    "p",
    "slow",
    "similarly",
    "p",
    "fast",
    "calculate",
    "number",
    "fast",
    "outcomes",
    "divided",
    "total",
    "number",
    "outcomes",
    "two",
    "four",
    "get",
    "next",
    "thing",
    "calculate",
    "entropy",
    "node",
    "calculate",
    "entropy",
    "formula",
    "substitute",
    "substitute",
    "value",
    "formula",
    "p",
    "slow",
    "substituting",
    "similarly",
    "p",
    "fast",
    "substitute",
    "value",
    "get",
    "answer",
    "one",
    "entropy",
    "parent",
    "node",
    "one",
    "calculating",
    "entropy",
    "parent",
    "node",
    "calculate",
    "information",
    "gain",
    "child",
    "node",
    "guys",
    "remember",
    "information",
    "gain",
    "road",
    "type",
    "variable",
    "great",
    "information",
    "gain",
    "predictor",
    "variables",
    "root",
    "node",
    "split",
    "using",
    "road",
    "type",
    "variable",
    "calculate",
    "information",
    "gain",
    "road",
    "type",
    "variable",
    "first",
    "need",
    "split",
    "root",
    "node",
    "sing",
    "road",
    "type",
    "variable",
    "order",
    "check",
    "road",
    "type",
    "variable",
    "giving",
    "us",
    "maximum",
    "information",
    "data",
    "okay",
    "notice",
    "road",
    "type",
    "two",
    "outcomes",
    "two",
    "values",
    "either",
    "steep",
    "flat",
    "go",
    "back",
    "data",
    "set",
    "notice",
    "whenever",
    "road",
    "type",
    "steep",
    "first",
    "check",
    "value",
    "speed",
    "get",
    "road",
    "type",
    "steep",
    "first",
    "observation",
    "see",
    "whenever",
    "road",
    "type",
    "steep",
    "getting",
    "speed",
    "slow",
    "similarly",
    "second",
    "observation",
    "road",
    "type",
    "steep",
    "get",
    "value",
    "slow",
    "road",
    "type",
    "flat",
    "get",
    "observation",
    "fast",
    "steep",
    "value",
    "fast",
    "three",
    "steep",
    "values",
    "slow",
    "slow",
    "fast",
    "road",
    "type",
    "flat",
    "get",
    "output",
    "fast",
    "exactly",
    "done",
    "decision",
    "tree",
    "whenever",
    "road",
    "type",
    "steep",
    "get",
    "slow",
    "slow",
    "fast",
    "whenever",
    "road",
    "type",
    "flat",
    "get",
    "fast",
    "entropy",
    "side",
    "zero",
    "entropy",
    "nothing",
    "uncertainty",
    "uncertainty",
    "soon",
    "see",
    "road",
    "type",
    "flat",
    "output",
    "fast",
    "uncertainty",
    "road",
    "type",
    "steep",
    "one",
    "following",
    "outcomes",
    "either",
    "speed",
    "slow",
    "fast",
    "start",
    "calculating",
    "entropy",
    "rhs",
    "lhs",
    "decision",
    "tree",
    "entropy",
    "right",
    "side",
    "child",
    "node",
    "zero",
    "uncertainty",
    "immediately",
    "see",
    "road",
    "type",
    "flat",
    "speed",
    "car",
    "fast",
    "okay",
    "uncertainty",
    "therefore",
    "entropy",
    "becomes",
    "zero",
    "entropy",
    "side",
    "calculate",
    "fraction",
    "p",
    "slow",
    "fraction",
    "p",
    "fast",
    "three",
    "observations",
    "two",
    "observations",
    "slow",
    "two",
    "three",
    "similarly",
    "p",
    "fast",
    "one",
    "p",
    "fast",
    "divided",
    "total",
    "number",
    "observation",
    "three",
    "three",
    "two",
    "slows",
    "one",
    "fast",
    "calculate",
    "p",
    "slow",
    "p",
    "fast",
    "get",
    "two",
    "values",
    "substitute",
    "entropy",
    "formula",
    "get",
    "entropy",
    "road",
    "type",
    "variable",
    "hope",
    "understanding",
    "go",
    "basically",
    "calculating",
    "information",
    "gain",
    "entropy",
    "road",
    "type",
    "variable",
    "whenever",
    "consider",
    "road",
    "type",
    "variable",
    "two",
    "values",
    "steep",
    "flat",
    "whenever",
    "value",
    "road",
    "type",
    "steep",
    "get",
    "anyone",
    "three",
    "outcomes",
    "either",
    "get",
    "slow",
    "slow",
    "fast",
    "road",
    "type",
    "flat",
    "outcome",
    "fast",
    "uncertainty",
    "whenever",
    "road",
    "type",
    "flat",
    "always",
    "get",
    "outcome",
    "fast",
    "means",
    "entropy",
    "zero",
    "uncertainty",
    "value",
    "zero",
    "lot",
    "uncertainty",
    "whenever",
    "road",
    "type",
    "steep",
    "output",
    "either",
    "slow",
    "fast",
    "finally",
    "get",
    "python",
    "order",
    "calculate",
    "information",
    "gain",
    "road",
    "type",
    "variable",
    "need",
    "calculate",
    "weighted",
    "average",
    "tell",
    "order",
    "calculate",
    "information",
    "gain",
    "need",
    "know",
    "entropy",
    "parent",
    "calculate",
    "one",
    "minus",
    "weighted",
    "average",
    "entropy",
    "children",
    "okay",
    "formula",
    "need",
    "calculate",
    "values",
    "first",
    "need",
    "calculate",
    "entropy",
    "weighted",
    "average",
    "total",
    "number",
    "outcomes",
    "parent",
    "node",
    "saw",
    "four",
    "total",
    "number",
    "outcomes",
    "left",
    "child",
    "node",
    "three",
    "total",
    "number",
    "outcomes",
    "right",
    "child",
    "node",
    "one",
    "correct",
    "order",
    "verify",
    "total",
    "number",
    "outcomes",
    "parent",
    "node",
    "four",
    "one",
    "two",
    "three",
    "four",
    "coming",
    "child",
    "node",
    "road",
    "type",
    "total",
    "number",
    "outcomes",
    "side",
    "child",
    "node",
    "one",
    "total",
    "number",
    "outcomes",
    "side",
    "child",
    "node",
    "three",
    "exactly",
    "written",
    "alright",
    "hope",
    "understood",
    "three",
    "values",
    "substitute",
    "values",
    "formula",
    "get",
    "entropy",
    "children",
    "weighted",
    "average",
    "around",
    "substitute",
    "value",
    "formula",
    "calculate",
    "information",
    "gain",
    "road",
    "type",
    "variable",
    "get",
    "value",
    "using",
    "method",
    "going",
    "calculate",
    "information",
    "gain",
    "predictor",
    "variable",
    "road",
    "type",
    "obstruction",
    "speed",
    "limit",
    "follow",
    "method",
    "calculate",
    "information",
    "gain",
    "get",
    "values",
    "information",
    "gain",
    "road",
    "type",
    "equal",
    "denote",
    "value",
    "road",
    "type",
    "denotes",
    "getting",
    "little",
    "information",
    "gain",
    "road",
    "type",
    "variable",
    "obstruction",
    "literally",
    "information",
    "gain",
    "zero",
    "similarly",
    "information",
    "gained",
    "speed",
    "limit",
    "one",
    "highest",
    "value",
    "got",
    "information",
    "gain",
    "means",
    "use",
    "speed",
    "limit",
    "variable",
    "root",
    "node",
    "order",
    "split",
    "data",
    "set",
    "guys",
    "get",
    "confused",
    "whichever",
    "variable",
    "gives",
    "maximum",
    "information",
    "gain",
    "variable",
    "chosen",
    "root",
    "node",
    "root",
    "node",
    "speed",
    "limit",
    "maintained",
    "speed",
    "limit",
    "going",
    "go",
    "slow",
    "maintained",
    "speed",
    "limit",
    "speed",
    "car",
    "going",
    "fast",
    "entropy",
    "literally",
    "zero",
    "information",
    "one",
    "meaning",
    "use",
    "variable",
    "root",
    "node",
    "order",
    "split",
    "data",
    "set",
    "speed",
    "limit",
    "gives",
    "maximum",
    "information",
    "gain",
    "guys",
    "hope",
    "use",
    "case",
    "clear",
    "sum",
    "everything",
    "repeat",
    "entire",
    "thing",
    "basically",
    "given",
    "problem",
    "statement",
    "order",
    "create",
    "decision",
    "tree",
    "classifies",
    "speed",
    "car",
    "either",
    "slow",
    "fast",
    "given",
    "three",
    "predictor",
    "variables",
    "output",
    "variable",
    "information",
    "gained",
    "entropy",
    "basically",
    "two",
    "measures",
    "used",
    "decide",
    "variable",
    "assigned",
    "root",
    "node",
    "decision",
    "tree",
    "okay",
    "guys",
    "soon",
    "look",
    "data",
    "set",
    "compare",
    "two",
    "columns",
    "speed",
    "limit",
    "speed",
    "get",
    "output",
    "easily",
    "meaning",
    "maintaining",
    "speed",
    "limit",
    "going",
    "go",
    "slow",
    "maintaining",
    "speed",
    "limit",
    "going",
    "fast",
    "understand",
    "speed",
    "limit",
    "uncertainty",
    "every",
    "time",
    "maintained",
    "speed",
    "limit",
    "going",
    "slow",
    "every",
    "time",
    "outside",
    "speed",
    "limit",
    "going",
    "fast",
    "simple",
    "start",
    "started",
    "calculating",
    "entropy",
    "parent",
    "node",
    "calculated",
    "entropy",
    "parent",
    "node",
    "came",
    "one",
    "okay",
    "calculated",
    "information",
    "gain",
    "child",
    "nodes",
    "order",
    "calculate",
    "information",
    "gain",
    "child",
    "node",
    "stat",
    "calculating",
    "entropy",
    "side",
    "side",
    "decision",
    "tree",
    "okay",
    "calculate",
    "entropy",
    "along",
    "weighted",
    "average",
    "substitute",
    "values",
    "information",
    "gain",
    "formula",
    "get",
    "information",
    "gain",
    "predictor",
    "variables",
    "get",
    "information",
    "gain",
    "predictor",
    "variables",
    "check",
    "variable",
    "gives",
    "maximum",
    "information",
    "gain",
    "assign",
    "variable",
    "root",
    "node",
    "simple",
    "guys",
    "decision",
    "trees",
    "let",
    "look",
    "next",
    "classification",
    "algorithm",
    "random",
    "forest",
    "first",
    "random",
    "forest",
    "random",
    "forest",
    "basically",
    "builds",
    "multiple",
    "decision",
    "trees",
    "glues",
    "together",
    "get",
    "accurate",
    "stable",
    "prediction",
    "already",
    "decision",
    "trees",
    "random",
    "forest",
    "nothing",
    "collection",
    "decision",
    "tree",
    "use",
    "random",
    "forest",
    "already",
    "decision",
    "tree",
    "three",
    "main",
    "reasons",
    "random",
    "forest",
    "used",
    "even",
    "though",
    "decision",
    "trees",
    "convenient",
    "easily",
    "implemented",
    "accurate",
    "random",
    "forest",
    "decision",
    "trees",
    "work",
    "effectively",
    "training",
    "data",
    "backup",
    "flexible",
    "comes",
    "classifying",
    "anew",
    "sample",
    "happens",
    "something",
    "known",
    "overfitting",
    "overfitting",
    "problem",
    "seen",
    "decision",
    "trees",
    "something",
    "commonly",
    "occurs",
    "use",
    "decision",
    "trees",
    "overfitting",
    "occurs",
    "model",
    "studies",
    "training",
    "data",
    "extent",
    "negatively",
    "influences",
    "performance",
    "model",
    "new",
    "data",
    "means",
    "disturbance",
    "training",
    "data",
    "recorded",
    "learned",
    "concept",
    "model",
    "disturbance",
    "thought",
    "noise",
    "training",
    "data",
    "error",
    "training",
    "data",
    "also",
    "studied",
    "model",
    "problem",
    "concepts",
    "apply",
    "testing",
    "data",
    "negatively",
    "impacts",
    "model",
    "ability",
    "classify",
    "new",
    "data",
    "sum",
    "overfitting",
    "occurs",
    "whenever",
    "model",
    "learns",
    "training",
    "data",
    "along",
    "disturbance",
    "training",
    "data",
    "basically",
    "memorized",
    "training",
    "data",
    "whenever",
    "new",
    "data",
    "given",
    "model",
    "predict",
    "outcome",
    "accurately",
    "problem",
    "seen",
    "decision",
    "trees",
    "okay",
    "random",
    "forest",
    "something",
    "known",
    "bagging",
    "basic",
    "idea",
    "behind",
    "bagging",
    "reduce",
    "variations",
    "predictions",
    "combining",
    "result",
    "multiple",
    "decision",
    "trees",
    "different",
    "samples",
    "data",
    "set",
    "data",
    "set",
    "divided",
    "different",
    "samples",
    "building",
    "decision",
    "tree",
    "samples",
    "way",
    "decision",
    "tree",
    "studying",
    "one",
    "subset",
    "data",
    "way",
    "fitting",
    "get",
    "reduced",
    "one",
    "decision",
    "tree",
    "studying",
    "entire",
    "data",
    "set",
    "let",
    "focus",
    "random",
    "forest",
    "order",
    "understand",
    "random",
    "forest",
    "look",
    "small",
    "example",
    "consider",
    "data",
    "set",
    "data",
    "four",
    "predictor",
    "variables",
    "blood",
    "flow",
    "blocked",
    "arteries",
    "chest",
    "pain",
    "weight",
    "variables",
    "used",
    "predict",
    "whether",
    "person",
    "heart",
    "disease",
    "going",
    "use",
    "data",
    "set",
    "create",
    "random",
    "forest",
    "predicts",
    "person",
    "heart",
    "disease",
    "first",
    "step",
    "creating",
    "random",
    "forest",
    "create",
    "bootstrap",
    "data",
    "set",
    "bootstrapping",
    "randomly",
    "select",
    "samples",
    "original",
    "data",
    "set",
    "okay",
    "point",
    "note",
    "select",
    "sample",
    "look",
    "original",
    "data",
    "set",
    "abnormal",
    "normal",
    "normal",
    "abnormal",
    "look",
    "blood",
    "flow",
    "section",
    "randomly",
    "selected",
    "samples",
    "normal",
    "abnormal",
    "selected",
    "one",
    "sample",
    "twice",
    "bootstrap",
    "data",
    "set",
    "created",
    "bootstrap",
    "data",
    "set",
    "boot",
    "strapping",
    "nothing",
    "estimation",
    "method",
    "used",
    "make",
    "predictions",
    "data",
    "data",
    "bootstrap",
    "data",
    "set",
    "even",
    "though",
    "seems",
    "simple",
    "real",
    "world",
    "problems",
    "never",
    "get",
    "small",
    "data",
    "set",
    "okay",
    "bootstrapping",
    "actually",
    "little",
    "complex",
    "usually",
    "real",
    "world",
    "problems",
    "huge",
    "data",
    "set",
    "bootstrapping",
    "data",
    "set",
    "actually",
    "pretty",
    "complex",
    "problem",
    "making",
    "understand",
    "random",
    "forest",
    "works",
    "considered",
    "small",
    "data",
    "set",
    "going",
    "use",
    "bootstrap",
    "data",
    "set",
    "created",
    "going",
    "build",
    "decision",
    "trees",
    "one",
    "thing",
    "note",
    "random",
    "forest",
    "using",
    "entire",
    "data",
    "set",
    "okay",
    "using",
    "variables",
    "node",
    "example",
    "consider",
    "two",
    "variables",
    "step",
    "begin",
    "root",
    "node",
    "randomly",
    "select",
    "two",
    "variables",
    "candidates",
    "root",
    "node",
    "okay",
    "let",
    "say",
    "selected",
    "blood",
    "flow",
    "blocked",
    "arteries",
    "two",
    "variables",
    "select",
    "variable",
    "best",
    "separates",
    "sample",
    "okay",
    "sake",
    "example",
    "let",
    "say",
    "blocked",
    "arteries",
    "significant",
    "predictor",
    "assign",
    "root",
    "node",
    "next",
    "step",
    "repeat",
    "process",
    "upcoming",
    "branch",
    "nodes",
    "select",
    "two",
    "variables",
    "random",
    "candidates",
    "branch",
    "nodes",
    "choose",
    "variable",
    "best",
    "separates",
    "samples",
    "right",
    "let",
    "repeat",
    "entire",
    "process",
    "know",
    "start",
    "creating",
    "decision",
    "tree",
    "selecting",
    "root",
    "node",
    "random",
    "forest",
    "randomly",
    "select",
    "couple",
    "variables",
    "node",
    "calculate",
    "variable",
    "best",
    "splits",
    "data",
    "node",
    "node",
    "randomly",
    "select",
    "two",
    "three",
    "variables",
    "two",
    "three",
    "variables",
    "see",
    "variable",
    "best",
    "separates",
    "data",
    "okay",
    "node",
    "calculating",
    "information",
    "gain",
    "entropy",
    "basically",
    "mean",
    "every",
    "node",
    "calculate",
    "information",
    "gain",
    "entropy",
    "two",
    "three",
    "variables",
    "see",
    "variable",
    "highest",
    "information",
    "gain",
    "keep",
    "descending",
    "downwards",
    "create",
    "decision",
    "tree",
    "created",
    "first",
    "decision",
    "tree",
    "go",
    "back",
    "step",
    "one",
    "repeat",
    "entire",
    "process",
    "decision",
    "tree",
    "predict",
    "output",
    "class",
    "based",
    "predictor",
    "variables",
    "assigned",
    "decision",
    "tree",
    "let",
    "say",
    "decision",
    "tree",
    "assigned",
    "blood",
    "flow",
    "blocked",
    "arteries",
    "root",
    "node",
    "might",
    "blood",
    "flow",
    "root",
    "node",
    "output",
    "depend",
    "predictor",
    "variable",
    "root",
    "node",
    "decision",
    "tree",
    "predict",
    "output",
    "class",
    "based",
    "predictor",
    "variable",
    "assigned",
    "tree",
    "go",
    "back",
    "step",
    "one",
    "create",
    "new",
    "bootstrap",
    "data",
    "set",
    "build",
    "new",
    "decision",
    "tree",
    "decision",
    "tree",
    "consider",
    "subset",
    "variables",
    "choose",
    "best",
    "predictor",
    "variable",
    "calculating",
    "information",
    "gain",
    "keep",
    "repeating",
    "process",
    "keep",
    "repeating",
    "step",
    "two",
    "step",
    "one",
    "okay",
    "keep",
    "creating",
    "multiple",
    "decision",
    "trees",
    "okay",
    "variety",
    "decision",
    "trees",
    "random",
    "forest",
    "makes",
    "effective",
    "individual",
    "decision",
    "tree",
    "instead",
    "individual",
    "decision",
    "tree",
    "created",
    "using",
    "features",
    "build",
    "random",
    "forest",
    "uses",
    "multiple",
    "decision",
    "trees",
    "wherein",
    "decision",
    "tree",
    "random",
    "set",
    "predictor",
    "variables",
    "step",
    "number",
    "four",
    "predicting",
    "outcome",
    "new",
    "data",
    "point",
    "created",
    "random",
    "forest",
    "let",
    "see",
    "used",
    "predict",
    "whether",
    "new",
    "patient",
    "heart",
    "disease",
    "okay",
    "diagram",
    "basically",
    "data",
    "new",
    "patient",
    "okay",
    "data",
    "new",
    "patient",
    "blocked",
    "arteries",
    "chest",
    "pain",
    "weight",
    "around",
    "185",
    "kgs",
    "run",
    "data",
    "decision",
    "trees",
    "made",
    "first",
    "decision",
    "tree",
    "shows",
    "yes",
    "person",
    "heart",
    "disease",
    "similarly",
    "run",
    "information",
    "new",
    "patient",
    "every",
    "decision",
    "tree",
    "created",
    "depending",
    "many",
    "votes",
    "get",
    "yes",
    "classify",
    "patient",
    "either",
    "heart",
    "disease",
    "run",
    "information",
    "new",
    "patient",
    "decision",
    "trees",
    "created",
    "previous",
    "step",
    "final",
    "output",
    "based",
    "number",
    "votes",
    "class",
    "getting",
    "okay",
    "let",
    "say",
    "three",
    "decision",
    "trees",
    "said",
    "yes",
    "patient",
    "heart",
    "disease",
    "one",
    "decision",
    "tree",
    "said",
    "means",
    "obviously",
    "classify",
    "patient",
    "heart",
    "disease",
    "three",
    "voted",
    "yes",
    "based",
    "majority",
    "guys",
    "hope",
    "concept",
    "behind",
    "random",
    "forest",
    "understandable",
    "next",
    "step",
    "evaluate",
    "efficiency",
    "model",
    "earlier",
    "created",
    "bootstrap",
    "data",
    "set",
    "left",
    "one",
    "entry",
    "sample",
    "entry",
    "sample",
    "left",
    "repeated",
    "one",
    "sample",
    "twice",
    "remember",
    "bootstrap",
    "data",
    "set",
    "repeated",
    "entry",
    "twice",
    "missed",
    "one",
    "entries",
    "missed",
    "one",
    "entries",
    "gon",
    "na",
    "evaluating",
    "model",
    "using",
    "data",
    "entry",
    "missed",
    "real",
    "world",
    "problem",
    "original",
    "data",
    "set",
    "included",
    "bootstrap",
    "dataset",
    "huge",
    "amount",
    "data",
    "real",
    "world",
    "problem",
    "original",
    "data",
    "set",
    "included",
    "bootstrap",
    "data",
    "set",
    "guys",
    "sample",
    "data",
    "set",
    "bootstrap",
    "data",
    "set",
    "known",
    "data",
    "set",
    "basically",
    "data",
    "set",
    "data",
    "set",
    "used",
    "check",
    "accuracy",
    "model",
    "model",
    "created",
    "using",
    "data",
    "set",
    "give",
    "us",
    "good",
    "understanding",
    "whether",
    "model",
    "effective",
    "data",
    "set",
    "nothing",
    "testing",
    "data",
    "set",
    "remember",
    "machine",
    "learning",
    "training",
    "testing",
    "data",
    "set",
    "data",
    "set",
    "nothing",
    "testing",
    "data",
    "set",
    "used",
    "evaluate",
    "efficiency",
    "model",
    "eventually",
    "measure",
    "accuracy",
    "random",
    "forest",
    "proportion",
    "samples",
    "correctly",
    "classified",
    "data",
    "set",
    "used",
    "evaluate",
    "efficiency",
    "model",
    "calculate",
    "accuracy",
    "understanding",
    "many",
    "samples",
    "data",
    "set",
    "correctly",
    "able",
    "classify",
    "guys",
    "explanation",
    "random",
    "forest",
    "works",
    "give",
    "overview",
    "let",
    "run",
    "steps",
    "took",
    "basically",
    "data",
    "set",
    "predict",
    "whether",
    "patient",
    "heart",
    "disease",
    "first",
    "step",
    "create",
    "bootstrap",
    "data",
    "set",
    "bootstrap",
    "data",
    "set",
    "nothing",
    "randomly",
    "selected",
    "observations",
    "original",
    "data",
    "set",
    "also",
    "duplicate",
    "values",
    "bootstrap",
    "data",
    "set",
    "okay",
    "next",
    "step",
    "going",
    "create",
    "decision",
    "tree",
    "considering",
    "random",
    "set",
    "predictor",
    "variables",
    "decision",
    "tree",
    "okay",
    "third",
    "step",
    "go",
    "back",
    "step",
    "one",
    "create",
    "bootstrap",
    "data",
    "set",
    "create",
    "decision",
    "tree",
    "iteration",
    "performed",
    "hundreds",
    "times",
    "multiple",
    "decision",
    "trees",
    "created",
    "random",
    "forest",
    "use",
    "random",
    "forest",
    "predict",
    "outcome",
    "given",
    "new",
    "data",
    "point",
    "classify",
    "one",
    "two",
    "classes",
    "run",
    "new",
    "information",
    "decision",
    "trees",
    "take",
    "majority",
    "output",
    "getting",
    "decision",
    "trees",
    "outcome",
    "order",
    "evaluate",
    "efficiency",
    "model",
    "use",
    "bag",
    "sample",
    "data",
    "set",
    "sample",
    "basically",
    "sample",
    "included",
    "bootstrap",
    "data",
    "set",
    "sample",
    "coming",
    "original",
    "data",
    "set",
    "guys",
    "something",
    "randomly",
    "create",
    "data",
    "set",
    "original",
    "data",
    "set",
    "mentioned",
    "bootstrap",
    "data",
    "set",
    "use",
    "sample",
    "order",
    "calculate",
    "accuracy",
    "random",
    "forest",
    "proportion",
    "samples",
    "correctly",
    "classified",
    "give",
    "accuracy",
    "model",
    "random",
    "forest",
    "guys",
    "discuss",
    "classification",
    "algorithms",
    "show",
    "demo",
    "classification",
    "algorithms",
    "next",
    "algorithm",
    "something",
    "known",
    "naive",
    "bayes",
    "naive",
    "bayes",
    "supervised",
    "classification",
    "algorithm",
    "based",
    "bayes",
    "theorem",
    "bayes",
    "theorem",
    "basically",
    "follows",
    "probabilistic",
    "approach",
    "main",
    "idea",
    "behind",
    "naive",
    "bayes",
    "predictor",
    "variables",
    "machine",
    "learning",
    "model",
    "independent",
    "meaning",
    "outcome",
    "model",
    "depends",
    "set",
    "independent",
    "variables",
    "nothing",
    "lot",
    "might",
    "ask",
    "naive",
    "bayes",
    "called",
    "naive",
    "usually",
    "tell",
    "anybody",
    "naive",
    "bayes",
    "keep",
    "asking",
    "naive",
    "bayes",
    "called",
    "naive",
    "real",
    "world",
    "problems",
    "predictor",
    "variables",
    "always",
    "independent",
    "always",
    "correlation",
    "independent",
    "variables",
    "naive",
    "bayes",
    "considers",
    "predictor",
    "variable",
    "independent",
    "variable",
    "model",
    "called",
    "naive",
    "assumption",
    "naive",
    "bayes",
    "states",
    "let",
    "understand",
    "math",
    "behind",
    "naive",
    "bayes",
    "algorithm",
    "like",
    "mentioned",
    "principle",
    "behind",
    "naive",
    "bayes",
    "bayes",
    "theorem",
    "also",
    "known",
    "bayes",
    "rule",
    "bayes",
    "theorem",
    "used",
    "calculate",
    "conditional",
    "probability",
    "nothing",
    "probability",
    "event",
    "occurring",
    "based",
    "information",
    "events",
    "past",
    "mathematical",
    "equation",
    "bayes",
    "theorem",
    "equation",
    "lhs",
    "nothing",
    "conditional",
    "probability",
    "event",
    "occurring",
    "given",
    "event",
    "p",
    "nothing",
    "probability",
    "event",
    "occurring",
    "p",
    "b",
    "probability",
    "event",
    "pb",
    "nothing",
    "conditional",
    "probability",
    "event",
    "b",
    "occurring",
    "given",
    "event",
    "let",
    "try",
    "understand",
    "naive",
    "bayes",
    "works",
    "consider",
    "data",
    "set",
    "around",
    "thousand",
    "500",
    "observations",
    "okay",
    "following",
    "output",
    "classes",
    "either",
    "cat",
    "parrot",
    "turtle",
    "output",
    "classes",
    "predictor",
    "variables",
    "swim",
    "wings",
    "green",
    "color",
    "sharp",
    "teeth",
    "okay",
    "basically",
    "type",
    "output",
    "variable",
    "swim",
    "wings",
    "green",
    "sharp",
    "teeth",
    "predictor",
    "variables",
    "output",
    "variables",
    "three",
    "classes",
    "cat",
    "parrot",
    "turtle",
    "okay",
    "summarized",
    "table",
    "shown",
    "screen",
    "first",
    "thing",
    "see",
    "class",
    "type",
    "cats",
    "shows",
    "500",
    "cats",
    "450",
    "swim",
    "meaning",
    "90",
    "zero",
    "number",
    "cats",
    "wings",
    "zero",
    "number",
    "cats",
    "green",
    "color",
    "500",
    "500",
    "cats",
    "sharp",
    "teeth",
    "okay",
    "coming",
    "parrot",
    "says",
    "50",
    "500",
    "parrots",
    "true",
    "value",
    "swim",
    "guys",
    "obviously",
    "hold",
    "true",
    "real",
    "world",
    "think",
    "parrots",
    "swim",
    "created",
    "data",
    "set",
    "understand",
    "naive",
    "bayes",
    "meaning",
    "10",
    "parrots",
    "true",
    "value",
    "swim",
    "500",
    "parrots",
    "wings",
    "400",
    "500",
    "parrots",
    "green",
    "color",
    "zero",
    "parrots",
    "sharp",
    "teeth",
    "coming",
    "turtle",
    "class",
    "500",
    "turtles",
    "swim",
    "zero",
    "number",
    "turtles",
    "wings",
    "500",
    "hundred",
    "turtles",
    "green",
    "color",
    "meaning",
    "20",
    "turtles",
    "green",
    "color",
    "50",
    "500",
    "turtles",
    "sharp",
    "teeth",
    "understand",
    "data",
    "set",
    "problem",
    "given",
    "observation",
    "given",
    "value",
    "swim",
    "wings",
    "green",
    "sharp",
    "teeth",
    "need",
    "need",
    "predict",
    "whether",
    "animal",
    "cat",
    "parrot",
    "turtle",
    "based",
    "values",
    "goal",
    "predict",
    "whether",
    "cat",
    "parrot",
    "turtle",
    "based",
    "defined",
    "parameters",
    "okay",
    "based",
    "value",
    "swim",
    "wings",
    "green",
    "sharp",
    "teeth",
    "understand",
    "whether",
    "animal",
    "cat",
    "parrot",
    "turtle",
    "look",
    "observation",
    "variables",
    "swim",
    "green",
    "value",
    "true",
    "outcome",
    "anyone",
    "types",
    "either",
    "cat",
    "parrot",
    "turtle",
    "order",
    "check",
    "animal",
    "cat",
    "calculate",
    "conditional",
    "probability",
    "step",
    "need",
    "calculate",
    "probability",
    "cat",
    "given",
    "swim",
    "green",
    "color",
    "first",
    "calculate",
    "probability",
    "swim",
    "given",
    "cat",
    "two",
    "probability",
    "green",
    "probability",
    "green",
    "given",
    "cat",
    "multiply",
    "probability",
    "cat",
    "divided",
    "probability",
    "swim",
    "green",
    "okay",
    "guys",
    "know",
    "calculate",
    "probability",
    "quite",
    "simple",
    "calculate",
    "probability",
    "get",
    "direct",
    "value",
    "zero",
    "okay",
    "get",
    "value",
    "zero",
    "meaning",
    "animal",
    "definitely",
    "cat",
    "similarly",
    "parrots",
    "calculate",
    "conditional",
    "probability",
    "get",
    "value",
    "divided",
    "probability",
    "swim",
    "comma",
    "green",
    "know",
    "probability",
    "similarly",
    "check",
    "turtle",
    "get",
    "probability",
    "divided",
    "p",
    "swim",
    "comma",
    "green",
    "okay",
    "calculations",
    "denominator",
    "value",
    "denominator",
    "value",
    "probability",
    "turtle",
    "greater",
    "parrot",
    "correctly",
    "predict",
    "animal",
    "actually",
    "turtle",
    "guys",
    "naive",
    "bayes",
    "works",
    "basically",
    "calculate",
    "conditional",
    "probability",
    "step",
    "whatever",
    "classification",
    "needs",
    "done",
    "calculated",
    "probability",
    "lot",
    "statistic",
    "comes",
    "naive",
    "bayes",
    "want",
    "learn",
    "statistics",
    "probability",
    "leave",
    "link",
    "description",
    "watch",
    "video",
    "well",
    "explain",
    "exactly",
    "conditional",
    "probability",
    "bayes",
    "theorem",
    "also",
    "explained",
    "well",
    "check",
    "video",
    "also",
    "apart",
    "doubts",
    "regarding",
    "algorithms",
    "please",
    "leave",
    "comment",
    "section",
    "okay",
    "solve",
    "doubts",
    "apart",
    "also",
    "leave",
    "couple",
    "links",
    "algorithms",
    "description",
    "box",
    "want",
    "understanding",
    "algorithms",
    "check",
    "content",
    "since",
    "full",
    "course",
    "video",
    "cover",
    "topics",
    "hard",
    "make",
    "understand",
    "topic",
    "leave",
    "couple",
    "links",
    "description",
    "box",
    "watch",
    "videos",
    "well",
    "make",
    "sure",
    "checkout",
    "probability",
    "statistics",
    "video",
    "let",
    "move",
    "locate",
    "next",
    "algorithm",
    "k",
    "nearest",
    "neighbor",
    "algorithm",
    "knn",
    "basically",
    "stands",
    "k",
    "nearest",
    "neighbor",
    "supervised",
    "classification",
    "algorithm",
    "classifies",
    "new",
    "data",
    "point",
    "target",
    "class",
    "output",
    "class",
    "depending",
    "features",
    "neighboring",
    "data",
    "points",
    "called",
    "k",
    "nearest",
    "neighbor",
    "let",
    "try",
    "understand",
    "knn",
    "small",
    "analogy",
    "okay",
    "let",
    "say",
    "want",
    "machine",
    "distinguish",
    "images",
    "cats",
    "dogs",
    "must",
    "input",
    "data",
    "set",
    "cat",
    "dog",
    "images",
    "train",
    "model",
    "detect",
    "animal",
    "based",
    "certain",
    "features",
    "example",
    "features",
    "pointy",
    "ears",
    "used",
    "identify",
    "cats",
    "similarly",
    "identify",
    "dogs",
    "based",
    "long",
    "ears",
    "starting",
    "data",
    "set",
    "training",
    "phase",
    "new",
    "image",
    "given",
    "model",
    "knn",
    "algorithm",
    "classify",
    "either",
    "cats",
    "dogs",
    "depending",
    "similarity",
    "features",
    "okay",
    "let",
    "say",
    "new",
    "image",
    "pointy",
    "ears",
    "classify",
    "image",
    "cat",
    "similar",
    "cat",
    "images",
    "similar",
    "neighbors",
    "manner",
    "knn",
    "algorithm",
    "classifies",
    "data",
    "point",
    "based",
    "similar",
    "neighboring",
    "data",
    "points",
    "small",
    "example",
    "discuss",
    "slides",
    "let",
    "tell",
    "couple",
    "features",
    "knn",
    "algorithm",
    "first",
    "know",
    "supervised",
    "learning",
    "algorithm",
    "uses",
    "labeled",
    "input",
    "data",
    "set",
    "predict",
    "output",
    "data",
    "points",
    "also",
    "one",
    "simplest",
    "machine",
    "learning",
    "algorithms",
    "easily",
    "implemented",
    "varied",
    "set",
    "problems",
    "another",
    "feature",
    "meaning",
    "take",
    "assumptions",
    "example",
    "naive",
    "bayes",
    "parametric",
    "model",
    "assumes",
    "independent",
    "variables",
    "way",
    "related",
    "assumptions",
    "model",
    "k",
    "nearest",
    "neighbor",
    "assumptions",
    "considered",
    "model",
    "another",
    "feature",
    "lazy",
    "algorithm",
    "lazy",
    "algorithm",
    "basically",
    "algorithm",
    "memorizes",
    "training",
    "set",
    "instead",
    "learning",
    "discriminative",
    "function",
    "training",
    "data",
    "even",
    "though",
    "knn",
    "mainly",
    "classification",
    "algorithm",
    "also",
    "used",
    "regression",
    "cases",
    "knn",
    "actually",
    "classification",
    "regression",
    "algorithm",
    "mostly",
    "see",
    "used",
    "four",
    "classification",
    "problems",
    "important",
    "feature",
    "k",
    "nearest",
    "neighbor",
    "based",
    "feature",
    "similarity",
    "neighboring",
    "data",
    "points",
    "understand",
    "example",
    "gon",
    "na",
    "tell",
    "image",
    "two",
    "classes",
    "data",
    "class",
    "squares",
    "class",
    "b",
    "triangles",
    "problem",
    "statement",
    "assign",
    "new",
    "input",
    "data",
    "point",
    "one",
    "two",
    "classes",
    "using",
    "knn",
    "algorithm",
    "first",
    "step",
    "knn",
    "algorithm",
    "define",
    "value",
    "k",
    "knn",
    "algorithm",
    "stand",
    "k",
    "stands",
    "number",
    "nearest",
    "neighbors",
    "got",
    "name",
    "k",
    "nearest",
    "neighbors",
    "image",
    "defined",
    "value",
    "k",
    "three",
    "means",
    "algorithm",
    "consider",
    "three",
    "neighbors",
    "closest",
    "new",
    "data",
    "point",
    "order",
    "decide",
    "class",
    "new",
    "data",
    "point",
    "closest",
    "data",
    "point",
    "calculated",
    "using",
    "measure",
    "euclidean",
    "distance",
    "manhattan",
    "distance",
    "explaining",
    "k",
    "equal",
    "three",
    "neighbors",
    "include",
    "two",
    "squares",
    "one",
    "triangle",
    "classify",
    "new",
    "data",
    "point",
    "based",
    "k",
    "equal",
    "three",
    "assigned",
    "class",
    "correct",
    "assigned",
    "squares",
    "k",
    "value",
    "set",
    "seven",
    "basically",
    "telling",
    "algorithm",
    "look",
    "seven",
    "nearest",
    "neighbors",
    "classify",
    "new",
    "data",
    "point",
    "class",
    "similar",
    "k",
    "equal",
    "seven",
    "neighbors",
    "include",
    "three",
    "squares",
    "four",
    "triangles",
    "classify",
    "new",
    "data",
    "point",
    "based",
    "k",
    "equal",
    "seven",
    "would",
    "assigned",
    "class",
    "b",
    "since",
    "majority",
    "neighbors",
    "class",
    "lot",
    "us",
    "get",
    "confused",
    "know",
    "k",
    "values",
    "suitable",
    "k",
    "nearest",
    "neighbor",
    "couple",
    "methods",
    "used",
    "calculate",
    "k",
    "value",
    "one",
    "known",
    "elbow",
    "method",
    "discussing",
    "elbow",
    "method",
    "upcoming",
    "slides",
    "let",
    "show",
    "measures",
    "involved",
    "behind",
    "knn",
    "okay",
    "simple",
    "math",
    "behind",
    "k",
    "nearest",
    "neighbor",
    "algorithm",
    "discussing",
    "euclidean",
    "distance",
    "figure",
    "measure",
    "distance",
    "p",
    "one",
    "p",
    "two",
    "using",
    "euclidean",
    "distance",
    "sure",
    "lot",
    "already",
    "know",
    "euclidean",
    "distance",
    "something",
    "learned",
    "eighth",
    "10th",
    "grade",
    "sure",
    "extracting",
    "x",
    "one",
    "formula",
    "basically",
    "x",
    "two",
    "minus",
    "x",
    "one",
    "whole",
    "square",
    "plus",
    "two",
    "minus",
    "one",
    "whole",
    "square",
    "root",
    "euclidean",
    "distance",
    "simple",
    "euclidean",
    "distance",
    "used",
    "measure",
    "check",
    "closeness",
    "data",
    "points",
    "basically",
    "knn",
    "uses",
    "euclidean",
    "distance",
    "check",
    "closeness",
    "new",
    "data",
    "point",
    "neighbors",
    "guys",
    "simple",
    "knn",
    "makes",
    "use",
    "simple",
    "measures",
    "order",
    "solve",
    "complex",
    "problems",
    "okay",
    "one",
    "reasons",
    "knn",
    "commonly",
    "used",
    "algorithm",
    "coming",
    "support",
    "vector",
    "machine",
    "last",
    "algorithm",
    "classification",
    "algorithms",
    "guys",
    "get",
    "paranoid",
    "name",
    "support",
    "vector",
    "machine",
    "actually",
    "one",
    "simplest",
    "algorithms",
    "supervised",
    "learning",
    "okay",
    "basically",
    "used",
    "classify",
    "data",
    "different",
    "classes",
    "classification",
    "algorithm",
    "unlike",
    "algorithms",
    "svm",
    "makes",
    "use",
    "something",
    "known",
    "hyperplane",
    "acts",
    "like",
    "decision",
    "boundary",
    "separate",
    "classes",
    "okay",
    "svm",
    "used",
    "generate",
    "multiple",
    "separating",
    "hyperplane",
    "data",
    "divided",
    "segments",
    "segment",
    "contains",
    "one",
    "kind",
    "data",
    "features",
    "svm",
    "include",
    "supervised",
    "learning",
    "algorithm",
    "meaning",
    "going",
    "study",
    "labeled",
    "training",
    "data",
    "another",
    "feature",
    "regression",
    "classification",
    "algorithm",
    "even",
    "though",
    "svm",
    "mainly",
    "used",
    "classification",
    "something",
    "known",
    "support",
    "vector",
    "regressor",
    "useful",
    "regression",
    "problems",
    "svm",
    "also",
    "used",
    "classify",
    "data",
    "using",
    "kernel",
    "tricks",
    "data",
    "basically",
    "data",
    "separated",
    "using",
    "single",
    "linear",
    "line",
    "talking",
    "upcoming",
    "slides",
    "let",
    "move",
    "discuss",
    "svm",
    "works",
    "order",
    "make",
    "understand",
    "support",
    "vector",
    "machine",
    "works",
    "look",
    "small",
    "scenario",
    "second",
    "pretend",
    "farm",
    "problem",
    "need",
    "set",
    "fence",
    "protect",
    "rabbits",
    "pack",
    "wolves",
    "okay",
    "need",
    "decide",
    "want",
    "build",
    "fence",
    "one",
    "way",
    "solve",
    "problem",
    "using",
    "support",
    "vector",
    "machines",
    "try",
    "draw",
    "decision",
    "boundary",
    "rabbits",
    "wolves",
    "looks",
    "something",
    "like",
    "clearly",
    "build",
    "fence",
    "along",
    "line",
    "simple",
    "terms",
    "exactly",
    "support",
    "vector",
    "machines",
    "work",
    "draws",
    "decision",
    "boundary",
    "nothing",
    "hyperplane",
    "two",
    "classes",
    "order",
    "separate",
    "classify",
    "know",
    "thinking",
    "know",
    "draw",
    "hyperplane",
    "basic",
    "principle",
    "behind",
    "svm",
    "draw",
    "hyperplane",
    "best",
    "separates",
    "two",
    "classes",
    "case",
    "two",
    "classes",
    "rabbits",
    "wolves",
    "move",
    "let",
    "discuss",
    "different",
    "terminologies",
    "support",
    "vector",
    "machine",
    "basically",
    "hyperplane",
    "decision",
    "boundary",
    "best",
    "separates",
    "two",
    "classes",
    "support",
    "vectors",
    "exactly",
    "support",
    "vectors",
    "start",
    "support",
    "vector",
    "machine",
    "start",
    "drawing",
    "random",
    "hyperplane",
    "check",
    "distance",
    "hyperplane",
    "closest",
    "data",
    "point",
    "class",
    "closest",
    "data",
    "points",
    "hyperplane",
    "known",
    "support",
    "vectors",
    "two",
    "data",
    "points",
    "closest",
    "hyperplane",
    "known",
    "support",
    "vectors",
    "name",
    "comes",
    "support",
    "vector",
    "machines",
    "hyperplane",
    "drawn",
    "based",
    "support",
    "vectors",
    "optimum",
    "hyperplane",
    "one",
    "maximum",
    "distance",
    "support",
    "vectors",
    "meaning",
    "distance",
    "hyperplane",
    "support",
    "vectors",
    "maximum",
    "sum",
    "svm",
    "used",
    "classify",
    "data",
    "using",
    "hyperplane",
    "distance",
    "hyperplane",
    "support",
    "vector",
    "maximum",
    "distance",
    "nothing",
    "margin",
    "let",
    "try",
    "solve",
    "problem",
    "let",
    "say",
    "input",
    "new",
    "data",
    "point",
    "want",
    "draw",
    "hyperplane",
    "best",
    "separates",
    "two",
    "classes",
    "start",
    "drawing",
    "hyperplane",
    "check",
    "distance",
    "hyperplane",
    "support",
    "vectors",
    "basically",
    "trying",
    "check",
    "margin",
    "maximum",
    "hyperplane",
    "drew",
    "hyperplane",
    "like",
    "margin",
    "hyperplane",
    "clearly",
    "previous",
    "one",
    "optimal",
    "hyperplane",
    "exactly",
    "understand",
    "hyperplane",
    "needs",
    "chosen",
    "draw",
    "multiple",
    "hyperplanes",
    "best",
    "hyperplane",
    "one",
    "maximum",
    "module",
    "optimal",
    "hyperplane",
    "far",
    "quite",
    "easy",
    "data",
    "linearly",
    "separable",
    "means",
    "could",
    "draw",
    "straight",
    "line",
    "separate",
    "two",
    "classes",
    "data",
    "looks",
    "like",
    "possibly",
    "draw",
    "hyperplane",
    "like",
    "possibly",
    "draw",
    "hyperplane",
    "like",
    "separate",
    "two",
    "classes",
    "clearly",
    "see",
    "rabbits",
    "wolves",
    "classes",
    "exactly",
    "svm",
    "comes",
    "picture",
    "okay",
    "kernel",
    "trick",
    "kernel",
    "basically",
    "something",
    "used",
    "transform",
    "data",
    "another",
    "dimension",
    "clear",
    "dividing",
    "margin",
    "classes",
    "data",
    "basically",
    "kernel",
    "function",
    "offers",
    "user",
    "option",
    "transforming",
    "spaces",
    "linear",
    "ones",
    "point",
    "notice",
    "plotting",
    "data",
    "two",
    "dimensional",
    "space",
    "x",
    "simple",
    "trick",
    "transforming",
    "two",
    "variables",
    "x",
    "new",
    "feature",
    "space",
    "involves",
    "new",
    "variable",
    "basically",
    "visualizing",
    "data",
    "three",
    "dimensional",
    "space",
    "transform",
    "2d",
    "space",
    "3d",
    "space",
    "clearly",
    "see",
    "dividing",
    "margin",
    "two",
    "classes",
    "data",
    "clearly",
    "draw",
    "line",
    "middle",
    "separates",
    "two",
    "data",
    "sets",
    "guys",
    "sums",
    "whole",
    "idea",
    "behind",
    "support",
    "vector",
    "machines",
    "support",
    "vector",
    "machines",
    "easy",
    "understand",
    "supervised",
    "learning",
    "algorithms",
    "move",
    "unsupervised",
    "learning",
    "algorithms",
    "running",
    "demo",
    "running",
    "demo",
    "order",
    "understand",
    "classification",
    "algorithms",
    "studied",
    "far",
    "earlier",
    "session",
    "ran",
    "demo",
    "regression",
    "algorithms",
    "run",
    "classification",
    "algorithms",
    "enough",
    "theory",
    "let",
    "open",
    "python",
    "let",
    "start",
    "looking",
    "classification",
    "algorithms",
    "work",
    "implement",
    "multiple",
    "classification",
    "algorithms",
    "using",
    "okay",
    "one",
    "popular",
    "machine",
    "learning",
    "tool",
    "python",
    "using",
    "simple",
    "data",
    "set",
    "task",
    "training",
    "classifier",
    "distinguish",
    "different",
    "types",
    "fruits",
    "purpose",
    "demo",
    "implement",
    "multiple",
    "classification",
    "algorithms",
    "set",
    "problem",
    "usual",
    "start",
    "importing",
    "libraries",
    "python",
    "guys",
    "know",
    "python",
    "check",
    "description",
    "box",
    "leave",
    "link",
    "go",
    "video",
    "well",
    "next",
    "reading",
    "fruit",
    "data",
    "form",
    "table",
    "stored",
    "variable",
    "called",
    "fruits",
    "wan",
    "na",
    "see",
    "first",
    "rows",
    "data",
    "let",
    "print",
    "first",
    "observations",
    "data",
    "set",
    "data",
    "set",
    "fruit",
    "labels",
    "around",
    "four",
    "fruits",
    "data",
    "set",
    "apple",
    "mandarin",
    "orange",
    "lemon",
    "okay",
    "fruit",
    "label",
    "denotes",
    "nothing",
    "label",
    "apple",
    "one",
    "mandarin",
    "two",
    "similarly",
    "orange",
    "labeled",
    "three",
    "lemon",
    "labeled",
    "four",
    "fruit",
    "subtype",
    "basically",
    "family",
    "fruit",
    "belongs",
    "mass",
    "mass",
    "fruit",
    "width",
    "height",
    "color",
    "score",
    "predictor",
    "variables",
    "identify",
    "type",
    "fruit",
    "depending",
    "predictor",
    "variables",
    "first",
    "saw",
    "couple",
    "observations",
    "next",
    "want",
    "see",
    "shape",
    "data",
    "set",
    "looks",
    "like",
    "around",
    "59",
    "observations",
    "seven",
    "predictor",
    "variables",
    "one",
    "two",
    "three",
    "four",
    "five",
    "six",
    "seven",
    "seven",
    "variables",
    "total",
    "sorry",
    "predictor",
    "variables",
    "seven",
    "denotes",
    "predictor",
    "target",
    "variable",
    "next",
    "showing",
    "four",
    "fruits",
    "data",
    "set",
    "apple",
    "mandarin",
    "orange",
    "lemon",
    "next",
    "grouping",
    "fruits",
    "names",
    "okay",
    "19",
    "apples",
    "data",
    "set",
    "16",
    "lemons",
    "five",
    "mandarins",
    "19",
    "oranges",
    "even",
    "though",
    "number",
    "mandarin",
    "samples",
    "low",
    "work",
    "right",
    "trying",
    "make",
    "understand",
    "classification",
    "algorithms",
    "main",
    "aim",
    "behind",
    "demos",
    "understand",
    "classification",
    "algorithms",
    "work",
    "also",
    "plot",
    "graph",
    "order",
    "see",
    "frequency",
    "fruits",
    "okay",
    "show",
    "plot",
    "looks",
    "like",
    "number",
    "apples",
    "oranges",
    "think",
    "around",
    "19",
    "apples",
    "oranges",
    "similarly",
    "count",
    "lemons",
    "okay",
    "small",
    "visualization",
    "guys",
    "visualization",
    "actually",
    "important",
    "comes",
    "machine",
    "learning",
    "see",
    "relations",
    "correlations",
    "plotting",
    "graphs",
    "ca",
    "see",
    "correlations",
    "running",
    "code",
    "plot",
    "different",
    "variables",
    "graph",
    "understand",
    "related",
    "one",
    "main",
    "task",
    "machine",
    "learning",
    "visualize",
    "data",
    "ensures",
    "understand",
    "correlation",
    "data",
    "next",
    "gon",
    "na",
    "graph",
    "something",
    "known",
    "box",
    "plot",
    "okay",
    "box",
    "plot",
    "basically",
    "helps",
    "understand",
    "distribution",
    "data",
    "let",
    "run",
    "box",
    "plot",
    "show",
    "exactly",
    "mean",
    "box",
    "plot",
    "box",
    "plot",
    "basically",
    "give",
    "clearer",
    "idea",
    "distribution",
    "input",
    "variables",
    "mainly",
    "used",
    "exploratory",
    "data",
    "analysis",
    "represents",
    "distribution",
    "data",
    "variability",
    "box",
    "plot",
    "contains",
    "upper",
    "quartile",
    "lower",
    "quartile",
    "box",
    "plot",
    "basically",
    "spanned",
    "interquartile",
    "range",
    "something",
    "known",
    "iqr",
    "iqr",
    "nothing",
    "third",
    "quartile",
    "subtracted",
    "first",
    "quartile",
    "involves",
    "statistics",
    "probability",
    "leaving",
    "link",
    "description",
    "box",
    "go",
    "video",
    "explained",
    "statistics",
    "probability",
    "iqr",
    "range",
    "one",
    "main",
    "reasons",
    "box",
    "plots",
    "used",
    "detect",
    "sort",
    "outliers",
    "data",
    "since",
    "box",
    "plot",
    "spans",
    "iqr",
    "detects",
    "data",
    "point",
    "lie",
    "outside",
    "average",
    "range",
    "see",
    "colored",
    "space",
    "data",
    "distributed",
    "around",
    "iqr",
    "whereas",
    "data",
    "well",
    "distributed",
    "height",
    "also",
    "well",
    "distributed",
    "color",
    "space",
    "pretty",
    "well",
    "distributed",
    "box",
    "plot",
    "shows",
    "guys",
    "involves",
    "lot",
    "math",
    "every",
    "function",
    "machine",
    "learning",
    "involves",
    "lot",
    "math",
    "know",
    "necessary",
    "good",
    "understanding",
    "statistics",
    "probability",
    "next",
    "plot",
    "histogram",
    "histogram",
    "basically",
    "show",
    "frequency",
    "occurrence",
    "let",
    "plot",
    "try",
    "understand",
    "understand",
    "correlations",
    "okay",
    "pairs",
    "attributes",
    "correlated",
    "example",
    "mass",
    "width",
    "somehow",
    "correlated",
    "along",
    "ranges",
    "suggests",
    "high",
    "correlation",
    "predictable",
    "relationship",
    "like",
    "look",
    "graphs",
    "quite",
    "similar",
    "predictor",
    "variables",
    "drawn",
    "histogram",
    "input",
    "data",
    "drawn",
    "histogram",
    "guys",
    "like",
    "said",
    "plotting",
    "graphs",
    "important",
    "understand",
    "lot",
    "correlations",
    "understand",
    "looking",
    "data",
    "running",
    "operations",
    "data",
    "repeat",
    "running",
    "code",
    "data",
    "okay",
    "next",
    "dividing",
    "data",
    "set",
    "target",
    "predictor",
    "variables",
    "basically",
    "created",
    "array",
    "feature",
    "names",
    "predictor",
    "variables",
    "mass",
    "width",
    "height",
    "color",
    "space",
    "assigned",
    "x",
    "since",
    "input",
    "output",
    "fruit",
    "label",
    "show",
    "whether",
    "apple",
    "orange",
    "lemon",
    "next",
    "step",
    "perform",
    "pretty",
    "evident",
    "data",
    "splicing",
    "data",
    "splicing",
    "sure",
    "know",
    "splitting",
    "data",
    "training",
    "testing",
    "data",
    "done",
    "next",
    "importing",
    "something",
    "known",
    "minmaxscaler",
    "scaling",
    "normalizing",
    "data",
    "important",
    "machine",
    "learning",
    "seeing",
    "raw",
    "data",
    "biased",
    "important",
    "normalize",
    "data",
    "say",
    "normalize",
    "data",
    "look",
    "value",
    "mass",
    "look",
    "value",
    "height",
    "color",
    "see",
    "mass",
    "ranging",
    "hundreds",
    "double",
    "digits",
    "whereas",
    "height",
    "single",
    "digit",
    "color",
    "score",
    "even",
    "single",
    "digits",
    "variables",
    "high",
    "range",
    "know",
    "high",
    "scale",
    "like",
    "two",
    "digits",
    "three",
    "digits",
    "whereas",
    "variables",
    "single",
    "digits",
    "lesser",
    "output",
    "going",
    "biased",
    "obvious",
    "gon",
    "na",
    "biased",
    "scale",
    "data",
    "way",
    "values",
    "similar",
    "range",
    "exactly",
    "scaler",
    "function",
    "okay",
    "since",
    "already",
    "divided",
    "data",
    "training",
    "testing",
    "data",
    "next",
    "step",
    "build",
    "model",
    "first",
    "gon",
    "na",
    "using",
    "logistic",
    "regression",
    "algorithm",
    "already",
    "discussed",
    "logistic",
    "regression",
    "classification",
    "algorithm",
    "basically",
    "used",
    "predict",
    "outcome",
    "categorical",
    "variable",
    "already",
    "logistic",
    "regression",
    "class",
    "python",
    "give",
    "instance",
    "function",
    "logreg",
    "fitting",
    "instance",
    "training",
    "data",
    "set",
    "meaning",
    "running",
    "algorithm",
    "training",
    "data",
    "set",
    "calculate",
    "accuracy",
    "using",
    "function",
    "calculate",
    "accuracy",
    "training",
    "data",
    "set",
    "testing",
    "data",
    "set",
    "okay",
    "let",
    "look",
    "output",
    "guys",
    "ignore",
    "future",
    "warning",
    "warnings",
    "ignored",
    "python",
    "accuracy",
    "logistic",
    "regression",
    "classifier",
    "training",
    "data",
    "set",
    "around",
    "70",
    "pretty",
    "good",
    "training",
    "data",
    "set",
    "comes",
    "classifying",
    "test",
    "data",
    "set",
    "40",
    "good",
    "classifier",
    "depend",
    "problem",
    "statement",
    "problem",
    "statement",
    "logistic",
    "regression",
    "suitable",
    "next",
    "thing",
    "using",
    "decision",
    "tree",
    "call",
    "decision",
    "tree",
    "function",
    "fit",
    "training",
    "data",
    "set",
    "calculate",
    "accuracy",
    "decision",
    "tree",
    "training",
    "testing",
    "data",
    "set",
    "decision",
    "tree",
    "training",
    "data",
    "set",
    "get",
    "100",
    "accuracy",
    "testing",
    "data",
    "set",
    "around",
    "87",
    "accuracy",
    "something",
    "discussed",
    "earlier",
    "decision",
    "trees",
    "good",
    "training",
    "data",
    "set",
    "process",
    "known",
    "overfitting",
    "comes",
    "classifying",
    "outcome",
    "testing",
    "data",
    "set",
    "accuracy",
    "reduces",
    "good",
    "compared",
    "logistic",
    "regression",
    "problem",
    "statement",
    "decision",
    "trees",
    "works",
    "better",
    "logistic",
    "regression",
    "coming",
    "knn",
    "classifier",
    "call",
    "k",
    "neighbor",
    "classifier",
    "function",
    "fit",
    "training",
    "data",
    "set",
    "calculate",
    "accuracy",
    "knn",
    "classifier",
    "get",
    "good",
    "accuracy",
    "actually",
    "training",
    "data",
    "set",
    "get",
    "accuracy",
    "95",
    "testing",
    "data",
    "set",
    "100",
    "really",
    "good",
    "testing",
    "data",
    "set",
    "actually",
    "achieved",
    "accuracy",
    "training",
    "data",
    "set",
    "depends",
    "value",
    "k",
    "chosen",
    "knn",
    "mentioned",
    "use",
    "elbow",
    "method",
    "choose",
    "k",
    "value",
    "k",
    "nearest",
    "neighbor",
    "discussing",
    "elbow",
    "method",
    "next",
    "section",
    "worry",
    "understood",
    "yet",
    "also",
    "using",
    "naive",
    "bayes",
    "classifier",
    "using",
    "gaussian",
    "naive",
    "bayes",
    "classifier",
    "gaussian",
    "basically",
    "type",
    "naive",
    "bayes",
    "classifier",
    "going",
    "go",
    "depth",
    "extend",
    "session",
    "much",
    "longer",
    "okay",
    "want",
    "know",
    "leave",
    "link",
    "description",
    "box",
    "read",
    "caution",
    "naive",
    "bayes",
    "classifier",
    "math",
    "behind",
    "uses",
    "naive",
    "bayes",
    "uses",
    "bayes",
    "theorem",
    "gon",
    "na",
    "call",
    "class",
    "going",
    "run",
    "data",
    "training",
    "data",
    "using",
    "naive",
    "bayes",
    "classifier",
    "getting",
    "accuracy",
    "training",
    "data",
    "set",
    "testing",
    "data",
    "set",
    "getting",
    "67",
    "accuracy",
    "okay",
    "let",
    "thing",
    "support",
    "vector",
    "machines",
    "importing",
    "support",
    "vector",
    "classifier",
    "fitting",
    "training",
    "data",
    "algorithm",
    "getting",
    "accuracy",
    "around",
    "61",
    "training",
    "data",
    "set",
    "33",
    "testing",
    "data",
    "set",
    "guys",
    "accuracy",
    "depends",
    "also",
    "problem",
    "statement",
    "depends",
    "type",
    "data",
    "support",
    "vector",
    "machines",
    "get",
    "usually",
    "svm",
    "good",
    "large",
    "data",
    "sets",
    "since",
    "small",
    "data",
    "set",
    "sort",
    "obvious",
    "accuracy",
    "less",
    "guys",
    "couple",
    "classification",
    "algorithms",
    "showed",
    "knn",
    "classifier",
    "classified",
    "data",
    "set",
    "accurately",
    "look",
    "predictions",
    "knn",
    "classifier",
    "mean",
    "okay",
    "storing",
    "predicted",
    "values",
    "predict",
    "variable",
    "order",
    "show",
    "accuracy",
    "knn",
    "model",
    "going",
    "us",
    "something",
    "known",
    "confusion",
    "matrix",
    "confusion",
    "matrix",
    "table",
    "often",
    "used",
    "describe",
    "performance",
    "classification",
    "model",
    "confusion",
    "matrix",
    "actually",
    "represents",
    "tabular",
    "representation",
    "actual",
    "versus",
    "predicted",
    "values",
    "draw",
    "confusion",
    "matrix",
    "actual",
    "versus",
    "predicted",
    "values",
    "knn",
    "classifier",
    "confusion",
    "matrix",
    "looks",
    "like",
    "four",
    "rows",
    "see",
    "four",
    "rows",
    "first",
    "row",
    "represents",
    "apples",
    "second",
    "mandarin",
    "third",
    "represents",
    "lemons",
    "fourth",
    "oranges",
    "four",
    "value",
    "corresponds",
    "zero",
    "comma",
    "zero",
    "meaning",
    "correctly",
    "able",
    "classify",
    "four",
    "apples",
    "okay",
    "one",
    "value",
    "represents",
    "one",
    "comma",
    "one",
    "meaning",
    "classifier",
    "correctly",
    "classified",
    "mandarins",
    "matrix",
    "drawn",
    "actual",
    "values",
    "versus",
    "predicted",
    "values",
    "look",
    "summary",
    "confusion",
    "matrix",
    "get",
    "something",
    "known",
    "precision",
    "recall",
    "support",
    "precision",
    "basically",
    "ratio",
    "correctly",
    "predicted",
    "positive",
    "observations",
    "total",
    "predicted",
    "positive",
    "observations",
    "correctly",
    "predicted",
    "positive",
    "observations",
    "four",
    "total",
    "four",
    "apples",
    "testing",
    "data",
    "set",
    "get",
    "precision",
    "one",
    "okay",
    "recall",
    "hand",
    "ratio",
    "correctly",
    "predicted",
    "positive",
    "observations",
    "observations",
    "class",
    "correctly",
    "classified",
    "four",
    "apples",
    "total",
    "four",
    "apples",
    "nothing",
    "weighted",
    "average",
    "precision",
    "recall",
    "okay",
    "support",
    "basically",
    "denotes",
    "number",
    "data",
    "points",
    "correctly",
    "classified",
    "knn",
    "algorithm",
    "since",
    "got",
    "100",
    "accuracy",
    "data",
    "points",
    "correctly",
    "classified",
    "15",
    "15",
    "correctly",
    "classified",
    "100",
    "accuracy",
    "read",
    "confusion",
    "matrix",
    "okay",
    "four",
    "important",
    "measures",
    "precision",
    "recall",
    "support",
    "ratio",
    "weighted",
    "average",
    "precision",
    "recall",
    "precision",
    "basically",
    "correctly",
    "predicted",
    "positive",
    "observations",
    "total",
    "predicted",
    "positive",
    "observations",
    "recall",
    "ratio",
    "predicted",
    "positive",
    "observations",
    "observations",
    "guys",
    "demo",
    "classification",
    "algorithms",
    "discuss",
    "regression",
    "algorithms",
    "discussed",
    "classification",
    "algorithms",
    "time",
    "talk",
    "unsupervised",
    "learning",
    "algorithms",
    "unsupervised",
    "learning",
    "algorithms",
    "may",
    "try",
    "solve",
    "clustering",
    "problems",
    "important",
    "clustering",
    "algorithm",
    "known",
    "clustering",
    "going",
    "discuss",
    "algorithm",
    "also",
    "show",
    "demo",
    "executing",
    "clustering",
    "algorithm",
    "seeing",
    "implemented",
    "solve",
    "problem",
    "main",
    "aim",
    "algorithm",
    "group",
    "similar",
    "elements",
    "data",
    "points",
    "cluster",
    "basically",
    "process",
    "objects",
    "classified",
    "interest",
    "predefined",
    "number",
    "groups",
    "much",
    "dissimilar",
    "possible",
    "one",
    "group",
    "another",
    "group",
    "much",
    "similar",
    "possible",
    "within",
    "group",
    "mean",
    "let",
    "say",
    "trying",
    "cluster",
    "population",
    "four",
    "different",
    "groups",
    "group",
    "people",
    "within",
    "specified",
    "range",
    "age",
    "let",
    "say",
    "group",
    "one",
    "people",
    "age",
    "18",
    "similarly",
    "group",
    "two",
    "23",
    "group",
    "three",
    "36",
    "39",
    "something",
    "like",
    "let",
    "say",
    "trying",
    "cluster",
    "people",
    "different",
    "groups",
    "based",
    "age",
    "problems",
    "make",
    "use",
    "clustering",
    "algorithm",
    "one",
    "major",
    "applications",
    "clustering",
    "algorithm",
    "seen",
    "targeted",
    "marketing",
    "know",
    "many",
    "aware",
    "targeted",
    "marketing",
    "targeted",
    "marketing",
    "marketing",
    "specific",
    "product",
    "specific",
    "audience",
    "let",
    "say",
    "trying",
    "sell",
    "fancy",
    "clothes",
    "fancy",
    "set",
    "bags",
    "perfect",
    "audience",
    "product",
    "would",
    "teenagers",
    "would",
    "people",
    "around",
    "age",
    "16",
    "21",
    "target",
    "marketing",
    "product",
    "marketed",
    "specific",
    "audience",
    "might",
    "interested",
    "targeted",
    "marketing",
    "k",
    "means",
    "clustering",
    "use",
    "majorly",
    "targeted",
    "marketing",
    "lot",
    "ecommerce",
    "websites",
    "like",
    "amazon",
    "flipkart",
    "ebay",
    "make",
    "use",
    "clustering",
    "algorithms",
    "order",
    "target",
    "right",
    "audience",
    "let",
    "see",
    "clustering",
    "works",
    "k",
    "denotes",
    "number",
    "clusters",
    "let",
    "say",
    "give",
    "data",
    "set",
    "containing",
    "20",
    "points",
    "want",
    "cluster",
    "data",
    "set",
    "four",
    "clusters",
    "means",
    "k",
    "equal",
    "four",
    "k",
    "basically",
    "stands",
    "number",
    "clusters",
    "data",
    "set",
    "number",
    "clusters",
    "want",
    "form",
    "start",
    "defining",
    "number",
    "clusters",
    "going",
    "choose",
    "centroid",
    "every",
    "cluster",
    "four",
    "cluster",
    "data",
    "set",
    "clusters",
    "randomly",
    "select",
    "one",
    "data",
    "points",
    "centroid",
    "start",
    "computing",
    "distance",
    "centroid",
    "every",
    "point",
    "cluster",
    "keep",
    "computing",
    "centroid",
    "distance",
    "centroid",
    "data",
    "points",
    "cluster",
    "centroid",
    "keep",
    "shifting",
    "trying",
    "get",
    "average",
    "cluster",
    "whenever",
    "trying",
    "get",
    "average",
    "cluster",
    "centroid",
    "keeps",
    "shifting",
    "centroid",
    "keeps",
    "converging",
    "keeps",
    "shifting",
    "let",
    "try",
    "understand",
    "works",
    "let",
    "say",
    "data",
    "set",
    "given",
    "us",
    "let",
    "say",
    "given",
    "random",
    "points",
    "like",
    "asked",
    "us",
    "algorithm",
    "first",
    "step",
    "decide",
    "number",
    "clusters",
    "want",
    "create",
    "let",
    "say",
    "wan",
    "na",
    "create",
    "three",
    "different",
    "clusters",
    "k",
    "value",
    "equal",
    "three",
    "next",
    "step",
    "provide",
    "centroids",
    "clusters",
    "initially",
    "randomly",
    "pick",
    "three",
    "data",
    "points",
    "centroids",
    "three",
    "different",
    "clusters",
    "basically",
    "red",
    "denotes",
    "centroid",
    "one",
    "cluster",
    "blue",
    "denotes",
    "centroid",
    "another",
    "cluster",
    "green",
    "dot",
    "denotes",
    "centroid",
    "another",
    "cluster",
    "happens",
    "algorithm",
    "calculate",
    "euclidean",
    "distance",
    "points",
    "centroid",
    "assign",
    "points",
    "closest",
    "cluster",
    "since",
    "three",
    "centroids",
    "gon",
    "na",
    "going",
    "calculate",
    "distance",
    "every",
    "data",
    "point",
    "centroids",
    "going",
    "check",
    "data",
    "point",
    "closest",
    "centroid",
    "let",
    "say",
    "data",
    "point",
    "closest",
    "blue",
    "centroid",
    "going",
    "assign",
    "data",
    "point",
    "blue",
    "cluster",
    "based",
    "distance",
    "centroid",
    "cluster",
    "going",
    "form",
    "three",
    "different",
    "clusters",
    "going",
    "calculate",
    "centroid",
    "going",
    "form",
    "new",
    "cluster",
    "better",
    "clusters",
    "recomputing",
    "centroids",
    "basically",
    "centroids",
    "represent",
    "mean",
    "cluster",
    "need",
    "make",
    "sure",
    "mean",
    "actually",
    "centroid",
    "cluster",
    "keep",
    "recomputing",
    "centroids",
    "position",
    "centroid",
    "change",
    "means",
    "centroid",
    "actually",
    "main",
    "average",
    "particular",
    "cluster",
    "works",
    "simple",
    "start",
    "defining",
    "k",
    "value",
    "randomly",
    "pick",
    "number",
    "case",
    "centroids",
    "going",
    "calculate",
    "average",
    "distance",
    "data",
    "points",
    "centroids",
    "going",
    "assign",
    "data",
    "point",
    "centroid",
    "closest",
    "works",
    "simple",
    "process",
    "us",
    "keep",
    "iterating",
    "recompute",
    "centroid",
    "value",
    "centroid",
    "value",
    "change",
    "get",
    "constant",
    "centroid",
    "value",
    "guys",
    "make",
    "use",
    "distance",
    "measures",
    "like",
    "euclidean",
    "already",
    "discussed",
    "euclidean",
    "summarize",
    "works",
    "start",
    "picking",
    "number",
    "clusters",
    "pick",
    "centroid",
    "calculate",
    "distance",
    "objects",
    "centroid",
    "group",
    "data",
    "points",
    "specific",
    "clusters",
    "based",
    "distance",
    "keep",
    "computing",
    "centroid",
    "data",
    "point",
    "assigned",
    "closest",
    "cluster",
    "works",
    "let",
    "look",
    "elbow",
    "method",
    "elbow",
    "method",
    "basically",
    "used",
    "order",
    "find",
    "optimum",
    "k",
    "value",
    "particular",
    "problem",
    "elbow",
    "method",
    "quite",
    "simple",
    "actually",
    "start",
    "computing",
    "sum",
    "squared",
    "errors",
    "values",
    "sum",
    "squared",
    "error",
    "basically",
    "sum",
    "squared",
    "distance",
    "member",
    "cluster",
    "centroid",
    "basically",
    "calculate",
    "sum",
    "squared",
    "errors",
    "different",
    "values",
    "example",
    "consider",
    "k",
    "value",
    "two",
    "four",
    "six",
    "eight",
    "10",
    "consider",
    "values",
    "compute",
    "sum",
    "squared",
    "errors",
    "values",
    "plot",
    "k",
    "value",
    "sum",
    "squared",
    "errors",
    "see",
    "error",
    "decreases",
    "k",
    "gets",
    "larger",
    "number",
    "clusters",
    "increase",
    "number",
    "clusters",
    "increases",
    "means",
    "distortion",
    "gets",
    "smaller",
    "distortion",
    "keeps",
    "decreasing",
    "number",
    "clusters",
    "increase",
    "clusters",
    "closer",
    "centroid",
    "data",
    "points",
    "keep",
    "increasing",
    "number",
    "clusters",
    "distortion",
    "also",
    "decrease",
    "idea",
    "elbow",
    "method",
    "choose",
    "k",
    "distortion",
    "decreases",
    "abruptly",
    "look",
    "graph",
    "k",
    "equal",
    "four",
    "distortion",
    "abruptly",
    "decreasing",
    "find",
    "value",
    "distortion",
    "drops",
    "abruptly",
    "optimal",
    "k",
    "value",
    "choosing",
    "problem",
    "statement",
    "let",
    "repeat",
    "idea",
    "behind",
    "elbow",
    "method",
    "going",
    "graph",
    "number",
    "clusters",
    "versus",
    "squared",
    "sum",
    "errors",
    "graph",
    "basically",
    "give",
    "distortion",
    "distortion",
    "obviously",
    "going",
    "decrease",
    "increase",
    "number",
    "clusters",
    "gon",
    "na",
    "one",
    "point",
    "graph",
    "wherein",
    "distortion",
    "decreases",
    "abruptly",
    "point",
    "need",
    "find",
    "value",
    "k",
    "optimal",
    "k",
    "value",
    "choose",
    "k",
    "value",
    "knn",
    "k",
    "value",
    "well",
    "guys",
    "elbow",
    "method",
    "simple",
    "easily",
    "implemented",
    "gon",
    "na",
    "look",
    "small",
    "demo",
    "involves",
    "actually",
    "interesting",
    "demo",
    "guys",
    "one",
    "interesting",
    "application",
    "clustering",
    "color",
    "compression",
    "images",
    "example",
    "imagine",
    "image",
    "millions",
    "colors",
    "images",
    "large",
    "number",
    "colors",
    "unused",
    "many",
    "pixels",
    "image",
    "similar",
    "even",
    "identical",
    "colors",
    "many",
    "colors",
    "image",
    "makes",
    "hard",
    "image",
    "processing",
    "image",
    "analysis",
    "one",
    "area",
    "applied",
    "often",
    "applied",
    "image",
    "segmentation",
    "image",
    "analysis",
    "image",
    "compression",
    "gon",
    "na",
    "demo",
    "going",
    "use",
    "image",
    "data",
    "set",
    "okay",
    "prebuilt",
    "image",
    "require",
    "install",
    "pillow",
    "package",
    "going",
    "use",
    "image",
    "form",
    "data",
    "set",
    "module",
    "begin",
    "importing",
    "libraries",
    "usual",
    "loading",
    "image",
    "china",
    "image",
    "loading",
    "variable",
    "called",
    "china",
    "wan",
    "na",
    "look",
    "shape",
    "image",
    "run",
    "command",
    "gon",
    "na",
    "get",
    "value",
    "getting",
    "427",
    "comma",
    "640",
    "comma",
    "three",
    "basically",
    "three",
    "dimensional",
    "array",
    "size",
    "height",
    "width",
    "rgb",
    "contains",
    "red",
    "blue",
    "green",
    "contributions",
    "integers",
    "zero",
    "pixel",
    "values",
    "range",
    "zero",
    "255",
    "think",
    "zero",
    "stands",
    "black",
    "255",
    "represents",
    "white",
    "wrong",
    "basically",
    "array",
    "shape",
    "denotes",
    "one",
    "way",
    "view",
    "set",
    "pixels",
    "cloud",
    "points",
    "three",
    "dimensional",
    "color",
    "space",
    "reshape",
    "data",
    "rescale",
    "color",
    "lie",
    "zero",
    "one",
    "output",
    "two",
    "dimensional",
    "array",
    "basically",
    "visualize",
    "pixels",
    "color",
    "space",
    "gon",
    "na",
    "gon",
    "na",
    "try",
    "plot",
    "pixels",
    "really",
    "huge",
    "data",
    "set",
    "contains",
    "around",
    "16",
    "million",
    "possible",
    "colors",
    "denotes",
    "large",
    "data",
    "set",
    "let",
    "show",
    "looks",
    "like",
    "red",
    "green",
    "red",
    "blue",
    "rgb",
    "value",
    "around",
    "16",
    "million",
    "possible",
    "combination",
    "colors",
    "data",
    "set",
    "way",
    "large",
    "us",
    "compute",
    "reduce",
    "16",
    "million",
    "colors",
    "16",
    "colors",
    "using",
    "clustering",
    "cluster",
    "similar",
    "colors",
    "similar",
    "groups",
    "exactly",
    "importing",
    "one",
    "thing",
    "note",
    "dealing",
    "large",
    "data",
    "set",
    "use",
    "minibatchkmeans",
    "operates",
    "subsets",
    "data",
    "compute",
    "results",
    "quickly",
    "accurately",
    "like",
    "algorithm",
    "told",
    "data",
    "set",
    "really",
    "huge",
    "even",
    "though",
    "single",
    "image",
    "number",
    "pixel",
    "combinations",
    "come",
    "16",
    "million",
    "lot",
    "pixel",
    "considered",
    "data",
    "point",
    "taken",
    "image",
    "consideration",
    "data",
    "points",
    "data",
    "values",
    "different",
    "starting",
    "image",
    "image",
    "classification",
    "image",
    "segmentation",
    "every",
    "pixel",
    "considered",
    "basically",
    "building",
    "matrices",
    "pixel",
    "values",
    "16",
    "million",
    "pixels",
    "huge",
    "data",
    "set",
    "reason",
    "using",
    "minibatchkmeans",
    "similar",
    "difference",
    "operate",
    "subsets",
    "data",
    "data",
    "set",
    "huge",
    "operate",
    "subsets",
    "basically",
    "making",
    "use",
    "order",
    "cluster",
    "16",
    "million",
    "color",
    "combinations",
    "16",
    "colors",
    "basically",
    "gon",
    "na",
    "form",
    "16",
    "clusters",
    "data",
    "set",
    "result",
    "recoloring",
    "original",
    "pixel",
    "every",
    "pixel",
    "assigned",
    "color",
    "closest",
    "cluster",
    "center",
    "let",
    "say",
    "couple",
    "colors",
    "close",
    "green",
    "going",
    "cluster",
    "similar",
    "colors",
    "one",
    "cluster",
    "keep",
    "get",
    "16",
    "clusters",
    "obviously",
    "using",
    "clustering",
    "method",
    "let",
    "show",
    "output",
    "looks",
    "like",
    "basically",
    "original",
    "image",
    "scikit",
    "data",
    "set",
    "segmented",
    "image",
    "basically",
    "16",
    "colors",
    "around",
    "16",
    "million",
    "colors",
    "16",
    "colors",
    "ca",
    "also",
    "see",
    "particular",
    "colors",
    "obviously",
    "lot",
    "distortion",
    "study",
    "image",
    "remove",
    "extra",
    "contrast",
    "image",
    "try",
    "reduce",
    "pixel",
    "smaller",
    "set",
    "data",
    "possible",
    "varied",
    "pixels",
    "harder",
    "going",
    "study",
    "image",
    "analysis",
    "obviously",
    "details",
    "lost",
    "overall",
    "image",
    "still",
    "recognizable",
    "basically",
    "compressed",
    "compression",
    "factor",
    "around",
    "one",
    "million",
    "cluster",
    "around",
    "one",
    "million",
    "data",
    "points",
    "pixel",
    "values",
    "pixels",
    "interesting",
    "application",
    "actually",
    "better",
    "ways",
    "compress",
    "information",
    "image",
    "basically",
    "showed",
    "example",
    "want",
    "understand",
    "power",
    "algorithm",
    "cluster",
    "data",
    "set",
    "huge",
    "16",
    "colors",
    "initially",
    "16",
    "million",
    "cluster",
    "16",
    "colors",
    "guys",
    "plays",
    "huge",
    "role",
    "computer",
    "vision",
    "image",
    "processing",
    "object",
    "detection",
    "important",
    "algorithm",
    "comes",
    "detecting",
    "objects",
    "cars",
    "make",
    "use",
    "algorithms",
    "guys",
    "unsupervised",
    "learning",
    "supervised",
    "learning",
    "last",
    "type",
    "machine",
    "learning",
    "reinforcement",
    "learning",
    "actually",
    "interesting",
    "part",
    "machine",
    "learning",
    "quite",
    "difference",
    "supervised",
    "unsupervised",
    "discussing",
    "concepts",
    "involved",
    "reinforcement",
    "learning",
    "also",
    "reinforcement",
    "learning",
    "little",
    "advanced",
    "say",
    "advanced",
    "mean",
    "used",
    "applications",
    "cars",
    "also",
    "part",
    "lot",
    "deep",
    "learning",
    "applications",
    "alphago",
    "reinforcement",
    "learning",
    "different",
    "concept",
    "discussing",
    "concepts",
    "brush",
    "information",
    "reinforcement",
    "learning",
    "reinforcement",
    "learning",
    "part",
    "machine",
    "learning",
    "agent",
    "put",
    "unknown",
    "environment",
    "learns",
    "behave",
    "environment",
    "performing",
    "certain",
    "actions",
    "observing",
    "rewards",
    "gets",
    "actions",
    "reinforcement",
    "learning",
    "taking",
    "appropriate",
    "action",
    "order",
    "maximize",
    "reward",
    "particular",
    "situation",
    "let",
    "understand",
    "reinforcement",
    "learning",
    "analogy",
    "let",
    "consider",
    "scenario",
    "wherein",
    "baby",
    "learning",
    "walk",
    "scenario",
    "go",
    "two",
    "different",
    "ways",
    "first",
    "baby",
    "starts",
    "walking",
    "makes",
    "candy",
    "since",
    "candy",
    "end",
    "goal",
    "baby",
    "happy",
    "positive",
    "meaning",
    "baby",
    "happy",
    "received",
    "positive",
    "reward",
    "second",
    "way",
    "go",
    "baby",
    "starts",
    "walking",
    "falls",
    "due",
    "hurdle",
    "really",
    "cute",
    "baby",
    "gets",
    "hurt",
    "get",
    "candy",
    "negative",
    "baby",
    "sad",
    "receives",
    "negative",
    "reward",
    "like",
    "humans",
    "learn",
    "mistakes",
    "trial",
    "error",
    "reinforcement",
    "learning",
    "also",
    "similar",
    "agent",
    "case",
    "agent",
    "baby",
    "reward",
    "candy",
    "many",
    "hurdles",
    "agent",
    "supposed",
    "find",
    "best",
    "possible",
    "path",
    "reach",
    "reward",
    "main",
    "goal",
    "reinforcement",
    "learning",
    "reinforcement",
    "learning",
    "process",
    "two",
    "important",
    "components",
    "something",
    "known",
    "agent",
    "something",
    "known",
    "environment",
    "environment",
    "setting",
    "agent",
    "acting",
    "agent",
    "represents",
    "reinforcement",
    "learning",
    "algorithm",
    "whole",
    "reinforcement",
    "learning",
    "basically",
    "agent",
    "environment",
    "setting",
    "place",
    "agent",
    "setting",
    "wherein",
    "agent",
    "takes",
    "various",
    "action",
    "reinforcement",
    "learning",
    "process",
    "starts",
    "environment",
    "sends",
    "state",
    "agent",
    "agent",
    "based",
    "observations",
    "makes",
    "takes",
    "action",
    "response",
    "state",
    "turn",
    "environment",
    "send",
    "next",
    "state",
    "respective",
    "reward",
    "back",
    "agent",
    "agent",
    "update",
    "knowledge",
    "reward",
    "returned",
    "environment",
    "evaluate",
    "last",
    "actions",
    "loop",
    "continues",
    "environment",
    "sends",
    "terminal",
    "state",
    "means",
    "agent",
    "accomplished",
    "task",
    "understand",
    "better",
    "let",
    "suppose",
    "agent",
    "playing",
    "counter",
    "strike",
    "reinforcement",
    "learning",
    "process",
    "broken",
    "couple",
    "steps",
    "first",
    "step",
    "reinforcement",
    "learning",
    "agent",
    "basically",
    "player",
    "collects",
    "state",
    "naught",
    "environment",
    "whenever",
    "playing",
    "counter",
    "strike",
    "start",
    "stage",
    "zero",
    "stage",
    "one",
    "start",
    "first",
    "level",
    "based",
    "state",
    "naught",
    "reinforcement",
    "learning",
    "agent",
    "take",
    "action",
    "naught",
    "guys",
    "action",
    "anything",
    "causes",
    "result",
    "agent",
    "moves",
    "left",
    "right",
    "game",
    "also",
    "considered",
    "action",
    "initially",
    "action",
    "random",
    "agent",
    "clue",
    "environment",
    "let",
    "suppose",
    "playing",
    "counter",
    "strike",
    "first",
    "time",
    "idea",
    "play",
    "start",
    "randomly",
    "go",
    "whatever",
    "whichever",
    "action",
    "think",
    "right",
    "environment",
    "stage",
    "one",
    "passing",
    "stage",
    "zero",
    "environment",
    "go",
    "stage",
    "one",
    "environment",
    "updates",
    "stage",
    "stage",
    "reinforcement",
    "learning",
    "agent",
    "get",
    "reward",
    "r",
    "one",
    "environment",
    "reward",
    "anything",
    "like",
    "additional",
    "points",
    "get",
    "additional",
    "weapons",
    "playing",
    "counter",
    "strike",
    "reinforcement",
    "learning",
    "loop",
    "go",
    "agent",
    "dead",
    "reaches",
    "destination",
    "continuously",
    "outputs",
    "sequence",
    "state",
    "action",
    "rewards",
    "exactly",
    "reinforcement",
    "learning",
    "works",
    "starts",
    "agent",
    "put",
    "environment",
    "agent",
    "randomly",
    "take",
    "action",
    "state",
    "zero",
    "taking",
    "action",
    "depending",
    "action",
    "either",
    "get",
    "reward",
    "move",
    "state",
    "number",
    "one",
    "either",
    "die",
    "go",
    "back",
    "state",
    "keep",
    "happening",
    "agent",
    "reaches",
    "last",
    "stage",
    "dies",
    "reaches",
    "destination",
    "exactly",
    "reinforcement",
    "learning",
    "works",
    "reinforcement",
    "learning",
    "logic",
    "behind",
    "lot",
    "games",
    "days",
    "implemented",
    "various",
    "games",
    "dota",
    "lot",
    "play",
    "dota",
    "might",
    "know",
    "let",
    "talk",
    "couple",
    "reinforcement",
    "learning",
    "definitions",
    "terminologies",
    "first",
    "something",
    "known",
    "agent",
    "like",
    "mentioned",
    "agent",
    "reinforcement",
    "learning",
    "algorithm",
    "learns",
    "trial",
    "error",
    "agent",
    "one",
    "takes",
    "actions",
    "like",
    "example",
    "solider",
    "counter",
    "strike",
    "navigating",
    "game",
    "going",
    "right",
    "left",
    "agent",
    "taking",
    "action",
    "environment",
    "world",
    "agent",
    "moves",
    "environment",
    "basically",
    "takes",
    "agent",
    "current",
    "state",
    "action",
    "input",
    "returns",
    "agent",
    "reward",
    "next",
    "state",
    "output",
    "next",
    "something",
    "known",
    "action",
    "possible",
    "steps",
    "agent",
    "take",
    "considered",
    "action",
    "next",
    "something",
    "known",
    "state",
    "current",
    "condition",
    "returned",
    "environment",
    "known",
    "state",
    "reward",
    "instant",
    "return",
    "environment",
    "apprise",
    "last",
    "action",
    "reinforcement",
    "learning",
    "agent",
    "terms",
    "pretty",
    "understandable",
    "next",
    "something",
    "known",
    "policy",
    "policy",
    "approach",
    "agent",
    "uses",
    "determine",
    "next",
    "action",
    "based",
    "current",
    "state",
    "policy",
    "basically",
    "approach",
    "go",
    "around",
    "environment",
    "next",
    "something",
    "known",
    "value",
    "expected",
    "return",
    "discount",
    "opposed",
    "rewards",
    "r",
    "known",
    "value",
    "terms",
    "like",
    "discount",
    "value",
    "discussing",
    "upcoming",
    "slides",
    "also",
    "similar",
    "value",
    "except",
    "takes",
    "extra",
    "parameter",
    "known",
    "current",
    "action",
    "worry",
    "action",
    "q",
    "value",
    "talk",
    "upcoming",
    "slides",
    "make",
    "familiar",
    "terms",
    "seeing",
    "whole",
    "lot",
    "session",
    "move",
    "let",
    "discuss",
    "couple",
    "reinforcement",
    "learning",
    "concepts",
    "something",
    "known",
    "reward",
    "maximization",
    "realized",
    "already",
    "basic",
    "aim",
    "reinforcement",
    "learning",
    "agent",
    "maximize",
    "report",
    "happen",
    "let",
    "try",
    "understand",
    "little",
    "detail",
    "basically",
    "agent",
    "works",
    "based",
    "theory",
    "reward",
    "maximization",
    "exactly",
    "agent",
    "must",
    "trained",
    "way",
    "takes",
    "best",
    "action",
    "reward",
    "maximal",
    "let",
    "explain",
    "reward",
    "maximization",
    "small",
    "example",
    "figure",
    "see",
    "fox",
    "meat",
    "tiger",
    "reinforcement",
    "learning",
    "agent",
    "fox",
    "end",
    "goal",
    "eat",
    "maximum",
    "amount",
    "meat",
    "eaten",
    "tiger",
    "fox",
    "clever",
    "guy",
    "eats",
    "meat",
    "closer",
    "rather",
    "meat",
    "close",
    "tiger",
    "closer",
    "gets",
    "tiger",
    "higher",
    "chances",
    "getting",
    "killed",
    "pretty",
    "obvious",
    "even",
    "reward",
    "near",
    "tiger",
    "bigger",
    "meat",
    "chunks",
    "discounted",
    "exactly",
    "discount",
    "discussed",
    "previous",
    "slide",
    "done",
    "uncertainty",
    "factor",
    "tiger",
    "might",
    "actually",
    "kill",
    "fox",
    "next",
    "thing",
    "understand",
    "discounting",
    "reward",
    "works",
    "order",
    "understand",
    "discounting",
    "define",
    "discount",
    "rate",
    "called",
    "gamma",
    "value",
    "gamma",
    "zero",
    "one",
    "smaller",
    "gamma",
    "larger",
    "discount",
    "worry",
    "concepts",
    "gamma",
    "seeing",
    "practical",
    "demo",
    "today",
    "let",
    "move",
    "discuss",
    "another",
    "concept",
    "known",
    "exploration",
    "exploitation",
    "guys",
    "hope",
    "understood",
    "reward",
    "maximization",
    "basically",
    "main",
    "aim",
    "behind",
    "reinforcement",
    "learning",
    "maximize",
    "rewards",
    "agent",
    "get",
    "one",
    "important",
    "concepts",
    "reinforcement",
    "learning",
    "exploration",
    "exploitation",
    "exploration",
    "like",
    "name",
    "suggests",
    "exploring",
    "capturing",
    "information",
    "environment",
    "hand",
    "exploitation",
    "using",
    "already",
    "known",
    "exploited",
    "information",
    "heighten",
    "reward",
    "consider",
    "example",
    "saw",
    "previously",
    "fox",
    "eats",
    "meat",
    "chunks",
    "close",
    "eat",
    "bigger",
    "meat",
    "chunks",
    "top",
    "even",
    "though",
    "bigger",
    "meat",
    "chunks",
    "would",
    "get",
    "reward",
    "fox",
    "focuses",
    "closest",
    "reward",
    "never",
    "reach",
    "big",
    "chunks",
    "meat",
    "process",
    "known",
    "exploitation",
    "fox",
    "decide",
    "explore",
    "bit",
    "find",
    "bigger",
    "reward",
    "big",
    "chunk",
    "meat",
    "known",
    "exploration",
    "difference",
    "exploitation",
    "exploration",
    "always",
    "best",
    "agent",
    "explores",
    "environment",
    "tries",
    "figure",
    "way",
    "get",
    "maximum",
    "number",
    "rewards",
    "let",
    "discuss",
    "another",
    "important",
    "concept",
    "reinforcement",
    "learning",
    "known",
    "markov",
    "decision",
    "process",
    "basically",
    "mathematical",
    "approach",
    "mapping",
    "solution",
    "reinforcement",
    "learning",
    "called",
    "markov",
    "decision",
    "process",
    "mathematics",
    "behind",
    "reinforcement",
    "learning",
    "way",
    "purpose",
    "reinforcement",
    "learning",
    "solve",
    "markov",
    "decision",
    "process",
    "order",
    "get",
    "solution",
    "set",
    "parameters",
    "markov",
    "decision",
    "process",
    "set",
    "actions",
    "set",
    "states",
    "reward",
    "r",
    "policy",
    "pi",
    "value",
    "also",
    "image",
    "represents",
    "reinforcement",
    "learning",
    "works",
    "agent",
    "agent",
    "take",
    "action",
    "environment",
    "environment",
    "turn",
    "reward",
    "agent",
    "give",
    "next",
    "state",
    "reinforcement",
    "learning",
    "works",
    "sum",
    "everything",
    "happens",
    "markov",
    "decision",
    "process",
    "reinforcement",
    "learning",
    "agent",
    "take",
    "action",
    "transition",
    "start",
    "state",
    "end",
    "state",
    "agent",
    "receive",
    "reward",
    "r",
    "action",
    "takes",
    "series",
    "action",
    "taken",
    "agent",
    "define",
    "policy",
    "rewards",
    "collected",
    "find",
    "value",
    "main",
    "goal",
    "maximize",
    "rewards",
    "choosing",
    "optimum",
    "policy",
    "gon",
    "na",
    "choose",
    "best",
    "possible",
    "approach",
    "order",
    "maximize",
    "rewards",
    "main",
    "aim",
    "markov",
    "decision",
    "process",
    "understand",
    "markov",
    "decision",
    "process",
    "let",
    "look",
    "small",
    "example",
    "sure",
    "already",
    "know",
    "shortest",
    "path",
    "problem",
    "problems",
    "concepts",
    "math",
    "find",
    "shortest",
    "path",
    "consider",
    "representation",
    "figure",
    "goal",
    "find",
    "shortest",
    "path",
    "two",
    "nodes",
    "let",
    "say",
    "trying",
    "find",
    "shortest",
    "path",
    "node",
    "node",
    "edge",
    "see",
    "number",
    "linked",
    "number",
    "denotes",
    "cost",
    "traverse",
    "edge",
    "need",
    "choose",
    "policy",
    "travel",
    "way",
    "cost",
    "minimum",
    "problem",
    "set",
    "states",
    "denoted",
    "nodes",
    "b",
    "c",
    "action",
    "traverse",
    "one",
    "node",
    "example",
    "going",
    "c",
    "action",
    "c",
    "b",
    "action",
    "b",
    "another",
    "action",
    "reward",
    "cost",
    "represented",
    "edge",
    "policy",
    "path",
    "taken",
    "reach",
    "destination",
    "need",
    "make",
    "sure",
    "choose",
    "policy",
    "way",
    "cost",
    "minimal",
    "start",
    "node",
    "take",
    "baby",
    "steps",
    "reach",
    "destination",
    "initially",
    "next",
    "possible",
    "node",
    "visible",
    "either",
    "go",
    "b",
    "go",
    "follow",
    "greedy",
    "approach",
    "take",
    "optimum",
    "step",
    "choosing",
    "c",
    "instead",
    "choosing",
    "b",
    "node",
    "c",
    "want",
    "traverse",
    "node",
    "must",
    "choose",
    "path",
    "wisely",
    "traverse",
    "c",
    "c",
    "b",
    "b",
    "cost",
    "lest",
    "traverse",
    "c",
    "cost",
    "actually",
    "increase",
    "need",
    "choose",
    "policy",
    "minimize",
    "cost",
    "let",
    "say",
    "example",
    "agent",
    "chose",
    "c",
    "came",
    "node",
    "c",
    "directly",
    "chose",
    "policy",
    "followed",
    "agent",
    "problem",
    "exploitation",
    "type",
    "explore",
    "notes",
    "selected",
    "three",
    "nodes",
    "traversed",
    "policy",
    "followed",
    "actually",
    "optimal",
    "policy",
    "must",
    "always",
    "explore",
    "find",
    "optimal",
    "policy",
    "even",
    "nodes",
    "giving",
    "us",
    "reward",
    "actually",
    "increasing",
    "cost",
    "still",
    "explore",
    "find",
    "paths",
    "actually",
    "better",
    "policy",
    "actually",
    "better",
    "method",
    "implemented",
    "known",
    "learning",
    "aim",
    "find",
    "best",
    "policy",
    "among",
    "possible",
    "policies",
    "guys",
    "apart",
    "also",
    "approach",
    "approach",
    "value",
    "based",
    "emphasizes",
    "maximizing",
    "rewards",
    "action",
    "base",
    "emphasize",
    "action",
    "taken",
    "agent",
    "point",
    "note",
    "learning",
    "approaches",
    "simple",
    "end",
    "goal",
    "end",
    "goal",
    "effectively",
    "guide",
    "agent",
    "environment",
    "acquire",
    "number",
    "rewards",
    "simple",
    "understand",
    "markov",
    "decision",
    "process",
    "exploitation",
    "exploration",
    "also",
    "discussed",
    "different",
    "reinforcement",
    "learning",
    "definitions",
    "hope",
    "understandable",
    "let",
    "move",
    "understand",
    "algorithm",
    "known",
    "algorithm",
    "guys",
    "one",
    "important",
    "algorithms",
    "reinforcement",
    "learning",
    "discuss",
    "algorithm",
    "help",
    "small",
    "example",
    "study",
    "example",
    "implement",
    "example",
    "using",
    "python",
    "see",
    "works",
    "demonstration",
    "looks",
    "problem",
    "statement",
    "place",
    "agent",
    "one",
    "rooms",
    "numbered",
    "zero",
    "one",
    "two",
    "three",
    "four",
    "goal",
    "agent",
    "reach",
    "outside",
    "building",
    "room",
    "number",
    "five",
    "basically",
    "zero",
    "one",
    "two",
    "three",
    "four",
    "represents",
    "building",
    "five",
    "represents",
    "room",
    "outside",
    "building",
    "rooms",
    "connected",
    "gaps",
    "see",
    "rooms",
    "basically",
    "room",
    "numbered",
    "zero",
    "four",
    "outside",
    "building",
    "taught",
    "big",
    "room",
    "room",
    "number",
    "five",
    "noticed",
    "diagram",
    "door",
    "number",
    "one",
    "door",
    "number",
    "four",
    "lead",
    "directly",
    "room",
    "number",
    "five",
    "one",
    "directly",
    "go",
    "five",
    "four",
    "also",
    "directly",
    "go",
    "five",
    "want",
    "go",
    "five",
    "room",
    "number",
    "two",
    "first",
    "go",
    "room",
    "number",
    "three",
    "room",
    "number",
    "one",
    "room",
    "number",
    "five",
    "indirect",
    "links",
    "direct",
    "links",
    "room",
    "number",
    "one",
    "room",
    "number",
    "four",
    "hope",
    "clear",
    "problem",
    "statement",
    "basically",
    "going",
    "reinforcement",
    "learning",
    "agent",
    "agent",
    "traverse",
    "rooms",
    "way",
    "reaches",
    "room",
    "number",
    "five",
    "solve",
    "problem",
    "first",
    "represent",
    "rooms",
    "graph",
    "room",
    "denoted",
    "anode",
    "links",
    "connecting",
    "nodes",
    "doors",
    "alright",
    "node",
    "one",
    "five",
    "links",
    "nodes",
    "represent",
    "doors",
    "example",
    "look",
    "graph",
    "see",
    "direct",
    "connection",
    "one",
    "five",
    "meaning",
    "directly",
    "go",
    "room",
    "number",
    "one",
    "goal",
    "room",
    "number",
    "five",
    "want",
    "go",
    "room",
    "number",
    "three",
    "five",
    "either",
    "go",
    "room",
    "number",
    "one",
    "go",
    "five",
    "go",
    "room",
    "number",
    "three",
    "four",
    "five",
    "guys",
    "remember",
    "end",
    "goal",
    "reach",
    "room",
    "number",
    "five",
    "set",
    "room",
    "number",
    "five",
    "goal",
    "state",
    "associate",
    "reward",
    "value",
    "door",
    "doors",
    "lead",
    "immediately",
    "goal",
    "instant",
    "reward",
    "basically",
    "one",
    "five",
    "reward",
    "hundred",
    "four",
    "five",
    "also",
    "reward",
    "hundred",
    "doors",
    "directly",
    "connected",
    "target",
    "room",
    "zero",
    "reward",
    "directly",
    "lead",
    "us",
    "goal",
    "let",
    "say",
    "placed",
    "agent",
    "room",
    "number",
    "three",
    "go",
    "room",
    "number",
    "three",
    "one",
    "agent",
    "get",
    "reward",
    "zero",
    "go",
    "one",
    "five",
    "agent",
    "get",
    "reward",
    "hundred",
    "doors",
    "two",
    "arrows",
    "assigned",
    "room",
    "see",
    "arrow",
    "going",
    "towards",
    "room",
    "one",
    "coming",
    "room",
    "arrow",
    "contains",
    "instant",
    "reward",
    "shown",
    "figure",
    "course",
    "room",
    "number",
    "five",
    "loop",
    "back",
    "reward",
    "hundred",
    "direct",
    "connections",
    "goal",
    "room",
    "carry",
    "reward",
    "hundred",
    "goal",
    "reach",
    "state",
    "highest",
    "reward",
    "agent",
    "arrives",
    "goal",
    "remain",
    "forever",
    "hope",
    "clear",
    "diagram",
    "terminologies",
    "include",
    "two",
    "terms",
    "state",
    "action",
    "okay",
    "room",
    "basically",
    "represents",
    "state",
    "state",
    "two",
    "basically",
    "means",
    "room",
    "number",
    "two",
    "action",
    "basically",
    "moment",
    "agent",
    "one",
    "room",
    "room",
    "let",
    "say",
    "going",
    "room",
    "number",
    "two",
    "room",
    "number",
    "three",
    "basically",
    "action",
    "let",
    "consider",
    "example",
    "let",
    "say",
    "place",
    "agent",
    "room",
    "number",
    "two",
    "get",
    "goal",
    "initial",
    "state",
    "state",
    "number",
    "two",
    "room",
    "number",
    "two",
    "room",
    "number",
    "two",
    "go",
    "room",
    "number",
    "three",
    "state",
    "three",
    "state",
    "three",
    "either",
    "go",
    "back",
    "state",
    "two",
    "go",
    "state",
    "one",
    "state",
    "four",
    "go",
    "state",
    "four",
    "directly",
    "go",
    "goal",
    "room",
    "five",
    "agent",
    "going",
    "traverse",
    "order",
    "depict",
    "rewards",
    "going",
    "get",
    "going",
    "create",
    "matrix",
    "known",
    "reward",
    "matrix",
    "okay",
    "represented",
    "r",
    "also",
    "known",
    "r",
    "matrix",
    "minus",
    "one",
    "table",
    "represents",
    "null",
    "values",
    "basically",
    "link",
    "nodes",
    "represented",
    "minus",
    "one",
    "link",
    "zero",
    "zero",
    "minus",
    "one",
    "look",
    "diagram",
    "direct",
    "link",
    "zero",
    "one",
    "put",
    "minus",
    "one",
    "well",
    "look",
    "zero",
    "comma",
    "four",
    "value",
    "zero",
    "means",
    "traverse",
    "zero",
    "four",
    "reward",
    "going",
    "zero",
    "four",
    "goal",
    "state",
    "however",
    "look",
    "matrix",
    "look",
    "one",
    "comma",
    "five",
    "one",
    "comma",
    "five",
    "reward",
    "value",
    "hundred",
    "directly",
    "go",
    "room",
    "number",
    "one",
    "five",
    "five",
    "end",
    "goal",
    "assigned",
    "reward",
    "hundred",
    "similarly",
    "four",
    "comma",
    "five",
    "reward",
    "hundred",
    "five",
    "comma",
    "five",
    "reward",
    "hundred",
    "zeroes",
    "basically",
    "represent",
    "links",
    "zero",
    "lead",
    "end",
    "goal",
    "hope",
    "understood",
    "reward",
    "matrix",
    "simple",
    "move",
    "creating",
    "another",
    "matrix",
    "known",
    "equitable",
    "q",
    "matrix",
    "q",
    "matrix",
    "basically",
    "represents",
    "memory",
    "agent",
    "learned",
    "experience",
    "rules",
    "q",
    "matrix",
    "represent",
    "current",
    "state",
    "agent",
    "columns",
    "represent",
    "next",
    "possible",
    "actions",
    "leading",
    "next",
    "state",
    "formula",
    "calculate",
    "q",
    "matrix",
    "formula",
    "right",
    "q",
    "state",
    "comma",
    "action",
    "r",
    "state",
    "comma",
    "action",
    "nothing",
    "reward",
    "matrix",
    "parameter",
    "known",
    "gamma",
    "parameter",
    "explain",
    "shortly",
    "multiplying",
    "maximum",
    "q",
    "next",
    "state",
    "comma",
    "actions",
    "worry",
    "understood",
    "formula",
    "explain",
    "small",
    "example",
    "let",
    "understand",
    "gamma",
    "parameter",
    "basically",
    "value",
    "gamma",
    "zero",
    "one",
    "gamma",
    "closer",
    "zero",
    "means",
    "agent",
    "tend",
    "consider",
    "immediate",
    "rewards",
    "gamma",
    "closer",
    "one",
    "means",
    "agent",
    "consider",
    "future",
    "rewards",
    "greater",
    "weight",
    "exactly",
    "trying",
    "say",
    "gamma",
    "closer",
    "one",
    "performing",
    "something",
    "known",
    "exploitation",
    "hope",
    "remember",
    "exploitation",
    "exploration",
    "gamma",
    "closer",
    "zero",
    "means",
    "agent",
    "going",
    "explore",
    "environment",
    "instead",
    "choose",
    "couple",
    "states",
    "traverse",
    "states",
    "gamma",
    "parameter",
    "closer",
    "one",
    "means",
    "agent",
    "traverse",
    "possible",
    "states",
    "meaning",
    "perform",
    "exploration",
    "exploitation",
    "closer",
    "gamma",
    "parameter",
    "one",
    "agent",
    "explore",
    "exactly",
    "gamma",
    "parameter",
    "want",
    "get",
    "best",
    "policy",
    "always",
    "practical",
    "choose",
    "gamma",
    "parameter",
    "closer",
    "one",
    "want",
    "agent",
    "explore",
    "environment",
    "much",
    "possible",
    "get",
    "best",
    "policy",
    "maximum",
    "rewards",
    "hope",
    "clear",
    "let",
    "tell",
    "algorithm",
    "step",
    "step",
    "begin",
    "algorithm",
    "setting",
    "gamma",
    "parameter",
    "environment",
    "rewards",
    "matrix",
    "okay",
    "first",
    "set",
    "two",
    "values",
    "already",
    "calculated",
    "reward",
    "matrix",
    "need",
    "set",
    "gamma",
    "parameter",
    "next",
    "initialize",
    "matrix",
    "q",
    "zero",
    "remember",
    "said",
    "q",
    "matrix",
    "basically",
    "memory",
    "agent",
    "initially",
    "obviously",
    "agent",
    "memory",
    "environment",
    "new",
    "environment",
    "placing",
    "randomly",
    "anywhere",
    "zero",
    "memory",
    "initialize",
    "matrix",
    "q",
    "zero",
    "select",
    "random",
    "initial",
    "state",
    "place",
    "agent",
    "initial",
    "state",
    "set",
    "initial",
    "state",
    "current",
    "state",
    "current",
    "state",
    "select",
    "action",
    "lead",
    "next",
    "state",
    "basically",
    "get",
    "maximum",
    "q",
    "value",
    "next",
    "state",
    "based",
    "possible",
    "actions",
    "take",
    "keep",
    "computing",
    "skew",
    "value",
    "reach",
    "goals",
    "state",
    "might",
    "little",
    "bit",
    "confusing",
    "let",
    "look",
    "entire",
    "thing",
    "small",
    "example",
    "let",
    "say",
    "first",
    "gon",
    "na",
    "begin",
    "setting",
    "gamma",
    "parameter",
    "setting",
    "gamma",
    "parameter",
    "pretty",
    "close",
    "one",
    "means",
    "agent",
    "explore",
    "environment",
    "much",
    "possible",
    "also",
    "setting",
    "initial",
    "state",
    "room",
    "one",
    "meaning",
    "state",
    "one",
    "room",
    "one",
    "basically",
    "agent",
    "going",
    "room",
    "number",
    "one",
    "next",
    "step",
    "initialize",
    "q",
    "matrix",
    "zero",
    "matrix",
    "q",
    "matrix",
    "see",
    "everything",
    "set",
    "zero",
    "agent",
    "memory",
    "traversed",
    "node",
    "memory",
    "since",
    "agent",
    "room",
    "one",
    "either",
    "go",
    "room",
    "number",
    "three",
    "go",
    "room",
    "number",
    "five",
    "let",
    "randomly",
    "select",
    "room",
    "number",
    "five",
    "room",
    "number",
    "five",
    "going",
    "calculate",
    "maximum",
    "q",
    "value",
    "next",
    "state",
    "based",
    "possible",
    "actions",
    "possible",
    "actions",
    "room",
    "number",
    "five",
    "one",
    "four",
    "five",
    "basically",
    "traversing",
    "q",
    "one",
    "comma",
    "five",
    "put",
    "one",
    "comma",
    "five",
    "state",
    "comma",
    "action",
    "reward",
    "matrix",
    "r",
    "one",
    "comma",
    "five",
    "r",
    "one",
    "comma",
    "five",
    "basically",
    "hundred",
    "put",
    "hundred",
    "comma",
    "parameter",
    "guys",
    "substituting",
    "values",
    "formula",
    "let",
    "repeat",
    "whole",
    "thing",
    "q",
    "state",
    "comma",
    "action",
    "state",
    "number",
    "one",
    "correct",
    "action",
    "going",
    "room",
    "number",
    "five",
    "q",
    "state",
    "comma",
    "action",
    "one",
    "comma",
    "five",
    "reward",
    "matrix",
    "r",
    "one",
    "comma",
    "five",
    "hundred",
    "gon",
    "na",
    "put",
    "hundred",
    "plus",
    "gamma",
    "parameter",
    "gamma",
    "parameter",
    "going",
    "calculate",
    "maximum",
    "q",
    "value",
    "next",
    "state",
    "based",
    "possible",
    "actions",
    "let",
    "look",
    "next",
    "state",
    "room",
    "number",
    "five",
    "go",
    "either",
    "one",
    "go",
    "four",
    "go",
    "five",
    "actions",
    "five",
    "comma",
    "one",
    "five",
    "comma",
    "four",
    "five",
    "comma",
    "five",
    "exactly",
    "mentioned",
    "q",
    "five",
    "comma",
    "one",
    "q",
    "five",
    "comma",
    "four",
    "q",
    "five",
    "comma",
    "five",
    "basically",
    "putting",
    "next",
    "possible",
    "actions",
    "state",
    "number",
    "five",
    "calculate",
    "maximum",
    "q",
    "value",
    "getting",
    "q",
    "value",
    "zero",
    "initially",
    "q",
    "matrix",
    "set",
    "zero",
    "going",
    "get",
    "zero",
    "q",
    "five",
    "comma",
    "one",
    "five",
    "comma",
    "four",
    "five",
    "comma",
    "five",
    "get",
    "zero",
    "hence",
    "q",
    "one",
    "comma",
    "five",
    "becomes",
    "hundred",
    "hundred",
    "comes",
    "r",
    "one",
    "comma",
    "five",
    "hope",
    "understood",
    "next",
    "update",
    "one",
    "comma",
    "five",
    "value",
    "q",
    "matrix",
    "calculated",
    "q",
    "one",
    "comma",
    "five",
    "updated",
    "next",
    "episode",
    "start",
    "randomly",
    "chosen",
    "initial",
    "state",
    "let",
    "say",
    "randomly",
    "chose",
    "state",
    "number",
    "three",
    "room",
    "number",
    "three",
    "either",
    "go",
    "room",
    "number",
    "one",
    "two",
    "four",
    "let",
    "randomly",
    "select",
    "room",
    "number",
    "one",
    "room",
    "number",
    "five",
    "calculate",
    "maximum",
    "q",
    "value",
    "next",
    "possible",
    "actions",
    "let",
    "calculate",
    "q",
    "formula",
    "q",
    "state",
    "comma",
    "action",
    "becomes",
    "three",
    "comma",
    "one",
    "state",
    "number",
    "three",
    "action",
    "going",
    "room",
    "number",
    "one",
    "r",
    "three",
    "comma",
    "one",
    "let",
    "see",
    "r",
    "three",
    "comma",
    "one",
    "r",
    "three",
    "comma",
    "one",
    "zero",
    "going",
    "put",
    "zero",
    "plus",
    "gamma",
    "parameter",
    "going",
    "check",
    "next",
    "possible",
    "actions",
    "room",
    "number",
    "one",
    "going",
    "choose",
    "maximum",
    "value",
    "two",
    "q",
    "one",
    "comma",
    "three",
    "q",
    "one",
    "comma",
    "five",
    "denote",
    "next",
    "possible",
    "actions",
    "room",
    "number",
    "one",
    "q",
    "one",
    "comma",
    "three",
    "zero",
    "q",
    "one",
    "comma",
    "five",
    "hundred",
    "calculated",
    "hundred",
    "previous",
    "step",
    "zero",
    "hundred",
    "hundred",
    "maximum",
    "value",
    "going",
    "choose",
    "hundred",
    "hundred",
    "nothing",
    "q",
    "matrix",
    "gets",
    "updated",
    "see",
    "80",
    "basically",
    "taking",
    "actions",
    "updating",
    "q",
    "value",
    "calculating",
    "q",
    "value",
    "every",
    "step",
    "putting",
    "q",
    "matrix",
    "agent",
    "remembers",
    "okay",
    "went",
    "room",
    "number",
    "one",
    "room",
    "number",
    "five",
    "q",
    "value",
    "hundred",
    "similarly",
    "three",
    "one",
    "gave",
    "q",
    "value",
    "basically",
    "q",
    "matrix",
    "represents",
    "memory",
    "agent",
    "hope",
    "clear",
    "basically",
    "gon",
    "na",
    "gon",
    "na",
    "keep",
    "iterating",
    "loop",
    "gone",
    "possible",
    "states",
    "reach",
    "goal",
    "state",
    "five",
    "also",
    "main",
    "aim",
    "find",
    "optimum",
    "policy",
    "get",
    "room",
    "number",
    "five",
    "let",
    "implement",
    "exact",
    "thing",
    "using",
    "python",
    "lot",
    "theory",
    "let",
    "understand",
    "done",
    "practically",
    "alright",
    "begin",
    "importing",
    "library",
    "gon",
    "na",
    "using",
    "numpy",
    "library",
    "import",
    "r",
    "matrix",
    "already",
    "created",
    "r",
    "matrix",
    "exact",
    "matrix",
    "showed",
    "couple",
    "minutes",
    "ago",
    "created",
    "matrix",
    "called",
    "r",
    "basically",
    "stored",
    "rewards",
    "want",
    "see",
    "r",
    "matrix",
    "let",
    "print",
    "basically",
    "r",
    "matrix",
    "remember",
    "node",
    "one",
    "five",
    "reward",
    "hundred",
    "node",
    "four",
    "five",
    "reward",
    "hundred",
    "five",
    "five",
    "reward",
    "hundred",
    "nodes",
    "directly",
    "lead",
    "us",
    "reward",
    "correct",
    "next",
    "creating",
    "q",
    "matrix",
    "basically",
    "six",
    "six",
    "matrix",
    "represents",
    "states",
    "zero",
    "five",
    "matrix",
    "basically",
    "zero",
    "setting",
    "gamma",
    "parameter",
    "guys",
    "play",
    "around",
    "code",
    "know",
    "change",
    "comma",
    "parameter",
    "see",
    "much",
    "agent",
    "explore",
    "whether",
    "perform",
    "exploitation",
    "set",
    "gamma",
    "parameter",
    "pretty",
    "good",
    "number",
    "setting",
    "initial",
    "state",
    "one",
    "randomly",
    "choose",
    "state",
    "according",
    "needs",
    "set",
    "initial",
    "state",
    "one",
    "function",
    "basically",
    "give",
    "available",
    "actions",
    "initial",
    "state",
    "since",
    "set",
    "initial",
    "state",
    "one",
    "give",
    "possible",
    "actions",
    "since",
    "initial",
    "state",
    "one",
    "checking",
    "row",
    "number",
    "one",
    "value",
    "equal",
    "zero",
    "greater",
    "zero",
    "denote",
    "available",
    "actions",
    "look",
    "row",
    "number",
    "one",
    "one",
    "zero",
    "hundred",
    "one",
    "comma",
    "four",
    "one",
    "comma",
    "five",
    "look",
    "row",
    "number",
    "one",
    "since",
    "selected",
    "initial",
    "state",
    "one",
    "consider",
    "row",
    "number",
    "one",
    "okay",
    "row",
    "number",
    "one",
    "two",
    "numbers",
    "either",
    "equal",
    "zero",
    "greater",
    "zero",
    "denote",
    "possible",
    "actions",
    "one",
    "comma",
    "three",
    "value",
    "zero",
    "one",
    "comma",
    "five",
    "value",
    "hundred",
    "means",
    "agent",
    "either",
    "go",
    "room",
    "number",
    "three",
    "go",
    "room",
    "number",
    "five",
    "trying",
    "say",
    "room",
    "number",
    "one",
    "basically",
    "go",
    "room",
    "number",
    "three",
    "room",
    "number",
    "five",
    "exactly",
    "coded",
    "remember",
    "reward",
    "matrix",
    "one",
    "traverse",
    "room",
    "number",
    "three",
    "directly",
    "room",
    "number",
    "five",
    "directly",
    "okay",
    "exactly",
    "mentioned",
    "code",
    "basically",
    "give",
    "available",
    "actions",
    "current",
    "state",
    "moved",
    "next",
    "state",
    "need",
    "check",
    "available",
    "actions",
    "state",
    "basically",
    "remember",
    "room",
    "number",
    "one",
    "go",
    "three",
    "five",
    "correct",
    "three",
    "five",
    "randomly",
    "select",
    "state",
    "state",
    "need",
    "find",
    "possible",
    "actions",
    "exactly",
    "done",
    "okay",
    "randomly",
    "choose",
    "action",
    "available",
    "actions",
    "next",
    "need",
    "update",
    "q",
    "matrix",
    "depending",
    "actions",
    "took",
    "remember",
    "exactly",
    "update",
    "function",
    "four",
    "guys",
    "entire",
    "calculating",
    "q",
    "value",
    "hope",
    "remember",
    "formula",
    "q",
    "state",
    "comma",
    "action",
    "r",
    "state",
    "comma",
    "action",
    "plus",
    "gamma",
    "max",
    "value",
    "max",
    "value",
    "basically",
    "give",
    "maximum",
    "value",
    "possible",
    "actions",
    "basically",
    "computing",
    "formula",
    "update",
    "q",
    "matrix",
    "coming",
    "training",
    "phase",
    "gon",
    "na",
    "going",
    "set",
    "range",
    "set",
    "range",
    "meaning",
    "agent",
    "perform",
    "iterations",
    "set",
    "depending",
    "needs",
    "iteration",
    "pretty",
    "huge",
    "number",
    "basically",
    "agent",
    "going",
    "go",
    "possible",
    "iterations",
    "order",
    "find",
    "best",
    "policy",
    "exact",
    "thing",
    "earlier",
    "setting",
    "current",
    "state",
    "choosing",
    "available",
    "action",
    "current",
    "state",
    "choose",
    "action",
    "random",
    "calculate",
    "q",
    "value",
    "update",
    "q",
    "value",
    "matrix",
    "alright",
    "nothing",
    "printing",
    "trained",
    "q",
    "matrix",
    "training",
    "phase",
    "testing",
    "phase",
    "basically",
    "going",
    "randomly",
    "choose",
    "current",
    "state",
    "gon",
    "na",
    "choose",
    "current",
    "state",
    "going",
    "keep",
    "looping",
    "entire",
    "code",
    "reach",
    "goal",
    "state",
    "room",
    "number",
    "five",
    "exactly",
    "whole",
    "thing",
    "also",
    "end",
    "printing",
    "selected",
    "part",
    "basically",
    "policy",
    "agent",
    "took",
    "reach",
    "room",
    "number",
    "five",
    "set",
    "current",
    "state",
    "one",
    "give",
    "best",
    "policy",
    "reach",
    "room",
    "number",
    "five",
    "room",
    "number",
    "one",
    "alright",
    "let",
    "run",
    "code",
    "let",
    "see",
    "giving",
    "us",
    "happens",
    "want",
    "check",
    "tell",
    "best",
    "possible",
    "way",
    "get",
    "room",
    "number",
    "one",
    "room",
    "number",
    "five",
    "obviously",
    "directly",
    "like",
    "one",
    "five",
    "best",
    "policy",
    "get",
    "room",
    "number",
    "one",
    "room",
    "number",
    "five",
    "get",
    "output",
    "one",
    "comma",
    "five",
    "exactly",
    "getting",
    "q",
    "matrix",
    "q",
    "values",
    "getting",
    "selected",
    "path",
    "current",
    "state",
    "one",
    "best",
    "policy",
    "go",
    "one",
    "five",
    "want",
    "change",
    "current",
    "state",
    "let",
    "say",
    "set",
    "current",
    "state",
    "two",
    "run",
    "code",
    "let",
    "see",
    "best",
    "possible",
    "way",
    "get",
    "room",
    "number",
    "five",
    "room",
    "number",
    "two",
    "room",
    "number",
    "two",
    "go",
    "three",
    "go",
    "one",
    "go",
    "five",
    "give",
    "reward",
    "hundred",
    "go",
    "room",
    "number",
    "three",
    "go",
    "four",
    "go",
    "five",
    "also",
    "give",
    "reward",
    "hundred",
    "path",
    "something",
    "like",
    "let",
    "save",
    "let",
    "run",
    "file",
    "basically",
    "stage",
    "two",
    "going",
    "say",
    "three",
    "four",
    "five",
    "best",
    "possible",
    "path",
    "two",
    "room",
    "number",
    "five",
    "guys",
    "exactly",
    "q",
    "learning",
    "algorithm",
    "works",
    "simple",
    "implementation",
    "entire",
    "example",
    "told",
    "still",
    "doubts",
    "regarding",
    "q",
    "learning",
    "reinforcement",
    "learning",
    "make",
    "sure",
    "comment",
    "comment",
    "section",
    "try",
    "answer",
    "doubts",
    "done",
    "machine",
    "learning",
    "completed",
    "whole",
    "machine",
    "learning",
    "model",
    "understood",
    "reinforcement",
    "learning",
    "supervised",
    "learning",
    "unsupervised",
    "learning",
    "get",
    "deep",
    "learning",
    "want",
    "clear",
    "common",
    "misconception",
    "lot",
    "people",
    "get",
    "confused",
    "ai",
    "machine",
    "learning",
    "deep",
    "learning",
    "know",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "deep",
    "learning",
    "common",
    "applications",
    "example",
    "siri",
    "application",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "deep",
    "learning",
    "three",
    "connected",
    "thing",
    "exactly",
    "relationship",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "deep",
    "learning",
    "discussing",
    "artificial",
    "intelligence",
    "basically",
    "science",
    "getting",
    "machines",
    "mimic",
    "behavior",
    "human",
    "beings",
    "comes",
    "machine",
    "learning",
    "machine",
    "learning",
    "subset",
    "artificial",
    "intelligence",
    "focuses",
    "getting",
    "machines",
    "make",
    "decisions",
    "feeding",
    "data",
    "exactly",
    "machine",
    "learning",
    "subset",
    "artificial",
    "intelligence",
    "deep",
    "learning",
    "hand",
    "subset",
    "machine",
    "learning",
    "uses",
    "concept",
    "neural",
    "networks",
    "solve",
    "complex",
    "problems",
    "sum",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "deep",
    "learning",
    "interconnected",
    "fields",
    "machine",
    "learning",
    "deep",
    "learning",
    "aids",
    "artificial",
    "intelligence",
    "providing",
    "set",
    "algorithms",
    "neural",
    "networks",
    "solve",
    "problems",
    "ai",
    "machine",
    "learning",
    "deep",
    "learning",
    "related",
    "hope",
    "cleared",
    "misconceptions",
    "doubts",
    "ai",
    "ml",
    "deep",
    "learning",
    "let",
    "look",
    "next",
    "topic",
    "limitations",
    "machine",
    "learning",
    "first",
    "limitation",
    "machine",
    "learning",
    "capable",
    "enough",
    "handle",
    "high",
    "dimensional",
    "data",
    "input",
    "output",
    "large",
    "handling",
    "processing",
    "type",
    "data",
    "becomes",
    "complex",
    "takes",
    "lot",
    "resources",
    "also",
    "sometimes",
    "known",
    "curse",
    "dimensionality",
    "understand",
    "simpler",
    "terms",
    "look",
    "image",
    "shown",
    "slide",
    "consider",
    "line",
    "hundred",
    "yards",
    "let",
    "say",
    "dropped",
    "coin",
    "somewhere",
    "line",
    "quite",
    "convenient",
    "find",
    "coin",
    "simply",
    "walking",
    "along",
    "line",
    "simple",
    "line",
    "considered",
    "single",
    "dimensional",
    "entity",
    "next",
    "consider",
    "square",
    "hundred",
    "yards",
    "let",
    "say",
    "dropped",
    "coin",
    "somewhere",
    "quite",
    "evident",
    "going",
    "take",
    "time",
    "find",
    "coin",
    "within",
    "square",
    "compared",
    "previous",
    "scenario",
    "square",
    "let",
    "say",
    "two",
    "dimensional",
    "entity",
    "let",
    "take",
    "step",
    "ahead",
    "let",
    "consider",
    "cube",
    "okay",
    "let",
    "say",
    "cube",
    "500",
    "yards",
    "dropped",
    "coin",
    "somewhere",
    "cube",
    "becomes",
    "even",
    "difficult",
    "find",
    "coin",
    "time",
    "three",
    "dimensional",
    "entity",
    "dimension",
    "increases",
    "problem",
    "becomes",
    "complex",
    "observe",
    "complexity",
    "increasing",
    "increase",
    "dimensions",
    "real",
    "life",
    "high",
    "dimensional",
    "data",
    "talking",
    "thousands",
    "dimensions",
    "makes",
    "complex",
    "handle",
    "process",
    "high",
    "dimensional",
    "data",
    "easily",
    "found",
    "used",
    "cases",
    "like",
    "image",
    "processing",
    "natural",
    "language",
    "processing",
    "image",
    "translation",
    "saw",
    "16",
    "million",
    "possible",
    "colors",
    "lot",
    "data",
    "machine",
    "learning",
    "restricted",
    "used",
    "process",
    "image",
    "recognition",
    "image",
    "recognition",
    "images",
    "lot",
    "pixels",
    "lot",
    "high",
    "dimensional",
    "data",
    "machine",
    "learning",
    "becomes",
    "restrictive",
    "comes",
    "uses",
    "cases",
    "second",
    "major",
    "challenge",
    "tell",
    "computer",
    "features",
    "look",
    "play",
    "important",
    "role",
    "predicted",
    "outcome",
    "getting",
    "good",
    "accuracy",
    "process",
    "something",
    "known",
    "feature",
    "extraction",
    "feeding",
    "raw",
    "data",
    "algorithm",
    "rarely",
    "works",
    "reason",
    "feature",
    "extraction",
    "critical",
    "part",
    "machine",
    "learning",
    "workflow",
    "challenge",
    "programmer",
    "increases",
    "effectiveness",
    "algorithm",
    "depends",
    "insightful",
    "programmer",
    "programmer",
    "tell",
    "machine",
    "features",
    "depending",
    "features",
    "predict",
    "outcome",
    "machine",
    "learning",
    "works",
    "far",
    "demos",
    "saw",
    "providing",
    "predictor",
    "variables",
    "providing",
    "input",
    "variables",
    "help",
    "us",
    "predict",
    "outcome",
    "trying",
    "find",
    "correlations",
    "variables",
    "trying",
    "find",
    "variable",
    "important",
    "predicting",
    "output",
    "variable",
    "becomes",
    "challenge",
    "programmer",
    "difficult",
    "apply",
    "machine",
    "learning",
    "model",
    "complex",
    "problems",
    "like",
    "object",
    "recognition",
    "handwriting",
    "recognition",
    "natural",
    "language",
    "processing",
    "problems",
    "limitations",
    "machine",
    "learning",
    "led",
    "introduction",
    "deep",
    "learning",
    "gon",
    "na",
    "discuss",
    "deep",
    "learning",
    "deep",
    "learning",
    "one",
    "methods",
    "overcome",
    "challenges",
    "feature",
    "extraction",
    "deep",
    "learning",
    "models",
    "capable",
    "learning",
    "focus",
    "right",
    "features",
    "requires",
    "little",
    "guidance",
    "programmer",
    "basically",
    "deep",
    "learning",
    "mimics",
    "way",
    "brain",
    "functions",
    "learns",
    "experience",
    "deep",
    "learning",
    "happens",
    "feature",
    "extraction",
    "happens",
    "automatically",
    "need",
    "little",
    "guidance",
    "programmer",
    "deep",
    "learning",
    "learn",
    "model",
    "understand",
    "feature",
    "variable",
    "important",
    "predicting",
    "outcome",
    "let",
    "say",
    "millions",
    "predictor",
    "variables",
    "particular",
    "problem",
    "statement",
    "going",
    "sit",
    "understand",
    "significance",
    "predictor",
    "variables",
    "going",
    "almost",
    "impossible",
    "sit",
    "many",
    "features",
    "deep",
    "learning",
    "whenever",
    "high",
    "dimensionality",
    "data",
    "whenever",
    "data",
    "really",
    "large",
    "lot",
    "features",
    "lot",
    "predictor",
    "variables",
    "use",
    "deep",
    "learning",
    "deep",
    "learning",
    "extract",
    "features",
    "understand",
    "features",
    "important",
    "predicting",
    "output",
    "main",
    "idea",
    "behind",
    "deep",
    "learning",
    "let",
    "give",
    "small",
    "example",
    "also",
    "suppose",
    "want",
    "make",
    "system",
    "recognize",
    "face",
    "different",
    "people",
    "image",
    "okay",
    "basically",
    "creating",
    "system",
    "identify",
    "faces",
    "different",
    "people",
    "image",
    "solve",
    "using",
    "typical",
    "machine",
    "learning",
    "algorithms",
    "define",
    "facial",
    "features",
    "like",
    "eyes",
    "nose",
    "ears",
    "et",
    "cetera",
    "okay",
    "system",
    "identify",
    "features",
    "important",
    "person",
    "consider",
    "deep",
    "learning",
    "example",
    "deep",
    "learning",
    "automatically",
    "find",
    "features",
    "important",
    "classification",
    "uses",
    "concept",
    "neural",
    "networks",
    "whereas",
    "machine",
    "learning",
    "manually",
    "define",
    "features",
    "main",
    "difference",
    "deep",
    "learning",
    "machine",
    "learning",
    "next",
    "question",
    "deep",
    "learning",
    "work",
    "people",
    "started",
    "coming",
    "deep",
    "learning",
    "main",
    "aim",
    "human",
    "brain",
    "okay",
    "deep",
    "learning",
    "studies",
    "basic",
    "unit",
    "brain",
    "called",
    "brain",
    "cell",
    "neuron",
    "biology",
    "students",
    "know",
    "talking",
    "basically",
    "deep",
    "learning",
    "inspired",
    "brain",
    "structure",
    "okay",
    "brains",
    "something",
    "known",
    "neurons",
    "neurons",
    "replicated",
    "deep",
    "learning",
    "artificial",
    "neurons",
    "also",
    "called",
    "perceptrons",
    "understand",
    "artificial",
    "neural",
    "networks",
    "artificial",
    "neurons",
    "work",
    "let",
    "understand",
    "biological",
    "neurons",
    "work",
    "sure",
    "many",
    "bio",
    "students",
    "let",
    "understand",
    "functionality",
    "biological",
    "neurons",
    "mimic",
    "functionality",
    "perceptron",
    "artificial",
    "neuron",
    "guys",
    "loo",
    "image",
    "basically",
    "image",
    "biological",
    "neuron",
    "focus",
    "structure",
    "biological",
    "neuron",
    "something",
    "known",
    "dendrites",
    "dendrites",
    "basically",
    "used",
    "receive",
    "inputs",
    "inputs",
    "basically",
    "found",
    "cell",
    "body",
    "passed",
    "next",
    "biological",
    "neuron",
    "dendrites",
    "going",
    "receive",
    "signals",
    "neurons",
    "basically",
    "input",
    "cell",
    "body",
    "sum",
    "inputs",
    "axon",
    "transmit",
    "input",
    "neurons",
    "axon",
    "fire",
    "threshold",
    "get",
    "passed",
    "onto",
    "next",
    "neuron",
    "similar",
    "perceptron",
    "artificial",
    "neuron",
    "receives",
    "multiple",
    "inputs",
    "applies",
    "various",
    "transformations",
    "functions",
    "provides",
    "us",
    "output",
    "multiple",
    "inputs",
    "nothing",
    "input",
    "variables",
    "predictor",
    "variables",
    "feeding",
    "input",
    "data",
    "artificial",
    "neuron",
    "perceptron",
    "perceptron",
    "apply",
    "various",
    "functions",
    "transformations",
    "give",
    "output",
    "like",
    "brain",
    "consists",
    "multiple",
    "connected",
    "neurons",
    "called",
    "neural",
    "networks",
    "also",
    "build",
    "something",
    "known",
    "network",
    "artificial",
    "neurons",
    "called",
    "artificial",
    "neural",
    "networks",
    "basic",
    "concept",
    "behind",
    "deep",
    "learning",
    "sum",
    "exactly",
    "deep",
    "learning",
    "deep",
    "learning",
    "collection",
    "statistical",
    "machine",
    "learning",
    "techniques",
    "used",
    "learn",
    "feature",
    "hierarchies",
    "based",
    "concept",
    "artificial",
    "neural",
    "networks",
    "main",
    "idea",
    "behind",
    "deep",
    "learning",
    "artificial",
    "neural",
    "networks",
    "work",
    "exactly",
    "like",
    "brain",
    "works",
    "diagram",
    "see",
    "couple",
    "layers",
    "first",
    "layer",
    "known",
    "input",
    "layer",
    "receive",
    "inputs",
    "last",
    "layer",
    "known",
    "output",
    "layer",
    "provides",
    "desired",
    "output",
    "layers",
    "input",
    "layer",
    "output",
    "layer",
    "known",
    "hidden",
    "layers",
    "number",
    "hidden",
    "layers",
    "thanks",
    "resources",
    "days",
    "hundreds",
    "hidden",
    "layers",
    "number",
    "hidden",
    "layers",
    "number",
    "perceptrons",
    "layers",
    "entirely",
    "depend",
    "problem",
    "use",
    "case",
    "trying",
    "solve",
    "basically",
    "deep",
    "learning",
    "works",
    "let",
    "look",
    "example",
    "saw",
    "earlier",
    "want",
    "want",
    "perform",
    "image",
    "recognition",
    "using",
    "deep",
    "networks",
    "first",
    "gon",
    "na",
    "going",
    "pass",
    "high",
    "dimensional",
    "data",
    "input",
    "layer",
    "mach",
    "dimensionality",
    "input",
    "data",
    "input",
    "layer",
    "contain",
    "multiple",
    "sub",
    "layers",
    "perceptrons",
    "consume",
    "entire",
    "input",
    "okay",
    "multiple",
    "sub",
    "layers",
    "perceptrons",
    "output",
    "received",
    "input",
    "layer",
    "contain",
    "patterns",
    "able",
    "identify",
    "edges",
    "images",
    "based",
    "contrast",
    "levels",
    "output",
    "fed",
    "hidden",
    "layer",
    "number",
    "one",
    "able",
    "identify",
    "facial",
    "features",
    "like",
    "eyes",
    "nose",
    "ears",
    "output",
    "fed",
    "hidden",
    "layer",
    "number",
    "two",
    "able",
    "form",
    "entire",
    "faces",
    "go",
    "deeper",
    "face",
    "recognition",
    "output",
    "hidden",
    "layer",
    "sent",
    "output",
    "layer",
    "hidden",
    "layer",
    "output",
    "layer",
    "finally",
    "output",
    "layer",
    "perform",
    "classification",
    "based",
    "result",
    "get",
    "previous",
    "layers",
    "exactly",
    "deep",
    "learning",
    "works",
    "small",
    "analogy",
    "use",
    "make",
    "understand",
    "deep",
    "learning",
    "let",
    "understand",
    "single",
    "layer",
    "perceptron",
    "like",
    "said",
    "perceptron",
    "basically",
    "artificial",
    "neuron",
    "something",
    "known",
    "single",
    "layer",
    "multiple",
    "layer",
    "perceptron",
    "first",
    "focus",
    "single",
    "layer",
    "perceptron",
    "explain",
    "perceptron",
    "really",
    "known",
    "perceptrons",
    "linear",
    "classifiers",
    "single",
    "layer",
    "perceptron",
    "linear",
    "binary",
    "classifier",
    "used",
    "mainly",
    "supervised",
    "learning",
    "helps",
    "classify",
    "given",
    "input",
    "data",
    "separate",
    "classes",
    "diagram",
    "basically",
    "represents",
    "perceptron",
    "perceptron",
    "multiple",
    "inputs",
    "set",
    "inputs",
    "labeled",
    "x",
    "one",
    "x",
    "two",
    "x",
    "input",
    "given",
    "specific",
    "weight",
    "okay",
    "w",
    "one",
    "represents",
    "weight",
    "input",
    "x",
    "one",
    "w",
    "two",
    "represents",
    "weight",
    "input",
    "x",
    "two",
    "assign",
    "weights",
    "different",
    "thing",
    "altogether",
    "need",
    "know",
    "input",
    "assigned",
    "particular",
    "weightage",
    "perceptron",
    "computes",
    "functions",
    "weighted",
    "inputs",
    "give",
    "output",
    "basically",
    "weighted",
    "inputs",
    "go",
    "something",
    "known",
    "summation",
    "okay",
    "summation",
    "nothing",
    "product",
    "input",
    "respective",
    "weight",
    "summation",
    "done",
    "passed",
    "onto",
    "transfer",
    "function",
    "transfer",
    "function",
    "nothing",
    "activation",
    "function",
    "discussing",
    "minute",
    "activation",
    "function",
    "activation",
    "function",
    "get",
    "outputs",
    "one",
    "two",
    "guys",
    "need",
    "understand",
    "four",
    "important",
    "parts",
    "perceptron",
    "firstly",
    "input",
    "values",
    "x",
    "one",
    "x",
    "two",
    "x",
    "three",
    "something",
    "known",
    "weights",
    "bias",
    "something",
    "known",
    "net",
    "sum",
    "finally",
    "activation",
    "function",
    "inputs",
    "x",
    "multiplied",
    "respective",
    "weights",
    "x",
    "one",
    "multiplied",
    "w",
    "one",
    "known",
    "summation",
    "add",
    "multiplied",
    "values",
    "call",
    "weighted",
    "sum",
    "done",
    "using",
    "summation",
    "function",
    "apply",
    "weighted",
    "sum",
    "correct",
    "activation",
    "function",
    "lot",
    "people",
    "confusion",
    "activation",
    "function",
    "activation",
    "function",
    "also",
    "known",
    "transfer",
    "function",
    "order",
    "understand",
    "activation",
    "function",
    "word",
    "stems",
    "way",
    "neurons",
    "human",
    "brain",
    "work",
    "neuron",
    "becomes",
    "activate",
    "certain",
    "potential",
    "reached",
    "threshold",
    "known",
    "activation",
    "protection",
    "therefore",
    "mathematically",
    "represented",
    "function",
    "reaches",
    "saturation",
    "threshold",
    "okay",
    "lot",
    "activation",
    "functions",
    "like",
    "signum",
    "sigmoid",
    "tan",
    "hedge",
    "think",
    "activation",
    "function",
    "function",
    "maps",
    "input",
    "respective",
    "output",
    "also",
    "spoke",
    "weights",
    "bias",
    "assign",
    "weights",
    "inputs",
    "weights",
    "show",
    "strength",
    "particular",
    "input",
    "important",
    "particular",
    "input",
    "predicting",
    "final",
    "output",
    "basically",
    "weightage",
    "input",
    "denotes",
    "importance",
    "input",
    "bias",
    "basically",
    "allows",
    "us",
    "shift",
    "activation",
    "function",
    "order",
    "get",
    "precise",
    "output",
    "perceptrons",
    "order",
    "make",
    "understand",
    "perceptrons",
    "better",
    "let",
    "look",
    "small",
    "analogy",
    "suppose",
    "wan",
    "na",
    "go",
    "party",
    "happening",
    "near",
    "hose",
    "decision",
    "depend",
    "set",
    "factors",
    "first",
    "weather",
    "second",
    "probably",
    "wife",
    "girlfriend",
    "boyfriend",
    "going",
    "third",
    "public",
    "transport",
    "available",
    "let",
    "say",
    "three",
    "factors",
    "going",
    "consider",
    "go",
    "party",
    "depending",
    "predictor",
    "variables",
    "features",
    "going",
    "decide",
    "whether",
    "going",
    "stay",
    "home",
    "go",
    "party",
    "weather",
    "going",
    "first",
    "input",
    "represent",
    "value",
    "x",
    "one",
    "wife",
    "going",
    "another",
    "input",
    "x",
    "two",
    "public",
    "transport",
    "available",
    "another",
    "input",
    "x",
    "three",
    "x",
    "one",
    "two",
    "values",
    "one",
    "zero",
    "one",
    "represents",
    "weather",
    "good",
    "zero",
    "represents",
    "weather",
    "bad",
    "similarly",
    "one",
    "represents",
    "wife",
    "going",
    "zero",
    "represents",
    "wife",
    "going",
    "x",
    "three",
    "one",
    "represents",
    "public",
    "transport",
    "zero",
    "represents",
    "public",
    "transport",
    "output",
    "either",
    "one",
    "zero",
    "one",
    "means",
    "going",
    "party",
    "zero",
    "means",
    "sitting",
    "home",
    "order",
    "understand",
    "weightage",
    "let",
    "say",
    "important",
    "factor",
    "weather",
    "weather",
    "good",
    "means",
    "100",
    "go",
    "party",
    "weather",
    "good",
    "decided",
    "sit",
    "home",
    "maximum",
    "weightage",
    "weather",
    "variable",
    "weather",
    "really",
    "good",
    "go",
    "party",
    "important",
    "factor",
    "order",
    "understand",
    "whether",
    "going",
    "sit",
    "home",
    "going",
    "go",
    "party",
    "basically",
    "x",
    "one",
    "equal",
    "one",
    "output",
    "one",
    "meaning",
    "weather",
    "good",
    "go",
    "party",
    "let",
    "randomly",
    "assign",
    "weights",
    "input",
    "w",
    "one",
    "weight",
    "associated",
    "input",
    "x",
    "one",
    "w",
    "two",
    "weight",
    "x",
    "two",
    "w",
    "three",
    "weight",
    "associated",
    "x",
    "three",
    "let",
    "say",
    "w",
    "one",
    "six",
    "w",
    "two",
    "two",
    "w",
    "three",
    "two",
    "using",
    "activation",
    "function",
    "going",
    "set",
    "threshold",
    "five",
    "means",
    "fire",
    "weather",
    "good",
    "wo",
    "fire",
    "weather",
    "bad",
    "irrespective",
    "inputs",
    "weightage",
    "six",
    "basically",
    "consider",
    "first",
    "input",
    "weightage",
    "six",
    "means",
    "100",
    "going",
    "go",
    "let",
    "say",
    "considering",
    "second",
    "input",
    "means",
    "going",
    "go",
    "weightage",
    "two",
    "threshold",
    "five",
    "weightage",
    "threshold",
    "means",
    "going",
    "go",
    "let",
    "consider",
    "another",
    "scenario",
    "threshold",
    "three",
    "means",
    "fire",
    "either",
    "x",
    "one",
    "high",
    "two",
    "inputs",
    "high",
    "w",
    "two",
    "associated",
    "wife",
    "going",
    "let",
    "say",
    "weather",
    "bad",
    "public",
    "transportation",
    "meaning",
    "x",
    "one",
    "x",
    "three",
    "zero",
    "x",
    "two",
    "one",
    "x",
    "two",
    "one",
    "weightage",
    "going",
    "two",
    "weightage",
    "two",
    "go",
    "threshold",
    "value",
    "set",
    "three",
    "threshold",
    "value",
    "set",
    "way",
    "x",
    "two",
    "x",
    "three",
    "combined",
    "together",
    "go",
    "x",
    "one",
    "true",
    "go",
    "assigning",
    "threshold",
    "way",
    "go",
    "sure",
    "weather",
    "good",
    "assign",
    "threshold",
    "nothing",
    "activation",
    "function",
    "guys",
    "hope",
    "understood",
    "amount",
    "weightage",
    "associated",
    "input",
    "important",
    "predicting",
    "output",
    "exactly",
    "perceptron",
    "works",
    "let",
    "look",
    "limitations",
    "perceptron",
    "perceptron",
    "hidden",
    "layers",
    "input",
    "layer",
    "output",
    "layer",
    "hidden",
    "layers",
    "classify",
    "separable",
    "data",
    "points",
    "okay",
    "data",
    "like",
    "figure",
    "separate",
    "use",
    "perceptron",
    "alright",
    "complex",
    "problems",
    "involve",
    "lot",
    "parameters",
    "solved",
    "single",
    "layer",
    "perceptron",
    "need",
    "something",
    "known",
    "multiple",
    "layer",
    "perceptron",
    "discuss",
    "something",
    "known",
    "multilayer",
    "perceptron",
    "multilayer",
    "perceptron",
    "structure",
    "single",
    "layer",
    "perceptron",
    "one",
    "hidden",
    "layer",
    "okay",
    "consider",
    "deep",
    "neural",
    "network",
    "single",
    "layer",
    "perceptron",
    "input",
    "layer",
    "output",
    "layer",
    "hidden",
    "layer",
    "comes",
    "perceptron",
    "hidden",
    "layers",
    "output",
    "layer",
    "similar",
    "manner",
    "like",
    "said",
    "first",
    "input",
    "x",
    "one",
    "x",
    "two",
    "x",
    "three",
    "inputs",
    "assigned",
    "weight",
    "w",
    "one",
    "w",
    "two",
    "w",
    "three",
    "calculate",
    "weighted",
    "summation",
    "inputs",
    "weights",
    "send",
    "transformation",
    "activation",
    "function",
    "finally",
    "get",
    "output",
    "thing",
    "multiple",
    "hidden",
    "layers",
    "one",
    "one",
    "hidden",
    "layers",
    "guys",
    "multilayer",
    "perceptron",
    "works",
    "works",
    "concept",
    "feed",
    "forward",
    "neural",
    "networks",
    "feed",
    "forward",
    "means",
    "every",
    "node",
    "level",
    "layer",
    "connected",
    "every",
    "node",
    "feed",
    "forward",
    "networks",
    "comes",
    "assigning",
    "weights",
    "randomly",
    "assign",
    "weights",
    "initially",
    "input",
    "x",
    "one",
    "x",
    "two",
    "x",
    "three",
    "randomly",
    "assign",
    "weight",
    "w",
    "one",
    "w",
    "two",
    "w",
    "three",
    "always",
    "necessary",
    "whatever",
    "weights",
    "assign",
    "input",
    "weights",
    "actually",
    "correct",
    "meaning",
    "weights",
    "company",
    "significant",
    "predicting",
    "output",
    "multilayer",
    "perceptron",
    "works",
    "set",
    "inputs",
    "passed",
    "first",
    "hidden",
    "layer",
    "activations",
    "layer",
    "passed",
    "next",
    "layer",
    "layer",
    "passed",
    "next",
    "hidden",
    "layer",
    "reach",
    "output",
    "layer",
    "output",
    "layer",
    "form",
    "two",
    "classes",
    "class",
    "one",
    "class",
    "two",
    "basically",
    "classify",
    "input",
    "one",
    "two",
    "classes",
    "multilayer",
    "perceptron",
    "works",
    "important",
    "concept",
    "multiple",
    "layer",
    "perceptron",
    "back",
    "propagation",
    "back",
    "propagation",
    "back",
    "propagation",
    "algorithm",
    "supervised",
    "learning",
    "method",
    "multilayer",
    "perceptrons",
    "okay",
    "need",
    "back",
    "propagation",
    "guys",
    "designing",
    "neural",
    "network",
    "beginning",
    "initialize",
    "weights",
    "random",
    "values",
    "variable",
    "fact",
    "obviously",
    "need",
    "make",
    "sure",
    "weights",
    "actually",
    "correct",
    "meaning",
    "weights",
    "show",
    "significance",
    "predictor",
    "variable",
    "weights",
    "fit",
    "model",
    "way",
    "output",
    "precise",
    "let",
    "say",
    "randomly",
    "selected",
    "weights",
    "beginning",
    "model",
    "output",
    "much",
    "different",
    "actual",
    "output",
    "meaning",
    "error",
    "value",
    "huge",
    "reduce",
    "error",
    "basically",
    "need",
    "need",
    "somehow",
    "explain",
    "model",
    "need",
    "change",
    "weight",
    "way",
    "error",
    "becomes",
    "minimum",
    "main",
    "thing",
    "weight",
    "error",
    "highly",
    "related",
    "weightage",
    "give",
    "input",
    "show",
    "much",
    "error",
    "output",
    "significant",
    "variables",
    "highest",
    "weightage",
    "weightage",
    "correct",
    "output",
    "also",
    "correct",
    "back",
    "propagation",
    "way",
    "update",
    "weights",
    "way",
    "outcome",
    "precise",
    "error",
    "reduced",
    "short",
    "back",
    "propagation",
    "used",
    "train",
    "multilayer",
    "perceptron",
    "basically",
    "use",
    "update",
    "weights",
    "way",
    "output",
    "precise",
    "error",
    "reduced",
    "training",
    "neural",
    "network",
    "back",
    "propagation",
    "common",
    "deep",
    "learning",
    "algorithm",
    "supervised",
    "training",
    "multilayer",
    "perceptron",
    "known",
    "back",
    "propagation",
    "calculating",
    "weighted",
    "sum",
    "inputs",
    "passing",
    "activation",
    "function",
    "propagate",
    "backwards",
    "update",
    "weights",
    "reduce",
    "error",
    "simple",
    "beginning",
    "going",
    "assign",
    "weights",
    "input",
    "inputs",
    "go",
    "activation",
    "function",
    "go",
    "hidden",
    "layers",
    "give",
    "us",
    "output",
    "get",
    "output",
    "output",
    "precise",
    "desired",
    "output",
    "propagate",
    "backwards",
    "start",
    "updating",
    "weights",
    "way",
    "error",
    "minimum",
    "possible",
    "going",
    "repeat",
    "idea",
    "behind",
    "back",
    "propagation",
    "choose",
    "weights",
    "way",
    "error",
    "gets",
    "minimized",
    "understand",
    "look",
    "small",
    "example",
    "let",
    "say",
    "data",
    "set",
    "labels",
    "okay",
    "input",
    "zero",
    "one",
    "two",
    "desired",
    "output",
    "zero",
    "one",
    "four",
    "output",
    "model",
    "w",
    "equal",
    "three",
    "like",
    "notice",
    "difference",
    "model",
    "output",
    "desired",
    "output",
    "model",
    "output",
    "three",
    "desired",
    "output",
    "two",
    "similarly",
    "model",
    "output",
    "six",
    "desired",
    "output",
    "supposed",
    "four",
    "let",
    "calculate",
    "error",
    "weight",
    "equal",
    "three",
    "error",
    "zero",
    "desired",
    "output",
    "zero",
    "model",
    "output",
    "also",
    "zero",
    "error",
    "second",
    "case",
    "one",
    "basically",
    "model",
    "output",
    "minus",
    "desired",
    "output",
    "three",
    "minus",
    "two",
    "error",
    "one",
    "similarly",
    "error",
    "third",
    "input",
    "two",
    "six",
    "minus",
    "four",
    "take",
    "square",
    "actually",
    "huge",
    "difference",
    "error",
    "becomes",
    "larger",
    "need",
    "need",
    "update",
    "weight",
    "value",
    "way",
    "error",
    "decreases",
    "considered",
    "weight",
    "four",
    "consider",
    "weight",
    "four",
    "model",
    "output",
    "becomes",
    "zero",
    "four",
    "eight",
    "desired",
    "output",
    "zero",
    "two",
    "four",
    "model",
    "output",
    "becomes",
    "zero",
    "four",
    "eight",
    "lot",
    "guys",
    "hope",
    "know",
    "calculate",
    "output",
    "multiplying",
    "input",
    "weightage",
    "weightage",
    "four",
    "zero",
    "four",
    "give",
    "zero",
    "one",
    "four",
    "give",
    "four",
    "two",
    "four",
    "give",
    "eight",
    "getting",
    "model",
    "output",
    "getting",
    "output",
    "calculate",
    "weightage",
    "see",
    "desire",
    "output",
    "supposed",
    "zero",
    "two",
    "four",
    "getting",
    "output",
    "zero",
    "four",
    "eight",
    "error",
    "actually",
    "increasing",
    "increase",
    "weight",
    "error",
    "four",
    "w",
    "equal",
    "four",
    "become",
    "zero",
    "four",
    "16",
    "whereas",
    "error",
    "w",
    "equal",
    "three",
    "zero",
    "one",
    "four",
    "mean",
    "square",
    "error",
    "look",
    "increase",
    "weightage",
    "error",
    "increasing",
    "obviously",
    "know",
    "point",
    "increasing",
    "value",
    "w",
    "decrease",
    "value",
    "w",
    "error",
    "actually",
    "decreases",
    "alright",
    "give",
    "weightage",
    "two",
    "error",
    "decreases",
    "find",
    "relationship",
    "weight",
    "error",
    "basically",
    "increase",
    "weight",
    "error",
    "also",
    "increases",
    "decrease",
    "weight",
    "error",
    "also",
    "decreases",
    "first",
    "initialize",
    "random",
    "value",
    "w",
    "propagated",
    "forward",
    "notice",
    "error",
    "reduce",
    "error",
    "propagated",
    "backwards",
    "increase",
    "value",
    "notice",
    "error",
    "increased",
    "came",
    "know",
    "ca",
    "increase",
    "w",
    "value",
    "obviously",
    "error",
    "increasing",
    "increasing",
    "weight",
    "increase",
    "weight",
    "propagated",
    "backwards",
    "decreased",
    "w",
    "value",
    "noticed",
    "error",
    "reduced",
    "trying",
    "trying",
    "get",
    "value",
    "weight",
    "way",
    "error",
    "becomes",
    "minimum",
    "possible",
    "need",
    "figure",
    "whether",
    "need",
    "increase",
    "decrease",
    "thew",
    "eight",
    "value",
    "know",
    "keep",
    "updating",
    "weight",
    "value",
    "direction",
    "error",
    "becomes",
    "minimum",
    "might",
    "reach",
    "point",
    "update",
    "weight",
    "error",
    "increase",
    "point",
    "need",
    "stop",
    "okay",
    "point",
    "final",
    "weight",
    "value",
    "basically",
    "graph",
    "denotes",
    "point",
    "point",
    "nothing",
    "global",
    "loss",
    "minimum",
    "update",
    "weights",
    "error",
    "also",
    "increase",
    "need",
    "find",
    "global",
    "loss",
    "minimum",
    "optimum",
    "weight",
    "lies",
    "let",
    "summarize",
    "steps",
    "first",
    "calculate",
    "error",
    "far",
    "model",
    "output",
    "actual",
    "output",
    "check",
    "whether",
    "error",
    "minimized",
    "error",
    "huge",
    "update",
    "weight",
    "check",
    "error",
    "repeat",
    "process",
    "error",
    "becomes",
    "minimum",
    "reach",
    "global",
    "loss",
    "minimum",
    "stop",
    "updating",
    "weights",
    "finalize",
    "weight",
    "value",
    "exactly",
    "back",
    "propagation",
    "works",
    "order",
    "tell",
    "mathematically",
    "using",
    "method",
    "known",
    "gradient",
    "descent",
    "okay",
    "method",
    "used",
    "adjust",
    "weights",
    "network",
    "aim",
    "reducing",
    "error",
    "output",
    "layer",
    "gradient",
    "descent",
    "optimize",
    "works",
    "first",
    "step",
    "calculate",
    "error",
    "considering",
    "equation",
    "subtracting",
    "summation",
    "actual",
    "output",
    "network",
    "output",
    "step",
    "two",
    "based",
    "error",
    "get",
    "calculate",
    "rate",
    "change",
    "error",
    "respect",
    "change",
    "weight",
    "learning",
    "rate",
    "something",
    "set",
    "beginning",
    "step",
    "three",
    "based",
    "change",
    "weight",
    "calculate",
    "new",
    "weight",
    "alright",
    "updated",
    "weight",
    "weight",
    "plus",
    "rate",
    "change",
    "weight",
    "guys",
    "back",
    "propagation",
    "weight",
    "update",
    "let",
    "look",
    "limitations",
    "feed",
    "forward",
    "network",
    "far",
    "discussing",
    "multiple",
    "layer",
    "perceptron",
    "uses",
    "feed",
    "forward",
    "network",
    "let",
    "discuss",
    "limitations",
    "feed",
    "forward",
    "networks",
    "let",
    "consider",
    "example",
    "image",
    "classification",
    "okay",
    "let",
    "say",
    "trained",
    "neural",
    "network",
    "classify",
    "images",
    "various",
    "animals",
    "let",
    "consider",
    "example",
    "first",
    "output",
    "elephant",
    "elephant",
    "output",
    "nothing",
    "previous",
    "output",
    "dog",
    "means",
    "output",
    "time",
    "independent",
    "output",
    "time",
    "minus",
    "one",
    "consider",
    "scenario",
    "require",
    "use",
    "previously",
    "obtained",
    "output",
    "okay",
    "concept",
    "similarly",
    "reading",
    "book",
    "turn",
    "every",
    "page",
    "need",
    "understanding",
    "previous",
    "pages",
    "want",
    "make",
    "sense",
    "information",
    "need",
    "know",
    "learned",
    "exactly",
    "right",
    "order",
    "understand",
    "deep",
    "learning",
    "understand",
    "machine",
    "learning",
    "basically",
    "feed",
    "forward",
    "network",
    "new",
    "output",
    "time",
    "plus",
    "one",
    "nothing",
    "output",
    "time",
    "minus",
    "one",
    "minus",
    "two",
    "feed",
    "forward",
    "networks",
    "used",
    "predicting",
    "word",
    "sentence",
    "absolutely",
    "relationship",
    "previous",
    "set",
    "words",
    "feed",
    "forward",
    "network",
    "used",
    "use",
    "cases",
    "wherein",
    "predict",
    "outcome",
    "based",
    "previous",
    "outcome",
    "lot",
    "use",
    "cases",
    "previous",
    "output",
    "also",
    "determine",
    "next",
    "output",
    "cases",
    "may",
    "make",
    "use",
    "feed",
    "forward",
    "network",
    "modification",
    "make",
    "network",
    "learn",
    "previous",
    "mistakes",
    "solution",
    "solution",
    "recurrent",
    "neural",
    "networks",
    "basically",
    "let",
    "say",
    "input",
    "time",
    "minus",
    "one",
    "get",
    "output",
    "feed",
    "network",
    "information",
    "input",
    "minus",
    "one",
    "fed",
    "next",
    "input",
    "input",
    "time",
    "information",
    "output",
    "fed",
    "next",
    "input",
    "input",
    "plus",
    "one",
    "basically",
    "keep",
    "feeding",
    "information",
    "previous",
    "input",
    "next",
    "input",
    "recurrent",
    "neural",
    "networks",
    "really",
    "work",
    "recurrent",
    "networks",
    "type",
    "artificial",
    "neural",
    "networks",
    "designed",
    "recognize",
    "patterns",
    "sequence",
    "data",
    "text",
    "genomes",
    "handwriting",
    "spoken",
    "words",
    "time",
    "series",
    "data",
    "sensors",
    "stock",
    "markets",
    "government",
    "agencies",
    "guys",
    "recurrent",
    "neural",
    "networks",
    "actually",
    "important",
    "part",
    "deep",
    "learning",
    "recurring",
    "neural",
    "networks",
    "applications",
    "lot",
    "domains",
    "okay",
    "time",
    "series",
    "stock",
    "markets",
    "main",
    "network",
    "use",
    "recurrent",
    "neural",
    "networks",
    "inputs",
    "correlated",
    "better",
    "understand",
    "recurrent",
    "neural",
    "networks",
    "let",
    "consider",
    "small",
    "example",
    "let",
    "say",
    "go",
    "gym",
    "regularly",
    "trainer",
    "given",
    "schedule",
    "workout",
    "basically",
    "exercises",
    "repeated",
    "every",
    "third",
    "day",
    "okay",
    "schedule",
    "looks",
    "like",
    "make",
    "note",
    "exercises",
    "repeated",
    "proper",
    "order",
    "sequence",
    "every",
    "week",
    "first",
    "let",
    "us",
    "use",
    "feedforward",
    "network",
    "try",
    "predict",
    "type",
    "exercises",
    "going",
    "inputs",
    "day",
    "week",
    "month",
    "health",
    "status",
    "okay",
    "neural",
    "network",
    "trained",
    "using",
    "inputs",
    "provide",
    "us",
    "prediction",
    "exercise",
    "let",
    "try",
    "understand",
    "thing",
    "using",
    "recurrent",
    "neural",
    "networks",
    "recurrent",
    "neural",
    "networks",
    "consider",
    "inputs",
    "previous",
    "day",
    "okay",
    "shoulder",
    "workout",
    "yesterday",
    "bicep",
    "exercise",
    "today",
    "goes",
    "rest",
    "week",
    "however",
    "happen",
    "miss",
    "day",
    "gym",
    "data",
    "previously",
    "attended",
    "time",
    "stamps",
    "considered",
    "done",
    "like",
    "model",
    "trained",
    "based",
    "data",
    "obtain",
    "previous",
    "exercise",
    "output",
    "model",
    "extremely",
    "accurate",
    "cases",
    "need",
    "know",
    "output",
    "minus",
    "one",
    "order",
    "predict",
    "output",
    "cases",
    "recurrent",
    "neural",
    "networks",
    "essential",
    "basically",
    "feeding",
    "inputs",
    "neural",
    "networks",
    "go",
    "functions",
    "get",
    "output",
    "basically",
    "predicting",
    "output",
    "based",
    "past",
    "information",
    "based",
    "past",
    "input",
    "recurrent",
    "neural",
    "networks",
    "work",
    "let",
    "look",
    "another",
    "type",
    "neural",
    "network",
    "known",
    "convolutional",
    "neural",
    "network",
    "understand",
    "need",
    "convolutional",
    "neural",
    "networks",
    "let",
    "look",
    "analogy",
    "think",
    "computer",
    "reads",
    "image",
    "consider",
    "image",
    "new",
    "york",
    "skyline",
    "image",
    "first",
    "glance",
    "see",
    "lot",
    "buildings",
    "lot",
    "colors",
    "computer",
    "process",
    "image",
    "image",
    "actually",
    "broken",
    "three",
    "color",
    "channels",
    "red",
    "green",
    "blue",
    "reads",
    "form",
    "rgb",
    "values",
    "color",
    "channels",
    "mapped",
    "image",
    "pixel",
    "computer",
    "recognize",
    "value",
    "associated",
    "pixel",
    "determine",
    "size",
    "image",
    "black",
    "white",
    "images",
    "one",
    "channel",
    "concept",
    "still",
    "thing",
    "make",
    "use",
    "fully",
    "connected",
    "networks",
    "comes",
    "convolutional",
    "neural",
    "networks",
    "tell",
    "consider",
    "first",
    "input",
    "image",
    "okay",
    "first",
    "image",
    "size",
    "28",
    "28",
    "three",
    "pixels",
    "input",
    "neural",
    "network",
    "get",
    "weights",
    "first",
    "hidden",
    "layer",
    "consider",
    "another",
    "example",
    "okay",
    "let",
    "say",
    "image",
    "200",
    "200",
    "three",
    "pixels",
    "size",
    "first",
    "hidden",
    "layer",
    "becomes",
    "around",
    "first",
    "hidden",
    "layer",
    "imagine",
    "number",
    "neurons",
    "need",
    "process",
    "entire",
    "complex",
    "image",
    "set",
    "leads",
    "something",
    "known",
    "overfitting",
    "hidden",
    "layers",
    "connected",
    "massively",
    "connected",
    "connection",
    "every",
    "node",
    "face",
    "overfitting",
    "way",
    "much",
    "data",
    "use",
    "way",
    "many",
    "neurons",
    "practical",
    "something",
    "known",
    "convolutional",
    "neural",
    "networks",
    "convolutional",
    "neural",
    "networks",
    "like",
    "neural",
    "network",
    "made",
    "neurons",
    "learnable",
    "weights",
    "basis",
    "neuron",
    "receives",
    "several",
    "input",
    "takes",
    "weighted",
    "sum",
    "gets",
    "passed",
    "activation",
    "function",
    "finally",
    "responds",
    "output",
    "concept",
    "convolutional",
    "neural",
    "networks",
    "neuron",
    "particular",
    "layer",
    "connected",
    "small",
    "region",
    "layer",
    "neurons",
    "connected",
    "manner",
    "leads",
    "overfitting",
    "need",
    "way",
    "many",
    "neurons",
    "solve",
    "problem",
    "regions",
    "significant",
    "connected",
    "full",
    "connection",
    "convolutional",
    "neural",
    "networks",
    "gus",
    "far",
    "discussed",
    "perceptron",
    "discussed",
    "different",
    "types",
    "neural",
    "networks",
    "discussed",
    "feedforward",
    "neural",
    "network",
    "discuss",
    "multi",
    "layer",
    "perceptrons",
    "discussed",
    "recurrent",
    "neural",
    "networks",
    "convolutional",
    "neural",
    "networks",
    "going",
    "go",
    "much",
    "depth",
    "concepts",
    "executing",
    "demo",
    "understood",
    "theoretical",
    "concept",
    "deep",
    "learning",
    "please",
    "let",
    "know",
    "comment",
    "section",
    "apart",
    "also",
    "leave",
    "couple",
    "links",
    "description",
    "box",
    "understand",
    "whole",
    "download",
    "better",
    "way",
    "okay",
    "want",
    "explanation",
    "leave",
    "couple",
    "links",
    "description",
    "box",
    "gon",
    "na",
    "running",
    "practical",
    "demonstration",
    "show",
    "exactly",
    "download",
    "basically",
    "going",
    "demo",
    "going",
    "predict",
    "stock",
    "prices",
    "like",
    "said",
    "stock",
    "price",
    "prediction",
    "one",
    "good",
    "applications",
    "deep",
    "neural",
    "networks",
    "easily",
    "predict",
    "stock",
    "price",
    "particular",
    "stock",
    "next",
    "minute",
    "next",
    "day",
    "using",
    "deep",
    "neural",
    "networks",
    "exactly",
    "gon",
    "na",
    "demo",
    "discuss",
    "code",
    "let",
    "tell",
    "things",
    "data",
    "set",
    "data",
    "set",
    "contains",
    "around",
    "minutes",
    "data",
    "ranging",
    "april",
    "august",
    "2017",
    "500",
    "stocks",
    "well",
    "total",
    "p",
    "500",
    "index",
    "price",
    "index",
    "stocks",
    "arranged",
    "wide",
    "format",
    "data",
    "set",
    "csv",
    "format",
    "gon",
    "na",
    "going",
    "use",
    "read",
    "csv",
    "function",
    "order",
    "import",
    "data",
    "set",
    "part",
    "data",
    "set",
    "stored",
    "data",
    "set",
    "actually",
    "cleaned",
    "prepared",
    "meaning",
    "missing",
    "stock",
    "index",
    "prices",
    "file",
    "contain",
    "missing",
    "values",
    "gon",
    "na",
    "first",
    "drop",
    "data",
    "valuable",
    "variable",
    "known",
    "date",
    "really",
    "necessary",
    "predicting",
    "outcome",
    "exactly",
    "dropping",
    "date",
    "variable",
    "checking",
    "dimensions",
    "data",
    "set",
    "pretty",
    "understandable",
    "using",
    "shape",
    "function",
    "always",
    "make",
    "data",
    "nympy",
    "array",
    "makes",
    "computation",
    "much",
    "easier",
    "next",
    "process",
    "data",
    "splicing",
    "already",
    "discussed",
    "data",
    "data",
    "splicing",
    "preparing",
    "training",
    "testing",
    "data",
    "training",
    "data",
    "contain",
    "80",
    "total",
    "data",
    "set",
    "okay",
    "also",
    "shuffling",
    "data",
    "set",
    "slicing",
    "data",
    "set",
    "sequentially",
    "test",
    "start",
    "start",
    "test",
    "end",
    "variable",
    "sequence",
    "selecting",
    "data",
    "need",
    "shuffling",
    "data",
    "set",
    "stock",
    "prices",
    "make",
    "sense",
    "shuffle",
    "data",
    "next",
    "step",
    "going",
    "going",
    "scale",
    "data",
    "scaling",
    "data",
    "data",
    "normalization",
    "one",
    "important",
    "steps",
    "miss",
    "step",
    "already",
    "mentioned",
    "earlier",
    "normalization",
    "scaling",
    "neural",
    "networks",
    "benefit",
    "scaling",
    "inputs",
    "common",
    "activation",
    "function",
    "networks",
    "neuron",
    "tan",
    "hedge",
    "sigmoid",
    "tan",
    "hedge",
    "sigmoid",
    "basically",
    "activation",
    "functions",
    "defined",
    "range",
    "minus",
    "one",
    "one",
    "zero",
    "one",
    "scaling",
    "important",
    "thing",
    "deep",
    "neural",
    "networks",
    "scaling",
    "use",
    "minmaxscaler",
    "importing",
    "function",
    "also",
    "one",
    "point",
    "note",
    "cautious",
    "part",
    "data",
    "scaling",
    "common",
    "mistake",
    "scale",
    "whole",
    "data",
    "set",
    "training",
    "test",
    "splits",
    "applied",
    "data",
    "splicing",
    "scaling",
    "data",
    "mistake",
    "scaling",
    "invokes",
    "calculation",
    "statistics",
    "example",
    "minimum",
    "maximum",
    "range",
    "variable",
    "gets",
    "affected",
    "performing",
    "time",
    "series",
    "forecasting",
    "real",
    "life",
    "information",
    "future",
    "observations",
    "time",
    "forecasting",
    "calculation",
    "scaling",
    "statistics",
    "conducted",
    "training",
    "data",
    "applied",
    "test",
    "data",
    "otherwise",
    "basically",
    "using",
    "future",
    "information",
    "time",
    "forecasting",
    "obviously",
    "going",
    "lead",
    "biasness",
    "need",
    "make",
    "sure",
    "scaling",
    "accurately",
    "basically",
    "number",
    "features",
    "training",
    "data",
    "stored",
    "variable",
    "known",
    "n",
    "stocks",
    "import",
    "infamous",
    "tensorflow",
    "guys",
    "tensorflow",
    "actually",
    "good",
    "piece",
    "software",
    "currently",
    "leading",
    "deep",
    "learning",
    "neural",
    "network",
    "computation",
    "framework",
    "based",
    "backend",
    "usually",
    "controlled",
    "python",
    "tensorflow",
    "actually",
    "operates",
    "graphical",
    "representation",
    "computations",
    "important",
    "neural",
    "networks",
    "actually",
    "graphs",
    "data",
    "mathematical",
    "operation",
    "tensorflow",
    "perfect",
    "neural",
    "networks",
    "deep",
    "learning",
    "next",
    "thing",
    "importing",
    "tensorflow",
    "library",
    "something",
    "known",
    "placeholders",
    "placeholders",
    "used",
    "store",
    "import",
    "target",
    "data",
    "need",
    "two",
    "placeholders",
    "order",
    "fit",
    "model",
    "basically",
    "x",
    "contain",
    "network",
    "input",
    "stock",
    "prices",
    "stocks",
    "time",
    "equal",
    "contain",
    "network",
    "output",
    "stock",
    "price",
    "time",
    "equal",
    "plus",
    "one",
    "shape",
    "x",
    "placeholder",
    "means",
    "inputs",
    "matrix",
    "outputs",
    "vector",
    "guys",
    "basically",
    "indicates",
    "point",
    "yet",
    "know",
    "number",
    "observations",
    "flow",
    "neural",
    "network",
    "keep",
    "flexible",
    "array",
    "later",
    "define",
    "variable",
    "batch",
    "size",
    "controls",
    "number",
    "observations",
    "training",
    "batch",
    "apart",
    "form",
    "also",
    "something",
    "know",
    "initializers",
    "tell",
    "initializers",
    "need",
    "understand",
    "something",
    "known",
    "variables",
    "used",
    "flexible",
    "containers",
    "allowed",
    "change",
    "execution",
    "weights",
    "bias",
    "represented",
    "variables",
    "order",
    "adapt",
    "training",
    "already",
    "discuss",
    "weights",
    "bias",
    "earlier",
    "weights",
    "bias",
    "something",
    "need",
    "initialize",
    "train",
    "model",
    "discussed",
    "even",
    "explaining",
    "neural",
    "networks",
    "basically",
    "make",
    "use",
    "something",
    "known",
    "variant",
    "scaling",
    "initializer",
    "bias",
    "initializer",
    "make",
    "use",
    "zeros",
    "initializers",
    "predefined",
    "functions",
    "tensorflow",
    "model",
    "get",
    "depth",
    "things",
    "let",
    "look",
    "model",
    "architecture",
    "parameters",
    "next",
    "thing",
    "discuss",
    "model",
    "architecture",
    "parameters",
    "model",
    "build",
    "consists",
    "four",
    "hidden",
    "layers",
    "first",
    "layer",
    "assigned",
    "neurons",
    "likely",
    "double",
    "size",
    "inputs",
    "subsequent",
    "hidden",
    "layers",
    "always",
    "half",
    "size",
    "previous",
    "layer",
    "means",
    "hidden",
    "layer",
    "number",
    "two",
    "512",
    "neurons",
    "hidden",
    "layer",
    "three",
    "similarly",
    "hidden",
    "layer",
    "number",
    "four",
    "128",
    "neurons",
    "keep",
    "reducing",
    "number",
    "neurons",
    "go",
    "hidden",
    "layer",
    "number",
    "neurons",
    "subsequent",
    "layer",
    "compresses",
    "information",
    "network",
    "identifies",
    "previous",
    "layer",
    "course",
    "possible",
    "network",
    "architectures",
    "apply",
    "problem",
    "statement",
    "trying",
    "keep",
    "simple",
    "possible",
    "introducing",
    "deep",
    "learning",
    "ca",
    "build",
    "model",
    "architecture",
    "complex",
    "hard",
    "explain",
    "course",
    "output",
    "assigned",
    "single",
    "neuron",
    "important",
    "understand",
    "variable",
    "dimensions",
    "input",
    "hidden",
    "output",
    "layers",
    "rule",
    "thumb",
    "multilayer",
    "perceptrons",
    "second",
    "dimension",
    "previous",
    "layer",
    "first",
    "dimension",
    "current",
    "layer",
    "second",
    "dimension",
    "first",
    "hidden",
    "layer",
    "going",
    "first",
    "dimension",
    "second",
    "hidden",
    "layer",
    "reason",
    "behind",
    "pretty",
    "logical",
    "output",
    "first",
    "hidden",
    "layer",
    "passed",
    "input",
    "second",
    "hidden",
    "layer",
    "second",
    "dimension",
    "previous",
    "layer",
    "first",
    "dimension",
    "next",
    "layer",
    "current",
    "layer",
    "hope",
    "understandable",
    "coming",
    "bias",
    "dimension",
    "bias",
    "dimension",
    "always",
    "equal",
    "second",
    "dimension",
    "current",
    "layer",
    "meaning",
    "going",
    "pass",
    "number",
    "neurons",
    "particular",
    "hidden",
    "layer",
    "dimension",
    "bias",
    "number",
    "neurons",
    "passing",
    "number",
    "parameter",
    "bias",
    "similarly",
    "even",
    "hidden",
    "layer",
    "number",
    "two",
    "see",
    "second",
    "dimension",
    "passing",
    "parameter",
    "well",
    "similarly",
    "hidden",
    "layer",
    "three",
    "hidden",
    "layer",
    "number",
    "four",
    "alright",
    "hope",
    "understandable",
    "come",
    "output",
    "layer",
    "output",
    "layer",
    "obviously",
    "output",
    "hidden",
    "layer",
    "number",
    "four",
    "output",
    "hidden",
    "layer",
    "four",
    "passed",
    "first",
    "dimension",
    "output",
    "layer",
    "finally",
    "n",
    "target",
    "set",
    "one",
    "output",
    "bias",
    "basically",
    "current",
    "layer",
    "dimension",
    "n",
    "target",
    "passing",
    "parameter",
    "define",
    "required",
    "weight",
    "bias",
    "variables",
    "architecture",
    "network",
    "specified",
    "placeholders",
    "variables",
    "need",
    "combined",
    "system",
    "sequential",
    "matrix",
    "multiplication",
    "exactly",
    "happening",
    "apart",
    "hidden",
    "layers",
    "need",
    "transformed",
    "using",
    "activation",
    "function",
    "activation",
    "functions",
    "important",
    "components",
    "network",
    "introduce",
    "system",
    "means",
    "high",
    "dimensional",
    "data",
    "dealt",
    "help",
    "activation",
    "functions",
    "obviously",
    "high",
    "dimensional",
    "data",
    "comes",
    "neural",
    "networks",
    "single",
    "dimension",
    "two",
    "three",
    "inputs",
    "thousands",
    "thousands",
    "inputs",
    "order",
    "neural",
    "network",
    "process",
    "much",
    "high",
    "dimensional",
    "data",
    "need",
    "something",
    "known",
    "activation",
    "functions",
    "make",
    "use",
    "activation",
    "functions",
    "dozens",
    "activation",
    "functions",
    "one",
    "common",
    "one",
    "rectified",
    "linear",
    "unit",
    "rectified",
    "linear",
    "unit",
    "relu",
    "nothing",
    "rectified",
    "linear",
    "unit",
    "gon",
    "na",
    "using",
    "model",
    "applied",
    "transformation",
    "function",
    "hidden",
    "layer",
    "need",
    "make",
    "sure",
    "output",
    "transposed",
    "followed",
    "important",
    "function",
    "known",
    "cost",
    "function",
    "cost",
    "function",
    "network",
    "used",
    "generate",
    "measure",
    "deviation",
    "network",
    "prediction",
    "actual",
    "observed",
    "training",
    "targets",
    "basically",
    "actual",
    "output",
    "minus",
    "model",
    "output",
    "basically",
    "calculates",
    "error",
    "actual",
    "output",
    "predicted",
    "output",
    "regression",
    "problems",
    "mean",
    "squared",
    "error",
    "function",
    "commonly",
    "used",
    "discussed",
    "msc",
    "mean",
    "squared",
    "error",
    "basically",
    "measuring",
    "deviation",
    "msc",
    "nothing",
    "bot",
    "deviation",
    "actual",
    "output",
    "exactly",
    "computed",
    "error",
    "next",
    "step",
    "obviously",
    "update",
    "weight",
    "bias",
    "something",
    "known",
    "optimizers",
    "basically",
    "take",
    "care",
    "necessary",
    "computations",
    "needed",
    "adapt",
    "network",
    "weight",
    "bias",
    "variables",
    "training",
    "phase",
    "exactly",
    "happening",
    "main",
    "function",
    "optimizer",
    "invoke",
    "something",
    "known",
    "gradient",
    "remember",
    "discussed",
    "gradient",
    "basically",
    "indicates",
    "direction",
    "weights",
    "bias",
    "changed",
    "training",
    "order",
    "minimize",
    "network",
    "cost",
    "function",
    "network",
    "error",
    "need",
    "figure",
    "whether",
    "need",
    "increase",
    "weight",
    "bias",
    "order",
    "decrease",
    "error",
    "way",
    "around",
    "need",
    "understand",
    "relationship",
    "error",
    "weight",
    "variable",
    "exactly",
    "optimizer",
    "invokes",
    "gradient",
    "give",
    "direction",
    "weights",
    "bias",
    "changed",
    "know",
    "optimizer",
    "model",
    "using",
    "something",
    "known",
    "adamoptimizer",
    "one",
    "current",
    "default",
    "optimizers",
    "deep",
    "learning",
    "adam",
    "basically",
    "stands",
    "adaptive",
    "moment",
    "estimation",
    "considered",
    "combination",
    "two",
    "popular",
    "optimizers",
    "called",
    "adagrad",
    "rmsprop",
    "let",
    "get",
    "depth",
    "optimizers",
    "main",
    "agenda",
    "understand",
    "logic",
    "behind",
    "deep",
    "learning",
    "go",
    "functions",
    "know",
    "predefined",
    "functions",
    "tensorflow",
    "takes",
    "care",
    "next",
    "something",
    "known",
    "initializers",
    "initializers",
    "used",
    "initialize",
    "network",
    "variables",
    "training",
    "already",
    "discussed",
    "define",
    "initializer",
    "already",
    "done",
    "earlier",
    "session",
    "initializers",
    "already",
    "defined",
    "removed",
    "line",
    "code",
    "next",
    "step",
    "would",
    "fitting",
    "neural",
    "network",
    "defined",
    "place",
    "holders",
    "variables",
    "variables",
    "basically",
    "weights",
    "bias",
    "initializers",
    "cost",
    "functions",
    "optimizers",
    "network",
    "model",
    "trained",
    "usually",
    "done",
    "using",
    "mini",
    "batch",
    "training",
    "method",
    "huge",
    "data",
    "set",
    "always",
    "best",
    "use",
    "mini",
    "batch",
    "training",
    "method",
    "happens",
    "mini",
    "batch",
    "training",
    "random",
    "data",
    "samples",
    "batch",
    "size",
    "drawn",
    "training",
    "data",
    "fed",
    "network",
    "training",
    "data",
    "set",
    "gets",
    "divided",
    "n",
    "divided",
    "batch",
    "size",
    "batches",
    "sequentially",
    "fed",
    "network",
    "one",
    "batches",
    "fed",
    "network",
    "point",
    "placeholder",
    "x",
    "come",
    "play",
    "store",
    "input",
    "target",
    "data",
    "present",
    "network",
    "inputs",
    "targets",
    "main",
    "functionality",
    "placeholders",
    "store",
    "input",
    "target",
    "data",
    "provide",
    "network",
    "inputs",
    "targets",
    "exactly",
    "placeholders",
    "let",
    "say",
    "sample",
    "data",
    "batch",
    "data",
    "batch",
    "flows",
    "network",
    "reaches",
    "output",
    "layer",
    "tensorflow",
    "compares",
    "model",
    "predictions",
    "actual",
    "observed",
    "targets",
    "stored",
    "remember",
    "stored",
    "actual",
    "observed",
    "targets",
    "tensorflow",
    "conduct",
    "something",
    "known",
    "optimization",
    "step",
    "update",
    "network",
    "parameters",
    "like",
    "weight",
    "network",
    "bias",
    "update",
    "weight",
    "bias",
    "next",
    "batch",
    "sampled",
    "process",
    "gets",
    "repeated",
    "procedure",
    "continue",
    "batches",
    "presented",
    "network",
    "one",
    "full",
    "sweep",
    "batches",
    "known",
    "epoch",
    "defined",
    "entire",
    "thing",
    "gon",
    "na",
    "go",
    "10",
    "epochs",
    "meaning",
    "batches",
    "going",
    "go",
    "training",
    "meaning",
    "going",
    "input",
    "batch",
    "x",
    "flow",
    "network",
    "reaches",
    "output",
    "layer",
    "happens",
    "tensorflow",
    "compare",
    "predictions",
    "basically",
    "model",
    "predicted",
    "actual",
    "observed",
    "targets",
    "stored",
    "tensorflow",
    "perform",
    "optimization",
    "wherein",
    "update",
    "network",
    "paramters",
    "like",
    "weight",
    "bias",
    "update",
    "weight",
    "bias",
    "next",
    "batch",
    "get",
    "sampled",
    "process",
    "keep",
    "repeating",
    "happens",
    "batches",
    "implemented",
    "network",
    "told",
    "one",
    "epoch",
    "going",
    "repeat",
    "10",
    "times",
    "batch",
    "size",
    "256",
    "meaning",
    "256",
    "batches",
    "going",
    "assign",
    "x",
    "spoke",
    "mini",
    "batch",
    "training",
    "starts",
    "basically",
    "first",
    "batch",
    "start",
    "flowing",
    "network",
    "reaches",
    "output",
    "layer",
    "tensorflow",
    "compare",
    "model",
    "prediction",
    "predictions",
    "happen",
    "compare",
    "model",
    "prediction",
    "actual",
    "observed",
    "targets",
    "stored",
    "tensorflow",
    "start",
    "optimization",
    "update",
    "network",
    "paramters",
    "like",
    "weight",
    "bias",
    "update",
    "weight",
    "biases",
    "next",
    "batch",
    "get",
    "input",
    "network",
    "process",
    "keep",
    "repeating",
    "process",
    "repeat",
    "10",
    "times",
    "defined",
    "10",
    "epochs",
    "also",
    "training",
    "evaluate",
    "network",
    "prediction",
    "test",
    "set",
    "basically",
    "data",
    "learned",
    "data",
    "set",
    "aside",
    "every",
    "fifth",
    "batch",
    "visualized",
    "problem",
    "statement",
    "network",
    "going",
    "going",
    "predict",
    "stock",
    "price",
    "continuously",
    "time",
    "period",
    "plus",
    "one",
    "feeding",
    "data",
    "stock",
    "price",
    "time",
    "going",
    "give",
    "us",
    "output",
    "time",
    "plus",
    "one",
    "let",
    "run",
    "code",
    "let",
    "see",
    "close",
    "predicted",
    "values",
    "actual",
    "values",
    "going",
    "visualize",
    "entire",
    "thing",
    "also",
    "exported",
    "order",
    "combine",
    "video",
    "animation",
    "show",
    "video",
    "looks",
    "like",
    "let",
    "look",
    "visualization",
    "look",
    "output",
    "orange",
    "basically",
    "shows",
    "model",
    "prediction",
    "model",
    "quickly",
    "learns",
    "shape",
    "location",
    "time",
    "series",
    "test",
    "data",
    "showing",
    "us",
    "accurate",
    "prediction",
    "pretty",
    "close",
    "actual",
    "prediction",
    "explaining",
    "batch",
    "running",
    "epoch",
    "two",
    "10",
    "epochs",
    "go",
    "see",
    "network",
    "actually",
    "adapting",
    "basic",
    "shape",
    "time",
    "series",
    "learning",
    "finer",
    "patterns",
    "data",
    "see",
    "keeps",
    "learning",
    "patterns",
    "production",
    "getting",
    "closer",
    "closer",
    "every",
    "epoch",
    "let",
    "wait",
    "til",
    "reach",
    "epoch",
    "10",
    "complete",
    "entire",
    "process",
    "guys",
    "think",
    "predictions",
    "pretty",
    "close",
    "like",
    "pattern",
    "shape",
    "learned",
    "well",
    "neural",
    "network",
    "actually",
    "mimicking",
    "network",
    "deviation",
    "values",
    "apart",
    "learning",
    "shape",
    "time",
    "series",
    "data",
    "almost",
    "way",
    "shape",
    "exactly",
    "looks",
    "similar",
    "also",
    "remember",
    "lot",
    "ways",
    "improving",
    "result",
    "change",
    "design",
    "layers",
    "change",
    "number",
    "neurons",
    "choose",
    "different",
    "initialization",
    "functions",
    "activation",
    "functions",
    "introduce",
    "something",
    "known",
    "dropout",
    "layers",
    "basically",
    "help",
    "get",
    "rid",
    "overfitting",
    "also",
    "something",
    "known",
    "early",
    "stopping",
    "early",
    "stopping",
    "helps",
    "understand",
    "must",
    "stop",
    "batch",
    "training",
    "also",
    "another",
    "method",
    "implement",
    "improving",
    "model",
    "also",
    "different",
    "types",
    "deep",
    "learning",
    "model",
    "use",
    "problem",
    "use",
    "feedforward",
    "network",
    "basically",
    "means",
    "batches",
    "flow",
    "left",
    "right",
    "okay",
    "10",
    "epochs",
    "final",
    "thing",
    "getting",
    "calculate",
    "error",
    "msc",
    "mean",
    "squared",
    "error",
    "guys",
    "worry",
    "warning",
    "warning",
    "mean",
    "square",
    "error",
    "comes",
    "pretty",
    "low",
    "target",
    "scaled",
    "means",
    "accuracy",
    "pretty",
    "good",
    "guys",
    "like",
    "mentioned",
    "want",
    "improve",
    "accuracy",
    "model",
    "use",
    "different",
    "schemes",
    "use",
    "different",
    "initialization",
    "functions",
    "try",
    "different",
    "transformation",
    "functions",
    "use",
    "something",
    "known",
    "dropout",
    "technique",
    "early",
    "stopping",
    "order",
    "make",
    "training",
    "phase",
    "even",
    "better",
    "guys",
    "end",
    "deep",
    "learning",
    "demo",
    "hope",
    "understood",
    "deep",
    "learning",
    "demo",
    "learning",
    "deep",
    "learning",
    "first",
    "time",
    "might",
    "little",
    "confusing",
    "doubts",
    "regarding",
    "demo",
    "let",
    "know",
    "comment",
    "section",
    "also",
    "leave",
    "couple",
    "links",
    "description",
    "box",
    "understand",
    "deep",
    "learning",
    "little",
    "depth",
    "let",
    "look",
    "final",
    "topic",
    "today",
    "natural",
    "language",
    "processing",
    "understand",
    "text",
    "mining",
    "natural",
    "language",
    "processing",
    "understand",
    "need",
    "text",
    "mining",
    "natural",
    "language",
    "processing",
    "guys",
    "number",
    "one",
    "reason",
    "need",
    "text",
    "mining",
    "natural",
    "language",
    "processing",
    "amount",
    "data",
    "generating",
    "time",
    "like",
    "mentioned",
    "earlier",
    "around",
    "quintillion",
    "bytes",
    "data",
    "created",
    "every",
    "day",
    "number",
    "going",
    "grow",
    "evolution",
    "communication",
    "social",
    "media",
    "generate",
    "tons",
    "tons",
    "data",
    "numbers",
    "screen",
    "numbers",
    "literally",
    "every",
    "minute",
    "instagram",
    "every",
    "minute",
    "million",
    "pictures",
    "posted",
    "okay",
    "million",
    "pictures",
    "posted",
    "similarly",
    "tweets",
    "around",
    "tweets",
    "every",
    "minute",
    "twitter",
    "actually",
    "lot",
    "lot",
    "data",
    "every",
    "time",
    "using",
    "phone",
    "generating",
    "way",
    "much",
    "data",
    "watching",
    "video",
    "youtube",
    "generating",
    "lot",
    "data",
    "sending",
    "text",
    "messages",
    "whatsapp",
    "also",
    "generating",
    "tons",
    "tons",
    "data",
    "problem",
    "data",
    "generation",
    "problem",
    "data",
    "generating",
    "21",
    "data",
    "structured",
    "remaining",
    "data",
    "unstructured",
    "major",
    "source",
    "unstructured",
    "data",
    "include",
    "text",
    "messages",
    "whatsapp",
    "facebook",
    "likes",
    "comments",
    "instagram",
    "bulk",
    "emails",
    "send",
    "ever",
    "single",
    "day",
    "accounts",
    "unstructured",
    "data",
    "today",
    "question",
    "done",
    "much",
    "data",
    "data",
    "generate",
    "used",
    "grow",
    "businesses",
    "analyzing",
    "mining",
    "data",
    "add",
    "value",
    "business",
    "exactly",
    "text",
    "mining",
    "text",
    "mining",
    "text",
    "analytics",
    "analysis",
    "data",
    "available",
    "us",
    "spoken",
    "written",
    "language",
    "amazing",
    "much",
    "data",
    "generate",
    "actually",
    "used",
    "text",
    "mining",
    "data",
    "word",
    "word",
    "documents",
    "powerpoints",
    "chat",
    "messages",
    "emails",
    "used",
    "add",
    "value",
    "business",
    "data",
    "get",
    "sources",
    "like",
    "social",
    "media",
    "iot",
    "mainly",
    "unstructured",
    "unstructured",
    "data",
    "used",
    "draw",
    "useful",
    "insights",
    "grow",
    "business",
    "exactly",
    "need",
    "text",
    "mining",
    "text",
    "mining",
    "text",
    "analytics",
    "process",
    "deriving",
    "meaningful",
    "information",
    "natural",
    "language",
    "text",
    "data",
    "generate",
    "text",
    "messages",
    "emails",
    "documents",
    "files",
    "written",
    "natural",
    "language",
    "text",
    "going",
    "use",
    "text",
    "mining",
    "natural",
    "language",
    "processing",
    "draw",
    "useful",
    "insights",
    "patterns",
    "data",
    "let",
    "look",
    "examples",
    "show",
    "natural",
    "language",
    "processing",
    "text",
    "mining",
    "used",
    "move",
    "want",
    "compare",
    "text",
    "mining",
    "nlp",
    "lot",
    "might",
    "confused",
    "exactly",
    "text",
    "mining",
    "related",
    "natural",
    "language",
    "processing",
    "lot",
    "people",
    "also",
    "asked",
    "nlp",
    "text",
    "mining",
    "considered",
    "one",
    "thing",
    "basically",
    "text",
    "mining",
    "vast",
    "field",
    "makes",
    "use",
    "natural",
    "language",
    "processing",
    "derive",
    "high",
    "quality",
    "information",
    "text",
    "basically",
    "text",
    "mining",
    "process",
    "natural",
    "language",
    "processing",
    "method",
    "used",
    "carry",
    "text",
    "mining",
    "way",
    "say",
    "text",
    "mining",
    "vast",
    "field",
    "uses",
    "nlp",
    "order",
    "perform",
    "text",
    "analysis",
    "text",
    "mining",
    "nlp",
    "part",
    "text",
    "mining",
    "let",
    "understand",
    "exactly",
    "natural",
    "language",
    "processing",
    "natural",
    "language",
    "processing",
    "component",
    "text",
    "mining",
    "basically",
    "helps",
    "machine",
    "reading",
    "text",
    "obviously",
    "machines",
    "actually",
    "known",
    "english",
    "french",
    "interpret",
    "data",
    "form",
    "zeroes",
    "ones",
    "natural",
    "language",
    "processing",
    "comes",
    "nlp",
    "computers",
    "smart",
    "phones",
    "use",
    "understand",
    "language",
    "spoken",
    "written",
    "language",
    "use",
    "language",
    "interact",
    "device",
    "nlp",
    "became",
    "integral",
    "part",
    "life",
    "nlp",
    "uses",
    "concepts",
    "computer",
    "science",
    "artificial",
    "intelligence",
    "study",
    "data",
    "derive",
    "useful",
    "information",
    "move",
    "let",
    "look",
    "applications",
    "nlp",
    "text",
    "mining",
    "spend",
    "lot",
    "time",
    "surfing",
    "webs",
    "ever",
    "notice",
    "start",
    "typing",
    "word",
    "google",
    "immediately",
    "get",
    "suggestions",
    "like",
    "feature",
    "also",
    "known",
    "auto",
    "complete",
    "basically",
    "suggest",
    "rest",
    "word",
    "also",
    "something",
    "known",
    "spam",
    "detection",
    "example",
    "google",
    "recognizes",
    "misspelling",
    "netflix",
    "shows",
    "results",
    "keywords",
    "match",
    "misspelling",
    "spam",
    "detection",
    "also",
    "based",
    "concepts",
    "text",
    "mining",
    "natural",
    "language",
    "processing",
    "next",
    "predictive",
    "typing",
    "spell",
    "checkers",
    "features",
    "like",
    "auto",
    "correct",
    "email",
    "classification",
    "applications",
    "text",
    "mining",
    "nlp",
    "look",
    "couple",
    "applications",
    "natural",
    "language",
    "processing",
    "something",
    "known",
    "sentimental",
    "analysis",
    "sentimental",
    "analysis",
    "extremely",
    "useful",
    "social",
    "media",
    "monitoring",
    "allows",
    "us",
    "gain",
    "overview",
    "wider",
    "public",
    "opinion",
    "behind",
    "certain",
    "topics",
    "basically",
    "sentimental",
    "analysis",
    "used",
    "understand",
    "public",
    "opinion",
    "customer",
    "opinion",
    "certain",
    "product",
    "certain",
    "topic",
    "sentimental",
    "analysis",
    "actually",
    "huge",
    "part",
    "lot",
    "social",
    "media",
    "platforms",
    "like",
    "twitter",
    "facebook",
    "use",
    "sentimental",
    "analysis",
    "frequently",
    "something",
    "known",
    "chatbot",
    "chatbots",
    "basically",
    "solutions",
    "consumer",
    "frustration",
    "regarding",
    "customer",
    "call",
    "assistance",
    "companies",
    "like",
    "pizza",
    "hut",
    "uber",
    "started",
    "using",
    "chatbots",
    "provide",
    "good",
    "customer",
    "service",
    "apart",
    "form",
    "speech",
    "recognition",
    "nlp",
    "widely",
    "used",
    "speech",
    "recognition",
    "aware",
    "alexa",
    "siri",
    "google",
    "assistant",
    "cortana",
    "applications",
    "natural",
    "language",
    "processing",
    "machine",
    "translation",
    "another",
    "important",
    "application",
    "nlp",
    "example",
    "google",
    "translator",
    "uses",
    "nlp",
    "process",
    "translate",
    "one",
    "language",
    "application",
    "include",
    "spell",
    "checkers",
    "keywords",
    "search",
    "information",
    "extraction",
    "nlp",
    "used",
    "get",
    "useful",
    "information",
    "various",
    "website",
    "word",
    "documents",
    "files",
    "et",
    "cetera",
    "also",
    "used",
    "advertisement",
    "matching",
    "basically",
    "means",
    "recommendation",
    "ads",
    "based",
    "history",
    "basic",
    "understanding",
    "natural",
    "language",
    "processing",
    "used",
    "exactly",
    "let",
    "take",
    "look",
    "important",
    "concepts",
    "firstly",
    "gon",
    "na",
    "discuss",
    "tokenization",
    "tokenization",
    "mos",
    "basic",
    "step",
    "text",
    "mining",
    "tokenization",
    "basically",
    "means",
    "breaking",
    "data",
    "smaller",
    "chunks",
    "tokens",
    "easily",
    "analyzed",
    "tokenization",
    "works",
    "works",
    "breaking",
    "complex",
    "sentence",
    "words",
    "breaking",
    "huge",
    "sentence",
    "words",
    "understand",
    "importance",
    "word",
    "respect",
    "whole",
    "sentence",
    "produce",
    "description",
    "input",
    "sentence",
    "example",
    "let",
    "say",
    "sentence",
    "tokens",
    "simple",
    "apply",
    "tokenization",
    "sentence",
    "get",
    "breaking",
    "sentence",
    "words",
    "understanding",
    "importance",
    "words",
    "perform",
    "nlp",
    "process",
    "words",
    "understand",
    "important",
    "word",
    "entire",
    "sentence",
    "think",
    "tokens",
    "simple",
    "important",
    "words",
    "basically",
    "another",
    "stop",
    "word",
    "discussing",
    "stop",
    "words",
    "slides",
    "eed",
    "understand",
    "tokenization",
    "simple",
    "process",
    "involves",
    "breaking",
    "sentences",
    "words",
    "next",
    "something",
    "known",
    "stemming",
    "stemming",
    "basically",
    "normalizing",
    "words",
    "base",
    "form",
    "root",
    "form",
    "take",
    "look",
    "example",
    "words",
    "like",
    "detection",
    "detecting",
    "detected",
    "detections",
    "know",
    "root",
    "word",
    "words",
    "detect",
    "basically",
    "words",
    "mean",
    "detect",
    "stemming",
    "algorithm",
    "works",
    "cutting",
    "end",
    "beginning",
    "word",
    "taking",
    "account",
    "list",
    "common",
    "prefixes",
    "suffixes",
    "found",
    "word",
    "guys",
    "stemming",
    "successful",
    "cases",
    "always",
    "lot",
    "people",
    "affirm",
    "stemming",
    "lot",
    "limitations",
    "order",
    "overcome",
    "limitations",
    "stemming",
    "something",
    "known",
    "lemmatization",
    "lemmatization",
    "takes",
    "consideration",
    "morphological",
    "analysis",
    "words",
    "necessary",
    "detailed",
    "dictionary",
    "algorithm",
    "look",
    "link",
    "form",
    "back",
    "lemma",
    "basically",
    "lemmatization",
    "also",
    "quite",
    "similar",
    "stemming",
    "maps",
    "different",
    "words",
    "one",
    "common",
    "root",
    "sometimes",
    "happens",
    "stemming",
    "words",
    "gets",
    "cut",
    "let",
    "say",
    "wanted",
    "cut",
    "detection",
    "detect",
    "sometimes",
    "becomes",
    "det",
    "becomes",
    "tect",
    "something",
    "like",
    "grammar",
    "importance",
    "word",
    "goes",
    "away",
    "know",
    "words",
    "mean",
    "anymore",
    "due",
    "indiscriminate",
    "cutting",
    "word",
    "sometimes",
    "grammar",
    "understanding",
    "word",
    "anymore",
    "lemmatization",
    "introduced",
    "output",
    "lemmatization",
    "always",
    "going",
    "proper",
    "word",
    "okay",
    "going",
    "something",
    "half",
    "cut",
    "anything",
    "like",
    "going",
    "understand",
    "morphological",
    "analysis",
    "going",
    "perform",
    "lemmatization",
    "example",
    "lemmatizer",
    "going",
    "convert",
    "gone",
    "going",
    "went",
    "go",
    "three",
    "words",
    "anyway",
    "mean",
    "thing",
    "going",
    "convert",
    "go",
    "removing",
    "first",
    "last",
    "part",
    "word",
    "understanding",
    "grammar",
    "behind",
    "word",
    "understanding",
    "english",
    "morphological",
    "analysis",
    "word",
    "going",
    "perform",
    "lemmatization",
    "lemmatization",
    "stop",
    "words",
    "basically",
    "set",
    "commonly",
    "used",
    "words",
    "language",
    "english",
    "reason",
    "stop",
    "words",
    "critical",
    "many",
    "applications",
    "remove",
    "words",
    "commonly",
    "used",
    "given",
    "language",
    "finally",
    "focus",
    "important",
    "words",
    "example",
    "context",
    "search",
    "engine",
    "let",
    "say",
    "open",
    "google",
    "try",
    "make",
    "strawberry",
    "milkshake",
    "search",
    "engine",
    "going",
    "going",
    "find",
    "lot",
    "pages",
    "contain",
    "terms",
    "make",
    "rather",
    "pages",
    "contain",
    "recipe",
    "strawberry",
    "milkshake",
    "disregard",
    "terms",
    "search",
    "engine",
    "actually",
    "focus",
    "strawberry",
    "milkshake",
    "recipe",
    "instead",
    "looking",
    "pages",
    "need",
    "remove",
    "stop",
    "words",
    "stop",
    "words",
    "begin",
    "gone",
    "various",
    "stop",
    "words",
    "necessarily",
    "important",
    "understand",
    "importance",
    "sentence",
    "get",
    "rid",
    "commonly",
    "used",
    "words",
    "focus",
    "actual",
    "keywords",
    "another",
    "term",
    "need",
    "understand",
    "document",
    "term",
    "matrix",
    "document",
    "term",
    "matrix",
    "basically",
    "matrix",
    "documents",
    "designated",
    "roles",
    "words",
    "columns",
    "document",
    "one",
    "sentence",
    "fun",
    "word",
    "fun",
    "going",
    "get",
    "one",
    "one",
    "one",
    "document",
    "two",
    "see",
    "fun",
    "document",
    "term",
    "matrix",
    "basically",
    "understand",
    "whether",
    "document",
    "contains",
    "words",
    "frequency",
    "matrix",
    "document",
    "term",
    "matrix",
    "let",
    "move",
    "look",
    "natural",
    "language",
    "processing",
    "demo",
    "gon",
    "na",
    "gon",
    "na",
    "perform",
    "sentimental",
    "analysis",
    "like",
    "said",
    "sentimental",
    "analysis",
    "one",
    "popular",
    "applications",
    "natural",
    "language",
    "processing",
    "refers",
    "processing",
    "determining",
    "whether",
    "given",
    "piece",
    "text",
    "given",
    "sentence",
    "text",
    "positive",
    "negative",
    "variations",
    "consider",
    "sentence",
    "also",
    "neutral",
    "third",
    "option",
    "technique",
    "commonly",
    "used",
    "discover",
    "people",
    "feel",
    "particular",
    "topic",
    "people",
    "opinion",
    "particular",
    "topic",
    "mainly",
    "used",
    "analyze",
    "sentiments",
    "users",
    "various",
    "forms",
    "marketing",
    "campaigns",
    "social",
    "media",
    "websites",
    "performing",
    "sentimental",
    "analysis",
    "using",
    "python",
    "going",
    "perform",
    "natural",
    "language",
    "processing",
    "using",
    "naivebayesclassifier",
    "importing",
    "naivebayesclassifier",
    "guys",
    "python",
    "provides",
    "library",
    "known",
    "natural",
    "language",
    "toolkit",
    "library",
    "contains",
    "functions",
    "needed",
    "perform",
    "natural",
    "language",
    "processing",
    "also",
    "library",
    "predefined",
    "data",
    "set",
    "called",
    "movie",
    "reviews",
    "gon",
    "na",
    "going",
    "download",
    "nltk",
    "natural",
    "language",
    "toolkit",
    "basically",
    "going",
    "run",
    "analysis",
    "movie",
    "review",
    "data",
    "set",
    "exactly",
    "defining",
    "function",
    "order",
    "extract",
    "features",
    "function",
    "going",
    "extract",
    "words",
    "extracted",
    "data",
    "need",
    "train",
    "using",
    "movie",
    "reviews",
    "data",
    "set",
    "downloaded",
    "going",
    "understand",
    "positive",
    "words",
    "negative",
    "words",
    "loading",
    "positive",
    "negative",
    "reviews",
    "loading",
    "separate",
    "positive",
    "features",
    "negative",
    "features",
    "pretty",
    "understandable",
    "next",
    "split",
    "data",
    "training",
    "testing",
    "set",
    "something",
    "demos",
    "also",
    "known",
    "data",
    "splicing",
    "also",
    "set",
    "threshold",
    "factor",
    "basically",
    "means",
    "80",
    "data",
    "set",
    "belong",
    "training",
    "20",
    "testing",
    "going",
    "even",
    "positive",
    "negative",
    "words",
    "extracting",
    "features",
    "printing",
    "number",
    "training",
    "data",
    "points",
    "printing",
    "length",
    "training",
    "features",
    "printing",
    "length",
    "testing",
    "features",
    "see",
    "output",
    "let",
    "run",
    "program",
    "see",
    "getting",
    "number",
    "training",
    "data",
    "points",
    "number",
    "testing",
    "data",
    "points",
    "400",
    "80",
    "20",
    "ration",
    "using",
    "naivebayesclassifier",
    "define",
    "object",
    "naivebayesclassifier",
    "basically",
    "classifier",
    "train",
    "using",
    "training",
    "data",
    "set",
    "also",
    "look",
    "accuracy",
    "model",
    "accuracy",
    "classifier",
    "around",
    "73",
    "really",
    "good",
    "number",
    "classifier",
    "object",
    "actually",
    "contain",
    "informative",
    "words",
    "obtained",
    "analysis",
    "words",
    "basically",
    "essential",
    "understanding",
    "word",
    "classified",
    "positive",
    "classified",
    "negative",
    "going",
    "review",
    "movies",
    "going",
    "see",
    "movie",
    "review",
    "positive",
    "movie",
    "review",
    "negative",
    "classifier",
    "basically",
    "informative",
    "words",
    "help",
    "us",
    "decide",
    "positive",
    "review",
    "negative",
    "review",
    "printing",
    "10",
    "informative",
    "words",
    "outstanding",
    "insulting",
    "vulnerable",
    "ludicrous",
    "uninvolving",
    "avoids",
    "fascination",
    "important",
    "words",
    "text",
    "gon",
    "na",
    "gon",
    "na",
    "test",
    "model",
    "randomly",
    "given",
    "reviews",
    "want",
    "let",
    "add",
    "another",
    "review",
    "say",
    "loved",
    "movie",
    "added",
    "another",
    "review",
    "printing",
    "review",
    "checking",
    "positive",
    "review",
    "negative",
    "review",
    "let",
    "look",
    "predictions",
    "save",
    "forgot",
    "put",
    "comma",
    "save",
    "let",
    "run",
    "file",
    "randomly",
    "written",
    "movie",
    "reviews",
    "predicted",
    "sentiment",
    "positive",
    "probability",
    "score",
    "pretty",
    "accurate",
    "dull",
    "movie",
    "would",
    "never",
    "recommend",
    "negative",
    "sentiment",
    "cinematography",
    "pretty",
    "great",
    "positive",
    "review",
    "movie",
    "pathetic",
    "obviously",
    "negative",
    "review",
    "direction",
    "terrible",
    "story",
    "place",
    "also",
    "considered",
    "negative",
    "review",
    "similarly",
    "love",
    "movie",
    "inputted",
    "got",
    "positive",
    "review",
    "classifier",
    "actually",
    "works",
    "really",
    "well",
    "giving",
    "us",
    "good",
    "accuracy",
    "classifying",
    "sentiments",
    "accurately",
    "guys",
    "sentimental",
    "analysis",
    "basically",
    "saw",
    "movie",
    "review",
    "positive",
    "negative",
    "guys",
    "nlp",
    "demo",
    "hope",
    "understood",
    "simple",
    "sentimental",
    "analysis",
    "saw",
    "python",
    "doubts",
    "please",
    "leave",
    "comment",
    "section",
    "help",
    "queries",
    "guys",
    "last",
    "module",
    "natural",
    "language",
    "processing",
    "end",
    "today",
    "session",
    "would",
    "like",
    "discuss",
    "machine",
    "learning",
    "engineers",
    "program",
    "edureka",
    "aware",
    "demand",
    "machine",
    "learning",
    "engineer",
    "edureka",
    "master",
    "program",
    "involves",
    "hours",
    "interactive",
    "training",
    "machine",
    "learning",
    "master",
    "program",
    "edureka",
    "around",
    "nine",
    "modules",
    "hours",
    "interactive",
    "learning",
    "let",
    "tell",
    "curriculum",
    "course",
    "provides",
    "first",
    "module",
    "basically",
    "cover",
    "python",
    "programming",
    "basics",
    "data",
    "visualization",
    "gui",
    "programming",
    "functions",
    "concepts",
    "second",
    "module",
    "cover",
    "machine",
    "learning",
    "python",
    "supervise",
    "algorithms",
    "unsupervised",
    "algorithms",
    "along",
    "statistics",
    "time",
    "series",
    "python",
    "covered",
    "second",
    "module",
    "third",
    "module",
    "graphical",
    "modeling",
    "quite",
    "important",
    "ti",
    "comes",
    "machine",
    "learning",
    "taught",
    "decision",
    "making",
    "graph",
    "theory",
    "inference",
    "bayesian",
    "markov",
    "network",
    "module",
    "number",
    "four",
    "cover",
    "reinforcement",
    "learning",
    "depth",
    "understanding",
    "dynamic",
    "programming",
    "temporal",
    "difference",
    "bellman",
    "equations",
    "concepts",
    "reinforcement",
    "learning",
    "depth",
    "detail",
    "advance",
    "concepts",
    "reinforcement",
    "learning",
    "module",
    "number",
    "five",
    "cover",
    "nlp",
    "python",
    "understand",
    "tokenization",
    "stemming",
    "lemmatization",
    "syntax",
    "tree",
    "parsing",
    "module",
    "number",
    "six",
    "module",
    "six",
    "artificial",
    "intelligence",
    "deep",
    "learning",
    "tensorflow",
    "module",
    "advanced",
    "version",
    "machine",
    "learning",
    "reinforcement",
    "learning",
    "learn",
    "deep",
    "learning",
    "depth",
    "using",
    "tensorflow",
    "throughout",
    "cover",
    "concepts",
    "saw",
    "cnn",
    "rnn",
    "cover",
    "various",
    "type",
    "neural",
    "networks",
    "like",
    "convolutional",
    "neural",
    "networks",
    "recurrent",
    "neural",
    "networks",
    "long",
    "memory",
    "neural",
    "networks",
    "auto",
    "encoders",
    "seventh",
    "module",
    "pyspark",
    "show",
    "spark",
    "sql",
    "works",
    "features",
    "functions",
    "spark",
    "ml",
    "library",
    "last",
    "module",
    "finally",
    "cover",
    "python",
    "spark",
    "using",
    "pyspark",
    "appropriate",
    "seven",
    "modules",
    "also",
    "get",
    "two",
    "free",
    "courses",
    "let",
    "actually",
    "take",
    "look",
    "course",
    "machine",
    "learning",
    "engineer",
    "master",
    "program",
    "nine",
    "courses",
    "hours",
    "interactive",
    "learning",
    "whole",
    "course",
    "curriculum",
    "discussed",
    "seven",
    "modules",
    "apart",
    "seven",
    "modules",
    "given",
    "two",
    "free",
    "courses",
    "discuss",
    "shortly",
    "also",
    "get",
    "know",
    "average",
    "annual",
    "salary",
    "machine",
    "learning",
    "engineer",
    "also",
    "lot",
    "job",
    "openings",
    "field",
    "machine",
    "learning",
    "ai",
    "data",
    "science",
    "job",
    "titles",
    "might",
    "get",
    "machine",
    "learning",
    "engineer",
    "ai",
    "engineer",
    "data",
    "scientist",
    "data",
    "analytics",
    "manger",
    "nlp",
    "engineer",
    "data",
    "engineer",
    "basically",
    "curriculum",
    "first",
    "python",
    "programming",
    "certification",
    "machine",
    "learning",
    "certification",
    "using",
    "python",
    "graphical",
    "modeling",
    "reinforcement",
    "learning",
    "natural",
    "language",
    "processing",
    "ai",
    "deep",
    "learning",
    "tensorflow",
    "python",
    "spark",
    "certification",
    "training",
    "using",
    "pyspark",
    "want",
    "learn",
    "modules",
    "go",
    "view",
    "curriculum",
    "explain",
    "every",
    "concept",
    "showing",
    "module",
    "going",
    "covered",
    "first",
    "module",
    "end",
    "project",
    "given",
    "verified",
    "certificate",
    "completion",
    "name",
    "free",
    "elective",
    "courses",
    "going",
    "get",
    "one",
    "python",
    "scripting",
    "certification",
    "training",
    "python",
    "statistics",
    "data",
    "science",
    "course",
    "courses",
    "explain",
    "python",
    "depth",
    "second",
    "course",
    "statistics",
    "explain",
    "concepts",
    "statistics",
    "probability",
    "descriptive",
    "statistics",
    "inferential",
    "statistics",
    "time",
    "series",
    "testing",
    "data",
    "data",
    "clustering",
    "regression",
    "modeling",
    "module",
    "designed",
    "way",
    "practical",
    "demo",
    "practical",
    "implementation",
    "every",
    "model",
    "concept",
    "theoretically",
    "taught",
    "explained",
    "practical",
    "demos",
    "way",
    "get",
    "good",
    "understanding",
    "entire",
    "machine",
    "learning",
    "ai",
    "concepts",
    "interested",
    "enrolling",
    "program",
    "want",
    "learn",
    "machine",
    "learning",
    "course",
    "offered",
    "edureka",
    "please",
    "leave",
    "email",
    "ids",
    "comment",
    "section",
    "get",
    "back",
    "details",
    "course",
    "guys",
    "come",
    "end",
    "ai",
    "full",
    "course",
    "session",
    "hope",
    "understood",
    "basic",
    "concepts",
    "idea",
    "behind",
    "ai",
    "machine",
    "learning",
    "deep",
    "learning",
    "natural",
    "language",
    "processing",
    "still",
    "doubts",
    "regarding",
    "topics",
    "mention",
    "comment",
    "section",
    "try",
    "answer",
    "queries",
    "guys",
    "thank",
    "much",
    "joining",
    "session",
    "great",
    "day",
    "hope",
    "enjoyed",
    "listening",
    "video",
    "please",
    "kind",
    "enough",
    "like",
    "comment",
    "doubts",
    "queries",
    "reply",
    "earliest",
    "look",
    "videos",
    "playlist",
    "subscribe",
    "edureka",
    "channel",
    "learn",
    "happy",
    "learning"
  ],
  "keywords": [
    "session",
    "artificial",
    "intelligence",
    "course",
    "video",
    "concepts",
    "also",
    "couple",
    "use",
    "cases",
    "practical",
    "using",
    "python",
    "lot",
    "cover",
    "let",
    "run",
    "today",
    "gon",
    "na",
    "begin",
    "understanding",
    "famous",
    "right",
    "look",
    "exactly",
    "discuss",
    "applications",
    "ai",
    "understand",
    "different",
    "types",
    "programming",
    "languages",
    "used",
    "study",
    "choose",
    "alright",
    "move",
    "machine",
    "learning",
    "algorithms",
    "include",
    "classification",
    "regression",
    "clustering",
    "make",
    "better",
    "wherein",
    "see",
    "solve",
    "real",
    "world",
    "problems",
    "deep",
    "needed",
    "concept",
    "neurons",
    "perceptrons",
    "multiple",
    "layer",
    "neural",
    "networks",
    "back",
    "propagation",
    "apart",
    "running",
    "demo",
    "depth",
    "finally",
    "next",
    "module",
    "natural",
    "language",
    "processing",
    "try",
    "text",
    "mining",
    "difference",
    "nlp",
    "end",
    "guys",
    "want",
    "would",
    "like",
    "learn",
    "training",
    "sure",
    "take",
    "first",
    "topic",
    "machines",
    "well",
    "example",
    "know",
    "many",
    "actually",
    "implemented",
    "get",
    "one",
    "important",
    "creating",
    "think",
    "created",
    "known",
    "test",
    "basically",
    "whether",
    "computer",
    "human",
    "define",
    "say",
    "meaning",
    "followed",
    "program",
    "time",
    "year",
    "term",
    "coming",
    "still",
    "line",
    "blue",
    "able",
    "car",
    "another",
    "question",
    "two",
    "around",
    "every",
    "everything",
    "us",
    "since",
    "based",
    "way",
    "image",
    "gain",
    "much",
    "tell",
    "main",
    "reason",
    "complex",
    "possible",
    "second",
    "data",
    "generating",
    "social",
    "media",
    "need",
    "find",
    "method",
    "solution",
    "help",
    "process",
    "useful",
    "order",
    "agent",
    "classify",
    "trained",
    "large",
    "idea",
    "nothing",
    "behind",
    "accuracy",
    "okay",
    "google",
    "works",
    "already",
    "mentioned",
    "defined",
    "science",
    "making",
    "words",
    "perform",
    "task",
    "recognition",
    "decision",
    "getting",
    "work",
    "range",
    "marketing",
    "search",
    "engine",
    "makes",
    "action",
    "might",
    "trying",
    "discussing",
    "slides",
    "simple",
    "create",
    "logic",
    "uses",
    "even",
    "though",
    "algorithm",
    "reach",
    "stage",
    "20",
    "million",
    "correctly",
    "patient",
    "give",
    "identify",
    "called",
    "features",
    "feature",
    "sort",
    "link",
    "people",
    "cars",
    "build",
    "netflix",
    "movie",
    "type",
    "movies",
    "patterns",
    "similar",
    "notice",
    "separate",
    "section",
    "certain",
    "denotes",
    "correlations",
    "understood",
    "common",
    "divided",
    "three",
    "involves",
    "problem",
    "good",
    "functions",
    "something",
    "10",
    "room",
    "zero",
    "go",
    "learned",
    "four",
    "classified",
    "said",
    "thing",
    "n",
    "number",
    "easily",
    "considered",
    "predefined",
    "call",
    "function",
    "best",
    "stands",
    "r",
    "environment",
    "formula",
    "support",
    "statistics",
    "easy",
    "part",
    "person",
    "information",
    "new",
    "pretty",
    "worry",
    "memory",
    "c",
    "huge",
    "code",
    "comes",
    "stored",
    "going",
    "explain",
    "leave",
    "links",
    "description",
    "box",
    "doubts",
    "always",
    "feed",
    "single",
    "day",
    "insights",
    "draw",
    "increase",
    "form",
    "improve",
    "various",
    "predict",
    "stock",
    "hidden",
    "building",
    "takes",
    "disease",
    "sum",
    "significant",
    "terms",
    "class",
    "measure",
    "p",
    "happens",
    "fed",
    "train",
    "model",
    "outcome",
    "set",
    "linear",
    "tree",
    "random",
    "forest",
    "given",
    "input",
    "correct",
    "output",
    "predictor",
    "variable",
    "height",
    "depending",
    "weight",
    "becomes",
    "target",
    "variables",
    "predicted",
    "testing",
    "splitting",
    "splicing",
    "must",
    "accurately",
    "done",
    "statement",
    "steps",
    "step",
    "exploration",
    "predictions",
    "rain",
    "weather",
    "continuous",
    "temperature",
    "particular",
    "upcoming",
    "approach",
    "available",
    "predicting",
    "analysis",
    "cleaning",
    "taking",
    "values",
    "small",
    "last",
    "80",
    "mean",
    "consider",
    "depends",
    "discussed",
    "split",
    "feeding",
    "randomly",
    "assign",
    "remember",
    "obviously",
    "outcomes",
    "case",
    "categorical",
    "yes",
    "logistic",
    "vector",
    "k",
    "nearest",
    "neighbor",
    "naive",
    "bayes",
    "six",
    "put",
    "road",
    "check",
    "calculated",
    "parameter",
    "previous",
    "calculate",
    "final",
    "either",
    "entire",
    "supervised",
    "unsupervised",
    "reinforcement",
    "labeled",
    "math",
    "similarly",
    "label",
    "figure",
    "tom",
    "jerry",
    "goal",
    "images",
    "classes",
    "contain",
    "note",
    "looks",
    "whenever",
    "name",
    "size",
    "clusters",
    "cluster",
    "quite",
    "actions",
    "rewards",
    "gets",
    "initially",
    "mainly",
    "really",
    "explore",
    "baby",
    "clear",
    "start",
    "errors",
    "error",
    "earlier",
    "quantity",
    "speed",
    "distance",
    "value",
    "aim",
    "assigned",
    "sentence",
    "points",
    "group",
    "little",
    "knn",
    "average",
    "classifier",
    "seven",
    "dependent",
    "independent",
    "x",
    "price",
    "relationship",
    "means",
    "curve",
    "equation",
    "plus",
    "hope",
    "represented",
    "along",
    "b",
    "naught",
    "intercept",
    "point",
    "graph",
    "beta",
    "negative",
    "positive",
    "represents",
    "actual",
    "represent",
    "maximum",
    "minimum",
    "path",
    "contains",
    "importing",
    "show",
    "printing",
    "shape",
    "plot",
    "comment",
    "repeat",
    "change",
    "prediction",
    "close",
    "saw",
    "squared",
    "root",
    "square",
    "probability",
    "confusion",
    "keep",
    "equal",
    "increasing",
    "node",
    "party",
    "traverse",
    "nodes",
    "entropy",
    "select",
    "attribute",
    "selected",
    "five",
    "stop",
    "separates",
    "decide",
    "slow",
    "fast",
    "limit",
    "desired",
    "uncertainty",
    "observations",
    "calculating",
    "parent",
    "total",
    "child",
    "steep",
    "flat",
    "weighted",
    "minus",
    "trees",
    "sample",
    "overfitting",
    "basic",
    "samples",
    "bootstrap",
    "original",
    "500",
    "cat",
    "turtle",
    "swim",
    "green",
    "color",
    "hundred",
    "comma",
    "neighbors",
    "closest",
    "euclidean",
    "elbow",
    "whole",
    "svm",
    "hyperplane",
    "dimension",
    "dimensional",
    "space",
    "16",
    "high",
    "scaling",
    "matrix",
    "centroid",
    "centroids",
    "distortion",
    "closer",
    "colors",
    "pixels",
    "pixel",
    "reward",
    "setting",
    "state",
    "update",
    "current",
    "policy",
    "q",
    "meat",
    "gamma",
    "exploitation",
    "markov",
    "series",
    "cost",
    "directly",
    "connected",
    "initial",
    "neuron",
    "perceptron",
    "inputs",
    "passed",
    "threshold",
    "network",
    "layers",
    "w",
    "weights",
    "weightage",
    "activation",
    "bias",
    "word",
    "multilayer",
    "forward",
    "recurrent",
    "convolutional",
    "tensorflow",
    "batch",
    "sentimental",
    "stemming",
    "lemmatization",
    "review"
  ]
}