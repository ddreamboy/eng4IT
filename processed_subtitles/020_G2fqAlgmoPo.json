{
  "text": "GWENDOLYN STRIPLING: Hello.\nAnd welcome to Introduction\nto Generative AI.\nMy name is Dr.\nGwendolyn Stripling.\nAnd I am the\nartificial intelligence\ntechnical curriculum developer\nhere at Google Cloud.\nIn this course, you learn\nto define generative AI,\nexplain how generative AI works,\ndescribe generative AI model\ntypes, and describe\ngenerative AI applications.\nGenerative AI is a type\nof artificial intelligence\ntechnology that can produce\nvarious types of content,\nincluding text, imagery,\naudio, and synthetic data.\nBut what is artificial\nintelligence?\nWell, since we are\ngoing to explore\ngenerative artificial\nintelligence,\nlet's provide a bit of context.\nSo two very common\nquestions asked\nare what is artificial\nintelligence\nand what is the difference\nbetween AI and machine\nlearning.\nOne way to think about it\nis that AI is a discipline,\nlike physics for example.\nAI is a branch of\ncomputer science\nthat deals with the creation\nof intelligence agents, which\nare systems that can reason,\nand learn, and act autonomously.\nEssentially, AI has to do\nwith the theory and methods\nto build machines that\nthink and act like humans.\nIn this discipline, we\nhave machine learning,\nwhich is a subfield of AI.\nIt is a program or system that\ntrains a model from input data.\nThat trained model can\nmake useful predictions\nfrom new or never\nbefore seen data\ndrawn from the same one\nused to train the model.\nMachine learning\ngives the computer\nthe ability to learn without\nexplicit programming.\nTwo of the most common classes\nof machine learning models\nare unsupervised and\nsupervised ML models.\nThe key difference\nbetween the two\nis that, with supervised\nmodels, we have labels.\nLabeled data is data that comes\nwith a tag like a name, a type,\nor a number.\nUnlabeled data is data\nthat comes with no tag.\nThis graph is an\nexample of the problem\nthat a supervised model\nmight try to solve.\nFor example, let's say you\nare the owner of a restaurant.\nYou have historical\ndata of the bill amount\nand how much different people\ntipped based on order type\nand whether it was\npicked up or delivered.\nIn supervised learning, the\nmodel learns from past examples\nto predict future values,\nin this case tips.\nSo here the model uses\nthe total bill amount\nto predict the future tip amount\nbased on whether an order was\npicked up or delivered.\nThis is an example\nof the problem\nthat an unsupervised\nmodel might try to solve.\nSo here you want to look\nat tenure and income\nand then group or\ncluster employees\nto see whether someone\nis on the fast track.\nUnsupervised problems\nare all about discovery,\nabout looking at the raw data\nand seeing if it naturally\nfalls into groups.\nLet's get a little deeper\nand show this graphically\nas understanding\nthese concepts are\nthe foundation for your\nunderstanding of generative AI.\nIn supervised learning,\ntesting data values or x\nare input into the model.\nThe model outputs a prediction\nand compares that prediction\nto the training data\nused to train the model.\nIf the predicted test data\nvalues and actual training data\nvalues are far apart,\nthat's called error.\nAnd the model tries\nto reduce this error\nuntil the predicted and actual\nvalues are closer together.\nThis is a classic\noptimization problem.\nNow that we've\nexplored the difference\nbetween artificial intelligence\nand machine learning,\nand supervised and\nunsupervised learning,\nlet's briefly explore\nwhere deep learning\nfits as a subset of\nmachine learning methods.\nWhile machine learning\nis a broad field that\nencompasses many\ndifferent techniques,\ndeep learning is a type\nof machine learning\nthat uses artificial\nneural networks,\nallowing them to process more\ncomplex patterns than machine\nlearning.\nArtificial neural networks are\ninspired by the human brain.\nThey are made up of many\ninterconnected nodes or neurons\nthat can learn to perform tasks\nby processing data and making\npredictions.\nDeep learning models\ntypically have many layers\nof neurons, which\nallows them to learn\nmore complex patterns than\ntraditional machine learning\nmodels.\nAnd neural networks can use\nboth labeled and unlabeled data.\nThis is called\nsemi-supervised learning.\nIn semi-supervised\nlearning, a neural network\nis trained on a small\namount of labeled data\nand a large amount\nof unlabeled data.\nThe labeled data helps\nthe neural network\nto learn the basic\nconcepts of the task\nwhile the unlabeled data\nhelps the neural network\nto generalize to new examples.\nNow we finally get to\nwhere generative AI\nfits into this AI discipline.\nGen AI is a subset of\ndeep learning, which\nmeans it uses artificial\nneural networks,\ncan process both labeled\nand unlabeled data using\nsupervised, unsupervised,\nand semi-supervised methods.\nLarge language models are also\na subset of deep learning.\nDeep learning models, or machine\nlearning models in general,\ncan be divided into two types,\ngenerative and discriminative.\nA discriminative model\nis a type of model\nthat is used to classify or\npredict labels for data points.\nDiscriminative\nmodels are typically\ntrained on a data set\nof labeled data points.\nAnd they learn the relationship\nbetween the features\nof the data points\nand the labels.\nOnce a discriminative\nmodel is trained,\nit can be used to predict the\nlabel for new data points.\nA generative model\ngenerates new data instances\nbased on a learned probability\ndistribution of existing data.\nThus generative models\ngenerate new content.\nTake this example here.\nThe discriminative model learns\nthe conditional probability\ndistribution or the\nprobability of y,\nour output, given x, our\ninput, that this is a dog\nand classifies it as\na dog and not a cat.\nThe generative model learns the\njoint probability distribution\nor the probability of\nx and y and predicts\nthe conditional probability\nthat this is a dog\nand can then generate\na picture of a dog.\nSo to summarize,\ngenerative models\ncan generate new data instances\nwhile discriminative models\ndiscriminate between different\nkinds of data instances.\nThe top image shows\na traditional machine\nlearning model which\nattempts to learn\nthe relationship between\nthe data and the label,\nor what you want to predict.\nThe bottom image shows\na generative AI model\nwhich attempts to learn\npatterns on content so that it\ncan generate new content.\nA good way to distinguish\nwhat is gen AI and what is not\nis shown in this illustration.\nIt is not gen AI when the\noutput, or y, or label is\na number or a class, for\nexample spam or not spam,\nor a probability.\nIt is gen AI when the output is\nnatural language, like speech\nor text, an image or\naudio, for example.\nVisualizing this mathematically\nwould look like this.\nIf you haven't seen\nthis for a while,\nthe y is equal to f of\nx equation calculates\nthe dependent output of a\nprocess given different inputs.\nThe y stands for\nthe model output.\nThe f embodies the function\nused in the calculation.\nAnd the x represents the input\nor inputs used for the formula.\nSo the model output is a\nfunction of all the inputs.\nIf the y is the number,\nlike predicted sales,\nit is not gen AI.\nIf y is a sentence,\nlike define sales,\nit is generative as the question\nwould elicit a text response.\nThe response would be based\non all the massive large data\nthe model was\nalready trained on.\nTo summarize at a high level,\nthe traditional, classical\nsupervised and unsupervised\nlearning process\ntakes training code and\nlabel data to build a model.\nDepending on the\nuse case or problem,\nthe model can give\nyou a prediction.\nIt can classify something\nor cluster something.\nWe use this example to show\nyou how much more robust\nthe gen AI process is.\nThe gen AI process can take\ntraining code, label data,\nand unlabeled data\nof all data types\nand build a foundation model.\nThe foundation model can\nthen generate new content.\nFor example, text, code,\nimages, audio, video, et cetera.\nWe've come a long away from\ntraditional programming\nto neural networks\nto generative models.\nIn traditional\nprogramming, we used\nto have to hard code the rules\nfor distinguishing a cat--\nthe type, animal; legs,\nfour; ears, two; fur, yes;\nlikes yarn and catnip.\nIn the wave of\nneural networks, we\ncould give the network\npictures of cats and dogs\nand ask is this a cat and\nit would predict a cat.\nIn the generative\nwave, we as users\ncan generate our own\ncontent, whether it\nbe text, images, audio,\nvideo, et cetera, for example\nmodels like PaLM or\nPathways Language Model,\nor LAMBDA, Language Model\nfor Dialogue Applications,\ningest very, very large data\nfrom the multiple sources\nacross the internet and\nbuild foundation language\nmodels we can use simply\nby asking a question,\nwhether typing it into\na prompt or verbally\ntalking into the prompt itself.\nSo when you ask it\nwhat's a cat, it\ncan give you everything it\nhas learned about a cat.\nNow we come to our\nformal definition.\nWhat is generative AI?\nGen AI is a type of\nartificial intelligence\nthat creates new content\nbased on what it has\nlearned from existing content.\nThe process of learning\nfrom existing content\nis called training and\nresults in the creation\nof a statistical model\nwhen given a prompt.\nAI uses the model to predict\nwhat an expected response might\nbe and this generates\nnew content.\nEssentially, it learns\nthe underlying structure\nof the data and\ncan then generate\nnew samples that are similar\nto the data it was trained on.\nAs previously mentioned, a\ngenerative language model\ncan take what it has learned\nfrom the examples it's\nbeen shown and create\nsomething entirely new\nbased on that information.\nLarge language models are\none type of generative AI\nsince they generate novel\ncombinations of text\nin the form of natural\nsounding language.\nA generative image\nmodel takes an image\nas input and can output text,\nanother image, or video.\nFor example, under\nthe output text,\nyou can get visual\nquestion answering\nwhile under output image, an\nimage completion is generated.\nAnd under output video,\nanimation is generated.\nA generative language\nmodel takes text as input\nand can output more text, an\nimage, audio, or decisions.\nFor example, under\nthe output text,\nquestion answering is generated.\nAnd under output image,\na video is generated.\nWe've stated that generative\nlanguage models learn\nabout patterns and language\nthrough training data,\nthen, given some text, they\npredict what comes next.\nThus generative language models\nare pattern matching systems.\nThey learn about patterns\nbased on the data you provide.\nHere is an example.\nBased on things it's learned\nfrom its training data,\nit offers predictions of how\nto complete this sentence,\nI'm making a sandwich with\npeanut butter and jelly.\nHere is the same\nexample using Bard,\nwhich is trained on a\nmassive amount of text data\nand is able to\ncommunicate and generate\nhumanlike text in response\nto a wide range of prompts\nand questions.\nHere is another example.\nThe meaning of life is--\nand Bart gives you\na contextual answer\nand then shows the highest\nprobability response.\nThe power of generative AI comes\nfrom the use of transformers.\nTransformers produced\na 2018 revolution\nin natural language processing.\nAt a high level, a\ntransformer model\nconsists of an\nencoder and decoder.\nThe encoder encodes\nthe input sequence\nand passes it to\nthe decoder, which\nlearns how to decode\nthe representation\nfor a relevant task.\nIn transformers, hallucinations\nare words or phrases\nthat are generated\nby the model that\nare often nonsensical or\ngrammatically incorrect.\nHallucinations can be caused\nby a number of factors,\nincluding the model is not\ntrained on enough data,\nor the model is trained\non noisy or dirty data,\nor the model is not\ngiven enough context,\nor the model is not\ngiven enough constraints.\nHallucinations can be a\nproblem for transformers\nbecause they can make the output\ntext difficult to understand.\nThey can also make\nthe model more\nlikely to generate incorrect\nor misleading information.\nA prompt is a\nshort piece of text\nthat is given to the large\nlanguage model as input.\nAnd it can be used to control\nthe output of the model\nin a variety of ways.\nPrompt design is the\nprocess of creating\na prompt that will\ngenerate the desired output\nfrom a large language model.\nAs previously mentioned,\ngen AI depends a lot\non the training data that\nyou have fed into it.\nAnd it analyzes the patterns\nand structures of the input data\nand thus learns.\nBut with access to a browser\nbased prompt, you, the user,\ncan generate your own content.\nWe've shown illustrations of the\ntypes of input based upon data.\nHere are the\nassociated model types.\nText-to-text.\nText-to-text models take\na natural language input\nand produces a text output.\nThese models are trained\nto learn the mapping\nbetween a pair of text, e.g.\nfor example, translation\nfrom one language to another.\nText-to-image.\nText-to-image models are trained\non a large set of images,\neach captioned with a\nshort text description.\nDiffusion is one method\nused to achieve this.\nText-to-video and text-to-3D.\nText-to-video models aim to\ngenerate a video representation\nfrom text input.\nThe input text can be anything\nfrom a single sentence\nto a full script.\nAnd the output is a video that\ncorresponds to the input text.\nSimilarly, text-to-3D\nmodels generate\nthree dimensional objects that\ncorrespond to a user's text\ndescription.\nFor example, this can be used\nin games or other 3D worlds.\nText-to-task.\nText-to-task models are trained\nto perform a defined task\nor action based on text input.\nThis task can be a\nwide range of actions\nsuch as answering a question,\nperforming a search,\nmaking a prediction, or\ntaking some sort of action.\nFor example, a\ntext-to-task model\ncould be trained to navigate a\nweb UI or make changes to a doc\nthrough the GUI.\nA foundation model is a\nlarge AI model pre-trained\non a vast quantity of data\ndesigned to be adapted or fine\ntuned to a wide range\nof downstream tasks,\nsuch as sentiment analysis,\nimage captioning, and object\nrecognition.\nFoundation models\nhave the potential\nto revolutionize many\nindustries, including\nhealth care, finance,\nand customer service.\nThey can be used to\ndetect fraud and provide\npersonalized customer support.\nVertex AI offers a\nmodel garden that\nincludes foundation models.\nThe language foundation\nmodels include\nPaLM API for chat and text.\nThe vision foundation models\nincludes stable diffusion,\nwhich has been shown to\nbe effective at generating\nhigh quality images\nfrom text descriptions.\nLet's say you have\na use case where\nyou need to gather sentiments\nabout how your customers are\nfeeling about your\nproduct or service.\nYou can use the classification\ntask sentiment analysis task\nmodel for just that purpose.\nAnd what if you needed to\nperform occupancy analytics?\nThere is a task model\nfor your use case.\nShown here are gen\nAI applications.\nLet's look at an example\nof code generation\nshown in the second block\nunder code at the top.\nIn this example, I've input a\ncode file conversion problem,\nconverting from Python to JSON.\nI use Bard.\nAnd I insert into the\nprompt box the following.\nI have a Pandas DataFrame with\ntwo columns, one with the file\nname and one with the hour\nin which it is generated.\nI'm trying to convert\nthis into a JSON file\nin the format shown onscreen.\nBard returns the steps I need\nto do this and the code snippet.\nAnd here my output\nis in a JSON format.\nIt gets better.\nI happen to be using Google's\nfree, browser-based Jupyter\nNotebook, known as Colab.\nAnd I simply export the\nPython code to Google's Colab.\nTo summarize, Bart\ncode generation\ncan help you debug your\nlines of source code,\nexplain your code\nto you line by line,\ncraft SQL queries\nfor your database,\ntranslate code from one\nlanguage to another,\nand generate documentation\nand tutorials for source code.\nGenerative AI Studio lets you\nquickly explore and customize\ngen AI models that you can\nleverage in your applications\non Google Cloud.\nGenerative AI Studio helps\ndevelopers create and deploy\nGen AI models by providing a\nvariety of tools and resources\nthat make it easy\nto get started.\nFor example, there's a\nlibrary of pre-trained models.\nThere is a tool for\nfine tuning models.\nThere is a tool for deploying\nmodels to production.\nAnd there is a community\nforum for developers\nto share ideas and collaborate.\nGenerative AI App\nBuilder lets you\ncreate gen AI apps without\nhaving to write any code.\nGen AI App Builder has a\ndrag and drop interface\nthat makes it easy to\ndesign and build apps.\nIt has a visual\neditor that makes\nit easy to create\nand edit app content.\nIt has a built-in\nsearch engine that\nallows users to search for\ninformation within the app.\nAnd it has a\nconversational AI Engine\nthat helps users to\ninteract with the app using\nnatural language.\nYou can create your own digital\nassistants, custom search\nengines, knowledge bases,\ntraining applications,\nand much more.\nPaLM API lets you\ntest and experiment\nwith Google's large language\nmodels and gen AI tools.\nTo make prototyping quick\nand more accessible,\ndevelopers can integrate\nPaLM API with Maker suite\nand use it to access the\nAPI using a graphical user\ninterface.\nThe suite includes a number of\ndifferent tools such as a model\ntraining tool, a model\ndeployment tool, and a model\nmonitoring tool.\nThe model training tool helps\ndevelopers train ML models\non their data using\ndifferent algorithms.\nThe model deployment tool helps\ndevelopers deploy ML models\nto production with a number of\ndifferent deployment options.\nThe model monitoring\ntool helps developers\nmonitor the performance\nof their ML models\nin production using a\ndashboard and a number\nof different metrics.\nThank you for watching\nour course, Introduction\nto Generative AI.\n",
  "words": [
    "gwendolyn",
    "stripling",
    "hello",
    "welcome",
    "introduction",
    "generative",
    "ai",
    "name",
    "gwendolyn",
    "stripling",
    "artificial",
    "intelligence",
    "technical",
    "curriculum",
    "developer",
    "google",
    "cloud",
    "course",
    "learn",
    "define",
    "generative",
    "ai",
    "explain",
    "generative",
    "ai",
    "works",
    "describe",
    "generative",
    "ai",
    "model",
    "types",
    "describe",
    "generative",
    "ai",
    "applications",
    "generative",
    "ai",
    "type",
    "artificial",
    "intelligence",
    "technology",
    "produce",
    "various",
    "types",
    "content",
    "including",
    "text",
    "imagery",
    "audio",
    "synthetic",
    "data",
    "artificial",
    "intelligence",
    "well",
    "since",
    "going",
    "explore",
    "generative",
    "artificial",
    "intelligence",
    "let",
    "provide",
    "bit",
    "context",
    "two",
    "common",
    "questions",
    "asked",
    "artificial",
    "intelligence",
    "difference",
    "ai",
    "machine",
    "learning",
    "one",
    "way",
    "think",
    "ai",
    "discipline",
    "like",
    "physics",
    "example",
    "ai",
    "branch",
    "computer",
    "science",
    "deals",
    "creation",
    "intelligence",
    "agents",
    "systems",
    "reason",
    "learn",
    "act",
    "autonomously",
    "essentially",
    "ai",
    "theory",
    "methods",
    "build",
    "machines",
    "think",
    "act",
    "like",
    "humans",
    "discipline",
    "machine",
    "learning",
    "subfield",
    "ai",
    "program",
    "system",
    "trains",
    "model",
    "input",
    "data",
    "trained",
    "model",
    "make",
    "useful",
    "predictions",
    "new",
    "never",
    "seen",
    "data",
    "drawn",
    "one",
    "used",
    "train",
    "model",
    "machine",
    "learning",
    "gives",
    "computer",
    "ability",
    "learn",
    "without",
    "explicit",
    "programming",
    "two",
    "common",
    "classes",
    "machine",
    "learning",
    "models",
    "unsupervised",
    "supervised",
    "ml",
    "models",
    "key",
    "difference",
    "two",
    "supervised",
    "models",
    "labels",
    "labeled",
    "data",
    "data",
    "comes",
    "tag",
    "like",
    "name",
    "type",
    "number",
    "unlabeled",
    "data",
    "data",
    "comes",
    "tag",
    "graph",
    "example",
    "problem",
    "supervised",
    "model",
    "might",
    "try",
    "solve",
    "example",
    "let",
    "say",
    "owner",
    "restaurant",
    "historical",
    "data",
    "bill",
    "amount",
    "much",
    "different",
    "people",
    "tipped",
    "based",
    "order",
    "type",
    "whether",
    "picked",
    "delivered",
    "supervised",
    "learning",
    "model",
    "learns",
    "past",
    "examples",
    "predict",
    "future",
    "values",
    "case",
    "tips",
    "model",
    "uses",
    "total",
    "bill",
    "amount",
    "predict",
    "future",
    "tip",
    "amount",
    "based",
    "whether",
    "order",
    "picked",
    "delivered",
    "example",
    "problem",
    "unsupervised",
    "model",
    "might",
    "try",
    "solve",
    "want",
    "look",
    "tenure",
    "income",
    "group",
    "cluster",
    "employees",
    "see",
    "whether",
    "someone",
    "fast",
    "track",
    "unsupervised",
    "problems",
    "discovery",
    "looking",
    "raw",
    "data",
    "seeing",
    "naturally",
    "falls",
    "groups",
    "let",
    "get",
    "little",
    "deeper",
    "show",
    "graphically",
    "understanding",
    "concepts",
    "foundation",
    "understanding",
    "generative",
    "ai",
    "supervised",
    "learning",
    "testing",
    "data",
    "values",
    "x",
    "input",
    "model",
    "model",
    "outputs",
    "prediction",
    "compares",
    "prediction",
    "training",
    "data",
    "used",
    "train",
    "model",
    "predicted",
    "test",
    "data",
    "values",
    "actual",
    "training",
    "data",
    "values",
    "far",
    "apart",
    "called",
    "error",
    "model",
    "tries",
    "reduce",
    "error",
    "predicted",
    "actual",
    "values",
    "closer",
    "together",
    "classic",
    "optimization",
    "problem",
    "explored",
    "difference",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "supervised",
    "unsupervised",
    "learning",
    "let",
    "briefly",
    "explore",
    "deep",
    "learning",
    "fits",
    "subset",
    "machine",
    "learning",
    "methods",
    "machine",
    "learning",
    "broad",
    "field",
    "encompasses",
    "many",
    "different",
    "techniques",
    "deep",
    "learning",
    "type",
    "machine",
    "learning",
    "uses",
    "artificial",
    "neural",
    "networks",
    "allowing",
    "process",
    "complex",
    "patterns",
    "machine",
    "learning",
    "artificial",
    "neural",
    "networks",
    "inspired",
    "human",
    "brain",
    "made",
    "many",
    "interconnected",
    "nodes",
    "neurons",
    "learn",
    "perform",
    "tasks",
    "processing",
    "data",
    "making",
    "predictions",
    "deep",
    "learning",
    "models",
    "typically",
    "many",
    "layers",
    "neurons",
    "allows",
    "learn",
    "complex",
    "patterns",
    "traditional",
    "machine",
    "learning",
    "models",
    "neural",
    "networks",
    "use",
    "labeled",
    "unlabeled",
    "data",
    "called",
    "learning",
    "learning",
    "neural",
    "network",
    "trained",
    "small",
    "amount",
    "labeled",
    "data",
    "large",
    "amount",
    "unlabeled",
    "data",
    "labeled",
    "data",
    "helps",
    "neural",
    "network",
    "learn",
    "basic",
    "concepts",
    "task",
    "unlabeled",
    "data",
    "helps",
    "neural",
    "network",
    "generalize",
    "new",
    "examples",
    "finally",
    "get",
    "generative",
    "ai",
    "fits",
    "ai",
    "discipline",
    "gen",
    "ai",
    "subset",
    "deep",
    "learning",
    "means",
    "uses",
    "artificial",
    "neural",
    "networks",
    "process",
    "labeled",
    "unlabeled",
    "data",
    "using",
    "supervised",
    "unsupervised",
    "methods",
    "large",
    "language",
    "models",
    "also",
    "subset",
    "deep",
    "learning",
    "deep",
    "learning",
    "models",
    "machine",
    "learning",
    "models",
    "general",
    "divided",
    "two",
    "types",
    "generative",
    "discriminative",
    "discriminative",
    "model",
    "type",
    "model",
    "used",
    "classify",
    "predict",
    "labels",
    "data",
    "points",
    "discriminative",
    "models",
    "typically",
    "trained",
    "data",
    "set",
    "labeled",
    "data",
    "points",
    "learn",
    "relationship",
    "features",
    "data",
    "points",
    "labels",
    "discriminative",
    "model",
    "trained",
    "used",
    "predict",
    "label",
    "new",
    "data",
    "points",
    "generative",
    "model",
    "generates",
    "new",
    "data",
    "instances",
    "based",
    "learned",
    "probability",
    "distribution",
    "existing",
    "data",
    "thus",
    "generative",
    "models",
    "generate",
    "new",
    "content",
    "take",
    "example",
    "discriminative",
    "model",
    "learns",
    "conditional",
    "probability",
    "distribution",
    "probability",
    "output",
    "given",
    "x",
    "input",
    "dog",
    "classifies",
    "dog",
    "cat",
    "generative",
    "model",
    "learns",
    "joint",
    "probability",
    "distribution",
    "probability",
    "x",
    "predicts",
    "conditional",
    "probability",
    "dog",
    "generate",
    "picture",
    "dog",
    "summarize",
    "generative",
    "models",
    "generate",
    "new",
    "data",
    "instances",
    "discriminative",
    "models",
    "discriminate",
    "different",
    "kinds",
    "data",
    "instances",
    "top",
    "image",
    "shows",
    "traditional",
    "machine",
    "learning",
    "model",
    "attempts",
    "learn",
    "relationship",
    "data",
    "label",
    "want",
    "predict",
    "bottom",
    "image",
    "shows",
    "generative",
    "ai",
    "model",
    "attempts",
    "learn",
    "patterns",
    "content",
    "generate",
    "new",
    "content",
    "good",
    "way",
    "distinguish",
    "gen",
    "ai",
    "shown",
    "illustration",
    "gen",
    "ai",
    "output",
    "label",
    "number",
    "class",
    "example",
    "spam",
    "spam",
    "probability",
    "gen",
    "ai",
    "output",
    "natural",
    "language",
    "like",
    "speech",
    "text",
    "image",
    "audio",
    "example",
    "visualizing",
    "mathematically",
    "would",
    "look",
    "like",
    "seen",
    "equal",
    "f",
    "x",
    "equation",
    "calculates",
    "dependent",
    "output",
    "process",
    "given",
    "different",
    "inputs",
    "stands",
    "model",
    "output",
    "f",
    "embodies",
    "function",
    "used",
    "calculation",
    "x",
    "represents",
    "input",
    "inputs",
    "used",
    "formula",
    "model",
    "output",
    "function",
    "inputs",
    "number",
    "like",
    "predicted",
    "sales",
    "gen",
    "ai",
    "sentence",
    "like",
    "define",
    "sales",
    "generative",
    "question",
    "would",
    "elicit",
    "text",
    "response",
    "response",
    "would",
    "based",
    "massive",
    "large",
    "data",
    "model",
    "already",
    "trained",
    "summarize",
    "high",
    "level",
    "traditional",
    "classical",
    "supervised",
    "unsupervised",
    "learning",
    "process",
    "takes",
    "training",
    "code",
    "label",
    "data",
    "build",
    "model",
    "depending",
    "use",
    "case",
    "problem",
    "model",
    "give",
    "prediction",
    "classify",
    "something",
    "cluster",
    "something",
    "use",
    "example",
    "show",
    "much",
    "robust",
    "gen",
    "ai",
    "process",
    "gen",
    "ai",
    "process",
    "take",
    "training",
    "code",
    "label",
    "data",
    "unlabeled",
    "data",
    "data",
    "types",
    "build",
    "foundation",
    "model",
    "foundation",
    "model",
    "generate",
    "new",
    "content",
    "example",
    "text",
    "code",
    "images",
    "audio",
    "video",
    "et",
    "cetera",
    "come",
    "long",
    "away",
    "traditional",
    "programming",
    "neural",
    "networks",
    "generative",
    "models",
    "traditional",
    "programming",
    "used",
    "hard",
    "code",
    "rules",
    "distinguishing",
    "cat",
    "type",
    "animal",
    "legs",
    "four",
    "ears",
    "two",
    "fur",
    "yes",
    "likes",
    "yarn",
    "catnip",
    "wave",
    "neural",
    "networks",
    "could",
    "give",
    "network",
    "pictures",
    "cats",
    "dogs",
    "ask",
    "cat",
    "would",
    "predict",
    "cat",
    "generative",
    "wave",
    "users",
    "generate",
    "content",
    "whether",
    "text",
    "images",
    "audio",
    "video",
    "et",
    "cetera",
    "example",
    "models",
    "like",
    "palm",
    "pathways",
    "language",
    "model",
    "lambda",
    "language",
    "model",
    "dialogue",
    "applications",
    "ingest",
    "large",
    "data",
    "multiple",
    "sources",
    "across",
    "internet",
    "build",
    "foundation",
    "language",
    "models",
    "use",
    "simply",
    "asking",
    "question",
    "whether",
    "typing",
    "prompt",
    "verbally",
    "talking",
    "prompt",
    "ask",
    "cat",
    "give",
    "everything",
    "learned",
    "cat",
    "come",
    "formal",
    "definition",
    "generative",
    "ai",
    "gen",
    "ai",
    "type",
    "artificial",
    "intelligence",
    "creates",
    "new",
    "content",
    "based",
    "learned",
    "existing",
    "content",
    "process",
    "learning",
    "existing",
    "content",
    "called",
    "training",
    "results",
    "creation",
    "statistical",
    "model",
    "given",
    "prompt",
    "ai",
    "uses",
    "model",
    "predict",
    "expected",
    "response",
    "might",
    "generates",
    "new",
    "content",
    "essentially",
    "learns",
    "underlying",
    "structure",
    "data",
    "generate",
    "new",
    "samples",
    "similar",
    "data",
    "trained",
    "previously",
    "mentioned",
    "generative",
    "language",
    "model",
    "take",
    "learned",
    "examples",
    "shown",
    "create",
    "something",
    "entirely",
    "new",
    "based",
    "information",
    "large",
    "language",
    "models",
    "one",
    "type",
    "generative",
    "ai",
    "since",
    "generate",
    "novel",
    "combinations",
    "text",
    "form",
    "natural",
    "sounding",
    "language",
    "generative",
    "image",
    "model",
    "takes",
    "image",
    "input",
    "output",
    "text",
    "another",
    "image",
    "video",
    "example",
    "output",
    "text",
    "get",
    "visual",
    "question",
    "answering",
    "output",
    "image",
    "image",
    "completion",
    "generated",
    "output",
    "video",
    "animation",
    "generated",
    "generative",
    "language",
    "model",
    "takes",
    "text",
    "input",
    "output",
    "text",
    "image",
    "audio",
    "decisions",
    "example",
    "output",
    "text",
    "question",
    "answering",
    "generated",
    "output",
    "image",
    "video",
    "generated",
    "stated",
    "generative",
    "language",
    "models",
    "learn",
    "patterns",
    "language",
    "training",
    "data",
    "given",
    "text",
    "predict",
    "comes",
    "next",
    "thus",
    "generative",
    "language",
    "models",
    "pattern",
    "matching",
    "systems",
    "learn",
    "patterns",
    "based",
    "data",
    "provide",
    "example",
    "based",
    "things",
    "learned",
    "training",
    "data",
    "offers",
    "predictions",
    "complete",
    "sentence",
    "making",
    "sandwich",
    "peanut",
    "butter",
    "jelly",
    "example",
    "using",
    "bard",
    "trained",
    "massive",
    "amount",
    "text",
    "data",
    "able",
    "communicate",
    "generate",
    "humanlike",
    "text",
    "response",
    "wide",
    "range",
    "prompts",
    "questions",
    "another",
    "example",
    "meaning",
    "life",
    "bart",
    "gives",
    "contextual",
    "answer",
    "shows",
    "highest",
    "probability",
    "response",
    "power",
    "generative",
    "ai",
    "comes",
    "use",
    "transformers",
    "transformers",
    "produced",
    "2018",
    "revolution",
    "natural",
    "language",
    "processing",
    "high",
    "level",
    "transformer",
    "model",
    "consists",
    "encoder",
    "decoder",
    "encoder",
    "encodes",
    "input",
    "sequence",
    "passes",
    "decoder",
    "learns",
    "decode",
    "representation",
    "relevant",
    "task",
    "transformers",
    "hallucinations",
    "words",
    "phrases",
    "generated",
    "model",
    "often",
    "nonsensical",
    "grammatically",
    "incorrect",
    "hallucinations",
    "caused",
    "number",
    "factors",
    "including",
    "model",
    "trained",
    "enough",
    "data",
    "model",
    "trained",
    "noisy",
    "dirty",
    "data",
    "model",
    "given",
    "enough",
    "context",
    "model",
    "given",
    "enough",
    "constraints",
    "hallucinations",
    "problem",
    "transformers",
    "make",
    "output",
    "text",
    "difficult",
    "understand",
    "also",
    "make",
    "model",
    "likely",
    "generate",
    "incorrect",
    "misleading",
    "information",
    "prompt",
    "short",
    "piece",
    "text",
    "given",
    "large",
    "language",
    "model",
    "input",
    "used",
    "control",
    "output",
    "model",
    "variety",
    "ways",
    "prompt",
    "design",
    "process",
    "creating",
    "prompt",
    "generate",
    "desired",
    "output",
    "large",
    "language",
    "model",
    "previously",
    "mentioned",
    "gen",
    "ai",
    "depends",
    "lot",
    "training",
    "data",
    "fed",
    "analyzes",
    "patterns",
    "structures",
    "input",
    "data",
    "thus",
    "learns",
    "access",
    "browser",
    "based",
    "prompt",
    "user",
    "generate",
    "content",
    "shown",
    "illustrations",
    "types",
    "input",
    "based",
    "upon",
    "data",
    "associated",
    "model",
    "types",
    "models",
    "take",
    "natural",
    "language",
    "input",
    "produces",
    "text",
    "output",
    "models",
    "trained",
    "learn",
    "mapping",
    "pair",
    "text",
    "example",
    "translation",
    "one",
    "language",
    "another",
    "models",
    "trained",
    "large",
    "set",
    "images",
    "captioned",
    "short",
    "text",
    "description",
    "diffusion",
    "one",
    "method",
    "used",
    "achieve",
    "models",
    "aim",
    "generate",
    "video",
    "representation",
    "text",
    "input",
    "input",
    "text",
    "anything",
    "single",
    "sentence",
    "full",
    "script",
    "output",
    "video",
    "corresponds",
    "input",
    "text",
    "similarly",
    "models",
    "generate",
    "three",
    "dimensional",
    "objects",
    "correspond",
    "user",
    "text",
    "description",
    "example",
    "used",
    "games",
    "3d",
    "worlds",
    "models",
    "trained",
    "perform",
    "defined",
    "task",
    "action",
    "based",
    "text",
    "input",
    "task",
    "wide",
    "range",
    "actions",
    "answering",
    "question",
    "performing",
    "search",
    "making",
    "prediction",
    "taking",
    "sort",
    "action",
    "example",
    "model",
    "could",
    "trained",
    "navigate",
    "web",
    "ui",
    "make",
    "changes",
    "doc",
    "gui",
    "foundation",
    "model",
    "large",
    "ai",
    "model",
    "vast",
    "quantity",
    "data",
    "designed",
    "adapted",
    "fine",
    "tuned",
    "wide",
    "range",
    "downstream",
    "tasks",
    "sentiment",
    "analysis",
    "image",
    "captioning",
    "object",
    "recognition",
    "foundation",
    "models",
    "potential",
    "revolutionize",
    "many",
    "industries",
    "including",
    "health",
    "care",
    "finance",
    "customer",
    "service",
    "used",
    "detect",
    "fraud",
    "provide",
    "personalized",
    "customer",
    "support",
    "vertex",
    "ai",
    "offers",
    "model",
    "garden",
    "includes",
    "foundation",
    "models",
    "language",
    "foundation",
    "models",
    "include",
    "palm",
    "api",
    "chat",
    "text",
    "vision",
    "foundation",
    "models",
    "includes",
    "stable",
    "diffusion",
    "shown",
    "effective",
    "generating",
    "high",
    "quality",
    "images",
    "text",
    "descriptions",
    "let",
    "say",
    "use",
    "case",
    "need",
    "gather",
    "sentiments",
    "customers",
    "feeling",
    "product",
    "service",
    "use",
    "classification",
    "task",
    "sentiment",
    "analysis",
    "task",
    "model",
    "purpose",
    "needed",
    "perform",
    "occupancy",
    "analytics",
    "task",
    "model",
    "use",
    "case",
    "shown",
    "gen",
    "ai",
    "applications",
    "let",
    "look",
    "example",
    "code",
    "generation",
    "shown",
    "second",
    "block",
    "code",
    "top",
    "example",
    "input",
    "code",
    "file",
    "conversion",
    "problem",
    "converting",
    "python",
    "json",
    "use",
    "bard",
    "insert",
    "prompt",
    "box",
    "following",
    "pandas",
    "dataframe",
    "two",
    "columns",
    "one",
    "file",
    "name",
    "one",
    "hour",
    "generated",
    "trying",
    "convert",
    "json",
    "file",
    "format",
    "shown",
    "onscreen",
    "bard",
    "returns",
    "steps",
    "need",
    "code",
    "snippet",
    "output",
    "json",
    "format",
    "gets",
    "better",
    "happen",
    "using",
    "google",
    "free",
    "jupyter",
    "notebook",
    "known",
    "colab",
    "simply",
    "export",
    "python",
    "code",
    "google",
    "colab",
    "summarize",
    "bart",
    "code",
    "generation",
    "help",
    "debug",
    "lines",
    "source",
    "code",
    "explain",
    "code",
    "line",
    "line",
    "craft",
    "sql",
    "queries",
    "database",
    "translate",
    "code",
    "one",
    "language",
    "another",
    "generate",
    "documentation",
    "tutorials",
    "source",
    "code",
    "generative",
    "ai",
    "studio",
    "lets",
    "quickly",
    "explore",
    "customize",
    "gen",
    "ai",
    "models",
    "leverage",
    "applications",
    "google",
    "cloud",
    "generative",
    "ai",
    "studio",
    "helps",
    "developers",
    "create",
    "deploy",
    "gen",
    "ai",
    "models",
    "providing",
    "variety",
    "tools",
    "resources",
    "make",
    "easy",
    "get",
    "started",
    "example",
    "library",
    "models",
    "tool",
    "fine",
    "tuning",
    "models",
    "tool",
    "deploying",
    "models",
    "production",
    "community",
    "forum",
    "developers",
    "share",
    "ideas",
    "collaborate",
    "generative",
    "ai",
    "app",
    "builder",
    "lets",
    "create",
    "gen",
    "ai",
    "apps",
    "without",
    "write",
    "code",
    "gen",
    "ai",
    "app",
    "builder",
    "drag",
    "drop",
    "interface",
    "makes",
    "easy",
    "design",
    "build",
    "apps",
    "visual",
    "editor",
    "makes",
    "easy",
    "create",
    "edit",
    "app",
    "content",
    "search",
    "engine",
    "allows",
    "users",
    "search",
    "information",
    "within",
    "app",
    "conversational",
    "ai",
    "engine",
    "helps",
    "users",
    "interact",
    "app",
    "using",
    "natural",
    "language",
    "create",
    "digital",
    "assistants",
    "custom",
    "search",
    "engines",
    "knowledge",
    "bases",
    "training",
    "applications",
    "much",
    "palm",
    "api",
    "lets",
    "test",
    "experiment",
    "google",
    "large",
    "language",
    "models",
    "gen",
    "ai",
    "tools",
    "make",
    "prototyping",
    "quick",
    "accessible",
    "developers",
    "integrate",
    "palm",
    "api",
    "maker",
    "suite",
    "use",
    "access",
    "api",
    "using",
    "graphical",
    "user",
    "interface",
    "suite",
    "includes",
    "number",
    "different",
    "tools",
    "model",
    "training",
    "tool",
    "model",
    "deployment",
    "tool",
    "model",
    "monitoring",
    "tool",
    "model",
    "training",
    "tool",
    "helps",
    "developers",
    "train",
    "ml",
    "models",
    "data",
    "using",
    "different",
    "algorithms",
    "model",
    "deployment",
    "tool",
    "helps",
    "developers",
    "deploy",
    "ml",
    "models",
    "production",
    "number",
    "different",
    "deployment",
    "options",
    "model",
    "monitoring",
    "tool",
    "helps",
    "developers",
    "monitor",
    "performance",
    "ml",
    "models",
    "production",
    "using",
    "dashboard",
    "number",
    "different",
    "metrics",
    "thank",
    "watching",
    "course",
    "introduction",
    "generative",
    "ai"
  ],
  "keywords": [
    "generative",
    "ai",
    "name",
    "artificial",
    "intelligence",
    "google",
    "learn",
    "model",
    "types",
    "applications",
    "type",
    "content",
    "including",
    "text",
    "audio",
    "data",
    "explore",
    "let",
    "provide",
    "two",
    "difference",
    "machine",
    "learning",
    "one",
    "discipline",
    "like",
    "example",
    "methods",
    "build",
    "input",
    "trained",
    "make",
    "predictions",
    "new",
    "used",
    "train",
    "programming",
    "models",
    "unsupervised",
    "supervised",
    "ml",
    "labels",
    "labeled",
    "comes",
    "number",
    "unlabeled",
    "problem",
    "might",
    "amount",
    "much",
    "different",
    "based",
    "whether",
    "learns",
    "examples",
    "predict",
    "values",
    "case",
    "uses",
    "look",
    "get",
    "foundation",
    "x",
    "prediction",
    "training",
    "predicted",
    "called",
    "deep",
    "subset",
    "many",
    "neural",
    "networks",
    "process",
    "patterns",
    "perform",
    "making",
    "traditional",
    "use",
    "network",
    "large",
    "helps",
    "task",
    "gen",
    "using",
    "language",
    "discriminative",
    "points",
    "label",
    "instances",
    "learned",
    "probability",
    "distribution",
    "existing",
    "thus",
    "generate",
    "take",
    "output",
    "given",
    "dog",
    "cat",
    "summarize",
    "image",
    "shows",
    "shown",
    "natural",
    "would",
    "inputs",
    "sentence",
    "question",
    "response",
    "high",
    "takes",
    "code",
    "give",
    "something",
    "images",
    "video",
    "users",
    "palm",
    "prompt",
    "create",
    "information",
    "another",
    "answering",
    "generated",
    "bard",
    "wide",
    "range",
    "transformers",
    "hallucinations",
    "enough",
    "user",
    "search",
    "includes",
    "api",
    "file",
    "json",
    "lets",
    "developers",
    "tools",
    "easy",
    "tool",
    "production",
    "app",
    "deployment"
  ]
}