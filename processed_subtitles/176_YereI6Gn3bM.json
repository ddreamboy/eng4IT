{
  "text": "speech it's the most natural form of\nhuman communication\nthis is my demo of a real-time speech\nrecognition system\nusing deep learning\nyo what's up world michael here and\ntoday we're going to be talking about\nspeech recognition\nwhy it's hard and how deep learning can\nhelp solve it\nlater in this video we're going to build\nour own neural network and train the\nspeech recognition model from scratch\nso humans are really good at\nunderstanding speech so you would also\nthink it's easy for computers to do too\nas well right\nspeech recognition is actually really\nhard for computers\nspeech is essentially sound waves which\nlives in a physical world\nwith their own physical properties for\nexample a person's age\ngender style personality accent\nall affects how they speak in the\nphysical properties of\nsound a computer also got to consider\nthe environmental noise around the\nspeaker\nand the type of microphones they're\nusing to record so because there's so\nmany variations and nuances\nin the physical properties of speech it\nmakes it extremely hard to come up with\nall the rules possible\nfor speech recognition not only do you\nhave to deal with the physical\nproperties of speech but you have to\ndeal with the linguistic\nproperties of it as well consider the\nsentence\ni read a book last night i like to read\nread and read are spelled the same but\nthey sound different\nred can be spelled like the color red\nbut in this context it needs to be\nspelled like red for reading\nso language itself is really complex and\nit has a lot of nuance and variations\nthat you would have to come up with\nall possible rules for it as well to\nhave an effective speech recognition\nso what do you do when you have like\nwhat seems like an insurmountable amount\nof rules\nyou use deep learning so deep learning\nhas changed the game for a lot of\ncomplex tasks\nany modern speech recognition system\ntoday leverages deep learning in some\nway\nso to build an effective speech\nrecognition system we have to have a\nstrategy\non how to tackle the physical properties\nof speech as well as the linguistic\nproperties of it\nlet's start with the physical property\nto properly deal with the variations in\nnuances that comes with the physicality\nof speech like age\ngender microphone environmental\ncondition etc\nwe'll build an acoustic model on a high\nlevel our acoustic model will be a\nneural network that takes in speech\nwaves as input and outputs to transcribe\ntext\nin order for our neural network to know\nhow to properly transcribe the speech\nwaves to texts\nwe'll have to train it with a ton of\nspeech data let's first consider what\nmodel we want to use by looking at the\ntype of problem we are trying to solve\nspeech is a naturally occurring time\nsequence meaning we need a neural\nnetwork that can process\nsequential data the neural network also\nneeds to be lightweight in terms of\nmemory and compute\nbecause we want to run it real time on\neveryday consumer machines\nrecurrent neural networks or rnn for\nshort are a natural fit for this task as\nit excels at processing sequential data\neven when we configure it to be a\nsmaller network size\nso we'll use that as our acoustic model\nnow let's consider the data\nwhat a neural network can learn is\ndependent on the data you train it with\nif we want our neural network to learn\nthe nuances of speech we'll need speech\ndata that has a lot of variations of\ngender\nage accent environmental noise and types\nof microphones\ncommon voice is an open source speech\ndata set initiative led by mozilla that\nhas many of those variations so it'll be\nperfect\nlet's listen to a couple samples\n[Music]\ngordon no longer mentions boot laces and\nthe two engines\nsoon talk about trucks\nfavors granted jews latin colonies\ncontinue\nit has since been renamed yes a raft\ninternational airport\neach audio sample comes with labels of\nthe transcribed text\nokay i think we have a solid approach we\nhave a data set that contains\nsome variation in nuances as well as a\nlightweight neural network architecture\nnow let's talk about the linguistic\naspect of speech\nto inject linguistic features into the\ntranscriptions we'll use something\ncalled a language model\nalongside a rescoring algorithm to\nunderstand how this works at a high\nlevel let's look at the acoustic model's\noutput\na speech recognition neural network is\nprobabilistic so for each time step it\noutputs a probability of possible words\nyou can naively take the highest\nprobable word of each time step\nand emit that as your transcript but\nyour network can easily make linguistic\nmistakes like using the word red for\ncolor\nwhen it should be read for reading this\nis when the language model comes into\nplay\na language model can determine what is a\nmore likely sentence\nby building a probability distribution\nover sequences of words it trains on\nyou can use a language model and rescore\nthe probabilities depending on the\ncontext of the sentence\nyou'll get an idea of how all this works\nin a minute for our implementation\nof a language model we can use an open\nsource project called ken lm which is a\nrules-based language model\nwe want to use ken lem because it's\nlightweight and super fast\nunlike the much heavier neural network\nbased language models\na neural based language model like\ntransformers from hugging face\nhave been proven to produce better\nresults but since our goal is low\ncompute\nwe'll use klm which works well enough\nfor the rescoring algorithm we'll use\nwhat's called a ctc beam search\nthe beam search combined with the\nlanguage model is how we'll rescore the\noutputs for better transcriptions\nthe logic of the beam search algorithm\ncan get pretty complex and very boring\nand i'm\nway too busy to attempt an in-depth\nexplanation here\nbut here's the basic premise the beam\nsearch algorithm will traverse the\noutputs of the acoustic model\nand use the language model to build\nhypothesis aka\nbeams for the final output during the\nbeam search\nif the language model sees that the word\nbook exists in the transcription\nit will boost the probability of the\nbeams that contains red\nlike reading instead of red like color\nbecause it makes more sense\nthis process will produce more accurate\ntranscriptions\nthank the programming guides for open\nsource code so we don't have to build\nthe language model and the ctc beam\nsearch rescoring algorithm ourselves\nwhich will save us a ton of time so to\nsum it up\nusing a language model in the ctc beam\nsearch algorithm\nwe can inject language information into\nthe acoustic model's output\nwhich results in more accurate\ntranscriptions\nokay i think we have a pretty solid\nstrategy on how to tackle the speech\nrecognition problem\nfor the physical properties we'll\nimplement an acoustic model and for the\nlinguistic properties we'll implement a\nlanguage model with a rescoring\nalgorithm\nlet's get to building\n[Music]\nfirst we need to build a data processing\npipeline we'll need to transform the raw\naudio waves into what's called metal\nspecial grams you can just think of male\nspectrograms as a pictorial\nrepresentation of sound\nwe also need to process our character\nlabels our models will be character\nbased meaning it will output characters\ninstead of word probabilities decoding\ncharacter probabilities is more\nefficient because we only have to worry\nabout 27 probabilities for each output\ninstead of like a hundred or thousand of\npossible words\nwe need to augment our data so we can\neffectively have a bigger data so we'll\nuse spec augment\nspec argument is augmentation technique\nthat cuts out the information in the\ntime and frequency domain effectively\ndestroying pieces of the data\nthis makes the neural network more\nrobust because it's forced to learn how\nto make correct predictions with\nimperfect data making it more\ngeneralizable to real world\nnow let's move on to the model the model\nconsists of a convolutional layer three\ndense layer and an r and lstm layer the\npurpose of the convolutional layer is\ntwo things\nit learns to extract better features\nfrom the mel spectrogram and also reduce\nthe time dimensions of the data\nin theory they say an n layer will\nproduce features that should be more\nrobust causing the rnns to produce\nbetter predictions\nwe also set the shot of the cnn layer to\n2 therefore reducing the time steps of\nthe male spectrogram by half allowing\nthe rns to do less work because there\nare less time steps which would make the\noverall network faster\nwe added two more dense layers in\nbetween the cnn and the rnns the purpose\nof the dense layer is to also learn to\nproduce a more robust set of features\nfor the rnn's\nfor the rnn layer we're using lstm\nbearing the rnn takes the features\nproduced by the previous dense layer and\nstep-by-step produces an output that can\nbe used for prediction\nwe also have a final dense layer with a\nsoftmax activation that acts like a\nclassifier classifier takes the rnn's\noutput and predicts character\nprobabilities for each time step\nwe add layer normalization yellow\nactivation and dropout between each\nlayer with the purpose of making the\nnetwork more generalizable and robust to\nreal-world data\nin deep learning adding more layers can\nlead to better results but since we want\nthis to be a lightweight model we stop\nat five layers we have one cnn layer one\nlsdmr and then layer and three dense\nlayers\nfor the training screen we'll use\npytorch lightning pytorch lightning is a\nlibrary for pytorch that decouples the\nscience code from the engineering code\nfor the training objective i use ctc\nloss function which makes it super easy\nto train speech recognition models\nit can assign probabilities given an\ninput making it possible to just have\nyour audio sample pair with their\ncorresponding text labels without\nneeding to align these characters to\nevery single frame of the audio\noh hey just finishing up the rest of the\ncode here\nthis code is open source so if you want\nto see the full implementation details\nmake sure you check out the github repo\nin the description below\nnow that we have the code we need to\nstart training this is the perfect time\nto introduce my training rig\nwar machine war machine is my personal\ndeep learning rig i use to train models\nif you're following along i recommend\nusing a gpu so if you don't have a gpu\nyou can use free alternatives like\ngoogle collab or kaggle kernels\nokay let's get to training\nso\n[Music]\nall right so training's finally finished\nit took a couple of days but i'm pretty\nhappy with the results check it out\nthe lost curves they both look pretty\ngood\nit doesn't seem like anything's\noverfitting also while\neverything was training i implemented\nthe language model\nand the rescoring algorithm from the\nopen source packages\nalso i made a little web demo using\nflask um to demo the speech recognition\nmodel\nso let me set everything up and let's\ntest this thing out\nokay so i got the demo prepared the\nfirst demo is going to be just the\nacoustic model without the language\nmodel and the rescoring algorithm\nthis is to showcase why it's important\nhi this is michael demoing my speech\nrecognition system\nwithout a language model and a rescoring\nalgorithm\nas you can see it's it's not very\ngood\nlet me set up the second demo\nokay so this is the second demo with the\nlanguage model and\nrescoring algorithm\nhi this is michael demoing my speech\nrecognition system\nwith a language model and a rescoring\nalgorithm\nas you can see it does a lot better but\nit's not perfect\nokay so the speech recognition system\nwith the language model\nand the rescoring algorithm works pretty\nwell with me\nbut let me reveal something i haven't\nmentioned yet i collected about an\nhour of my speech and trained it with\nthe common voice data set which is about\na thousand hours\none thing i forgot to mention when\nfilming this clip was that i also up\nsampled the one hour recording of myself\nto about 50 hours so it can be more\nrepresentative\nin the entire training data set okay\nplay so there is a possibility that that\nextra hour of my voice\nhas bias the algorithm to work really\nwell with me\nso to test that theory i want to try the\nspeech recognition system\nwith other people\nwell you know if it's my brother long\nlong i need you to test this out for me\nreal quick\nall right just press that start button\nand say whatever you want\nhi baby girl\nsay something else you look fine\nokay say support stuff\nhey you better quit go around\n[Music]\nokay as you can see it doesn't work very\nwell on his voice but when i start\ntalking\nyou can see it start picking up on what\ni'm saying right\noh then that's cool okay thank you\nokay so our next guest is big on privacy\nso we'll just skip the introductions and\ngo straight into the demo\nand play say anything you want\ni love charlie baby and oliver\nsay something else this thing sucks\n[Laughter]\nokay as you can tell it only works well\nfor me again\nit doesn't work very well for her so she\nthinks it sucks\nalright so as you can tell from my\nguest's reaction the speech recognition\nsystem is not that great\nat least on them works really well for\nme that's because i biased the algorithm\nby adding my own data\nall of this was expected though these\nspeech 2 a very famous speech\nrecognition paper\nfrom baidu claimed that you need about\n11 000 hours of audio data\nto have an effective speech recognition\nsystem and we use like what a thousand\nhours or so\ntheir model also has 70 million\nparameters\ncompared to our model which is 4 million\nparameters\ni chose a small architecture on purpose\nbecause i want it to be small and i\nwanted to run real time on\nany consumer device like my laptop so i\nthink overall the system works pretty\nwell\nif you can collect your own data so if\nyou want to train your own speech\nrecognition system i recommend you\ncollect your own data using something\nlike the mimic recording studio which is\nwhat i used\ni'll also open source a pre-trained\nmodel that you can download and then you\ncan just fine-tune that on your own data\nso you don't have to go through the\ntrouble of training it on the thousand\nhours of common voice like i did\ni have the links to all the goodies in\nthe description so make sure you check\nthat out\nso this video was part of the series of\nhow to build your own ai voice assistant\nusing pytorch so far i've done the\nwakeword detection which is the first\nvideo\nnow i did the automatic speech\nrecognition i still have\nthe natural language understanding part\nwhich is the way to map the\ntranscription\nto some sort of action like what's the\nweather like\nand then i also have to do the speed\nsynthesis part which is the synthetic\nvoice of the ai voice assistant so if\nyou want to be updated when those videos\ncome out make sure you hit that like and\nsubscribe button\nalso i have a discord server that's\ngetting pretty active\nif you want a community of ai\nenthusiasts practitioners and hackers\nmake sure you join the discord server\nwe want to start planning events in the\ndiscord server so if you're curious\nabout what they are then make sure you\njoin\nokay so that's it for this video and as\nalways\nthanks for watching\n[Music]\n[Music]\nyou\n",
  "words": [
    "speech",
    "natural",
    "form",
    "human",
    "communication",
    "demo",
    "speech",
    "recognition",
    "system",
    "using",
    "deep",
    "learning",
    "yo",
    "world",
    "michael",
    "today",
    "going",
    "talking",
    "speech",
    "recognition",
    "hard",
    "deep",
    "learning",
    "help",
    "solve",
    "later",
    "video",
    "going",
    "build",
    "neural",
    "network",
    "train",
    "speech",
    "recognition",
    "model",
    "scratch",
    "humans",
    "really",
    "good",
    "understanding",
    "speech",
    "would",
    "also",
    "think",
    "easy",
    "computers",
    "well",
    "right",
    "speech",
    "recognition",
    "actually",
    "really",
    "hard",
    "computers",
    "speech",
    "essentially",
    "sound",
    "waves",
    "lives",
    "physical",
    "world",
    "physical",
    "properties",
    "example",
    "person",
    "age",
    "gender",
    "style",
    "personality",
    "accent",
    "affects",
    "speak",
    "physical",
    "properties",
    "sound",
    "computer",
    "also",
    "got",
    "consider",
    "environmental",
    "noise",
    "around",
    "speaker",
    "type",
    "microphones",
    "using",
    "record",
    "many",
    "variations",
    "nuances",
    "physical",
    "properties",
    "speech",
    "makes",
    "extremely",
    "hard",
    "come",
    "rules",
    "possible",
    "speech",
    "recognition",
    "deal",
    "physical",
    "properties",
    "speech",
    "deal",
    "linguistic",
    "properties",
    "well",
    "consider",
    "sentence",
    "read",
    "book",
    "last",
    "night",
    "like",
    "read",
    "read",
    "read",
    "spelled",
    "sound",
    "different",
    "red",
    "spelled",
    "like",
    "color",
    "red",
    "context",
    "needs",
    "spelled",
    "like",
    "red",
    "reading",
    "language",
    "really",
    "complex",
    "lot",
    "nuance",
    "variations",
    "would",
    "come",
    "possible",
    "rules",
    "well",
    "effective",
    "speech",
    "recognition",
    "like",
    "seems",
    "like",
    "insurmountable",
    "amount",
    "rules",
    "use",
    "deep",
    "learning",
    "deep",
    "learning",
    "changed",
    "game",
    "lot",
    "complex",
    "tasks",
    "modern",
    "speech",
    "recognition",
    "system",
    "today",
    "leverages",
    "deep",
    "learning",
    "way",
    "build",
    "effective",
    "speech",
    "recognition",
    "system",
    "strategy",
    "tackle",
    "physical",
    "properties",
    "speech",
    "well",
    "linguistic",
    "properties",
    "let",
    "start",
    "physical",
    "property",
    "properly",
    "deal",
    "variations",
    "nuances",
    "comes",
    "physicality",
    "speech",
    "like",
    "age",
    "gender",
    "microphone",
    "environmental",
    "condition",
    "etc",
    "build",
    "acoustic",
    "model",
    "high",
    "level",
    "acoustic",
    "model",
    "neural",
    "network",
    "takes",
    "speech",
    "waves",
    "input",
    "outputs",
    "transcribe",
    "text",
    "order",
    "neural",
    "network",
    "know",
    "properly",
    "transcribe",
    "speech",
    "waves",
    "texts",
    "train",
    "ton",
    "speech",
    "data",
    "let",
    "first",
    "consider",
    "model",
    "want",
    "use",
    "looking",
    "type",
    "problem",
    "trying",
    "solve",
    "speech",
    "naturally",
    "occurring",
    "time",
    "sequence",
    "meaning",
    "need",
    "neural",
    "network",
    "process",
    "sequential",
    "data",
    "neural",
    "network",
    "also",
    "needs",
    "lightweight",
    "terms",
    "memory",
    "compute",
    "want",
    "run",
    "real",
    "time",
    "everyday",
    "consumer",
    "machines",
    "recurrent",
    "neural",
    "networks",
    "rnn",
    "short",
    "natural",
    "fit",
    "task",
    "excels",
    "processing",
    "sequential",
    "data",
    "even",
    "configure",
    "smaller",
    "network",
    "size",
    "use",
    "acoustic",
    "model",
    "let",
    "consider",
    "data",
    "neural",
    "network",
    "learn",
    "dependent",
    "data",
    "train",
    "want",
    "neural",
    "network",
    "learn",
    "nuances",
    "speech",
    "need",
    "speech",
    "data",
    "lot",
    "variations",
    "gender",
    "age",
    "accent",
    "environmental",
    "noise",
    "types",
    "microphones",
    "common",
    "voice",
    "open",
    "source",
    "speech",
    "data",
    "set",
    "initiative",
    "led",
    "mozilla",
    "many",
    "variations",
    "perfect",
    "let",
    "listen",
    "couple",
    "samples",
    "music",
    "gordon",
    "longer",
    "mentions",
    "boot",
    "laces",
    "two",
    "engines",
    "soon",
    "talk",
    "trucks",
    "favors",
    "granted",
    "jews",
    "latin",
    "colonies",
    "continue",
    "since",
    "renamed",
    "yes",
    "raft",
    "international",
    "airport",
    "audio",
    "sample",
    "comes",
    "labels",
    "transcribed",
    "text",
    "okay",
    "think",
    "solid",
    "approach",
    "data",
    "set",
    "contains",
    "variation",
    "nuances",
    "well",
    "lightweight",
    "neural",
    "network",
    "architecture",
    "let",
    "talk",
    "linguistic",
    "aspect",
    "speech",
    "inject",
    "linguistic",
    "features",
    "transcriptions",
    "use",
    "something",
    "called",
    "language",
    "model",
    "alongside",
    "rescoring",
    "algorithm",
    "understand",
    "works",
    "high",
    "level",
    "let",
    "look",
    "acoustic",
    "model",
    "output",
    "speech",
    "recognition",
    "neural",
    "network",
    "probabilistic",
    "time",
    "step",
    "outputs",
    "probability",
    "possible",
    "words",
    "naively",
    "take",
    "highest",
    "probable",
    "word",
    "time",
    "step",
    "emit",
    "transcript",
    "network",
    "easily",
    "make",
    "linguistic",
    "mistakes",
    "like",
    "using",
    "word",
    "red",
    "color",
    "read",
    "reading",
    "language",
    "model",
    "comes",
    "play",
    "language",
    "model",
    "determine",
    "likely",
    "sentence",
    "building",
    "probability",
    "distribution",
    "sequences",
    "words",
    "trains",
    "use",
    "language",
    "model",
    "rescore",
    "probabilities",
    "depending",
    "context",
    "sentence",
    "get",
    "idea",
    "works",
    "minute",
    "implementation",
    "language",
    "model",
    "use",
    "open",
    "source",
    "project",
    "called",
    "ken",
    "lm",
    "language",
    "model",
    "want",
    "use",
    "ken",
    "lem",
    "lightweight",
    "super",
    "fast",
    "unlike",
    "much",
    "heavier",
    "neural",
    "network",
    "based",
    "language",
    "models",
    "neural",
    "based",
    "language",
    "model",
    "like",
    "transformers",
    "hugging",
    "face",
    "proven",
    "produce",
    "better",
    "results",
    "since",
    "goal",
    "low",
    "compute",
    "use",
    "klm",
    "works",
    "well",
    "enough",
    "rescoring",
    "algorithm",
    "use",
    "called",
    "ctc",
    "beam",
    "search",
    "beam",
    "search",
    "combined",
    "language",
    "model",
    "rescore",
    "outputs",
    "better",
    "transcriptions",
    "logic",
    "beam",
    "search",
    "algorithm",
    "get",
    "pretty",
    "complex",
    "boring",
    "way",
    "busy",
    "attempt",
    "explanation",
    "basic",
    "premise",
    "beam",
    "search",
    "algorithm",
    "traverse",
    "outputs",
    "acoustic",
    "model",
    "use",
    "language",
    "model",
    "build",
    "hypothesis",
    "aka",
    "beams",
    "final",
    "output",
    "beam",
    "search",
    "language",
    "model",
    "sees",
    "word",
    "book",
    "exists",
    "transcription",
    "boost",
    "probability",
    "beams",
    "contains",
    "red",
    "like",
    "reading",
    "instead",
    "red",
    "like",
    "color",
    "makes",
    "sense",
    "process",
    "produce",
    "accurate",
    "transcriptions",
    "thank",
    "programming",
    "guides",
    "open",
    "source",
    "code",
    "build",
    "language",
    "model",
    "ctc",
    "beam",
    "search",
    "rescoring",
    "algorithm",
    "save",
    "us",
    "ton",
    "time",
    "sum",
    "using",
    "language",
    "model",
    "ctc",
    "beam",
    "search",
    "algorithm",
    "inject",
    "language",
    "information",
    "acoustic",
    "model",
    "output",
    "results",
    "accurate",
    "transcriptions",
    "okay",
    "think",
    "pretty",
    "solid",
    "strategy",
    "tackle",
    "speech",
    "recognition",
    "problem",
    "physical",
    "properties",
    "implement",
    "acoustic",
    "model",
    "linguistic",
    "properties",
    "implement",
    "language",
    "model",
    "rescoring",
    "algorithm",
    "let",
    "get",
    "building",
    "music",
    "first",
    "need",
    "build",
    "data",
    "processing",
    "pipeline",
    "need",
    "transform",
    "raw",
    "audio",
    "waves",
    "called",
    "metal",
    "special",
    "grams",
    "think",
    "male",
    "spectrograms",
    "pictorial",
    "representation",
    "sound",
    "also",
    "need",
    "process",
    "character",
    "labels",
    "models",
    "character",
    "based",
    "meaning",
    "output",
    "characters",
    "instead",
    "word",
    "probabilities",
    "decoding",
    "character",
    "probabilities",
    "efficient",
    "worry",
    "27",
    "probabilities",
    "output",
    "instead",
    "like",
    "hundred",
    "thousand",
    "possible",
    "words",
    "need",
    "augment",
    "data",
    "effectively",
    "bigger",
    "data",
    "use",
    "spec",
    "augment",
    "spec",
    "argument",
    "augmentation",
    "technique",
    "cuts",
    "information",
    "time",
    "frequency",
    "domain",
    "effectively",
    "destroying",
    "pieces",
    "data",
    "makes",
    "neural",
    "network",
    "robust",
    "forced",
    "learn",
    "make",
    "correct",
    "predictions",
    "imperfect",
    "data",
    "making",
    "generalizable",
    "real",
    "world",
    "let",
    "move",
    "model",
    "model",
    "consists",
    "convolutional",
    "layer",
    "three",
    "dense",
    "layer",
    "r",
    "lstm",
    "layer",
    "purpose",
    "convolutional",
    "layer",
    "two",
    "things",
    "learns",
    "extract",
    "better",
    "features",
    "mel",
    "spectrogram",
    "also",
    "reduce",
    "time",
    "dimensions",
    "data",
    "theory",
    "say",
    "n",
    "layer",
    "produce",
    "features",
    "robust",
    "causing",
    "rnns",
    "produce",
    "better",
    "predictions",
    "also",
    "set",
    "shot",
    "cnn",
    "layer",
    "2",
    "therefore",
    "reducing",
    "time",
    "steps",
    "male",
    "spectrogram",
    "half",
    "allowing",
    "rns",
    "less",
    "work",
    "less",
    "time",
    "steps",
    "would",
    "make",
    "overall",
    "network",
    "faster",
    "added",
    "two",
    "dense",
    "layers",
    "cnn",
    "rnns",
    "purpose",
    "dense",
    "layer",
    "also",
    "learn",
    "produce",
    "robust",
    "set",
    "features",
    "rnn",
    "rnn",
    "layer",
    "using",
    "lstm",
    "bearing",
    "rnn",
    "takes",
    "features",
    "produced",
    "previous",
    "dense",
    "layer",
    "produces",
    "output",
    "used",
    "prediction",
    "also",
    "final",
    "dense",
    "layer",
    "softmax",
    "activation",
    "acts",
    "like",
    "classifier",
    "classifier",
    "takes",
    "rnn",
    "output",
    "predicts",
    "character",
    "probabilities",
    "time",
    "step",
    "add",
    "layer",
    "normalization",
    "yellow",
    "activation",
    "dropout",
    "layer",
    "purpose",
    "making",
    "network",
    "generalizable",
    "robust",
    "data",
    "deep",
    "learning",
    "adding",
    "layers",
    "lead",
    "better",
    "results",
    "since",
    "want",
    "lightweight",
    "model",
    "stop",
    "five",
    "layers",
    "one",
    "cnn",
    "layer",
    "one",
    "lsdmr",
    "layer",
    "three",
    "dense",
    "layers",
    "training",
    "screen",
    "use",
    "pytorch",
    "lightning",
    "pytorch",
    "lightning",
    "library",
    "pytorch",
    "decouples",
    "science",
    "code",
    "engineering",
    "code",
    "training",
    "objective",
    "use",
    "ctc",
    "loss",
    "function",
    "makes",
    "super",
    "easy",
    "train",
    "speech",
    "recognition",
    "models",
    "assign",
    "probabilities",
    "given",
    "input",
    "making",
    "possible",
    "audio",
    "sample",
    "pair",
    "corresponding",
    "text",
    "labels",
    "without",
    "needing",
    "align",
    "characters",
    "every",
    "single",
    "frame",
    "audio",
    "oh",
    "hey",
    "finishing",
    "rest",
    "code",
    "code",
    "open",
    "source",
    "want",
    "see",
    "full",
    "implementation",
    "details",
    "make",
    "sure",
    "check",
    "github",
    "repo",
    "description",
    "code",
    "need",
    "start",
    "training",
    "perfect",
    "time",
    "introduce",
    "training",
    "rig",
    "war",
    "machine",
    "war",
    "machine",
    "personal",
    "deep",
    "learning",
    "rig",
    "use",
    "train",
    "models",
    "following",
    "along",
    "recommend",
    "using",
    "gpu",
    "gpu",
    "use",
    "free",
    "alternatives",
    "like",
    "google",
    "collab",
    "kaggle",
    "kernels",
    "okay",
    "let",
    "get",
    "training",
    "music",
    "right",
    "training",
    "finally",
    "finished",
    "took",
    "couple",
    "days",
    "pretty",
    "happy",
    "results",
    "check",
    "lost",
    "curves",
    "look",
    "pretty",
    "good",
    "seem",
    "like",
    "anything",
    "overfitting",
    "also",
    "everything",
    "training",
    "implemented",
    "language",
    "model",
    "rescoring",
    "algorithm",
    "open",
    "source",
    "packages",
    "also",
    "made",
    "little",
    "web",
    "demo",
    "using",
    "flask",
    "um",
    "demo",
    "speech",
    "recognition",
    "model",
    "let",
    "set",
    "everything",
    "let",
    "test",
    "thing",
    "okay",
    "got",
    "demo",
    "prepared",
    "first",
    "demo",
    "going",
    "acoustic",
    "model",
    "without",
    "language",
    "model",
    "rescoring",
    "algorithm",
    "showcase",
    "important",
    "hi",
    "michael",
    "demoing",
    "speech",
    "recognition",
    "system",
    "without",
    "language",
    "model",
    "rescoring",
    "algorithm",
    "see",
    "good",
    "let",
    "set",
    "second",
    "demo",
    "okay",
    "second",
    "demo",
    "language",
    "model",
    "rescoring",
    "algorithm",
    "hi",
    "michael",
    "demoing",
    "speech",
    "recognition",
    "system",
    "language",
    "model",
    "rescoring",
    "algorithm",
    "see",
    "lot",
    "better",
    "perfect",
    "okay",
    "speech",
    "recognition",
    "system",
    "language",
    "model",
    "rescoring",
    "algorithm",
    "works",
    "pretty",
    "well",
    "let",
    "reveal",
    "something",
    "mentioned",
    "yet",
    "collected",
    "hour",
    "speech",
    "trained",
    "common",
    "voice",
    "data",
    "set",
    "thousand",
    "hours",
    "one",
    "thing",
    "forgot",
    "mention",
    "filming",
    "clip",
    "also",
    "sampled",
    "one",
    "hour",
    "recording",
    "50",
    "hours",
    "representative",
    "entire",
    "training",
    "data",
    "set",
    "okay",
    "play",
    "possibility",
    "extra",
    "hour",
    "voice",
    "bias",
    "algorithm",
    "work",
    "really",
    "well",
    "test",
    "theory",
    "want",
    "try",
    "speech",
    "recognition",
    "system",
    "people",
    "well",
    "know",
    "brother",
    "long",
    "long",
    "need",
    "test",
    "real",
    "quick",
    "right",
    "press",
    "start",
    "button",
    "say",
    "whatever",
    "want",
    "hi",
    "baby",
    "girl",
    "say",
    "something",
    "else",
    "look",
    "fine",
    "okay",
    "say",
    "support",
    "stuff",
    "hey",
    "better",
    "quit",
    "go",
    "around",
    "music",
    "okay",
    "see",
    "work",
    "well",
    "voice",
    "start",
    "talking",
    "see",
    "start",
    "picking",
    "saying",
    "right",
    "oh",
    "cool",
    "okay",
    "thank",
    "okay",
    "next",
    "guest",
    "big",
    "privacy",
    "skip",
    "introductions",
    "go",
    "straight",
    "demo",
    "play",
    "say",
    "anything",
    "want",
    "love",
    "charlie",
    "baby",
    "oliver",
    "say",
    "something",
    "else",
    "thing",
    "sucks",
    "laughter",
    "okay",
    "tell",
    "works",
    "well",
    "work",
    "well",
    "thinks",
    "sucks",
    "alright",
    "tell",
    "guest",
    "reaction",
    "speech",
    "recognition",
    "system",
    "great",
    "least",
    "works",
    "really",
    "well",
    "biased",
    "algorithm",
    "adding",
    "data",
    "expected",
    "though",
    "speech",
    "2",
    "famous",
    "speech",
    "recognition",
    "paper",
    "baidu",
    "claimed",
    "need",
    "11",
    "000",
    "hours",
    "audio",
    "data",
    "effective",
    "speech",
    "recognition",
    "system",
    "use",
    "like",
    "thousand",
    "hours",
    "model",
    "also",
    "70",
    "million",
    "parameters",
    "compared",
    "model",
    "4",
    "million",
    "parameters",
    "chose",
    "small",
    "architecture",
    "purpose",
    "want",
    "small",
    "wanted",
    "run",
    "real",
    "time",
    "consumer",
    "device",
    "like",
    "laptop",
    "think",
    "overall",
    "system",
    "works",
    "pretty",
    "well",
    "collect",
    "data",
    "want",
    "train",
    "speech",
    "recognition",
    "system",
    "recommend",
    "collect",
    "data",
    "using",
    "something",
    "like",
    "mimic",
    "recording",
    "studio",
    "used",
    "also",
    "open",
    "source",
    "model",
    "download",
    "data",
    "go",
    "trouble",
    "training",
    "thousand",
    "hours",
    "common",
    "voice",
    "like",
    "links",
    "goodies",
    "description",
    "make",
    "sure",
    "check",
    "video",
    "part",
    "series",
    "build",
    "ai",
    "voice",
    "assistant",
    "using",
    "pytorch",
    "far",
    "done",
    "wakeword",
    "detection",
    "first",
    "video",
    "automatic",
    "speech",
    "recognition",
    "still",
    "natural",
    "language",
    "understanding",
    "part",
    "way",
    "map",
    "transcription",
    "sort",
    "action",
    "like",
    "weather",
    "like",
    "also",
    "speed",
    "synthesis",
    "part",
    "synthetic",
    "voice",
    "ai",
    "voice",
    "assistant",
    "want",
    "updated",
    "videos",
    "come",
    "make",
    "sure",
    "hit",
    "like",
    "subscribe",
    "button",
    "also",
    "discord",
    "server",
    "getting",
    "pretty",
    "active",
    "want",
    "community",
    "ai",
    "enthusiasts",
    "practitioners",
    "hackers",
    "make",
    "sure",
    "join",
    "discord",
    "server",
    "want",
    "start",
    "planning",
    "events",
    "discord",
    "server",
    "curious",
    "make",
    "sure",
    "join",
    "okay",
    "video",
    "always",
    "thanks",
    "watching",
    "music",
    "music"
  ],
  "keywords": [
    "speech",
    "natural",
    "demo",
    "recognition",
    "system",
    "using",
    "deep",
    "learning",
    "world",
    "michael",
    "going",
    "hard",
    "video",
    "build",
    "neural",
    "network",
    "train",
    "model",
    "really",
    "good",
    "would",
    "also",
    "think",
    "well",
    "right",
    "sound",
    "waves",
    "physical",
    "properties",
    "age",
    "gender",
    "consider",
    "environmental",
    "variations",
    "nuances",
    "makes",
    "come",
    "rules",
    "possible",
    "deal",
    "linguistic",
    "sentence",
    "read",
    "like",
    "spelled",
    "red",
    "color",
    "reading",
    "language",
    "complex",
    "lot",
    "effective",
    "use",
    "way",
    "let",
    "start",
    "comes",
    "acoustic",
    "takes",
    "outputs",
    "text",
    "data",
    "first",
    "want",
    "time",
    "need",
    "process",
    "lightweight",
    "real",
    "rnn",
    "learn",
    "common",
    "voice",
    "open",
    "source",
    "set",
    "perfect",
    "music",
    "two",
    "since",
    "audio",
    "labels",
    "okay",
    "features",
    "transcriptions",
    "something",
    "called",
    "rescoring",
    "algorithm",
    "works",
    "look",
    "output",
    "step",
    "probability",
    "words",
    "word",
    "make",
    "play",
    "probabilities",
    "get",
    "based",
    "models",
    "produce",
    "better",
    "results",
    "ctc",
    "beam",
    "search",
    "pretty",
    "instead",
    "code",
    "character",
    "thousand",
    "robust",
    "making",
    "layer",
    "dense",
    "purpose",
    "say",
    "cnn",
    "work",
    "layers",
    "one",
    "training",
    "pytorch",
    "without",
    "see",
    "sure",
    "check",
    "test",
    "thing",
    "hi",
    "hour",
    "hours",
    "go",
    "part",
    "ai",
    "discord",
    "server"
  ]
}