{
  "text": "in this lesson you are going to\nunderstand the concept of unsupervised\nlearning\nby the end of this lesson you will be\nable to\nexplain the mechanism of unsupervised\nlearning\nuse different clustering techniques in\npython\noverview\nunsupervised learning is a machine\nlearning technique used to train the\nmachine learning algorithm using data\nthat is either unclassified or unlabeled\nand allows the algorithm to act on that\ndata without guidance\nunlabeled data is a designation for\npieces of data that have not been tagged\nwith labels identified by\ncharacteristics properties or\nclassifications\nso the flow of unsupervised learning\nstarts with training data that has no\nlabels and depends on the feature vector\nthe machine learning model defines the\npredictive model this is tested with an\nindividual subset of data with its own\nfeature vector\nhere the predictive model defines the\nlikelihood or cluster id or a better\nrepresentation of unlabeled data\nlet's look at the difference between\nunsupervised and supervised learning\nsupervised learning technique deals with\nlabeled data where the output data\npatterns are known to the system\nunsupervised learning works with\nunlabeled data in which the output is\njust based on the collection of\nperceptions\nsupervised learning method is less\ncomplex the unsupervised learning method\nis more complex supervised learning\nconducts offline analysis unsupervised\nlearning performs real-time analysis\nthe outcome of the supervised learning\ntechnique is comparatively more accurate\nand reliable unsupervised learning\ngenerates moderately acute but reliable\nresults\nwhile classification and regression are\nthe types of problems solved under the\nsupervised learning method\nunsupervised learning includes\nclustering and associative rule mining\nproblems\nexample and application of unsupervised\nlearning\nlet's understand unsupervised learning\nthrough an example\nconsider a scenario where a child had no\nlearning phase and is shown images\nwithout the labels now if the child is\nasked to identify if any range is a bird\nor an animal he will lack the\ninformation that can help him do so\nthe best he can do is come up with the\nfollowing groups based on common\npatterns wings and legs for example this\nexplains how unsupervised learning works\nwe show a lot of data to our algorithm\nand ask it to find patterns in the data\nby itself\nlet's look at the application of\nunsupervised learning\nunsupervised learning can be used for\nanomaly detection as well as clustering\nto understand clustering let's look at a\nsimple real-life example a mother asks\nher two children to arrange the pieces\nof playing blocks the children come up\nwith two different groups as shown with\ndifferent similarities in the blocks\nthis is clustering\neach of our children came up with a\ndifferent type of grouping one child\ngrouped them based on the shape whereas\nthe other grouped them based on the\ncolor there is no right or wrong way\nthen how can you pick one set of\nclusters over the others\nthis will depend on the similarity\nmeasure used by the mother in this case\nthe arrangement of child 1 is better\nthan child 2 if the similarity measure\nchosen by the mother was that blocks\nshould have the same shape\nhowever the arrangement by child 2 is\nbetter if the similarity measure chosen\nby the mother was that blocks should\nhave the same color therefore defining\nthe similarity measure is important when\nperforming clustering\nthere may be different ways in which\ndata can be arranged in different groups\nbased on size shape color texture and\nother complex features\nanomaly detection is a clustering\ntechnique used to identify unusual\npatterns that do not conform to expected\nbehavior\nanomaly detection has many applications\nin business such as intrusion detection\nsystem health monitoring and fraud\ndetection\nclustering\nthe method of grouping similar entities\ntogether is called clustering the goal\nof this unsupervised machine learning\nmethod is to seek out similarities\nwithin the data points and to cluster\nsimilar data points together\nneed for clustering\nlet's look at the need for clustering\ngrouping similar entities together helps\nto merge the attributes of different\nclusters\nin other words this gives us insight\ninto underlying patterns of different\ngroups\nthere are a lot of applications of\ngrouping unlabeled data for example in\norder to maximize the revenue you can\nidentify different groups or clusters of\ncustomers and market to each group in a\ndifferent way\nanother example is grouping books\ntogether that belong to similar topics\nclustering is needed to\ndetermine the intrinsic grouping in a\nset of unlabeled data organize data into\nclusters that show internal structure of\nthe data partition the data points\nunderstand and extract value from large\nsets of structured and unstructured data\ntypes of clustering there are two types\nof clustering hierarchical clustering\nand partitional clustering\nhierarchical clustering can be\nagglomerative and divisive whereas\npartitional clustering can be k means\nand fuzzy c means a distinction among\ndifferent types of clustering is whether\nthe set of clusters is nested or\nunnested\na partitional clustering is just a\ndivision of the set of data objects into\nnon-overlapping sets or clusters such\nthat every data object is in just one\nsubset\na hierarchical clustering is a tree\nstructure that has a set of nested\nclusters\nhierarchical clustering the output of\nhierarchical clustering is a hierarchy\nhow does the hierarchical clustering\nform a hierarchy assume you are going to\ncreate a three-layer hierarchy from six\ndifferent data nodes\nso first combine a and b based on\nsimilarity and also combine d and e\nbased on similarity combination of a and\nb is combined with c\nin the similar way combination of d and\ne is combined with f\nnow combine c and f inside one cluster\nwhen you look at the final tree it\ncontains all clusters combined into a\nsingle cluster\nlet's understand the working of\nhierarchical clustering it works in four\nsteps\nstep one assign each item to its own\ncluster such that if you have n number\nof items you will have n number of\nclusters\nstep two\nmerge two clusters into a single cluster\nby finding the closest pair of clusters\nnow you will have one cluster less\nstep three compute distances between the\nnew cluster and all old clusters step\nfour repeat steps two and three until\nall items are clustered into a single\ncluster of size n\nlet's understand the distance measure in\nhierarchical clustering let's look at\nthe different kinds of linkage in\nclustering\ncomplete linkage clustering it finds the\nmaximum distance between points\nbelonging to two different clusters\nsingle linkage clustering it finds the\nminimum possible distance between points\nbelonging to two different clusters\nmean linkage clustering it finds all\npossible pairwise distances for points\nbelonging to two different clusters and\nthen calculates the average\ncentroid linkage clustering it finds the\ncentroid of each cluster and calculates\nthe distance between them\nwhat is dendrogram\nit is a tree diagram frequently used to\nillustrate the arrangement of the\nclusters produced by hierarchical\nclustering\nit shows the hierarchical relationship\nbetween objects it is most commonly\ncreated as an output of hierarchical\nclustering the main use of a dendrogram\nis to work out the best way to allocate\nobjects to clusters\nthe dendrogram also shows the\nhierarchical clustering of five\nobservations and the relationship\nbetween each of them\nhierarchical clustering example\nlet's understand hierarchical clustering\nthrough an example in the given example\nhierarchical clustering is used to find\nthe distances between the different\ncities in kilometers\nthe following matrix traces a\nhierarchical clustering of distances in\nmiles between different cities the\nmethod of clustering is single link\nhere as you can see from the given\ndistance matrix the nearest pair of\nobjects is t o and mi\nmi and tio are merged into a single\ncluster called mito as mi column has\nlower values than to column\nmito consists of mi column values\nmito column has one index with zero\nvalue this is because there is no\ndistance between cluster m i t o and m i\nt o\nto get a new distance matrix we compute\nthe distance from this new cluster to\nall other clusters\nnow the nearest pair of objects is n a\nand rm these are combined into a single\ncluster called narm to get a new\ndistance matrix we compute the distance\nfrom this new cluster to all other\nclusters in the similar way the nearest\npair of objects is ba and narm these are\ncombined into a single cluster called ba\nn a rm\nto get a new distance matrix we compute\nthe distance from the new cluster to all\nother clusters\nsimilarly now the nearest pair of\nobjects is ba narm and fi these combined\ninto a single cluster called\nb-a-n-a-r-m-f-i\nto get a new distance matrix we compute\nthe distance from this new cluster to\nall other clusters\nfinally we merge the last two clusters\nthis process is summarized by the\nclustering diagram on the right and the\nfinal distance matrix on the left\ndemo clustering animals problem scenario\nconsider the data set zoo dot data and\nlook at the information provided in the\nfirst five rows\nthe first column denotes the animal name\nand the last one specifies the high\nlevel class for the corresponding animal\nyou are supposed to find a solution to\nthe following questions\none identify the unique number of high\nlevel classes\ntwo perform agglomerative clustering\nusing the sixteen intermediate features\nthree compute the mean squared error by\ncomparing the actual high level class\nand the predicted high level class in a\nnutshell you just have to perform\nagglomerative clustering with the\nappropriate mse value\nlet's import the required libraries and\nthe data set\nsince we have now loaded the data set we\nwill extract some basic information from\nit as our first step with the info\ncommand it is clear that the data set\nhas 18 columns in total and 101 entries\nalso there are no null values let us now\nproceed towards the first question which\nis extracting the unique number of\nhigh-level classes\nmost probably the unique function from\nnumpy will help\nwe can plot the unique number of labels\nobtained using the matte plot lib\nlibrary\ncreate a figure and a set of subplots\nfrom the plot it can be seen that we\nhave seven unique class labels now since\nwe are about to group animals based on\ntheir features it's clear and quite\npredictive that clustering should be\nperformed\nlet's now extract the features leaving\nthe labels column and store them in\nanother data frame say features\nimport the necessary modules for\nperforming clustering\nspecify the number of clusters as seven\nnote that here we are specifying the\ntotal number of clusters as seven\nbecause there are seven unique class\nlabels\nalso specify the linkage method as\naverage and the similarity method as\ncosine\nfit the agglomerative clustering model\nover the feature variable defined\nearlier\nlet us extract the labels predicted by\nour model against the features\nwe can see that we have predicted labels\nagainst all of our 101 animals although\nwe have seven labels but it is numbered\nas six so in this case we can subtract\none from our original label column such\nthat it matches the predicted numbers\nnow let us move ahead and predict the\naccuracy of our model considering the\npredicting parameter as mean squared\nerror\nnow evaluate the absolute error by\napplying square root operation on the\nmean squared error\nprint the resultant error\nthe root mean squared error we got is\n2.43 approximately which is quite\nacceptable\nnow that we have clustered the animals\nlet's quickly recap the steps we have\ncovered\nimport libraries in the data set check\nfor missing values identify unique\nlabels and plot them extract features\nnecessary for clustering within a single\nvariable\nfit agglomerative clustering model on\nthe feature data\npredict labels for each animal print the\nrmse of the model k means clustering\nlet's look at the steps involved in\nk-means clustering\nk-means is an iterative clustering\nalgorithm whose goal is to find local\nmaxima in each iteration\nthis algorithm works in these four steps\nspecify the desired number of clusters k\nrandomly assign each data point to a\ncluster\ncompute cluster centroids\nreassign each point to the closest\ncluster centroid and recompute cluster\ncentroids in order to check if the\nconvergence criterion is met\nconsider the dots given in the diagram\nas the data points\nfirst k-means randomly chooses k\nexamples data points from the data set\nthe three colored points as initial\ncentroids this is because it does not\nknow yet where the center of each\ncluster is a centroid is the center of a\ncluster\nassign data points to the nearest\ncentroid then all the data points that\nare the nearest to a centroid will\ncreate a cluster as you can see there\nare three centroids as red blue and\npurple and all the data points of the\nsame color is one cluster so in total we\nhave three clusters now\nnow we have new clusters that need\ncenters\na centroid's new value is going to be\nthe mean of all the examples in a\ncluster\ncenters are moving because a centroid\nwill have the value of the mean of all\nthe data points in a cluster\nwe'll keep repeating steps 2 and 3 until\nthe k-means algorithm is converged that\nis until the centroids stop moving\noptimal number of clusters determining\nthe optimal number of clusters in a data\nset is a fundamental issue in\npartitioning clustering such as k-means\nclustering\nthis requires the user to specify the\nnumber of clusters k to be generated\nif you plot k against sse you will see\nthat the error decreases as k increases\nthis is because their size decreases and\nhence distortion is also smaller\nthe basic idea behind partitioning\nmethods such as k means clustering is to\ndefine clusters such that the total\nwithin cluster sum of square wss or the\ntotal intra cluster variation is\nminimized\nthe elbow method looks at the total wss\nas a function of the number of clusters\none should choose a number of clusters\nso that adding another cluster doesn't\nsignificantly improve the total wss\nit works in the following way\ncompute clustering algorithm for\ndifferent values of k\nfor instance by varying k from 1 to 20\nclusters calculate the total within\ncluster sum of square wss for each k\nvalue according to the number of\nclusters k plot the curve of wss the\nlocation of bend in the plot is\ngenerally considered as an indicator of\nthe appropriate number of clusters\ndemo cluster-based incentivization\nproblem scenario lithium power is the\nlargest producer of electric vehicle\ne-vehicle batteries they provide\nbatteries on rent to e-vehicle drivers\ndrivers rent a battery typically for a\nday and thereafter replacing it with a\ncharged battery from the company lithian\npower has a variable pricing model based\non the driver's driving history\nbattery life depends on factors such as\nover speeding distance driven per day\netc\nyou are supposed to create a cluster\nmodel where drivers can be grouped\ntogether based on the driving data and\nto group the data points so that drivers\nwill be incentivized based on the\ncluster\nlet's import the libraries numpy and\npandas\nimport visualization libraries namely\nmatplotlib and seaborne\nimport the warning module the warning\nmodule was introduced in pep230 as a way\nto warn programmers about changes in\nlanguage or library features in\nanticipation of backwards incompatible\nchanges coming with python 3.0\nimport met plot lib library for\nvisualization and an instance of rc\nparams for handling default met plot lib\nvalues\nplease note for the sake of simplicity\nwe will take only two features\nmean distance driven per day and the\nmean percentage of times a driver drove\nhigher than 5 miles per hour over the\nspeed limit\nlet us go through each of the columns\nfirst and understand them\nthe id column represents the unique id\nof the driver the mean underscore dist\nunderscore day column represents the\nmean distance driven by driver per day\nand the mean underscore over underscore\nspeed\nunderscore purse represents the mean\npercentage of the times a driver drove\nhigher than 5 miles per hour over the\nspeed limit\nlet's start with using pandas to read\ndriverdata.csv as a data frame called df\nwe will now use the info command to\ncheck the number of columns in total and\nentries also this will let us know if we\nhave any missing values in addition to\nit we will use the describe function\nhere to check the count mean and median\nvalues for each column now we will\nimport k means from sklearn dot cluster\nand run the algorithm with k equals 2\nwhich is the minimum number of clusters\nthat can exist in a data set\nalso let us create an instance of the\nk-means model with two clusters such\nthat it becomes easier to call the same\nlater\nplease note that we have dropped the id\ncolumn as it doesn't have any reference\nin forming clusters let's now fit the\nmodel to the data\nthe algorithm is now fitted on our data\nand you can claim that it has created\nthe clusters let us now use some\ncommands to get some information on\nthese clusters\nwe will use the command cluster centers\nfrom k means to determine the cluster\ncenter vectors\nuse the labels underscore command along\nwith print to display the labels also we\ncan go for the length of those labels\nnow let us check how many unique drivers\nare there in the first and second\ncluster\nwe will set the theme as white grid as\nit is better suited to plots with heavy\ndata elements\nplot the clusters using the lm plot\nfunction from the seaborne library such\nthat we have mean underscore dist\nunderscored day feature on x-axis and\nmean underscore over underscore speed\npurse on y-axis\nwe can clearly see from the graph\nplotted that there are two clusters one\ncentered around 50 mean distance delay\nand the other around 175\nalso we can see that there are more\ndrivers in the cluster with the delay\ncentered at 175.\nsince k means clustering gives optimum\nresults when iterated multiple times\nlet's try out the same with increasing\nthe number of clusters say four\nprint the cluster centers with four\nclusters and track the four unique\nlabels along with their frequency of\noccurrence\nzip the unique number of cluster and\ntheir frequency counts within a\ndictionary\nwe can clearly see the difference now in\ncluster centers also here we have a\ndistribution of data points in each\ncluster let's now plot the same\nsuch that we have mean underscore dist\nunderscored day feature on x-axis\nand mean underscore over underscore\nspeed purse on the y-axis\nfrom the four cluster plot we can see\nthat it's denser compared to the two\ncluster plot and hence more optimal\nnow that we have clustered the data with\nthe k means let's quickly recap the\nsteps we've covered\nimport libraries and the data set fit\nthe k-means model on the data set\nevaluate cluster centers into labels\nplot the clusters to see the\ndistribution of data points\niterate the same by changing the number\nof clusters to four\nagain evaluate the cluster centers plot\nthe clusters to see the distribution of\ndata points\ndraw inference out of both plots this\nbrings us to the end of unsupervised\nlearning you are now able to explain the\nmechanism of unsupervised learning use\ndifferent clustering techniques in\npython\nhi there if you like this video\nsubscribe to the simply learn youtube\nchannel and click here to watch similar\nvideos turn it up and get certified\nclick here\n",
  "words": [
    "lesson",
    "going",
    "understand",
    "concept",
    "unsupervised",
    "learning",
    "end",
    "lesson",
    "able",
    "explain",
    "mechanism",
    "unsupervised",
    "learning",
    "use",
    "different",
    "clustering",
    "techniques",
    "python",
    "overview",
    "unsupervised",
    "learning",
    "machine",
    "learning",
    "technique",
    "used",
    "train",
    "machine",
    "learning",
    "algorithm",
    "using",
    "data",
    "either",
    "unclassified",
    "unlabeled",
    "allows",
    "algorithm",
    "act",
    "data",
    "without",
    "guidance",
    "unlabeled",
    "data",
    "designation",
    "pieces",
    "data",
    "tagged",
    "labels",
    "identified",
    "characteristics",
    "properties",
    "classifications",
    "flow",
    "unsupervised",
    "learning",
    "starts",
    "training",
    "data",
    "labels",
    "depends",
    "feature",
    "vector",
    "machine",
    "learning",
    "model",
    "defines",
    "predictive",
    "model",
    "tested",
    "individual",
    "subset",
    "data",
    "feature",
    "vector",
    "predictive",
    "model",
    "defines",
    "likelihood",
    "cluster",
    "id",
    "better",
    "representation",
    "unlabeled",
    "data",
    "let",
    "look",
    "difference",
    "unsupervised",
    "supervised",
    "learning",
    "supervised",
    "learning",
    "technique",
    "deals",
    "labeled",
    "data",
    "output",
    "data",
    "patterns",
    "known",
    "system",
    "unsupervised",
    "learning",
    "works",
    "unlabeled",
    "data",
    "output",
    "based",
    "collection",
    "perceptions",
    "supervised",
    "learning",
    "method",
    "less",
    "complex",
    "unsupervised",
    "learning",
    "method",
    "complex",
    "supervised",
    "learning",
    "conducts",
    "offline",
    "analysis",
    "unsupervised",
    "learning",
    "performs",
    "analysis",
    "outcome",
    "supervised",
    "learning",
    "technique",
    "comparatively",
    "accurate",
    "reliable",
    "unsupervised",
    "learning",
    "generates",
    "moderately",
    "acute",
    "reliable",
    "results",
    "classification",
    "regression",
    "types",
    "problems",
    "solved",
    "supervised",
    "learning",
    "method",
    "unsupervised",
    "learning",
    "includes",
    "clustering",
    "associative",
    "rule",
    "mining",
    "problems",
    "example",
    "application",
    "unsupervised",
    "learning",
    "let",
    "understand",
    "unsupervised",
    "learning",
    "example",
    "consider",
    "scenario",
    "child",
    "learning",
    "phase",
    "shown",
    "images",
    "without",
    "labels",
    "child",
    "asked",
    "identify",
    "range",
    "bird",
    "animal",
    "lack",
    "information",
    "help",
    "best",
    "come",
    "following",
    "groups",
    "based",
    "common",
    "patterns",
    "wings",
    "legs",
    "example",
    "explains",
    "unsupervised",
    "learning",
    "works",
    "show",
    "lot",
    "data",
    "algorithm",
    "ask",
    "find",
    "patterns",
    "data",
    "let",
    "look",
    "application",
    "unsupervised",
    "learning",
    "unsupervised",
    "learning",
    "used",
    "anomaly",
    "detection",
    "well",
    "clustering",
    "understand",
    "clustering",
    "let",
    "look",
    "simple",
    "example",
    "mother",
    "asks",
    "two",
    "children",
    "arrange",
    "pieces",
    "playing",
    "blocks",
    "children",
    "come",
    "two",
    "different",
    "groups",
    "shown",
    "different",
    "similarities",
    "blocks",
    "clustering",
    "children",
    "came",
    "different",
    "type",
    "grouping",
    "one",
    "child",
    "grouped",
    "based",
    "shape",
    "whereas",
    "grouped",
    "based",
    "color",
    "right",
    "wrong",
    "way",
    "pick",
    "one",
    "set",
    "clusters",
    "others",
    "depend",
    "similarity",
    "measure",
    "used",
    "mother",
    "case",
    "arrangement",
    "child",
    "1",
    "better",
    "child",
    "2",
    "similarity",
    "measure",
    "chosen",
    "mother",
    "blocks",
    "shape",
    "however",
    "arrangement",
    "child",
    "2",
    "better",
    "similarity",
    "measure",
    "chosen",
    "mother",
    "blocks",
    "color",
    "therefore",
    "defining",
    "similarity",
    "measure",
    "important",
    "performing",
    "clustering",
    "may",
    "different",
    "ways",
    "data",
    "arranged",
    "different",
    "groups",
    "based",
    "size",
    "shape",
    "color",
    "texture",
    "complex",
    "features",
    "anomaly",
    "detection",
    "clustering",
    "technique",
    "used",
    "identify",
    "unusual",
    "patterns",
    "conform",
    "expected",
    "behavior",
    "anomaly",
    "detection",
    "many",
    "applications",
    "business",
    "intrusion",
    "detection",
    "system",
    "health",
    "monitoring",
    "fraud",
    "detection",
    "clustering",
    "method",
    "grouping",
    "similar",
    "entities",
    "together",
    "called",
    "clustering",
    "goal",
    "unsupervised",
    "machine",
    "learning",
    "method",
    "seek",
    "similarities",
    "within",
    "data",
    "points",
    "cluster",
    "similar",
    "data",
    "points",
    "together",
    "need",
    "clustering",
    "let",
    "look",
    "need",
    "clustering",
    "grouping",
    "similar",
    "entities",
    "together",
    "helps",
    "merge",
    "attributes",
    "different",
    "clusters",
    "words",
    "gives",
    "us",
    "insight",
    "underlying",
    "patterns",
    "different",
    "groups",
    "lot",
    "applications",
    "grouping",
    "unlabeled",
    "data",
    "example",
    "order",
    "maximize",
    "revenue",
    "identify",
    "different",
    "groups",
    "clusters",
    "customers",
    "market",
    "group",
    "different",
    "way",
    "another",
    "example",
    "grouping",
    "books",
    "together",
    "belong",
    "similar",
    "topics",
    "clustering",
    "needed",
    "determine",
    "intrinsic",
    "grouping",
    "set",
    "unlabeled",
    "data",
    "organize",
    "data",
    "clusters",
    "show",
    "internal",
    "structure",
    "data",
    "partition",
    "data",
    "points",
    "understand",
    "extract",
    "value",
    "large",
    "sets",
    "structured",
    "unstructured",
    "data",
    "types",
    "clustering",
    "two",
    "types",
    "clustering",
    "hierarchical",
    "clustering",
    "partitional",
    "clustering",
    "hierarchical",
    "clustering",
    "agglomerative",
    "divisive",
    "whereas",
    "partitional",
    "clustering",
    "k",
    "means",
    "fuzzy",
    "c",
    "means",
    "distinction",
    "among",
    "different",
    "types",
    "clustering",
    "whether",
    "set",
    "clusters",
    "nested",
    "unnested",
    "partitional",
    "clustering",
    "division",
    "set",
    "data",
    "objects",
    "sets",
    "clusters",
    "every",
    "data",
    "object",
    "one",
    "subset",
    "hierarchical",
    "clustering",
    "tree",
    "structure",
    "set",
    "nested",
    "clusters",
    "hierarchical",
    "clustering",
    "output",
    "hierarchical",
    "clustering",
    "hierarchy",
    "hierarchical",
    "clustering",
    "form",
    "hierarchy",
    "assume",
    "going",
    "create",
    "hierarchy",
    "six",
    "different",
    "data",
    "nodes",
    "first",
    "combine",
    "b",
    "based",
    "similarity",
    "also",
    "combine",
    "e",
    "based",
    "similarity",
    "combination",
    "b",
    "combined",
    "c",
    "similar",
    "way",
    "combination",
    "e",
    "combined",
    "f",
    "combine",
    "c",
    "f",
    "inside",
    "one",
    "cluster",
    "look",
    "final",
    "tree",
    "contains",
    "clusters",
    "combined",
    "single",
    "cluster",
    "let",
    "understand",
    "working",
    "hierarchical",
    "clustering",
    "works",
    "four",
    "steps",
    "step",
    "one",
    "assign",
    "item",
    "cluster",
    "n",
    "number",
    "items",
    "n",
    "number",
    "clusters",
    "step",
    "two",
    "merge",
    "two",
    "clusters",
    "single",
    "cluster",
    "finding",
    "closest",
    "pair",
    "clusters",
    "one",
    "cluster",
    "less",
    "step",
    "three",
    "compute",
    "distances",
    "new",
    "cluster",
    "old",
    "clusters",
    "step",
    "four",
    "repeat",
    "steps",
    "two",
    "three",
    "items",
    "clustered",
    "single",
    "cluster",
    "size",
    "n",
    "let",
    "understand",
    "distance",
    "measure",
    "hierarchical",
    "clustering",
    "let",
    "look",
    "different",
    "kinds",
    "linkage",
    "clustering",
    "complete",
    "linkage",
    "clustering",
    "finds",
    "maximum",
    "distance",
    "points",
    "belonging",
    "two",
    "different",
    "clusters",
    "single",
    "linkage",
    "clustering",
    "finds",
    "minimum",
    "possible",
    "distance",
    "points",
    "belonging",
    "two",
    "different",
    "clusters",
    "mean",
    "linkage",
    "clustering",
    "finds",
    "possible",
    "pairwise",
    "distances",
    "points",
    "belonging",
    "two",
    "different",
    "clusters",
    "calculates",
    "average",
    "centroid",
    "linkage",
    "clustering",
    "finds",
    "centroid",
    "cluster",
    "calculates",
    "distance",
    "dendrogram",
    "tree",
    "diagram",
    "frequently",
    "used",
    "illustrate",
    "arrangement",
    "clusters",
    "produced",
    "hierarchical",
    "clustering",
    "shows",
    "hierarchical",
    "relationship",
    "objects",
    "commonly",
    "created",
    "output",
    "hierarchical",
    "clustering",
    "main",
    "use",
    "dendrogram",
    "work",
    "best",
    "way",
    "allocate",
    "objects",
    "clusters",
    "dendrogram",
    "also",
    "shows",
    "hierarchical",
    "clustering",
    "five",
    "observations",
    "relationship",
    "hierarchical",
    "clustering",
    "example",
    "let",
    "understand",
    "hierarchical",
    "clustering",
    "example",
    "given",
    "example",
    "hierarchical",
    "clustering",
    "used",
    "find",
    "distances",
    "different",
    "cities",
    "kilometers",
    "following",
    "matrix",
    "traces",
    "hierarchical",
    "clustering",
    "distances",
    "miles",
    "different",
    "cities",
    "method",
    "clustering",
    "single",
    "link",
    "see",
    "given",
    "distance",
    "matrix",
    "nearest",
    "pair",
    "objects",
    "mi",
    "mi",
    "tio",
    "merged",
    "single",
    "cluster",
    "called",
    "mito",
    "mi",
    "column",
    "lower",
    "values",
    "column",
    "mito",
    "consists",
    "mi",
    "column",
    "values",
    "mito",
    "column",
    "one",
    "index",
    "zero",
    "value",
    "distance",
    "cluster",
    "get",
    "new",
    "distance",
    "matrix",
    "compute",
    "distance",
    "new",
    "cluster",
    "clusters",
    "nearest",
    "pair",
    "objects",
    "n",
    "rm",
    "combined",
    "single",
    "cluster",
    "called",
    "narm",
    "get",
    "new",
    "distance",
    "matrix",
    "compute",
    "distance",
    "new",
    "cluster",
    "clusters",
    "similar",
    "way",
    "nearest",
    "pair",
    "objects",
    "ba",
    "narm",
    "combined",
    "single",
    "cluster",
    "called",
    "ba",
    "n",
    "rm",
    "get",
    "new",
    "distance",
    "matrix",
    "compute",
    "distance",
    "new",
    "cluster",
    "clusters",
    "similarly",
    "nearest",
    "pair",
    "objects",
    "ba",
    "narm",
    "fi",
    "combined",
    "single",
    "cluster",
    "called",
    "get",
    "new",
    "distance",
    "matrix",
    "compute",
    "distance",
    "new",
    "cluster",
    "clusters",
    "finally",
    "merge",
    "last",
    "two",
    "clusters",
    "process",
    "summarized",
    "clustering",
    "diagram",
    "right",
    "final",
    "distance",
    "matrix",
    "left",
    "demo",
    "clustering",
    "animals",
    "problem",
    "scenario",
    "consider",
    "data",
    "set",
    "zoo",
    "dot",
    "data",
    "look",
    "information",
    "provided",
    "first",
    "five",
    "rows",
    "first",
    "column",
    "denotes",
    "animal",
    "name",
    "last",
    "one",
    "specifies",
    "high",
    "level",
    "class",
    "corresponding",
    "animal",
    "supposed",
    "find",
    "solution",
    "following",
    "questions",
    "one",
    "identify",
    "unique",
    "number",
    "high",
    "level",
    "classes",
    "two",
    "perform",
    "agglomerative",
    "clustering",
    "using",
    "sixteen",
    "intermediate",
    "features",
    "three",
    "compute",
    "mean",
    "squared",
    "error",
    "comparing",
    "actual",
    "high",
    "level",
    "class",
    "predicted",
    "high",
    "level",
    "class",
    "nutshell",
    "perform",
    "agglomerative",
    "clustering",
    "appropriate",
    "mse",
    "value",
    "let",
    "import",
    "required",
    "libraries",
    "data",
    "set",
    "since",
    "loaded",
    "data",
    "set",
    "extract",
    "basic",
    "information",
    "first",
    "step",
    "info",
    "command",
    "clear",
    "data",
    "set",
    "18",
    "columns",
    "total",
    "101",
    "entries",
    "also",
    "null",
    "values",
    "let",
    "us",
    "proceed",
    "towards",
    "first",
    "question",
    "extracting",
    "unique",
    "number",
    "classes",
    "probably",
    "unique",
    "function",
    "numpy",
    "help",
    "plot",
    "unique",
    "number",
    "labels",
    "obtained",
    "using",
    "matte",
    "plot",
    "lib",
    "library",
    "create",
    "figure",
    "set",
    "subplots",
    "plot",
    "seen",
    "seven",
    "unique",
    "class",
    "labels",
    "since",
    "group",
    "animals",
    "based",
    "features",
    "clear",
    "quite",
    "predictive",
    "clustering",
    "performed",
    "let",
    "extract",
    "features",
    "leaving",
    "labels",
    "column",
    "store",
    "another",
    "data",
    "frame",
    "say",
    "features",
    "import",
    "necessary",
    "modules",
    "performing",
    "clustering",
    "specify",
    "number",
    "clusters",
    "seven",
    "note",
    "specifying",
    "total",
    "number",
    "clusters",
    "seven",
    "seven",
    "unique",
    "class",
    "labels",
    "also",
    "specify",
    "linkage",
    "method",
    "average",
    "similarity",
    "method",
    "cosine",
    "fit",
    "agglomerative",
    "clustering",
    "model",
    "feature",
    "variable",
    "defined",
    "earlier",
    "let",
    "us",
    "extract",
    "labels",
    "predicted",
    "model",
    "features",
    "see",
    "predicted",
    "labels",
    "101",
    "animals",
    "although",
    "seven",
    "labels",
    "numbered",
    "six",
    "case",
    "subtract",
    "one",
    "original",
    "label",
    "column",
    "matches",
    "predicted",
    "numbers",
    "let",
    "us",
    "move",
    "ahead",
    "predict",
    "accuracy",
    "model",
    "considering",
    "predicting",
    "parameter",
    "mean",
    "squared",
    "error",
    "evaluate",
    "absolute",
    "error",
    "applying",
    "square",
    "root",
    "operation",
    "mean",
    "squared",
    "error",
    "print",
    "resultant",
    "error",
    "root",
    "mean",
    "squared",
    "error",
    "got",
    "approximately",
    "quite",
    "acceptable",
    "clustered",
    "animals",
    "let",
    "quickly",
    "recap",
    "steps",
    "covered",
    "import",
    "libraries",
    "data",
    "set",
    "check",
    "missing",
    "values",
    "identify",
    "unique",
    "labels",
    "plot",
    "extract",
    "features",
    "necessary",
    "clustering",
    "within",
    "single",
    "variable",
    "fit",
    "agglomerative",
    "clustering",
    "model",
    "feature",
    "data",
    "predict",
    "labels",
    "animal",
    "print",
    "rmse",
    "model",
    "k",
    "means",
    "clustering",
    "let",
    "look",
    "steps",
    "involved",
    "clustering",
    "iterative",
    "clustering",
    "algorithm",
    "whose",
    "goal",
    "find",
    "local",
    "maxima",
    "iteration",
    "algorithm",
    "works",
    "four",
    "steps",
    "specify",
    "desired",
    "number",
    "clusters",
    "k",
    "randomly",
    "assign",
    "data",
    "point",
    "cluster",
    "compute",
    "cluster",
    "centroids",
    "reassign",
    "point",
    "closest",
    "cluster",
    "centroid",
    "recompute",
    "cluster",
    "centroids",
    "order",
    "check",
    "convergence",
    "criterion",
    "met",
    "consider",
    "dots",
    "given",
    "diagram",
    "data",
    "points",
    "first",
    "randomly",
    "chooses",
    "k",
    "examples",
    "data",
    "points",
    "data",
    "set",
    "three",
    "colored",
    "points",
    "initial",
    "centroids",
    "know",
    "yet",
    "center",
    "cluster",
    "centroid",
    "center",
    "cluster",
    "assign",
    "data",
    "points",
    "nearest",
    "centroid",
    "data",
    "points",
    "nearest",
    "centroid",
    "create",
    "cluster",
    "see",
    "three",
    "centroids",
    "red",
    "blue",
    "purple",
    "data",
    "points",
    "color",
    "one",
    "cluster",
    "total",
    "three",
    "clusters",
    "new",
    "clusters",
    "need",
    "centers",
    "centroid",
    "new",
    "value",
    "going",
    "mean",
    "examples",
    "cluster",
    "centers",
    "moving",
    "centroid",
    "value",
    "mean",
    "data",
    "points",
    "cluster",
    "keep",
    "repeating",
    "steps",
    "2",
    "3",
    "algorithm",
    "converged",
    "centroids",
    "stop",
    "moving",
    "optimal",
    "number",
    "clusters",
    "determining",
    "optimal",
    "number",
    "clusters",
    "data",
    "set",
    "fundamental",
    "issue",
    "partitioning",
    "clustering",
    "clustering",
    "requires",
    "user",
    "specify",
    "number",
    "clusters",
    "k",
    "generated",
    "plot",
    "k",
    "sse",
    "see",
    "error",
    "decreases",
    "k",
    "increases",
    "size",
    "decreases",
    "hence",
    "distortion",
    "also",
    "smaller",
    "basic",
    "idea",
    "behind",
    "partitioning",
    "methods",
    "k",
    "means",
    "clustering",
    "define",
    "clusters",
    "total",
    "within",
    "cluster",
    "sum",
    "square",
    "wss",
    "total",
    "intra",
    "cluster",
    "variation",
    "minimized",
    "elbow",
    "method",
    "looks",
    "total",
    "wss",
    "function",
    "number",
    "clusters",
    "one",
    "choose",
    "number",
    "clusters",
    "adding",
    "another",
    "cluster",
    "significantly",
    "improve",
    "total",
    "wss",
    "works",
    "following",
    "way",
    "compute",
    "clustering",
    "algorithm",
    "different",
    "values",
    "k",
    "instance",
    "varying",
    "k",
    "1",
    "20",
    "clusters",
    "calculate",
    "total",
    "within",
    "cluster",
    "sum",
    "square",
    "wss",
    "k",
    "value",
    "according",
    "number",
    "clusters",
    "k",
    "plot",
    "curve",
    "wss",
    "location",
    "bend",
    "plot",
    "generally",
    "considered",
    "indicator",
    "appropriate",
    "number",
    "clusters",
    "demo",
    "incentivization",
    "problem",
    "scenario",
    "lithium",
    "power",
    "largest",
    "producer",
    "electric",
    "vehicle",
    "batteries",
    "provide",
    "batteries",
    "rent",
    "drivers",
    "drivers",
    "rent",
    "battery",
    "typically",
    "day",
    "thereafter",
    "replacing",
    "charged",
    "battery",
    "company",
    "lithian",
    "power",
    "variable",
    "pricing",
    "model",
    "based",
    "driver",
    "driving",
    "history",
    "battery",
    "life",
    "depends",
    "factors",
    "speeding",
    "distance",
    "driven",
    "per",
    "day",
    "etc",
    "supposed",
    "create",
    "cluster",
    "model",
    "drivers",
    "grouped",
    "together",
    "based",
    "driving",
    "data",
    "group",
    "data",
    "points",
    "drivers",
    "incentivized",
    "based",
    "cluster",
    "let",
    "import",
    "libraries",
    "numpy",
    "pandas",
    "import",
    "visualization",
    "libraries",
    "namely",
    "matplotlib",
    "seaborne",
    "import",
    "warning",
    "module",
    "warning",
    "module",
    "introduced",
    "pep230",
    "way",
    "warn",
    "programmers",
    "changes",
    "language",
    "library",
    "features",
    "anticipation",
    "backwards",
    "incompatible",
    "changes",
    "coming",
    "python",
    "import",
    "met",
    "plot",
    "lib",
    "library",
    "visualization",
    "instance",
    "rc",
    "params",
    "handling",
    "default",
    "met",
    "plot",
    "lib",
    "values",
    "please",
    "note",
    "sake",
    "simplicity",
    "take",
    "two",
    "features",
    "mean",
    "distance",
    "driven",
    "per",
    "day",
    "mean",
    "percentage",
    "times",
    "driver",
    "drove",
    "higher",
    "5",
    "miles",
    "per",
    "hour",
    "speed",
    "limit",
    "let",
    "us",
    "go",
    "columns",
    "first",
    "understand",
    "id",
    "column",
    "represents",
    "unique",
    "id",
    "driver",
    "mean",
    "underscore",
    "dist",
    "underscore",
    "day",
    "column",
    "represents",
    "mean",
    "distance",
    "driven",
    "driver",
    "per",
    "day",
    "mean",
    "underscore",
    "underscore",
    "speed",
    "underscore",
    "purse",
    "represents",
    "mean",
    "percentage",
    "times",
    "driver",
    "drove",
    "higher",
    "5",
    "miles",
    "per",
    "hour",
    "speed",
    "limit",
    "let",
    "start",
    "using",
    "pandas",
    "read",
    "data",
    "frame",
    "called",
    "df",
    "use",
    "info",
    "command",
    "check",
    "number",
    "columns",
    "total",
    "entries",
    "also",
    "let",
    "us",
    "know",
    "missing",
    "values",
    "addition",
    "use",
    "describe",
    "function",
    "check",
    "count",
    "mean",
    "median",
    "values",
    "column",
    "import",
    "k",
    "means",
    "sklearn",
    "dot",
    "cluster",
    "run",
    "algorithm",
    "k",
    "equals",
    "2",
    "minimum",
    "number",
    "clusters",
    "exist",
    "data",
    "set",
    "also",
    "let",
    "us",
    "create",
    "instance",
    "model",
    "two",
    "clusters",
    "becomes",
    "easier",
    "call",
    "later",
    "please",
    "note",
    "dropped",
    "id",
    "column",
    "reference",
    "forming",
    "clusters",
    "let",
    "fit",
    "model",
    "data",
    "algorithm",
    "fitted",
    "data",
    "claim",
    "created",
    "clusters",
    "let",
    "us",
    "use",
    "commands",
    "get",
    "information",
    "clusters",
    "use",
    "command",
    "cluster",
    "centers",
    "k",
    "means",
    "determine",
    "cluster",
    "center",
    "vectors",
    "use",
    "labels",
    "underscore",
    "command",
    "along",
    "print",
    "display",
    "labels",
    "also",
    "go",
    "length",
    "labels",
    "let",
    "us",
    "check",
    "many",
    "unique",
    "drivers",
    "first",
    "second",
    "cluster",
    "set",
    "theme",
    "white",
    "grid",
    "better",
    "suited",
    "plots",
    "heavy",
    "data",
    "elements",
    "plot",
    "clusters",
    "using",
    "lm",
    "plot",
    "function",
    "seaborne",
    "library",
    "mean",
    "underscore",
    "dist",
    "underscored",
    "day",
    "feature",
    "mean",
    "underscore",
    "underscore",
    "speed",
    "purse",
    "clearly",
    "see",
    "graph",
    "plotted",
    "two",
    "clusters",
    "one",
    "centered",
    "around",
    "50",
    "mean",
    "distance",
    "delay",
    "around",
    "175",
    "also",
    "see",
    "drivers",
    "cluster",
    "delay",
    "centered",
    "since",
    "k",
    "means",
    "clustering",
    "gives",
    "optimum",
    "results",
    "iterated",
    "multiple",
    "times",
    "let",
    "try",
    "increasing",
    "number",
    "clusters",
    "say",
    "four",
    "print",
    "cluster",
    "centers",
    "four",
    "clusters",
    "track",
    "four",
    "unique",
    "labels",
    "along",
    "frequency",
    "occurrence",
    "zip",
    "unique",
    "number",
    "cluster",
    "frequency",
    "counts",
    "within",
    "dictionary",
    "clearly",
    "see",
    "difference",
    "cluster",
    "centers",
    "also",
    "distribution",
    "data",
    "points",
    "cluster",
    "let",
    "plot",
    "mean",
    "underscore",
    "dist",
    "underscored",
    "day",
    "feature",
    "mean",
    "underscore",
    "underscore",
    "speed",
    "purse",
    "four",
    "cluster",
    "plot",
    "see",
    "denser",
    "compared",
    "two",
    "cluster",
    "plot",
    "hence",
    "optimal",
    "clustered",
    "data",
    "k",
    "means",
    "let",
    "quickly",
    "recap",
    "steps",
    "covered",
    "import",
    "libraries",
    "data",
    "set",
    "fit",
    "model",
    "data",
    "set",
    "evaluate",
    "cluster",
    "centers",
    "labels",
    "plot",
    "clusters",
    "see",
    "distribution",
    "data",
    "points",
    "iterate",
    "changing",
    "number",
    "clusters",
    "four",
    "evaluate",
    "cluster",
    "centers",
    "plot",
    "clusters",
    "see",
    "distribution",
    "data",
    "points",
    "draw",
    "inference",
    "plots",
    "brings",
    "us",
    "end",
    "unsupervised",
    "learning",
    "able",
    "explain",
    "mechanism",
    "unsupervised",
    "learning",
    "use",
    "different",
    "clustering",
    "techniques",
    "python",
    "hi",
    "like",
    "video",
    "subscribe",
    "simply",
    "learn",
    "youtube",
    "channel",
    "click",
    "watch",
    "similar",
    "videos",
    "turn",
    "get",
    "certified",
    "click"
  ],
  "keywords": [
    "going",
    "understand",
    "unsupervised",
    "learning",
    "use",
    "different",
    "clustering",
    "python",
    "machine",
    "technique",
    "used",
    "algorithm",
    "using",
    "data",
    "unlabeled",
    "labels",
    "feature",
    "model",
    "predictive",
    "cluster",
    "id",
    "better",
    "let",
    "look",
    "supervised",
    "output",
    "patterns",
    "works",
    "based",
    "method",
    "complex",
    "types",
    "example",
    "consider",
    "scenario",
    "child",
    "identify",
    "animal",
    "information",
    "following",
    "groups",
    "find",
    "anomaly",
    "detection",
    "mother",
    "two",
    "children",
    "blocks",
    "grouping",
    "one",
    "grouped",
    "shape",
    "color",
    "way",
    "set",
    "clusters",
    "similarity",
    "measure",
    "arrangement",
    "2",
    "size",
    "features",
    "similar",
    "together",
    "called",
    "within",
    "points",
    "need",
    "merge",
    "us",
    "group",
    "another",
    "extract",
    "value",
    "hierarchical",
    "partitional",
    "agglomerative",
    "k",
    "means",
    "c",
    "objects",
    "tree",
    "hierarchy",
    "create",
    "first",
    "combine",
    "also",
    "combined",
    "single",
    "four",
    "steps",
    "step",
    "assign",
    "n",
    "number",
    "pair",
    "three",
    "compute",
    "distances",
    "new",
    "clustered",
    "distance",
    "linkage",
    "finds",
    "belonging",
    "mean",
    "centroid",
    "dendrogram",
    "diagram",
    "given",
    "matrix",
    "miles",
    "see",
    "nearest",
    "mi",
    "mito",
    "column",
    "values",
    "get",
    "narm",
    "ba",
    "animals",
    "high",
    "level",
    "class",
    "unique",
    "squared",
    "error",
    "predicted",
    "import",
    "libraries",
    "since",
    "command",
    "columns",
    "total",
    "function",
    "plot",
    "lib",
    "library",
    "seven",
    "specify",
    "note",
    "fit",
    "variable",
    "evaluate",
    "square",
    "print",
    "check",
    "centroids",
    "met",
    "center",
    "centers",
    "optimal",
    "wss",
    "instance",
    "drivers",
    "battery",
    "day",
    "driver",
    "driven",
    "per",
    "times",
    "speed",
    "represents",
    "underscore",
    "dist",
    "purse",
    "distribution"
  ]
}