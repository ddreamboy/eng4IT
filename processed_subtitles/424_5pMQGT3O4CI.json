{
  "text": "[MUSIC PLAYING]\nJEN GENNAI: I'm an\noperations manager,\nso my role is to ensure that\nwe're making our considerations\naround ethically AI\ndeliberate, actionable,\nand scalable across the\nwhole organization in Google.\nSo one of the first\nthings to think about\nif you're a business\nleader or a developer\nis ensuring that people\nunderstand what you stand for.\nWhat does ethics mean to you?\nFor us, that meant setting\nvalues-driven principles\nas a company.\nThese value-driven\nprinciples, for us,\nare known as our AI principles.\nAnd last year, we\nannounced them in June.\nSo these are seven guidelines\naround AI development\nand deployment, which\nassigned to us how\nwe want to develop AI.\nWe want to ensure that we're not\ncreating or reinforcing bias.\nWe want to make sure that\nwe're building technology\nthat's accountable to people.\nAnd we have five others\nhere that you can read.\nIt's available on our website.\nBut at the same time\nthat we announce\nthese aspirational\nprinciples for the company,\nwe also identified\nfour areas that we\nhave considered our red lines.\nSo these are technologies\nthat we will not pursue.\nThese cover things like\nweapons technology.\nWe will not build\nor deploy weapons.\nWe will also not build\nor deploy technologies\nthat we feel violate\ninternational human rights.\nSo if you're a business\nleader or a developer,\nwe'd also encourage\nyou to understand what\nare your aspirational goals.\nBut at the same time,\nwhat are your guardrails?\nWhat point are you're\nnot going to cross?\nIt's the most important thing\nto do, is to know what is\nyour definition of\nethical AI development.\nAfter you've set\nyour AI principles,\nthe next thing is, how\ndo you make them real?\nHow do you make sure that you're\naligning with those principles?\nSo here, there are\nthree main things\nI'd suggest keeping in mind.\nThe first one is you need an\naccountable and authoritative\nbody.\nSo for us in Google, this means\nthat we have senior executives\nacross the whole company\nwho have the authority\nto approve or decline a launch.\nSo they have to\nwrestle with some\nof these very complex\nethical questions\nto ensure that we\nare launching things\nthat we do believe will lead\nto fair and ethical outcomes.\nSo they provide the authority\nand the accountability\nto make some really\ntough decisions.\nSecondly, you have to make sure\nthat the decision-makers have\nthe right information.\nThis involves talking to diverse\npeople within the company,\nbut also listening to\nyour external users,\nexternal stakeholders,\nand feeding that\ninto your\ndecision-making criteria.\nJamila will talk\nmore about engaging\nwith external\ncommunites in a moment.\nAnd then the third key\npart of building governance\nand accountability\nis having operations.\nWho's going to do the work?\nWhat are the structures\nand frameworks\nthat are repeatable,\nthat are transparent,\nand that are understood\nby the people who\nare making these decisions?\nSo for that, in Google, we've\nestablished a central team\nthat's not based in our\nengineering and product teams\nto ensure that there's a\nlevel of objectivity here.\nSo the same people who\nare building the products\nare not the only\npeople who are looking\nto make sure that those\nproducts are fair and ethical.\nSo now you have your\nprinciples that you're\ntrying to ensure that\npeople understand\nwhat does ethics mean for you.\nWe're talking about establishing\ngovernance structure\nto make sure that you're\nachieving those goals,\nand the next thing to do is to\nensure that you're encouraging\neveryone within your company or\nthe people that you work with\nand for are aligned\non those goals.\nSo making sure, one, that you've\nset overall goals in alignment\nwith ethical AI--\nso how are you going to\nachieve ethical development\nand deployment of technology?\nNext, you want to make sure\nthat you're training people\nto think about these\nissues from the start.\nYou don't want to catch\nsome ethical consideration\nlate in the product\ndevelopment lifecycle.\nYou want to make\nsure that you're\nstarting that as early\nas possible-- so getting\npeople trained to think\nabout these types of issues.\nThen we have rewards.\nYou have to make sure\nif you're holding people\naccountable to ethical\ndevelopment and deployment,\nyou may have to accept\nthat that might slow down\nsome development in order to\nget to the right outcomes--\nmaking sure people feel\nrewarded for thinking\nabout ethical development\nand deployment.\nAnd then, finally, making\nsure that you're hiring people\nand developing people\nwho are helping you\nachieve those goals.\nNext, you've established\nyour frameworks,\nyou've hired the right\npeople, you're rewarding them.\nHow do you know you're\nachieving your goals?\nSo we think about this as\nvalidating and testing.\nSo an example here\nis replicating\na user's experience.\nWho are your users?\nHow do you make sure\nthat you're thinking\nabout a representative\nsample of your users?\nSo you think about trying to\ntest different experiences,\nmostly from your core subgroups.\nBut you also want to\nbe thinking about,\nwho are your marginalized users?\nWho might be underrepresented\nin your workforce?\nAnd therefore, you might have\nto pay additional attention to\nto get it right.\nWe also think about, what\nare the failure modes?\nAnd what we mean by that is\nif people have been negatively\naffected by a\nproduct in the past,\nwe want to make sure they\nwon't be negatively affected\nin the future.\nSo how do we learn\nfrom that and make sure\nthat we're testing deliberately\nfor that in the future?\nAnd then the final bit\nof testing and validation\nis introducing some\nof those failures\ninto the product to make sure\nthat you're stress testing,\nand, again, have\nsome objectivity\nto stress test a product\nto make sure it's achieving\nyour fair and ethical goals.\nAnd then we think about\nit's not just you.\nYou're not alone.\nHow do we ensure that we're\nall sharing information\nto make us more fair and\nethical and to make sure\nthat the products we deliver\nare fair and ethical?\nSo we encourage the sharing of\nbest practices and guidelines.\nWe do that ourselves\nin Google by providing\nour research and best practices\non the Google AI site.\nSo these best practices\ncover everything\nfrom ML fairness\ntools and research\nthat Margaret Mitchell will\ntalk about in a moment,\nbut also best practices\nand guidelines\nthat any developer or\nany business leader\ncould follow themselves.\nSo we try to both provide\nthat ourselves, as well\nas encouraging other people\nto share their research\nand learnings also.\nSo with that, as we talk\nabout sharing with external,\nit's also about\nbringing voices in.\nSo I'll pass over\nto Jamila Smith-Loud\nto talk about understanding\nhuman impacts.\nJAMILA SMITH-LOUD: Thank you.\n[APPLAUSE]\nHi, everyone.\nI'm going to talk\nto you a little bit\ntoday about understanding,\nconceptualizing, and assessing\nhuman consequences and impacts\non real people and communities\nthrough the use of tools\nlike social equity impact\nassessments.\nSocial and equity\nimpact assessments\ncome primarily from the\nsocial science discipline\nand give us a\nresearch-based method\nto assess these questions in\na way that is broad enough\nto be able to apply\nacross products,\nbut also specific enough\nfor us to think about what\nare tangible product changes and\ninterventions that we can make.\nSo I'll start off with\none of the questions\nthat we often start when\nthinking about these questions.\nI always like to\nsay that when we're\nthinking about ethics, when\nwe're thinking about fairness,\nand even thinking about\nquestions of bias,\nthese are really\nsocial problems.\nAnd one major entry point into\nunderstanding social problems\nis really thinking about what's\nthe geographic context in which\nusers live, and how does\nthat impact their engagement\nwith the product?\nSo really asking,\nwhat experiences\ndo people have that are based\nsolely on where they live\nand that may differ greatly\nfor other peoples who\nlive in different\nneighborhoods that are either\nmore resourced, more\nconnected to internet-- all\nof these different aspects that\nmake regional differences so\nimportant?\nSecondly, we like to ask what\nhappens to people when they're\nengaging with our\nproducts in their families\nand in their communities.\nWe like to think about, what\nare economic changes that\nmay come as a part of engagement\nwith this new technology?\nWhat are social and cultural\nchanges that really do impact\nhow people view the technology\nand view their participation\nin the process?\nAnd so I'll start a little bit\nof talking about our approach.\nThe good thing\nabout utilizing kind\nof existing frameworks of social\nand equity impact assessments\nwhich come from--\nif you think about when\nwe do new land development\nprojects or even\nenvironmental assessments,\nthere's already the standard\nof considering social impacts\nas a part of that process.\nAnd so we really do think of\nemploying new technologies\nin the same way.\nWe should be asking similar\nquestions about how communities\nare impacted, what\nare their perceptions,\nand how are they framing\nthese engagements?\nAnd so one of the things\nthat we think about\nare kind of what is a\nprincipled approach to asking\nthese questions?\nAnd the first one\nreally is around\nengaging in the hard questions.\nWhen we're talking\nabout fairness,\nwhen we're talking\nabout ethics, we're\nnot talking about\nthem separately\nfrom issues of racism,\nsocial class, homophobia,\nand all forms of\ncultural prejudice.\nWe're talking about what\nare the issues as they\noverlay in those systems.?\nAnd so it really\nrequires us to be\nOK with those hard questions,\nand engaging with them,\nand realizing that our\ntechnologies and our products\ndon't exist separately\nfrom that world.\nThe next approach is really\ntowards thinking anticipatory.\nI think the different\nthing about thinking\nabout social and equity\nimpact assessments\nfrom other social\nscience research methods\nis that the relationships\nbetween causal impacts\nand correlations are going\nto be a little bit different,\nand we really are\ntrying to anticipate\nharms and consequences.\nAnd so it requires you to be OK\nwith the fuzzy conversations,\nbut also realize that\nthere's enough research,\nthere's enough\ndata that gives us\nthe understanding of how history\nand contexts impact outcomes.\nAnd so being anticipatory\nin your process\nis really, really an\nimportant part of it.\nAnd lastly, in terms of thinking\nabout the principled approach\nis really centering the\nvoices and experiences\nof those communities who\noften bear the burden\nof the negative impacts.\nAnd that requires\nunderstanding how\nthose communities would even\nconceptualize these problems.\nI think sometimes we come\nfrom a technical standpoint,\nand we think about\nthe communities\nas separate from the problem.\nBut if we're ready to center\nthose voices and engaged\nthroughout the whole\nprocess, I think\nit results in better outcomes.\nSo to go a little bit\ndeeper into engaging\nin the hard questions, what\nwe're really trying to do\nis be able to assess how\na product will impact\ncommunities,\nparticularly communities\nwho have been historically and\ntraditionally marginalized.\nSo it requires us\nto really think\nabout history and context.\nHow is that shaping this\nissue, and what could we\nlearn from that assessment?\nIt also requires an\nintersectional approach.\nIf we're thinking\nabout gender equity,\nif we're thinking\nabout racial equity,\nthese are not issues\nthat live separately.\nThey really do\nintersect, and being OK\nwith understanding of that\nintersectional approach\nallows for a much\nfuller assessment.\nAnd then, lastly, in thinking\nabout new technologies\nand thinking about\nnew products, how does\npower influence outcomes and the\nfeasibility of interventions?\nI think that the question\nof power and social impact\ngo hand-in-hand,\nand it requires us\nto be OK with [? answering. ?]\nAnswering might not\nget the best\nanswer, but at least\nasking those hard questions.\nSo our anticipatory process is\npart of a full process, right?\nSo it's not just us thinking\nabout the social and equity\nimpacts, but it really\nis thinking about them\nwithin the context\nof the product--\nso really having domain-specific\napplication of these questions,\nand then having some\nassessment of the likelihood\nof the severity of the risk.\nAnd then, lastly, thinking\nabout what are meaningful\nmitigations for whatever impacts\nthat we have to developed.\nAnd so it's a full process.\nIt requires work on\nour team in terms\nof understanding\nin the assessment,\nbut it also requires partnership\nwith our product teams\nto really do that\ndomain-specific analysis.\nCentering the assessment.\nI talked a little bit\nabout this before,\nbut when we're centering\nthis assessment, really,\nwhat we're trying to ask\nis, who's impacted most?\nSo if we're thinking\nabout a problem that\nmay have some\neconomic impact, it\nwould require us to\ndisaggregate the data based\non income to see what\ncommunities, what populations,\nare most impacted-- so being OK\nwith thinking about it in very\nspecific population\ndata and understanding\nwho is impacted the most.\nAnother important\npart is validation.\nAnd I think Jen mentioned\nthat a lot, but really\nthinking about community-based\nresearch engagements,\nwhether that's a\nparticipatory approach,\nwhether that's focus groups.\nBut really, how do we\nvalidate our assessments\nby engaging communities\ndirectly and really centering\ntheir framing of the problem\nas part of our project?\nAnd then going through\niteration and realizing\nthat it's not going to be\nperfect the first time, that it\nrequires some pull and\ntugging from both sides\nto really get the\nconversation right.\nSo what types of social\nproblems are we thinking of?\nWe're thinking about\nincome inequality, housing\nand displacement,\nhealth disparities,\nthe digital divide,\nand food access.\nWe're thinking about these and\nall different types of ways,\nbut I thought it\nmight be helpful\nif we thought about\na specific example.\nSo let's look at\nthe example of one\nof the types of social\nproblems that we\nwant to understand in relation\nto our products and users.\nThe topic of inequity\nrelated to food access, which\nthis map shows you--\nand it's definitely a\nUS context that we're\nthinking about this\nquestion for now,\nbut also always thinking\nabout it from a global way.\nBut I thought that this\nmap was a good way for us\nto look at it.\nAs you can see, the areas\nthat are shaded darker\nare the areas where those users\nmight have a significantly\ndifferent experience when we're\nthinking about products that\ngive personalization and\nrecommendations maybe\nfor something like restaurants.\nSo we're thinking\nabout questions\nabout how those users are\neither included or excluded\nfrom the product\nexperience, and then we're\nthinking about going even\nfurther and thinking about how\nsmall businesses and\nlow resource businesses\nalso impact that\ntype of product.\nSo it requires us to\nrealize that there's\na wealth of data that\nallows us to even go here as\ndeep as the census tract level\nand understand that there are\ncertain communities who\nhave a significantly\ndifferent experience\nthan other communities.\nAnd so, like I said,\nthis map is looking\nat communities at a\ncensus tract level\nwhere there's no car\nand no supermarket\nstore within a mile.\nAnd if we want it\nto look even deeper,\nwe can overlay this\ninformation with income.\nSo thinking about food\naccess and income disparity,\nwhich are often\nconnected, gives us\na better understanding of\nhow different groups may\nengage with a product.\nAnd so when thinking about a\nhard social problem like this,\nit really requires\nus to think, what's\nthe logical process\nfor us to get\ntowards a big social problem\nand have very specific outcomes\nand effects that are meaningful\nand are making a change?\nAnd it requires us\nto really acknowledge\nthat there's contexts\nthat overlays\nall parts of this process,\nfrom the inputs that we have,\nfrom the activities that we\ndo-- which may, in my case,\nbe very much\nresearch-based activities--\nand then thinking about\nwhat are meaningful outputs.\nAnd so to go in a\nlittle bit deeper\nin kind of this logic model\nway of thinking about it,\nwe have a purpose now, in\nthinking about the food access\nexample, to reduce negative\nunintended consequences\nin areas where access to\nquality food is an issue.\nWe're also very\naware of the context.\nSo we're thinking about\nthe context of food access,\nbut we're also thinking about\nquestions of gentrification.\nWe're thinking\nabout displacement.\nWe're thinking about\ncommunity distrust.\nSo we realize that\nthis question has\nmany other issues that\ninform the context, not just\naccess to food.\nBut as part of the process,\nwe're identifying resources.\nWe're thinking, where are there\nmultidisciplinary research\nteams that can help\nus think through?\nWhat are our external\nstakeholders that\ncan help us frame the problem?\nAnd then, what are the\ncross-functional relationships\nthat we need to\nbuild to really be\nable to solve this\nkind of problem,\nwhile acknowledging what\nour constraints are?\nOftentimes, time is\na huge constraint,\nand then gaps just in\nknowledge and comfort\nin being able to talk\nabout these hard problems.\nSome of the\nactivities and inputs\nthat we are thinking\nabout can help\nus get to some\nanswers are really\nthinking about case studies,\nthinking about surveys,\nthinking about user research\nwhere we're asking user\nperception about this issue.\nHow does engagement\nbased on your geography\ndiffer in being able\nto do that analysis?\nAnd then creating\ntangible outputs,\nsome that are product\ninterventions and really\nfocused on how we can make\nchanges to the product,\nbut also really community-based\nmitigations in thinking about\nare there ways in\nwhich we're engaging\nwith the community, ways\nin which we're pulling data\nthat we can really use to create\na fuller set of solutions.\nAnd really, it's always towards\naspiring for positive effects\nin principle and practice.\nSo this is one of\nthose areas where\nyou can feel like you have\na very principled approach,\nbut it really is about being\nable to put them into practice.\nAnd so some of the things\nthat I'll leave you\nwith today in thinking\nabout understanding\nthese human impacts are really\nbeing able to apply them\nand thinking about applying\nthem in specific technical\napplications,\nbuilding trust through\nequitable collaboration--\nso really thinking about,\nwhen you're engaging with\nexternal stakeholders,\nhow do you make\nit feel equitable\nand that we're both\nsharing knowledge\nand experiences in ways\nthat are meaningful--\nand then validating the\nknowledge generation.\nWhen we're engaging with\ndifferent communities,\nwe really have to be OK that\ninformation, data, and the way\nthat we frame this can come\nfrom multiple different sources,\nand it's really important.\nAnd then really thinking about,\nwithin your organization,\nwithin your team,\nwhat are change agents\nand what are change\ninstruments that really\nmake it a meaningful process?\nThank you.\nNow Margaret will talk more\nabout the machine learning\npipeline.\n[APPLAUSE]\nMARGARET MITCHELL: Great.\nThanks, Jamila.\nSo I'll be talking a bit about\nfairness and transparency\nand some frameworks and\napproaches for developing\nethical AI.\nSo in a typical machine\nlearning development pipeline,\nthe starting point for\ndevelopers is often the data.\nTraining data is first\ncollected and annotated.\nFrom there, a model\ncan be trained.\nThe model can then be\nused to output content\nsuch as predictions or rankings,\nand then downstream users\nwill see the output.\nAnd we often see\nthis approach as\nif it's a relatively\nclean pipeline that\nprovides objective information\nthat we can act on.\nHowever, from the\nbeginning of this pipeline,\nhuman bias has already shaped\nthe data that's collected.\nHuman bias then further\nshapes what we collect\nand how we annotate it.\nHere are some of the human\nbiases that commonly contribute\nto problematic biases and\ndata, and in the interpretation\nof model outputs.\nThings like reporting bias--\nwhere we tend to remark\non things that are\nnoticeable to us,\nas opposed to things\nthat are typical--\nthings like out-group\nhomogeneity bias--\nwhere we tend to see people\noutside of our social group\nas somehow being\nless nuanced or less\ncomplex than people within\nthe group that we work with--\nand things like\nautomation bias--\nwhere we tend to favor\nthe outputs of systems\nthat are automated over the\noutputs of what humans actually\nsay even when there's\ncontradictory information.\nSo rather than this\nstraightforward, clean,\nend-to-end pipeline,\nwe have human bias\ncoming in at the\nstart of the cycle,\nand then being propagated\nthroughout the rest\nof the system.\nAnd this creates a\nfeedback loop where,\nas users see the output of\nbiased systems and start\nto click or start to\ninteract with those outputs,\nthis then feeds data\nthat is further trained\non-- that's already been\nbiased in this way--\ncreating problematic\nfeedback loops\nwhere biases can\nget worse and worse.\nWe call this a sort of\nbias network effect,\nor bias \"laundering.\"\nAnd a lot of our work\nseeks to disrupt this cycle\nso that we can bring the\nbest kind of output possible.\nSo some of the\nquestions we consider\nis, who is at the table?\nWhat are the priorities\nin what we're working on?\nShould we be thinking\nabout different aspects\nof the problem and different\nperspectives as we develop?\nHow is the data that we're\nworking with collected?\nWhat kind of things\ndoes it represent?\nAre there problematic\ncorrelations in the data?\nOr are some kinds of subgroups\nunderrepresented in a way\nthat will lead to\ndisproportionate errors\ndownstream?\nWhat are some foreseeable risks?\nSo actually thinking\nwith foresight\nand anticipating possible\nnegative consequences\nof everything that we work on\nin order to better understand\nhow we should prioritize.\nWhat constraints and\nsupplements should be in place?\nBeyond a basic machine\nlearning system,\nwhat can we do to ensure\nthat we can account\nfor the kinds of risks\nthat we've anticipated\nand can foresee?\nAnd then what can we share\nwith you, the public,\nabout this process?\nWe aim to be transparent\nas we can about this\nin order to bring about\ninformation about how we're\nfocusing on this and make\nit clear that this is part\nof our development lifecycle.\nI'm going to briefly talk about\nsome technical approaches.\nThis is in the research world.\nYou can look at papers on\nthis, if you're interested,\nfor more details.\nSo there are two sorts of ML--\nMachine Learning--\ntechniques that we've\nfound to be relatively useful.\nOne is bias mitigation,\nand the other one we've\nbeen broadly calling inclusion.\nSo bias mitigation focuses\non removing a signal\nfor problematic variables.\nSo for example,\nsay you're working\non a system that is supposed\nto predict whether or not\nsomeone should be promoted.\nYou want to make sure\nthat that system is not\nkeying on something like gender,\nwhich we know is correlated\nwith promotion decisions.\nIn particular, women are\nless likely to be promoted\nor are promoted less quickly\nthan men in a lot of places,\nincluding in tech.\nWe can do this using an\nadversarial multi-task learning\nframework where, while\nwe predict something\nlike getting promoted,\nwe also try and predict\nthe subgroup that we'd like\nto make sure isn't affecting\nthe decision and\ndiscourage the model\nfrom being able to see that,\nremoving the representation\nby basically reversing the\ngradient and backpropagating.\nWhen we work on\ninclusion, we're working\non adding signal for\nsomething-- trying to make sure\nthat there are subgroups\nthat are accounted for,\neven if they're not\nwell-represented in the data.\nAnd one of the approaches that\nworks really well for this\nis transfer learning.\nSo we might take a\npre-trained network\nwith some understanding\nof gender,\nfor example, or some\nunderstanding of skin tone,\nand use that in\norder to influence\nthe decisions of\nanother network that\nis able to key on these\nrepresentations in order\nto better understand nuances in\nthe world that it's looking at.\nThis is a little bit\nof an example of one\nof the projects I was working on\nwhere we were able to increase\nhow well we could detect whether\nor not someone was smiling\nbased on working with some\nconsented gender-identified\nindividuals and having\nrepresentations of what\nthese gender presentations\nlooked like, using that\nwithin the model that then\npredicted whether or not\nsomeone was smiling.\nSome of the\ntransparency approaches\nthat we've been working on\nhelp to further explain to you\nand also help keep us\naccountable for doing\ngood work here.\nSo one of them is model cards.\nIn model cards, we're\nfocusing on reporting\nwhat model performance\nis, disaggregating\nacross various subgroups, and\nmaking it clear that we've\ntaken ethical\nconsiderations into account,\nmaking it clear\nwhat the intended\napplications of the\nmodel or the API is,\nand sharing, generally,\ndifferent kinds\nof considerations that\ndevelopers should keep in mind\nas they work with the models.\nAnother one is data cards.\nAnd this provides\nevaluation data about,\nwhen we report numbers,\nwhat is this based on?\nWho is represented when we\ndecide a model can be used--\nthat it's safe for use?\nThese kinds of things are useful\nfor learners-- so people who\ngenerally want to\nbetter understand\nhow models are working and\nwhat are the sort of things\nthat are affecting model\nperformance for third party\nusers.\nSo non-ML professionals\nwho just want\nto have a better\nunderstanding of their data\nsets that they're working with\nor what the representation\nis in different data sets that\nmachine learning models are\nbased on or evaluated\non, as well as machine\nlearning researchers.\nSo people like me, who want to\ncompare model performance, they\nwant to understand what\nneeds to be improved,\nwhat is already\ndoing well, and help\nbe able to sort of\nbenchmark and make progress\nin a way that's sensitive\nto the nuanced differences\nin different kinds\nof populations.\nOur commitment to\nyou, working on\nfair and ethical artificial\nintelligence and machine\nlearning, is to continue\nto measure, to improve,\nand to share real-world\nimpact related to ethical AI\ndevelopment.\nThanks.\n[APPLAUSE]\n",
  "words": [
    "music",
    "playing",
    "jen",
    "gennai",
    "operations",
    "manager",
    "role",
    "ensure",
    "making",
    "considerations",
    "around",
    "ethically",
    "ai",
    "deliberate",
    "actionable",
    "scalable",
    "across",
    "whole",
    "organization",
    "google",
    "one",
    "first",
    "things",
    "think",
    "business",
    "leader",
    "developer",
    "ensuring",
    "people",
    "understand",
    "stand",
    "ethics",
    "mean",
    "us",
    "meant",
    "setting",
    "principles",
    "company",
    "principles",
    "us",
    "known",
    "ai",
    "principles",
    "last",
    "year",
    "announced",
    "june",
    "seven",
    "guidelines",
    "around",
    "ai",
    "development",
    "deployment",
    "assigned",
    "us",
    "want",
    "develop",
    "ai",
    "want",
    "ensure",
    "creating",
    "reinforcing",
    "bias",
    "want",
    "make",
    "sure",
    "building",
    "technology",
    "accountable",
    "people",
    "five",
    "others",
    "read",
    "available",
    "website",
    "time",
    "announce",
    "aspirational",
    "principles",
    "company",
    "also",
    "identified",
    "four",
    "areas",
    "considered",
    "red",
    "lines",
    "technologies",
    "pursue",
    "cover",
    "things",
    "like",
    "weapons",
    "technology",
    "build",
    "deploy",
    "weapons",
    "also",
    "build",
    "deploy",
    "technologies",
    "feel",
    "violate",
    "international",
    "human",
    "rights",
    "business",
    "leader",
    "developer",
    "also",
    "encourage",
    "understand",
    "aspirational",
    "goals",
    "time",
    "guardrails",
    "point",
    "going",
    "cross",
    "important",
    "thing",
    "know",
    "definition",
    "ethical",
    "ai",
    "development",
    "set",
    "ai",
    "principles",
    "next",
    "thing",
    "make",
    "real",
    "make",
    "sure",
    "aligning",
    "principles",
    "three",
    "main",
    "things",
    "suggest",
    "keeping",
    "mind",
    "first",
    "one",
    "need",
    "accountable",
    "authoritative",
    "body",
    "us",
    "google",
    "means",
    "senior",
    "executives",
    "across",
    "whole",
    "company",
    "authority",
    "approve",
    "decline",
    "launch",
    "wrestle",
    "complex",
    "ethical",
    "questions",
    "ensure",
    "launching",
    "things",
    "believe",
    "lead",
    "fair",
    "ethical",
    "outcomes",
    "provide",
    "authority",
    "accountability",
    "make",
    "really",
    "tough",
    "decisions",
    "secondly",
    "make",
    "sure",
    "right",
    "information",
    "involves",
    "talking",
    "diverse",
    "people",
    "within",
    "company",
    "also",
    "listening",
    "external",
    "users",
    "external",
    "stakeholders",
    "feeding",
    "criteria",
    "jamila",
    "talk",
    "engaging",
    "external",
    "communites",
    "moment",
    "third",
    "key",
    "part",
    "building",
    "governance",
    "accountability",
    "operations",
    "going",
    "work",
    "structures",
    "frameworks",
    "repeatable",
    "transparent",
    "understood",
    "people",
    "making",
    "decisions",
    "google",
    "established",
    "central",
    "team",
    "based",
    "engineering",
    "product",
    "teams",
    "ensure",
    "level",
    "objectivity",
    "people",
    "building",
    "products",
    "people",
    "looking",
    "make",
    "sure",
    "products",
    "fair",
    "ethical",
    "principles",
    "trying",
    "ensure",
    "people",
    "understand",
    "ethics",
    "mean",
    "talking",
    "establishing",
    "governance",
    "structure",
    "make",
    "sure",
    "achieving",
    "goals",
    "next",
    "thing",
    "ensure",
    "encouraging",
    "everyone",
    "within",
    "company",
    "people",
    "work",
    "aligned",
    "goals",
    "making",
    "sure",
    "one",
    "set",
    "overall",
    "goals",
    "alignment",
    "ethical",
    "ai",
    "going",
    "achieve",
    "ethical",
    "development",
    "deployment",
    "technology",
    "next",
    "want",
    "make",
    "sure",
    "training",
    "people",
    "think",
    "issues",
    "start",
    "want",
    "catch",
    "ethical",
    "consideration",
    "late",
    "product",
    "development",
    "lifecycle",
    "want",
    "make",
    "sure",
    "starting",
    "early",
    "possible",
    "getting",
    "people",
    "trained",
    "think",
    "types",
    "issues",
    "rewards",
    "make",
    "sure",
    "holding",
    "people",
    "accountable",
    "ethical",
    "development",
    "deployment",
    "may",
    "accept",
    "might",
    "slow",
    "development",
    "order",
    "get",
    "right",
    "outcomes",
    "making",
    "sure",
    "people",
    "feel",
    "rewarded",
    "thinking",
    "ethical",
    "development",
    "deployment",
    "finally",
    "making",
    "sure",
    "hiring",
    "people",
    "developing",
    "people",
    "helping",
    "achieve",
    "goals",
    "next",
    "established",
    "frameworks",
    "hired",
    "right",
    "people",
    "rewarding",
    "know",
    "achieving",
    "goals",
    "think",
    "validating",
    "testing",
    "example",
    "replicating",
    "user",
    "experience",
    "users",
    "make",
    "sure",
    "thinking",
    "representative",
    "sample",
    "users",
    "think",
    "trying",
    "test",
    "different",
    "experiences",
    "mostly",
    "core",
    "subgroups",
    "also",
    "want",
    "thinking",
    "marginalized",
    "users",
    "might",
    "underrepresented",
    "workforce",
    "therefore",
    "might",
    "pay",
    "additional",
    "attention",
    "get",
    "right",
    "also",
    "think",
    "failure",
    "modes",
    "mean",
    "people",
    "negatively",
    "affected",
    "product",
    "past",
    "want",
    "make",
    "sure",
    "wo",
    "negatively",
    "affected",
    "future",
    "learn",
    "make",
    "sure",
    "testing",
    "deliberately",
    "future",
    "final",
    "bit",
    "testing",
    "validation",
    "introducing",
    "failures",
    "product",
    "make",
    "sure",
    "stress",
    "testing",
    "objectivity",
    "stress",
    "test",
    "product",
    "make",
    "sure",
    "achieving",
    "fair",
    "ethical",
    "goals",
    "think",
    "alone",
    "ensure",
    "sharing",
    "information",
    "make",
    "us",
    "fair",
    "ethical",
    "make",
    "sure",
    "products",
    "deliver",
    "fair",
    "ethical",
    "encourage",
    "sharing",
    "best",
    "practices",
    "guidelines",
    "google",
    "providing",
    "research",
    "best",
    "practices",
    "google",
    "ai",
    "site",
    "best",
    "practices",
    "cover",
    "everything",
    "ml",
    "fairness",
    "tools",
    "research",
    "margaret",
    "mitchell",
    "talk",
    "moment",
    "also",
    "best",
    "practices",
    "guidelines",
    "developer",
    "business",
    "leader",
    "could",
    "follow",
    "try",
    "provide",
    "well",
    "encouraging",
    "people",
    "share",
    "research",
    "learnings",
    "also",
    "talk",
    "sharing",
    "external",
    "also",
    "bringing",
    "voices",
    "pass",
    "jamila",
    "talk",
    "understanding",
    "human",
    "impacts",
    "jamila",
    "thank",
    "applause",
    "hi",
    "everyone",
    "going",
    "talk",
    "little",
    "bit",
    "today",
    "understanding",
    "conceptualizing",
    "assessing",
    "human",
    "consequences",
    "impacts",
    "real",
    "people",
    "communities",
    "use",
    "tools",
    "like",
    "social",
    "equity",
    "impact",
    "assessments",
    "social",
    "equity",
    "impact",
    "assessments",
    "come",
    "primarily",
    "social",
    "science",
    "discipline",
    "give",
    "us",
    "method",
    "assess",
    "questions",
    "way",
    "broad",
    "enough",
    "able",
    "apply",
    "across",
    "products",
    "also",
    "specific",
    "enough",
    "us",
    "think",
    "tangible",
    "product",
    "changes",
    "interventions",
    "make",
    "start",
    "one",
    "questions",
    "often",
    "start",
    "thinking",
    "questions",
    "always",
    "like",
    "say",
    "thinking",
    "ethics",
    "thinking",
    "fairness",
    "even",
    "thinking",
    "questions",
    "bias",
    "really",
    "social",
    "problems",
    "one",
    "major",
    "entry",
    "point",
    "understanding",
    "social",
    "problems",
    "really",
    "thinking",
    "geographic",
    "context",
    "users",
    "live",
    "impact",
    "engagement",
    "product",
    "really",
    "asking",
    "experiences",
    "people",
    "based",
    "solely",
    "live",
    "may",
    "differ",
    "greatly",
    "peoples",
    "live",
    "different",
    "neighborhoods",
    "either",
    "resourced",
    "connected",
    "internet",
    "different",
    "aspects",
    "make",
    "regional",
    "differences",
    "important",
    "secondly",
    "like",
    "ask",
    "happens",
    "people",
    "engaging",
    "products",
    "families",
    "communities",
    "like",
    "think",
    "economic",
    "changes",
    "may",
    "come",
    "part",
    "engagement",
    "new",
    "technology",
    "social",
    "cultural",
    "changes",
    "really",
    "impact",
    "people",
    "view",
    "technology",
    "view",
    "participation",
    "process",
    "start",
    "little",
    "bit",
    "talking",
    "approach",
    "good",
    "thing",
    "utilizing",
    "kind",
    "existing",
    "frameworks",
    "social",
    "equity",
    "impact",
    "assessments",
    "come",
    "think",
    "new",
    "land",
    "development",
    "projects",
    "even",
    "environmental",
    "assessments",
    "already",
    "standard",
    "considering",
    "social",
    "impacts",
    "part",
    "process",
    "really",
    "think",
    "employing",
    "new",
    "technologies",
    "way",
    "asking",
    "similar",
    "questions",
    "communities",
    "impacted",
    "perceptions",
    "framing",
    "engagements",
    "one",
    "things",
    "think",
    "kind",
    "principled",
    "approach",
    "asking",
    "questions",
    "first",
    "one",
    "really",
    "around",
    "engaging",
    "hard",
    "questions",
    "talking",
    "fairness",
    "talking",
    "ethics",
    "talking",
    "separately",
    "issues",
    "racism",
    "social",
    "class",
    "homophobia",
    "forms",
    "cultural",
    "prejudice",
    "talking",
    "issues",
    "overlay",
    "really",
    "requires",
    "us",
    "ok",
    "hard",
    "questions",
    "engaging",
    "realizing",
    "technologies",
    "products",
    "exist",
    "separately",
    "world",
    "next",
    "approach",
    "really",
    "towards",
    "thinking",
    "anticipatory",
    "think",
    "different",
    "thing",
    "thinking",
    "social",
    "equity",
    "impact",
    "assessments",
    "social",
    "science",
    "research",
    "methods",
    "relationships",
    "causal",
    "impacts",
    "correlations",
    "going",
    "little",
    "bit",
    "different",
    "really",
    "trying",
    "anticipate",
    "harms",
    "consequences",
    "requires",
    "ok",
    "fuzzy",
    "conversations",
    "also",
    "realize",
    "enough",
    "research",
    "enough",
    "data",
    "gives",
    "us",
    "understanding",
    "history",
    "contexts",
    "impact",
    "outcomes",
    "anticipatory",
    "process",
    "really",
    "really",
    "important",
    "part",
    "lastly",
    "terms",
    "thinking",
    "principled",
    "approach",
    "really",
    "centering",
    "voices",
    "experiences",
    "communities",
    "often",
    "bear",
    "burden",
    "negative",
    "impacts",
    "requires",
    "understanding",
    "communities",
    "would",
    "even",
    "conceptualize",
    "problems",
    "think",
    "sometimes",
    "come",
    "technical",
    "standpoint",
    "think",
    "communities",
    "separate",
    "problem",
    "ready",
    "center",
    "voices",
    "engaged",
    "throughout",
    "whole",
    "process",
    "think",
    "results",
    "better",
    "outcomes",
    "go",
    "little",
    "bit",
    "deeper",
    "engaging",
    "hard",
    "questions",
    "really",
    "trying",
    "able",
    "assess",
    "product",
    "impact",
    "communities",
    "particularly",
    "communities",
    "historically",
    "traditionally",
    "marginalized",
    "requires",
    "us",
    "really",
    "think",
    "history",
    "context",
    "shaping",
    "issue",
    "could",
    "learn",
    "assessment",
    "also",
    "requires",
    "intersectional",
    "approach",
    "thinking",
    "gender",
    "equity",
    "thinking",
    "racial",
    "equity",
    "issues",
    "live",
    "separately",
    "really",
    "intersect",
    "ok",
    "understanding",
    "intersectional",
    "approach",
    "allows",
    "much",
    "fuller",
    "assessment",
    "lastly",
    "thinking",
    "new",
    "technologies",
    "thinking",
    "new",
    "products",
    "power",
    "influence",
    "outcomes",
    "feasibility",
    "interventions",
    "think",
    "question",
    "power",
    "social",
    "impact",
    "go",
    "requires",
    "us",
    "ok",
    "answering",
    "answering",
    "might",
    "get",
    "best",
    "answer",
    "least",
    "asking",
    "hard",
    "questions",
    "anticipatory",
    "process",
    "part",
    "full",
    "process",
    "right",
    "us",
    "thinking",
    "social",
    "equity",
    "impacts",
    "really",
    "thinking",
    "within",
    "context",
    "product",
    "really",
    "application",
    "questions",
    "assessment",
    "likelihood",
    "severity",
    "risk",
    "lastly",
    "thinking",
    "meaningful",
    "mitigations",
    "whatever",
    "impacts",
    "developed",
    "full",
    "process",
    "requires",
    "work",
    "team",
    "terms",
    "understanding",
    "assessment",
    "also",
    "requires",
    "partnership",
    "product",
    "teams",
    "really",
    "analysis",
    "centering",
    "assessment",
    "talked",
    "little",
    "bit",
    "centering",
    "assessment",
    "really",
    "trying",
    "ask",
    "impacted",
    "thinking",
    "problem",
    "may",
    "economic",
    "impact",
    "would",
    "require",
    "us",
    "disaggregate",
    "data",
    "based",
    "income",
    "see",
    "communities",
    "populations",
    "impacted",
    "ok",
    "thinking",
    "specific",
    "population",
    "data",
    "understanding",
    "impacted",
    "another",
    "important",
    "part",
    "validation",
    "think",
    "jen",
    "mentioned",
    "lot",
    "really",
    "thinking",
    "research",
    "engagements",
    "whether",
    "participatory",
    "approach",
    "whether",
    "focus",
    "groups",
    "really",
    "validate",
    "assessments",
    "engaging",
    "communities",
    "directly",
    "really",
    "centering",
    "framing",
    "problem",
    "part",
    "project",
    "going",
    "iteration",
    "realizing",
    "going",
    "perfect",
    "first",
    "time",
    "requires",
    "pull",
    "tugging",
    "sides",
    "really",
    "get",
    "conversation",
    "right",
    "types",
    "social",
    "problems",
    "thinking",
    "thinking",
    "income",
    "inequality",
    "housing",
    "displacement",
    "health",
    "disparities",
    "digital",
    "divide",
    "food",
    "access",
    "thinking",
    "different",
    "types",
    "ways",
    "thought",
    "might",
    "helpful",
    "thought",
    "specific",
    "example",
    "let",
    "look",
    "example",
    "one",
    "types",
    "social",
    "problems",
    "want",
    "understand",
    "relation",
    "products",
    "users",
    "topic",
    "inequity",
    "related",
    "food",
    "access",
    "map",
    "shows",
    "definitely",
    "us",
    "context",
    "thinking",
    "question",
    "also",
    "always",
    "thinking",
    "global",
    "way",
    "thought",
    "map",
    "good",
    "way",
    "us",
    "look",
    "see",
    "areas",
    "shaded",
    "darker",
    "areas",
    "users",
    "might",
    "significantly",
    "different",
    "experience",
    "thinking",
    "products",
    "give",
    "personalization",
    "recommendations",
    "maybe",
    "something",
    "like",
    "restaurants",
    "thinking",
    "questions",
    "users",
    "either",
    "included",
    "excluded",
    "product",
    "experience",
    "thinking",
    "going",
    "even",
    "thinking",
    "small",
    "businesses",
    "low",
    "resource",
    "businesses",
    "also",
    "impact",
    "type",
    "product",
    "requires",
    "us",
    "realize",
    "wealth",
    "data",
    "allows",
    "us",
    "even",
    "go",
    "deep",
    "census",
    "tract",
    "level",
    "understand",
    "certain",
    "communities",
    "significantly",
    "different",
    "experience",
    "communities",
    "like",
    "said",
    "map",
    "looking",
    "communities",
    "census",
    "tract",
    "level",
    "car",
    "supermarket",
    "store",
    "within",
    "mile",
    "want",
    "look",
    "even",
    "deeper",
    "overlay",
    "information",
    "income",
    "thinking",
    "food",
    "access",
    "income",
    "disparity",
    "often",
    "connected",
    "gives",
    "us",
    "better",
    "understanding",
    "different",
    "groups",
    "may",
    "engage",
    "product",
    "thinking",
    "hard",
    "social",
    "problem",
    "like",
    "really",
    "requires",
    "us",
    "think",
    "logical",
    "process",
    "us",
    "get",
    "towards",
    "big",
    "social",
    "problem",
    "specific",
    "outcomes",
    "effects",
    "meaningful",
    "making",
    "change",
    "requires",
    "us",
    "really",
    "acknowledge",
    "contexts",
    "overlays",
    "parts",
    "process",
    "inputs",
    "activities",
    "may",
    "case",
    "much",
    "activities",
    "thinking",
    "meaningful",
    "outputs",
    "go",
    "little",
    "bit",
    "deeper",
    "kind",
    "logic",
    "model",
    "way",
    "thinking",
    "purpose",
    "thinking",
    "food",
    "access",
    "example",
    "reduce",
    "negative",
    "unintended",
    "consequences",
    "areas",
    "access",
    "quality",
    "food",
    "issue",
    "also",
    "aware",
    "context",
    "thinking",
    "context",
    "food",
    "access",
    "also",
    "thinking",
    "questions",
    "gentrification",
    "thinking",
    "displacement",
    "thinking",
    "community",
    "distrust",
    "realize",
    "question",
    "many",
    "issues",
    "inform",
    "context",
    "access",
    "food",
    "part",
    "process",
    "identifying",
    "resources",
    "thinking",
    "multidisciplinary",
    "research",
    "teams",
    "help",
    "us",
    "think",
    "external",
    "stakeholders",
    "help",
    "us",
    "frame",
    "problem",
    "relationships",
    "need",
    "build",
    "really",
    "able",
    "solve",
    "kind",
    "problem",
    "acknowledging",
    "constraints",
    "oftentimes",
    "time",
    "huge",
    "constraint",
    "gaps",
    "knowledge",
    "comfort",
    "able",
    "talk",
    "hard",
    "problems",
    "activities",
    "inputs",
    "thinking",
    "help",
    "us",
    "get",
    "answers",
    "really",
    "thinking",
    "case",
    "studies",
    "thinking",
    "surveys",
    "thinking",
    "user",
    "research",
    "asking",
    "user",
    "perception",
    "issue",
    "engagement",
    "based",
    "geography",
    "differ",
    "able",
    "analysis",
    "creating",
    "tangible",
    "outputs",
    "product",
    "interventions",
    "really",
    "focused",
    "make",
    "changes",
    "product",
    "also",
    "really",
    "mitigations",
    "thinking",
    "ways",
    "engaging",
    "community",
    "ways",
    "pulling",
    "data",
    "really",
    "use",
    "create",
    "fuller",
    "set",
    "solutions",
    "really",
    "always",
    "towards",
    "aspiring",
    "positive",
    "effects",
    "principle",
    "practice",
    "one",
    "areas",
    "feel",
    "like",
    "principled",
    "approach",
    "really",
    "able",
    "put",
    "practice",
    "things",
    "leave",
    "today",
    "thinking",
    "understanding",
    "human",
    "impacts",
    "really",
    "able",
    "apply",
    "thinking",
    "applying",
    "specific",
    "technical",
    "applications",
    "building",
    "trust",
    "equitable",
    "collaboration",
    "really",
    "thinking",
    "engaging",
    "external",
    "stakeholders",
    "make",
    "feel",
    "equitable",
    "sharing",
    "knowledge",
    "experiences",
    "ways",
    "meaningful",
    "validating",
    "knowledge",
    "generation",
    "engaging",
    "different",
    "communities",
    "really",
    "ok",
    "information",
    "data",
    "way",
    "frame",
    "come",
    "multiple",
    "different",
    "sources",
    "really",
    "important",
    "really",
    "thinking",
    "within",
    "organization",
    "within",
    "team",
    "change",
    "agents",
    "change",
    "instruments",
    "really",
    "make",
    "meaningful",
    "process",
    "thank",
    "margaret",
    "talk",
    "machine",
    "learning",
    "pipeline",
    "applause",
    "margaret",
    "mitchell",
    "great",
    "thanks",
    "jamila",
    "talking",
    "bit",
    "fairness",
    "transparency",
    "frameworks",
    "approaches",
    "developing",
    "ethical",
    "ai",
    "typical",
    "machine",
    "learning",
    "development",
    "pipeline",
    "starting",
    "point",
    "developers",
    "often",
    "data",
    "training",
    "data",
    "first",
    "collected",
    "annotated",
    "model",
    "trained",
    "model",
    "used",
    "output",
    "content",
    "predictions",
    "rankings",
    "downstream",
    "users",
    "see",
    "output",
    "often",
    "see",
    "approach",
    "relatively",
    "clean",
    "pipeline",
    "provides",
    "objective",
    "information",
    "act",
    "however",
    "beginning",
    "pipeline",
    "human",
    "bias",
    "already",
    "shaped",
    "data",
    "collected",
    "human",
    "bias",
    "shapes",
    "collect",
    "annotate",
    "human",
    "biases",
    "commonly",
    "contribute",
    "problematic",
    "biases",
    "data",
    "interpretation",
    "model",
    "outputs",
    "things",
    "like",
    "reporting",
    "bias",
    "tend",
    "remark",
    "things",
    "noticeable",
    "us",
    "opposed",
    "things",
    "typical",
    "things",
    "like",
    "homogeneity",
    "bias",
    "tend",
    "see",
    "people",
    "outside",
    "social",
    "group",
    "somehow",
    "less",
    "nuanced",
    "less",
    "complex",
    "people",
    "within",
    "group",
    "work",
    "things",
    "like",
    "automation",
    "bias",
    "tend",
    "favor",
    "outputs",
    "systems",
    "automated",
    "outputs",
    "humans",
    "actually",
    "say",
    "even",
    "contradictory",
    "information",
    "rather",
    "straightforward",
    "clean",
    "pipeline",
    "human",
    "bias",
    "coming",
    "start",
    "cycle",
    "propagated",
    "throughout",
    "rest",
    "system",
    "creates",
    "feedback",
    "loop",
    "users",
    "see",
    "output",
    "biased",
    "systems",
    "start",
    "click",
    "start",
    "interact",
    "outputs",
    "feeds",
    "data",
    "trained",
    "already",
    "biased",
    "way",
    "creating",
    "problematic",
    "feedback",
    "loops",
    "biases",
    "get",
    "worse",
    "worse",
    "call",
    "sort",
    "bias",
    "network",
    "effect",
    "bias",
    "laundering",
    "lot",
    "work",
    "seeks",
    "disrupt",
    "cycle",
    "bring",
    "best",
    "kind",
    "output",
    "possible",
    "questions",
    "consider",
    "table",
    "priorities",
    "working",
    "thinking",
    "different",
    "aspects",
    "problem",
    "different",
    "perspectives",
    "develop",
    "data",
    "working",
    "collected",
    "kind",
    "things",
    "represent",
    "problematic",
    "correlations",
    "data",
    "kinds",
    "subgroups",
    "underrepresented",
    "way",
    "lead",
    "disproportionate",
    "errors",
    "downstream",
    "foreseeable",
    "risks",
    "actually",
    "thinking",
    "foresight",
    "anticipating",
    "possible",
    "negative",
    "consequences",
    "everything",
    "work",
    "order",
    "better",
    "understand",
    "prioritize",
    "constraints",
    "supplements",
    "place",
    "beyond",
    "basic",
    "machine",
    "learning",
    "system",
    "ensure",
    "account",
    "kinds",
    "risks",
    "anticipated",
    "foresee",
    "share",
    "public",
    "process",
    "aim",
    "transparent",
    "order",
    "bring",
    "information",
    "focusing",
    "make",
    "clear",
    "part",
    "development",
    "lifecycle",
    "going",
    "briefly",
    "talk",
    "technical",
    "approaches",
    "research",
    "world",
    "look",
    "papers",
    "interested",
    "details",
    "two",
    "sorts",
    "ml",
    "machine",
    "learning",
    "techniques",
    "found",
    "relatively",
    "useful",
    "one",
    "bias",
    "mitigation",
    "one",
    "broadly",
    "calling",
    "inclusion",
    "bias",
    "mitigation",
    "focuses",
    "removing",
    "signal",
    "problematic",
    "variables",
    "example",
    "say",
    "working",
    "system",
    "supposed",
    "predict",
    "whether",
    "someone",
    "promoted",
    "want",
    "make",
    "sure",
    "system",
    "keying",
    "something",
    "like",
    "gender",
    "know",
    "correlated",
    "promotion",
    "decisions",
    "particular",
    "women",
    "less",
    "likely",
    "promoted",
    "promoted",
    "less",
    "quickly",
    "men",
    "lot",
    "places",
    "including",
    "tech",
    "using",
    "adversarial",
    "learning",
    "framework",
    "predict",
    "something",
    "like",
    "getting",
    "promoted",
    "also",
    "try",
    "predict",
    "subgroup",
    "like",
    "make",
    "sure",
    "affecting",
    "decision",
    "discourage",
    "model",
    "able",
    "see",
    "removing",
    "representation",
    "basically",
    "reversing",
    "gradient",
    "backpropagating",
    "work",
    "inclusion",
    "working",
    "adding",
    "signal",
    "something",
    "trying",
    "make",
    "sure",
    "subgroups",
    "accounted",
    "even",
    "data",
    "one",
    "approaches",
    "works",
    "really",
    "well",
    "transfer",
    "learning",
    "might",
    "take",
    "network",
    "understanding",
    "gender",
    "example",
    "understanding",
    "skin",
    "tone",
    "use",
    "order",
    "influence",
    "decisions",
    "another",
    "network",
    "able",
    "key",
    "representations",
    "order",
    "better",
    "understand",
    "nuances",
    "world",
    "looking",
    "little",
    "bit",
    "example",
    "one",
    "projects",
    "working",
    "able",
    "increase",
    "well",
    "could",
    "detect",
    "whether",
    "someone",
    "smiling",
    "based",
    "working",
    "consented",
    "individuals",
    "representations",
    "gender",
    "presentations",
    "looked",
    "like",
    "using",
    "within",
    "model",
    "predicted",
    "whether",
    "someone",
    "smiling",
    "transparency",
    "approaches",
    "working",
    "help",
    "explain",
    "also",
    "help",
    "keep",
    "us",
    "accountable",
    "good",
    "work",
    "one",
    "model",
    "cards",
    "model",
    "cards",
    "focusing",
    "reporting",
    "model",
    "performance",
    "disaggregating",
    "across",
    "various",
    "subgroups",
    "making",
    "clear",
    "taken",
    "ethical",
    "considerations",
    "account",
    "making",
    "clear",
    "intended",
    "applications",
    "model",
    "api",
    "sharing",
    "generally",
    "different",
    "kinds",
    "considerations",
    "developers",
    "keep",
    "mind",
    "work",
    "models",
    "another",
    "one",
    "data",
    "cards",
    "provides",
    "evaluation",
    "data",
    "report",
    "numbers",
    "based",
    "represented",
    "decide",
    "model",
    "used",
    "safe",
    "use",
    "kinds",
    "things",
    "useful",
    "learners",
    "people",
    "generally",
    "want",
    "better",
    "understand",
    "models",
    "working",
    "sort",
    "things",
    "affecting",
    "model",
    "performance",
    "third",
    "party",
    "users",
    "professionals",
    "want",
    "better",
    "understanding",
    "data",
    "sets",
    "working",
    "representation",
    "different",
    "data",
    "sets",
    "machine",
    "learning",
    "models",
    "based",
    "evaluated",
    "well",
    "machine",
    "learning",
    "researchers",
    "people",
    "like",
    "want",
    "compare",
    "model",
    "performance",
    "want",
    "understand",
    "needs",
    "improved",
    "already",
    "well",
    "help",
    "able",
    "sort",
    "benchmark",
    "make",
    "progress",
    "way",
    "sensitive",
    "nuanced",
    "differences",
    "different",
    "kinds",
    "populations",
    "commitment",
    "working",
    "fair",
    "ethical",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "continue",
    "measure",
    "improve",
    "share",
    "impact",
    "related",
    "ethical",
    "ai",
    "development",
    "thanks",
    "applause"
  ],
  "keywords": [
    "ensure",
    "making",
    "considerations",
    "around",
    "ai",
    "across",
    "whole",
    "google",
    "one",
    "first",
    "things",
    "think",
    "business",
    "leader",
    "developer",
    "people",
    "understand",
    "ethics",
    "mean",
    "us",
    "principles",
    "company",
    "guidelines",
    "development",
    "deployment",
    "want",
    "creating",
    "bias",
    "make",
    "sure",
    "building",
    "technology",
    "accountable",
    "time",
    "also",
    "areas",
    "technologies",
    "like",
    "build",
    "feel",
    "human",
    "goals",
    "point",
    "going",
    "important",
    "thing",
    "know",
    "ethical",
    "set",
    "next",
    "questions",
    "fair",
    "outcomes",
    "really",
    "decisions",
    "right",
    "information",
    "talking",
    "within",
    "external",
    "users",
    "stakeholders",
    "jamila",
    "talk",
    "engaging",
    "part",
    "work",
    "frameworks",
    "team",
    "based",
    "product",
    "teams",
    "level",
    "products",
    "looking",
    "trying",
    "achieving",
    "issues",
    "start",
    "possible",
    "trained",
    "types",
    "may",
    "might",
    "order",
    "get",
    "thinking",
    "testing",
    "example",
    "user",
    "experience",
    "different",
    "experiences",
    "subgroups",
    "bit",
    "sharing",
    "best",
    "practices",
    "research",
    "fairness",
    "margaret",
    "could",
    "well",
    "share",
    "voices",
    "understanding",
    "impacts",
    "applause",
    "little",
    "consequences",
    "communities",
    "use",
    "social",
    "equity",
    "impact",
    "assessments",
    "come",
    "way",
    "enough",
    "able",
    "specific",
    "changes",
    "interventions",
    "often",
    "always",
    "say",
    "even",
    "problems",
    "context",
    "live",
    "engagement",
    "asking",
    "new",
    "process",
    "approach",
    "good",
    "kind",
    "already",
    "impacted",
    "principled",
    "hard",
    "separately",
    "requires",
    "ok",
    "world",
    "towards",
    "anticipatory",
    "realize",
    "data",
    "lastly",
    "centering",
    "negative",
    "technical",
    "problem",
    "better",
    "go",
    "deeper",
    "issue",
    "assessment",
    "gender",
    "question",
    "meaningful",
    "income",
    "see",
    "another",
    "lot",
    "whether",
    "food",
    "access",
    "ways",
    "thought",
    "look",
    "map",
    "something",
    "change",
    "activities",
    "outputs",
    "model",
    "help",
    "knowledge",
    "machine",
    "learning",
    "pipeline",
    "approaches",
    "collected",
    "output",
    "biases",
    "problematic",
    "tend",
    "less",
    "system",
    "sort",
    "network",
    "working",
    "kinds",
    "clear",
    "predict",
    "someone",
    "promoted",
    "cards",
    "performance",
    "models"
  ]
}