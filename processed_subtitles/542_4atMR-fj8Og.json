{
  "text": "foreign\ntoday we will take you through a hands\nof lab demo of how we can use Gan the\nnative adversarial Network for the image\nclassification\nand for amazing videos like this\nsubscribe to our YouTube channel and\npress that Bell icon to stay updated so\nin today's session\nwe will discuss what Gan is and moving\nahead we will cover types of models in\nGM and in the end we will do a hands-up\nlab demo of celebrated face image using\nGN so now let's see what is gan\nso generative adversarial networks were\nintroduced in 2014 by inj Goodfellow and\nco-authors JNS perform unsupervised\nlearning tasks in machine learning gns\ncan be used to generate new examples\nthat possibly could have been drawn from\nthe original data set\nso this is an image of GN there is a\ndatabase that has a real 100 rupee node\nthe generator neural network generates\nfake hundred rupee node so the\ndiscriminator network will help to\nidentify the real and the fake node or\nthe real and the fake images you can see\nso moving ahead let's see what is\ngenerator\nso a generator is a GN neural network\nthat creates fake data to be trained on\nthe discriminator it learns to generate\nplausible data so the generator examples\nor instances become negative training\nexamples of the discriminator\nso as you can see here the random input\ngenerate a new fake image the main aim\nof the generator is to make the\ndiscriminator classify its output as\nreal\nso the part of GN that drains the\ngenerator includes the noisy input\nvector or generator Network which\ntransform the random input into a\ninstance or the discriminator network\nwhich classifies as generator data so\nafter seeing what is generated let's see\nwhat is a discriminator\nso the discriminator is a neural network\nthat identifies the real data from the\nfake data created by the generator\nso the discriminator training data comes\nfrom two sources the real data instance\nsuch as real pictures of birds human\ncurrency nodes and anything are used by\nthe riskimeter as a positive sample\nduring training the second one is the\nfake data instance created by the\ngenerator are used as a negative\nexamples during the training process so\ndiscriminator decide from the real\nimages and the fake images generated by\ngenerator and discriminator decide which\nis fake and which are real so now let's\nmove on to the programming part and see\nhow we can use Jan using celebrity face\nimage data set so before move on to the\nprogramming part let me tell you that\nthe demand for machine learning AI is\ngrowing faster than that of other\nprofession in fact according to\nstatistic there will be more than 2.3\nmillion job opening in the field of\nartificial intelligence and machine\nlearning by 2023 but you can beat the\ncow with a professional certificate\nprogram in Ai and machine learning\nco-sponsored by Pardi University and IBM\nthis course covers tools and techniques\nlike numpy pandas python sci-fi along\nwith industry project like social media\nby Twitter delivery service provider by\nzomato and transportation service\nprovided by Uber and many more Amazing\nprojects choosing this course can you\nget hired in renowned companies like\nNetflix Amazon Facebook and Adobe and\nmany more and an average salary hike of\n70 percent so what are you waiting for\njoin the professional certificate\nprogram in Ai and machine learning and\nExcel your career into machine learning\nthe link is in the description box below\nso here we will start with GN generative\nadversarial networks okay so first I\nwill rename with gan\nokay\nso here we will import some libraries\nlike import\nOS\nso we will do from PI torch machine\nlearning deep learning library\nwhich worked for like neural networks so\nhere I will add from\nlist\ndot data report\ndata loader\nokay so what is this torch dot\nutlist.data so this is an app set class\nrepresenting a data set and you here you\ncan custom data set\nthat inherit data set and override that\nthis is it okay\nand this import data loader so data\nloader is a client application for the\nbulk import or export of the data and we\ncan use it for to insert update delete\nor export like records and when\nimporting data data loader reads extract\nand loads data from the CSV files like\ncomma separated values or from a\ndatabase connection you can say and when\nexporting data it's output a CSV file\nokay then moving forward\nDodge\nvision\nDot\ntransform\nas\nt\nokay\nso Transformer like very common image\ntransformation available in the toss\nVision so transformation module they can\nbe changed together using compost so\nmost transform classes have function\nequivalent functional transform give\nfine grain control over the\ntransformations\nand one more like from\ntorch vision\nDot\ntransforms\nsorry data set\ns\nimport\nimage\nfolder\nokay invalid syntax\nthank you\nwhy it is invalid to let I will tell you\nnot it's important\nokay yes\nso now what I will do\nokay Dodge\nutils it is\nyeah now it's working fine so now we\nwill import the data set so we are here\nwe are using celebrity face image Okay\nso\nI will provide you the data in the\ndescription box below don't worry okay\nso you can download from\ndata set directly from there\nso this is my path\nto data set\non five\nlet's stop\nface image data set\nforeign\nnow I guess it's fine\nyeah\nso here\nwhat I will do I will set the image size\nand all so image\nsize\n64. then batch size\nequals to\n256.\nthen best size equal to 256\nthen stats\nequals to\n0.5\ncomma 0.5\nand again\n0.5\nokay comma\n0.5\ncomma 0.5\ncomma 0.5\nokay so here we have set the image size\nand the batch size and the stat values\nso now what we will do we will train the\ndata set so here I will write train\nDS equals\nimage\nfolder\ndata\nsorry\ndata directory\ncomma transform\nT Dot\nT Dot\ncompose\nhere I will add D dot\nuh study size\nthe image size\nokay\nthen again repeat Dot\nCenter crop\nCenter crop here I will write image\nsize\nI will click small\n[Music]\nthen here I will add T Dot\nto\ntensor\ncomma T Dot\nnormalize\nstats\nokay\nbecause here I can write train\nDL equals to data\nloader\nthen train\nideas\npress size\nthen Shuffle\ntrue\ncommon num\nworkers\nbecause two number of workers\nthen here I will let pin memory\nokay\nthe system cannot find the body specific\nuser\nokay so there is an\nokay so let me copy my path\nlet's see\nnow let me run\nyeah so it's working fine\nso\nlet me put\nDot\nso\ntorch vision\nDot utils\nimport\nokay then import matplotlab\nmy problem\nDot\nPi plot\nas PLT\nthen\nthat plotlet\nso this torchvision dot utils import\nmake grid is used to make a grade\nokay great you know small small boxes\nand this matplotlib you already know is\nused for the making charts\ndifferent types of chart line chart bar\nchart pie chart\nokay so let me run this\nso here I will write now make a function\nno\nIMG\ndancers\nthen\nreturn\nIMG\ndancers\nstats\nrun\n1 0\nplus that\nzero\nnegative\nokay\nso let me run this\nnow what we will do we will make again a\nnew function for show images and show\npatches okay for that I will write the\nshow\nimage\nokay\nand Max\nequals to 64. so simple will be there\nthen\nfigure\nfrom our axis\nequals to PLT Dot subplots\nfigure size\nso\n10 comma 10.\nokay\nthen ax axis dot set\nX takes\nax dot set\nvertex\nokay then ax dot I am sure this is image\nshow\nthen make grid\nthe norm with General function\nimages Dot\ndetect\nand Max\ncomma intro\nnumber of rows will be eight\nthen Dot\nbrought me out\none comma 2 comma zero\nokay\nthen the\nshow\nbadge\nDL comma\nand Max equals to 54.\nthen for\nimages\nin there\nshow\nimages\nthe images comma Max\nlike n Max\nthen break\nokay so now let's see some badges so I\nwill write show batch\nchain\ndeal\nit's loading it's loading\nokay\nokay image okay\nso\nthe none\nokay the spelling mistake\nso as you can see here this maybe Robert\nDowney Jr this is Robert Downey Junior\nand different celebrities here\nso\nwe have to do GN in this we will\ngenerate the fake images and will\ngenerate the new images that\ndiscriminator will set the images which\nare real or fake\nokay so now let's use GPU\nlike let's see GPU is available or not\nokay\nso here I will write the\nget\nfault\ndevice\nthen if\nDodge dot Q Dot\ndot is\navailable\nthe return\ndot dot device\nCuda\nokay\nas\nreturn\ndot dot device to CPU\nthen DF\n2 device\ndata from our device\nlike for from this we will move tensors\nto chosen device like okay if\nis instance\nlet's see stars\ndata comma\nlist command double\nreturn\nto\nforeign\nX comma\ndevice\nfor X in data\nreturn\ndata dot to\ndevice\nblocking equals to true\nokay T will be Capital here\nthen I will write class\ndevice\ndata loader\nso here what will we will do we will\nwrap a data loader to move data to our\ndevice so for the DF\ninit function and to self\ncomma TL device\nthen here I will write self\ndot DL equals to DN\nthen self\nDot\ndevice question device\nokay\nso\nhere I will write\nfor the attrition\nso here I have to give to underscore\nhere I will write again self\nso it yield a batch to data after moving\nit to a device\nso for\nfor\nb m\nself dot DL\nthen\nyield\nto device\nthen B comma cell\nthe device\nokay\nand the last one is DF\nlength\nwill write self\nthe\nit will return the number of batches so\nreturn\nlength of\nself dot DL\nokay invalid syntax\nokay not not\nokay so here I will write\ndevice\nas you get\nfault\ndevice\nokay\nthen train\nDL question\ndevice\ndata loader\nchain\nokay\nso uh as we already know what is GN and\nwhat is discriminator and\nyou know generator so let's take again\nGN overview so our generative adversial\nNetwork GN has two parts\nso the generator learns to generate\nplausible data the generator instant\nbecome negative training examples for\nthe for producing impossible results so\nso you have data so what discriminator\nwill do\ndiscriminator will you know decide from\nthe generated data and the real data\nwhich are fake and which are real\nokay this will generator will do\ndiscriminator sorry okay so\ndiscriminator like takes an image as an\ninput and tries to classify it as real\nor generated\nin this sense it's like any other neural\nnetwork so I will use here CNN which\noutputs is a single neural network for\nevery image so\nokay so I hope you know again like what\ndiscriminator is what generator is and\nwhat is like real data it is this okay\nand we will generate the data\nokay fake data and what discriminal will\ndo discriminator will\ncheck whether the data is fake or real\nokay\nso here I will write import\ntorch\nDot and then\nhere I will write this criminator\nequals to Ln Dot\nsequential\nforeign\nso these are some\nso these are some layer okay flight and\nlayer converter layer okay leaky uh\nso here I am setting you know descriptor\nlike 3 into 64 64. okay so here 64 by\n2128 128 by 256 so these are the sizes\nsizes of the images\nokay\nso\nhere discriminator\nbecause you\nto device\ndiscriminator\non my device\nokay\naddress\nokay what's wrong spelling is wrong\nMaybe\nokay so it's saying get this limit is\nnot defined\nokay let me debug\nokay nothing else the spelling was wrong\nso sorry for that\nso let me do for the better visuals\nokay\nso I know I hope you know the generator\nwhat generator network is\nso here what I will do I will set the\nsize latent\nsize equals to\n128\nokay so here\nwe have set this discriminator\nnow what we will do we will set the\ngenerator okay the size is\nlike 3 into 64 64 or 32 128 and so on\nfor all the layers\nso here I am setting for the generator\nthe same I will write here\ngenerator\nto device\ngenerator\ncommon device\nagain the generator is\nokay\nokay\nthen data is defined here\nokay\nnow it's working fine\nso here\nso now what I will do I will do the\ndiscriminator training okay\nso for that I have to write Def\ntrain\ndiscriminator\nreal images\nof the\nokay now we will clear the discriminator\ngradients so opt\nD dot\nzero\ngreat\nokay here we will pass real images\nthrough discriminator\nokay\nso these are the for the real images\nbecause we have to show the all the real\nand the fake images then we'll Shuffle\nthen and we'll find out which is real\nand which is not okay so and now we will\ngenerate the fake images using latent\nforeign\nso now what we will do we will pass the\nfake images through discriminator as we\ndid for the real images\nokay so now we will update discriminator\nweights for that I have to write laws\nequals to\nreal loss\nthen Plus\nfake loss\nokay\nthe loss Dot\nbackward\noption\nreturn\nloss dot item\ncomma\nyeah\ncool\nokay\ncool\nokay\nall right\num\nokay bracket is missing\nclose backward\nand 36.\nokay so here what we did we did the\nwidth pass the real images to\ndiscriminator then generate fake images\nand the same time we pass the fake\nimages through discriminator and the at\nthe end that loss equal to real loss and\nthe fake loss we update the\ndiscriminator bits\nokay so now so this was the\ndiscriminator training now what we will\ndo we will do the generator training\nokay so for that I have to write Def\nfor that after that DF train\ntrain generator\nthen OBT\nG Dot\nzero\nGrant\nso what we are doing here we are\nclearing the generator gradients\nbefore that we did for the same the\ndiscriminator one okay so now we will\ngenerate the fake images\nokay what generator do generator only uh\ngenerates the fake images okay\nso from this prediction\nfrom this prediction what we are doing\nwe are just make trying to fool the\ndiscriminator okay\nso\nso here we will update the generator\nrate so I will write loss Dot\nbackward\nthen I will add opt\nunderscore g dot step\nthen he will add return\nokay let's run it\nso here I will write from\ntorch\nvision\ndot YouTube\nsave\nimage\nand here I will write sample\ndirectory\nbecause you generated\ngenerated\nokay and Os dot me directory\nsample\ndirectory\ncomma\nexist\nokay\ntrue\nokay\nso\nnow what we will do we will save the\nsample data okay so we I have to create\nuh to save samples uh one function\nokay so here what I'm doing we are I'm\nmaking the fake images generating the\nfake images and saving it\nokay\nso moving forward well what I will fix\nthe\nI will fix the latent\nDot\nrandom input\nthen 64.\nsize comma one comma\none comma then device\nquestion device\nthen\nagain save\nsamples\ntwo zero comma fixed\nlatent\nokay save samples is not defined\nit's defined here\nyeah\nso see this is the generated images this\nis the fake image okay\nnow what I will do I will do the full\ntraining Loop for that I have to write\nfrom\ntqdm dot notebook\nimport\ntake you\nand import\nDot\n[Music]\nfunctional\nas f\nlet me keep the spaces\nso\nnow what we will do we will train this\nuh\nwe will do the full training Loop till\nthe 400 Epoch so it will take a\nvery long time so first I will write the\ndefinition\nokay I will Define one uh the function\nokay and then I will get back to you\nso yes what I did uh so this I have set\nthe losses and the scores okay and\nthese are the optimizer some optimizers\nopt you can say Optimizer we are\ncreating\nand here I'm training the uh\ndiscriminator and here I am training the\ngenerator\nokay for the loss\nand here the record of the loss in the\nyou know this course will save\nand this is for the log of\nlosses in this course last batch and for\nthis this is for the generated image\nokay it will save the generated image\nokay we have already created here you\ncan see\nfor the sample image for the saving\nokay now what I will do I will write\npercent\ntime\ntime then LR equals to 0.005\nthe Box\nequals to 400 a box means it will take a\nhuge time\nso\nhistory\nbecause to fit\nbox comma\nokay fit is not defined\nokay I have to run it again\nthis\nokay something random objective zero\nquit\nokay I have to check\nso as you can see it's started running\nso this box will run till 400\nso it will take a long time very long\ntime so I will get back to you after\nthat\nthank you\nso as you can see this is of 1 by 400 so\nit will run to three till 339 okay so it\nwill take a very very long time so it\nwill Define the loss of generated the\nloss of discriminator and the real score\nand the fake score and at the same time\nit's saving the generator images\nokay so it will take a long time and\nthen I will get back to you\nso as you can see here the gns are done\ntill like 400 okay\ntill all the 400 okay so now let's do\nsome losses\ncome on losses\nof the discriminator and the real score\nand the previous course\nquestion history\nso here I will touch\ndot save\nthe generator\nyeah\nthis state\nand let's go\ndirectly path\ncomma\ng dot\nokay\nthen I will write Dodge\nC\nthe discriminator\ndot state\ndirect path\ncomma D dot pth\nso the spelling mistake is there\nyeah so I've read from\nIPython\nyour display\nimport\nimage\nokay\nso here I will write image\nlike what the generator generated the\nimage\nthe dot slash\ngenerated\nslash\nimages\nokay let's see so this is this is the\nfirst image which generated by the\ngenerator okay so same we we have 400 a\nbox so let's see\nso here\nI will check the 100\nimage\nso as you can see 100 images more bit\nclear\nso what if I will check for the like 300\n300 image one it's morbid clear\nokay now let's check the 400 image\nI hope see it is clear so it is these\nare the fake images which are generated\nby the generator to fold the\ndiscriminator to confuse the\ndiscriminator okay\nso now we will\nplot a graph\nwe will protograph for the pocket loss\nin the\nfor the discriminator and the generator\nso for that\nthat's right\nso as you can see this is a\ndiscriminator okay blue one and there is\na generator generator so loss for the\ngenerator is the mode and the loss for\ndiscriminator is less which is very good\nand now let's see the real and fake\nimages\nokay so these are the real images score\nand these are the fake images\nso I hope you understand what is GA and\nhow to do GN with pi dot or python in ml\nso I hope you like this video please\ndon't forget to check the course link\nfrom the description box below okay and\ndon't forget to subscribe to our YouTube\nchannel till then stay safe and keep\nlearning\nhi there if you like this video\nsubscribe to the simply learned YouTube\nchannel and click here to watch similar\nvideos turn it up and get certified\nclick here\n",
  "words": [
    "foreign",
    "today",
    "take",
    "hands",
    "lab",
    "demo",
    "use",
    "gan",
    "native",
    "adversarial",
    "network",
    "image",
    "classification",
    "amazing",
    "videos",
    "like",
    "subscribe",
    "youtube",
    "channel",
    "press",
    "bell",
    "icon",
    "stay",
    "updated",
    "today",
    "session",
    "discuss",
    "gan",
    "moving",
    "ahead",
    "cover",
    "types",
    "models",
    "gm",
    "end",
    "lab",
    "demo",
    "celebrated",
    "face",
    "image",
    "using",
    "gn",
    "let",
    "see",
    "gan",
    "generative",
    "adversarial",
    "networks",
    "introduced",
    "2014",
    "inj",
    "goodfellow",
    "jns",
    "perform",
    "unsupervised",
    "learning",
    "tasks",
    "machine",
    "learning",
    "gns",
    "used",
    "generate",
    "new",
    "examples",
    "possibly",
    "could",
    "drawn",
    "original",
    "data",
    "set",
    "image",
    "gn",
    "database",
    "real",
    "100",
    "rupee",
    "node",
    "generator",
    "neural",
    "network",
    "generates",
    "fake",
    "hundred",
    "rupee",
    "node",
    "discriminator",
    "network",
    "help",
    "identify",
    "real",
    "fake",
    "node",
    "real",
    "fake",
    "images",
    "see",
    "moving",
    "ahead",
    "let",
    "see",
    "generator",
    "generator",
    "gn",
    "neural",
    "network",
    "creates",
    "fake",
    "data",
    "trained",
    "discriminator",
    "learns",
    "generate",
    "plausible",
    "data",
    "generator",
    "examples",
    "instances",
    "become",
    "negative",
    "training",
    "examples",
    "discriminator",
    "see",
    "random",
    "input",
    "generate",
    "new",
    "fake",
    "image",
    "main",
    "aim",
    "generator",
    "make",
    "discriminator",
    "classify",
    "output",
    "real",
    "part",
    "gn",
    "drains",
    "generator",
    "includes",
    "noisy",
    "input",
    "vector",
    "generator",
    "network",
    "transform",
    "random",
    "input",
    "instance",
    "discriminator",
    "network",
    "classifies",
    "generator",
    "data",
    "seeing",
    "generated",
    "let",
    "see",
    "discriminator",
    "discriminator",
    "neural",
    "network",
    "identifies",
    "real",
    "data",
    "fake",
    "data",
    "created",
    "generator",
    "discriminator",
    "training",
    "data",
    "comes",
    "two",
    "sources",
    "real",
    "data",
    "instance",
    "real",
    "pictures",
    "birds",
    "human",
    "currency",
    "nodes",
    "anything",
    "used",
    "riskimeter",
    "positive",
    "sample",
    "training",
    "second",
    "one",
    "fake",
    "data",
    "instance",
    "created",
    "generator",
    "used",
    "negative",
    "examples",
    "training",
    "process",
    "discriminator",
    "decide",
    "real",
    "images",
    "fake",
    "images",
    "generated",
    "generator",
    "discriminator",
    "decide",
    "fake",
    "real",
    "let",
    "move",
    "programming",
    "part",
    "see",
    "use",
    "jan",
    "using",
    "celebrity",
    "face",
    "image",
    "data",
    "set",
    "move",
    "programming",
    "part",
    "let",
    "tell",
    "demand",
    "machine",
    "learning",
    "ai",
    "growing",
    "faster",
    "profession",
    "fact",
    "according",
    "statistic",
    "million",
    "job",
    "opening",
    "field",
    "artificial",
    "intelligence",
    "machine",
    "learning",
    "2023",
    "beat",
    "cow",
    "professional",
    "certificate",
    "program",
    "ai",
    "machine",
    "learning",
    "pardi",
    "university",
    "ibm",
    "course",
    "covers",
    "tools",
    "techniques",
    "like",
    "numpy",
    "pandas",
    "python",
    "along",
    "industry",
    "project",
    "like",
    "social",
    "media",
    "twitter",
    "delivery",
    "service",
    "provider",
    "zomato",
    "transportation",
    "service",
    "provided",
    "uber",
    "many",
    "amazing",
    "projects",
    "choosing",
    "course",
    "get",
    "hired",
    "renowned",
    "companies",
    "like",
    "netflix",
    "amazon",
    "facebook",
    "adobe",
    "many",
    "average",
    "salary",
    "hike",
    "70",
    "percent",
    "waiting",
    "join",
    "professional",
    "certificate",
    "program",
    "ai",
    "machine",
    "learning",
    "excel",
    "career",
    "machine",
    "learning",
    "link",
    "description",
    "box",
    "start",
    "gn",
    "generative",
    "adversarial",
    "networks",
    "okay",
    "first",
    "rename",
    "gan",
    "okay",
    "import",
    "libraries",
    "like",
    "import",
    "os",
    "pi",
    "torch",
    "machine",
    "learning",
    "deep",
    "learning",
    "library",
    "worked",
    "like",
    "neural",
    "networks",
    "add",
    "list",
    "dot",
    "data",
    "report",
    "data",
    "loader",
    "okay",
    "torch",
    "dot",
    "app",
    "set",
    "class",
    "representing",
    "data",
    "set",
    "custom",
    "data",
    "set",
    "inherit",
    "data",
    "set",
    "override",
    "okay",
    "import",
    "data",
    "loader",
    "data",
    "loader",
    "client",
    "application",
    "bulk",
    "import",
    "export",
    "data",
    "use",
    "insert",
    "update",
    "delete",
    "export",
    "like",
    "records",
    "importing",
    "data",
    "data",
    "loader",
    "reads",
    "extract",
    "loads",
    "data",
    "csv",
    "files",
    "like",
    "comma",
    "separated",
    "values",
    "database",
    "connection",
    "say",
    "exporting",
    "data",
    "output",
    "csv",
    "file",
    "okay",
    "moving",
    "forward",
    "dodge",
    "vision",
    "dot",
    "transform",
    "okay",
    "transformer",
    "like",
    "common",
    "image",
    "transformation",
    "available",
    "toss",
    "vision",
    "transformation",
    "module",
    "changed",
    "together",
    "using",
    "compost",
    "transform",
    "classes",
    "function",
    "equivalent",
    "functional",
    "transform",
    "give",
    "fine",
    "grain",
    "control",
    "transformations",
    "one",
    "like",
    "torch",
    "vision",
    "dot",
    "transforms",
    "sorry",
    "data",
    "set",
    "import",
    "image",
    "folder",
    "okay",
    "invalid",
    "syntax",
    "thank",
    "invalid",
    "let",
    "tell",
    "important",
    "okay",
    "yes",
    "okay",
    "dodge",
    "utils",
    "yeah",
    "working",
    "fine",
    "import",
    "data",
    "set",
    "using",
    "celebrity",
    "face",
    "image",
    "okay",
    "provide",
    "data",
    "description",
    "box",
    "worry",
    "okay",
    "download",
    "data",
    "set",
    "directly",
    "path",
    "data",
    "set",
    "five",
    "let",
    "stop",
    "face",
    "image",
    "data",
    "set",
    "foreign",
    "guess",
    "fine",
    "yeah",
    "set",
    "image",
    "size",
    "image",
    "size",
    "batch",
    "size",
    "equals",
    "best",
    "size",
    "equal",
    "256",
    "stats",
    "equals",
    "comma",
    "okay",
    "comma",
    "comma",
    "comma",
    "okay",
    "set",
    "image",
    "size",
    "batch",
    "size",
    "stat",
    "values",
    "train",
    "data",
    "set",
    "write",
    "train",
    "ds",
    "equals",
    "image",
    "folder",
    "data",
    "sorry",
    "data",
    "directory",
    "comma",
    "transform",
    "dot",
    "dot",
    "compose",
    "add",
    "dot",
    "uh",
    "study",
    "size",
    "image",
    "size",
    "okay",
    "repeat",
    "dot",
    "center",
    "crop",
    "center",
    "crop",
    "write",
    "image",
    "size",
    "click",
    "small",
    "music",
    "add",
    "dot",
    "tensor",
    "comma",
    "dot",
    "normalize",
    "stats",
    "okay",
    "write",
    "train",
    "dl",
    "equals",
    "data",
    "loader",
    "train",
    "ideas",
    "press",
    "size",
    "shuffle",
    "true",
    "common",
    "num",
    "workers",
    "two",
    "number",
    "workers",
    "let",
    "pin",
    "memory",
    "okay",
    "system",
    "find",
    "body",
    "specific",
    "user",
    "okay",
    "okay",
    "let",
    "copy",
    "path",
    "let",
    "see",
    "let",
    "run",
    "yeah",
    "working",
    "fine",
    "let",
    "put",
    "dot",
    "torch",
    "vision",
    "dot",
    "utils",
    "import",
    "okay",
    "import",
    "matplotlab",
    "problem",
    "dot",
    "pi",
    "plot",
    "plt",
    "plotlet",
    "torchvision",
    "dot",
    "utils",
    "import",
    "make",
    "grid",
    "used",
    "make",
    "grade",
    "okay",
    "great",
    "know",
    "small",
    "small",
    "boxes",
    "matplotlib",
    "already",
    "know",
    "used",
    "making",
    "charts",
    "different",
    "types",
    "chart",
    "line",
    "chart",
    "bar",
    "chart",
    "pie",
    "chart",
    "okay",
    "let",
    "run",
    "write",
    "make",
    "function",
    "img",
    "dancers",
    "return",
    "img",
    "dancers",
    "stats",
    "run",
    "1",
    "0",
    "plus",
    "zero",
    "negative",
    "okay",
    "let",
    "run",
    "make",
    "new",
    "function",
    "show",
    "images",
    "show",
    "patches",
    "okay",
    "write",
    "show",
    "image",
    "okay",
    "max",
    "equals",
    "simple",
    "figure",
    "axis",
    "equals",
    "plt",
    "dot",
    "subplots",
    "figure",
    "size",
    "10",
    "comma",
    "okay",
    "ax",
    "axis",
    "dot",
    "set",
    "x",
    "takes",
    "ax",
    "dot",
    "set",
    "vertex",
    "okay",
    "ax",
    "dot",
    "sure",
    "image",
    "show",
    "make",
    "grid",
    "norm",
    "general",
    "function",
    "images",
    "dot",
    "detect",
    "max",
    "comma",
    "intro",
    "number",
    "rows",
    "eight",
    "dot",
    "brought",
    "one",
    "comma",
    "2",
    "comma",
    "zero",
    "okay",
    "show",
    "badge",
    "dl",
    "comma",
    "max",
    "equals",
    "images",
    "show",
    "images",
    "images",
    "comma",
    "max",
    "like",
    "n",
    "max",
    "break",
    "okay",
    "let",
    "see",
    "badges",
    "write",
    "show",
    "batch",
    "chain",
    "deal",
    "loading",
    "loading",
    "okay",
    "okay",
    "image",
    "okay",
    "none",
    "okay",
    "spelling",
    "mistake",
    "see",
    "maybe",
    "robert",
    "downey",
    "jr",
    "robert",
    "downey",
    "junior",
    "different",
    "celebrities",
    "gn",
    "generate",
    "fake",
    "images",
    "generate",
    "new",
    "images",
    "discriminator",
    "set",
    "images",
    "real",
    "fake",
    "okay",
    "let",
    "use",
    "gpu",
    "like",
    "let",
    "see",
    "gpu",
    "available",
    "okay",
    "write",
    "get",
    "fault",
    "device",
    "dodge",
    "dot",
    "q",
    "dot",
    "dot",
    "available",
    "return",
    "dot",
    "dot",
    "device",
    "cuda",
    "okay",
    "return",
    "dot",
    "dot",
    "device",
    "cpu",
    "df",
    "2",
    "device",
    "data",
    "device",
    "like",
    "move",
    "tensors",
    "chosen",
    "device",
    "like",
    "okay",
    "instance",
    "let",
    "see",
    "stars",
    "data",
    "comma",
    "list",
    "command",
    "double",
    "return",
    "foreign",
    "x",
    "comma",
    "device",
    "x",
    "data",
    "return",
    "data",
    "dot",
    "device",
    "blocking",
    "equals",
    "true",
    "okay",
    "capital",
    "write",
    "class",
    "device",
    "data",
    "loader",
    "wrap",
    "data",
    "loader",
    "move",
    "data",
    "device",
    "df",
    "init",
    "function",
    "self",
    "comma",
    "tl",
    "device",
    "write",
    "self",
    "dot",
    "dl",
    "equals",
    "dn",
    "self",
    "dot",
    "device",
    "question",
    "device",
    "okay",
    "write",
    "attrition",
    "give",
    "underscore",
    "write",
    "self",
    "yield",
    "batch",
    "data",
    "moving",
    "device",
    "b",
    "self",
    "dot",
    "dl",
    "yield",
    "device",
    "b",
    "comma",
    "cell",
    "device",
    "okay",
    "last",
    "one",
    "df",
    "length",
    "write",
    "self",
    "return",
    "number",
    "batches",
    "return",
    "length",
    "self",
    "dot",
    "dl",
    "okay",
    "invalid",
    "syntax",
    "okay",
    "okay",
    "write",
    "device",
    "get",
    "fault",
    "device",
    "okay",
    "train",
    "dl",
    "question",
    "device",
    "data",
    "loader",
    "chain",
    "okay",
    "uh",
    "already",
    "know",
    "gn",
    "discriminator",
    "know",
    "generator",
    "let",
    "take",
    "gn",
    "overview",
    "generative",
    "adversial",
    "network",
    "gn",
    "two",
    "parts",
    "generator",
    "learns",
    "generate",
    "plausible",
    "data",
    "generator",
    "instant",
    "become",
    "negative",
    "training",
    "examples",
    "producing",
    "impossible",
    "results",
    "data",
    "discriminator",
    "discriminator",
    "know",
    "decide",
    "generated",
    "data",
    "real",
    "data",
    "fake",
    "real",
    "okay",
    "generator",
    "discriminator",
    "sorry",
    "okay",
    "discriminator",
    "like",
    "takes",
    "image",
    "input",
    "tries",
    "classify",
    "real",
    "generated",
    "sense",
    "like",
    "neural",
    "network",
    "use",
    "cnn",
    "outputs",
    "single",
    "neural",
    "network",
    "every",
    "image",
    "okay",
    "hope",
    "know",
    "like",
    "discriminator",
    "generator",
    "like",
    "real",
    "data",
    "okay",
    "generate",
    "data",
    "okay",
    "fake",
    "data",
    "discriminal",
    "discriminator",
    "check",
    "whether",
    "data",
    "fake",
    "real",
    "okay",
    "write",
    "import",
    "torch",
    "dot",
    "write",
    "criminator",
    "equals",
    "ln",
    "dot",
    "sequential",
    "foreign",
    "layer",
    "okay",
    "flight",
    "layer",
    "converter",
    "layer",
    "okay",
    "leaky",
    "uh",
    "setting",
    "know",
    "descriptor",
    "like",
    "3",
    "64",
    "okay",
    "64",
    "2128",
    "128",
    "256",
    "sizes",
    "sizes",
    "images",
    "okay",
    "discriminator",
    "device",
    "discriminator",
    "device",
    "okay",
    "address",
    "okay",
    "wrong",
    "spelling",
    "wrong",
    "maybe",
    "okay",
    "saying",
    "get",
    "limit",
    "defined",
    "okay",
    "let",
    "debug",
    "okay",
    "nothing",
    "else",
    "spelling",
    "wrong",
    "sorry",
    "let",
    "better",
    "visuals",
    "okay",
    "know",
    "hope",
    "know",
    "generator",
    "generator",
    "network",
    "set",
    "size",
    "latent",
    "size",
    "equals",
    "128",
    "okay",
    "set",
    "discriminator",
    "set",
    "generator",
    "okay",
    "size",
    "like",
    "3",
    "64",
    "64",
    "32",
    "128",
    "layers",
    "setting",
    "generator",
    "write",
    "generator",
    "device",
    "generator",
    "common",
    "device",
    "generator",
    "okay",
    "okay",
    "data",
    "defined",
    "okay",
    "working",
    "fine",
    "discriminator",
    "training",
    "okay",
    "write",
    "def",
    "train",
    "discriminator",
    "real",
    "images",
    "okay",
    "clear",
    "discriminator",
    "gradients",
    "opt",
    "dot",
    "zero",
    "great",
    "okay",
    "pass",
    "real",
    "images",
    "discriminator",
    "okay",
    "real",
    "images",
    "show",
    "real",
    "fake",
    "images",
    "shuffle",
    "find",
    "real",
    "okay",
    "generate",
    "fake",
    "images",
    "using",
    "latent",
    "foreign",
    "pass",
    "fake",
    "images",
    "discriminator",
    "real",
    "images",
    "okay",
    "update",
    "discriminator",
    "weights",
    "write",
    "laws",
    "equals",
    "real",
    "loss",
    "plus",
    "fake",
    "loss",
    "okay",
    "loss",
    "dot",
    "backward",
    "option",
    "return",
    "loss",
    "dot",
    "item",
    "comma",
    "yeah",
    "cool",
    "okay",
    "cool",
    "okay",
    "right",
    "um",
    "okay",
    "bracket",
    "missing",
    "close",
    "backward",
    "okay",
    "width",
    "pass",
    "real",
    "images",
    "discriminator",
    "generate",
    "fake",
    "images",
    "time",
    "pass",
    "fake",
    "images",
    "discriminator",
    "end",
    "loss",
    "equal",
    "real",
    "loss",
    "fake",
    "loss",
    "update",
    "discriminator",
    "bits",
    "okay",
    "discriminator",
    "training",
    "generator",
    "training",
    "okay",
    "write",
    "def",
    "df",
    "train",
    "train",
    "generator",
    "obt",
    "g",
    "dot",
    "zero",
    "grant",
    "clearing",
    "generator",
    "gradients",
    "discriminator",
    "one",
    "okay",
    "generate",
    "fake",
    "images",
    "okay",
    "generator",
    "generator",
    "uh",
    "generates",
    "fake",
    "images",
    "okay",
    "prediction",
    "prediction",
    "make",
    "trying",
    "fool",
    "discriminator",
    "okay",
    "update",
    "generator",
    "rate",
    "write",
    "loss",
    "dot",
    "backward",
    "add",
    "opt",
    "underscore",
    "g",
    "dot",
    "step",
    "add",
    "return",
    "okay",
    "let",
    "run",
    "write",
    "torch",
    "vision",
    "dot",
    "youtube",
    "save",
    "image",
    "write",
    "sample",
    "directory",
    "generated",
    "generated",
    "okay",
    "os",
    "dot",
    "directory",
    "sample",
    "directory",
    "comma",
    "exist",
    "okay",
    "true",
    "okay",
    "save",
    "sample",
    "data",
    "okay",
    "create",
    "uh",
    "save",
    "samples",
    "uh",
    "one",
    "function",
    "okay",
    "making",
    "fake",
    "images",
    "generating",
    "fake",
    "images",
    "saving",
    "okay",
    "moving",
    "forward",
    "well",
    "fix",
    "fix",
    "latent",
    "dot",
    "random",
    "input",
    "size",
    "comma",
    "one",
    "comma",
    "one",
    "comma",
    "device",
    "question",
    "device",
    "save",
    "samples",
    "two",
    "zero",
    "comma",
    "fixed",
    "latent",
    "okay",
    "save",
    "samples",
    "defined",
    "defined",
    "yeah",
    "see",
    "generated",
    "images",
    "fake",
    "image",
    "okay",
    "full",
    "training",
    "loop",
    "write",
    "tqdm",
    "dot",
    "notebook",
    "import",
    "take",
    "import",
    "dot",
    "music",
    "functional",
    "f",
    "let",
    "keep",
    "spaces",
    "train",
    "uh",
    "full",
    "training",
    "loop",
    "till",
    "400",
    "epoch",
    "take",
    "long",
    "time",
    "first",
    "write",
    "definition",
    "okay",
    "define",
    "one",
    "uh",
    "function",
    "okay",
    "get",
    "back",
    "yes",
    "uh",
    "set",
    "losses",
    "scores",
    "okay",
    "optimizer",
    "optimizers",
    "opt",
    "say",
    "optimizer",
    "creating",
    "training",
    "uh",
    "discriminator",
    "training",
    "generator",
    "okay",
    "loss",
    "record",
    "loss",
    "know",
    "course",
    "save",
    "log",
    "losses",
    "course",
    "last",
    "batch",
    "generated",
    "image",
    "okay",
    "save",
    "generated",
    "image",
    "okay",
    "already",
    "created",
    "see",
    "sample",
    "image",
    "saving",
    "okay",
    "write",
    "percent",
    "time",
    "time",
    "lr",
    "equals",
    "box",
    "equals",
    "400",
    "box",
    "means",
    "take",
    "huge",
    "time",
    "history",
    "fit",
    "box",
    "comma",
    "okay",
    "fit",
    "defined",
    "okay",
    "run",
    "okay",
    "something",
    "random",
    "objective",
    "zero",
    "quit",
    "okay",
    "check",
    "see",
    "started",
    "running",
    "box",
    "run",
    "till",
    "400",
    "take",
    "long",
    "time",
    "long",
    "time",
    "get",
    "back",
    "thank",
    "see",
    "1",
    "400",
    "run",
    "three",
    "till",
    "339",
    "okay",
    "take",
    "long",
    "time",
    "define",
    "loss",
    "generated",
    "loss",
    "discriminator",
    "real",
    "score",
    "fake",
    "score",
    "time",
    "saving",
    "generator",
    "images",
    "okay",
    "take",
    "long",
    "time",
    "get",
    "back",
    "see",
    "gns",
    "done",
    "till",
    "like",
    "400",
    "okay",
    "till",
    "400",
    "okay",
    "let",
    "losses",
    "come",
    "losses",
    "discriminator",
    "real",
    "score",
    "previous",
    "course",
    "question",
    "history",
    "touch",
    "dot",
    "save",
    "generator",
    "yeah",
    "state",
    "let",
    "go",
    "directly",
    "path",
    "comma",
    "g",
    "dot",
    "okay",
    "write",
    "dodge",
    "c",
    "discriminator",
    "dot",
    "state",
    "direct",
    "path",
    "comma",
    "dot",
    "pth",
    "spelling",
    "mistake",
    "yeah",
    "read",
    "ipython",
    "display",
    "import",
    "image",
    "okay",
    "write",
    "image",
    "like",
    "generator",
    "generated",
    "image",
    "dot",
    "slash",
    "generated",
    "slash",
    "images",
    "okay",
    "let",
    "see",
    "first",
    "image",
    "generated",
    "generator",
    "okay",
    "400",
    "box",
    "let",
    "see",
    "check",
    "100",
    "image",
    "see",
    "100",
    "images",
    "bit",
    "clear",
    "check",
    "like",
    "300",
    "300",
    "image",
    "one",
    "morbid",
    "clear",
    "okay",
    "let",
    "check",
    "400",
    "image",
    "hope",
    "see",
    "clear",
    "fake",
    "images",
    "generated",
    "generator",
    "fold",
    "discriminator",
    "confuse",
    "discriminator",
    "okay",
    "plot",
    "graph",
    "protograph",
    "pocket",
    "loss",
    "discriminator",
    "generator",
    "right",
    "see",
    "discriminator",
    "okay",
    "blue",
    "one",
    "generator",
    "generator",
    "loss",
    "generator",
    "mode",
    "loss",
    "discriminator",
    "less",
    "good",
    "let",
    "see",
    "real",
    "fake",
    "images",
    "okay",
    "real",
    "images",
    "score",
    "fake",
    "images",
    "hope",
    "understand",
    "ga",
    "gn",
    "pi",
    "dot",
    "python",
    "ml",
    "hope",
    "like",
    "video",
    "please",
    "forget",
    "check",
    "course",
    "link",
    "description",
    "box",
    "okay",
    "forget",
    "subscribe",
    "youtube",
    "channel",
    "till",
    "stay",
    "safe",
    "keep",
    "learning",
    "hi",
    "like",
    "video",
    "subscribe",
    "simply",
    "learned",
    "youtube",
    "channel",
    "click",
    "watch",
    "similar",
    "videos",
    "turn",
    "get",
    "certified",
    "click"
  ],
  "keywords": [
    "foreign",
    "take",
    "use",
    "gan",
    "network",
    "image",
    "like",
    "youtube",
    "moving",
    "face",
    "using",
    "gn",
    "let",
    "see",
    "learning",
    "machine",
    "used",
    "generate",
    "new",
    "examples",
    "data",
    "set",
    "real",
    "generator",
    "neural",
    "fake",
    "discriminator",
    "images",
    "negative",
    "training",
    "random",
    "input",
    "make",
    "transform",
    "instance",
    "generated",
    "two",
    "sample",
    "one",
    "move",
    "course",
    "get",
    "box",
    "okay",
    "import",
    "torch",
    "add",
    "dot",
    "loader",
    "update",
    "comma",
    "dodge",
    "vision",
    "function",
    "fine",
    "sorry",
    "yeah",
    "path",
    "size",
    "batch",
    "equals",
    "train",
    "write",
    "directory",
    "uh",
    "dl",
    "run",
    "know",
    "chart",
    "return",
    "zero",
    "show",
    "max",
    "spelling",
    "device",
    "df",
    "self",
    "question",
    "hope",
    "check",
    "64",
    "defined",
    "latent",
    "clear",
    "pass",
    "loss",
    "time",
    "save",
    "till",
    "400",
    "long",
    "losses",
    "score"
  ]
}