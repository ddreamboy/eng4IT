{
  "text": "[Music]\nhello everyone this is janet here from\nedureka and i welcome you all to this\ninteresting session\nwhere we'll be looking into ensemble\nlearning so without any further ado\nlet's take a look at today's agenda\nwe'll start this session by discussing\nwhat exactly is ensemble learning and\nwhy do we need it\nfollowing that i'll be walking you\nthrough various techniques in ensemble\nlearning\nand finally we'll end the session by\nimplementing ensemble learning in our\nmachine learning model\nbefore we begin do consider subscribing\nto our youtube channel to stay updated\non training technologies\nand also if you're looking for online\ntraining certification in machine\nlearning\ncheck out the link given in the\ndescription box below\nalright so let us now understand what\nexactly is ensemble learning\nin the world of statistics and machine\nlearning ensemble learning techniques\nattempts to make performance of a\npredictive model better by improving\ntheir accuracy\nensemble learning is a process using\nwhich multiple machine learning models\nare strategically constructed to solve a\nparticular problem\nthis problem can be of a classification\ntype or of a regression type\nensemble learning models have three\nbasic components\nfirst off we have a data set here data\nis jumbled\nand sent to the machine learning model\nthe mixing of data is referred to as\nsampling\nand we can either perform row sampling\nor a column sampling\nnext we have group of base learners base\nlearners are machine learning models\nthat can either be independent or\ndependent to each other\nhere every base model gives it\nprediction in accordance with the data\nthat is fed to it\nand finally output or the prediction of\nall the base model\nis combined in a final model here the\ndecision is made based on the majority\nvote\nor by looking at their predictions\nweights\nso moving ahead now you might be\nwondering when we already had state of\nthe models like decision tree or svm\nthen why was there a need of ensemble\nlearning well you see\nensemble learning helps improve machine\nlearning results by combining several\nmodels\nthis approach allows a prediction of\nbetter predictive performance compared\nto a single model\nthis is why ensemble methods place a\nfirst in many prestigious machine\nlearning competitions\nsuch as netflix competition kdd 2009 and\nkaggle\nwhat basically i'm trying to say here is\nthat ensembl methods are meta algorithms\nthat combine several machine learning\ntechniques into one predictive model\nin order to decrease variance or by\nimproving the predictions\none of the most commonly or important\nterms used in ensemble learning is a\nbias and variance\nlet us now understand each of them in\ndetail starting off with bias\nbias error is useful to quantify how\nmuch on an\naverage are the predicted value\ndifferent from the actual value\nthe high bias error means that we have\nunderperforming model\nwhich keeps on missing essential trends\nthen we have\nvariance variance on the other side\nquantifies how much of the predictions\nmade on the same observation\ndifferent from each other a high\nvariance model will simply overfit your\ntraining population\nand perform poorly on any observation\nbeyond the training data set\nas you can see over here in the\nfollowing diagram the red spot over here\nrepresents the training data set\nand the blue spot over here represent\nthe testing data set\nokay the perfect model over here we can\nset as low bias and a low variance\nnow as you can see over here in this\nthree charts the under feeding model is\nsomething wherein it does not perform\nwell\neven on a training data set and as you\ncan see over here on the extreme right\nhand side the model has by hearted every\ncomponent\nso the model would perform excellent on\nthe training data set\nbut on a new data set or the test data\nset it will perform poorly\nthe best type of model over here is low\nvariance and low bias\nthis type of model is called as just\nright model\nand what happens over here is that we\nhave some kind of error or noise which\nis present on either side of the\nclassification or a regression task\nokay so now that you know what is bias\nand what is variance\nlet us now move ahead and understand the\nvarious ensemble learning techniques\na quick reminder that i would like to\nsay over here is that it is essential\nfor you to know\nhow decision tree works all right in\norder for you to understand how decision\ntree works you can check out our eduraka\ncontent\nand the link for it can be provided in\nthe description box below\nall right so let us now go ahead and see\nwhat are the different types of ensemble\nmethods\nyou see there are several different\ntypes of ensemble learning models\nand following are the three of the most\npopularly used in the industry\nwe have bagging boosting and stacking\nstacking can also be referred to as\nvoting\nlet us now see each of them in detail so\nlet us now start off by understanding\nbagging based ensemble learning bagging\nis one of the ensemble construction\ntechnique which is also known as\nbootstrap\naggregation bootstrap establishes the\nfoundation of bagging techniques\nyou see bootstrap is sampling techniques\nin which we select an\nobservation out of the population of an\nobservation\nbut the selection is entirely random you\nsee each observation can be chosen from\noriginal population\nso that each observation is equally\nlikely to be selected in each iteration\nof bootstrapping process after the\nbootstrap samples are formed\nseparate models are trained with the\nbootstrap samples\nin real experiments the bootstrap\nsamples are drawn from the training\ndataset\nand sub models are tested using the\ntesting data set\nthe final output prediction is combined\nacross a projection of all sub models\nso as you can see over here we have a\ntraining sample right\nand then we can perform column sampling\nas well as the row sampling\nand each of the samples are individually\nprovided to these classifiers\nthis can also be a regressions okay and\neach of these classifiers are\nindependent of each other\nand whatever the output they give is\nfinally passed on to this ensembl\nclassifier which gives out the final\npredictions over here\nalright so let us now move on to the\nnext type that is voting based ensemble\nlearning\nwe can also call this as stacking you\nsee voting is one of the most\nstraightforward ensemble learning\ntechniques\nin which predictions from multiple\nmodels are combined the model starts off\nwith creating two or more separate\nmodels\nwith the same data set then a voting\nbased ensemble model can be used to wrap\nthe previous models\nand aggregate the predictions of those\nparticular models\nafter voting based ensemble model is\nconstructed it can be used to make\npredictions on a new data\nthe predictions made by the sub models\ncan be assigned weights\nstack aggregation is a technique which\ncan be used to learn how to weight these\npredictions in the best way possible\nokay so as you can see over here we have\ncouple of models like model a model b\nmodel c\nand this model over here can be like\nsomething as simple as linear regression\nor logistic regression so as something\nas complicated as svm decision tree\nrandom forest or whatever model you\nwould like to add okay\nand each of these models will get the\nsame data set okay\nand whatever the output or the\npredictions that have been made\nwhat's gonna happen is this generalized\nmodel over here will try to vote okay\nso if model a and model b are trying to\nsay it belongs to class 1\nand model c is saying it belongs to\nclass 0 what happens is generalized\nmodel will consider\nthe output of a and b because we have\nmaximum votes\nand that particular class would be\nsomething called as prediction okay so\nthis is how stacking works so moving\nahead let us know understand\nboosting based ensemble learning you see\nboosting is a form of a sequential\nlearning technique\nokay the algorithm works by training\nmodel with its entire training set\nand subsequent models are considered by\nfitting the residual values\nor error into an initial model in this\nway boosting attempts to give high\nweightage to those observations that are\npoorly estimated\nby previous models when the sequence of\nthese models are created the predictions\nmade by these models are weighted by the\naccuracy score\nand the resultants are combined to\ncreate a final estimation\nmodels that are typically based on\nboosting can be something like extreme\ngradient boost\ngradient boosting add a boost and many\nmore so as you can see here from the\npicture\nyou know this is a basically a\nsequential model unlike backing or\nvoting where the models were totally\nindependent of each other\nhere the next model or the subsequent\nmodel is dependent upon the previous\nmodel's weight\nthe combinations of these model is going\nto be\nthe final model okay so as you can see\nhere in the first training classifier\nthere are two values over here that is\nin negative side were classified wrong\nand one value here was classified wrong\nnow this thing was passed as a feedback\nover here to this next model\nand as you can see here we have these\ntwo\nobjects or these two in the form of a\ncorrect class but now\nthe problem still remains that we have\nthree more parts over here which are\nwrongly classified and finally over here\nthis part is correctly classified and\nwe have lot of mess over here so as you\ncan see here all of the data points here\nare classified correctly in the final\nmodel\nnow that we have a brief intuition about\neach of these techniques\nlet me now quickly show you how to\nimplement each of these models using\npython\nand also let's see how we can implement\nthem using built-in python library that\nis sklen\nokay so let me quickly jump to my code\neditor here and the code editor that i\nwould be using today is gonna be google\ncollab\nall right so here we are at google\ncollab so now what i'm gonna do is we'll\nstart off by\nworking with backing techniques right so\nlet me quickly give a\nheading here so first off what we'll do\nis we'll\nimport couple of libraries that is from\nsklearn\ndot data sets we will be loading the\niris data set\nlet me quickly get that from scalar dot\ndata set\nload it's going to import\nload ids okay\nand apart from that import pandas\npd then import\nnumpy as np\nso far let's just have this and now\nin order to load our data what we'll do\nis we'll create this data is\nequal to load ids\nand let's hit enter here and let's see\nhow this data would look like\nso as you can see here we have three\ncolumns right and each of these column\nrepresents\na feature so let's see what is this\nfeature here so that will be\nfeature names\nokay first off we have sepal and sepal\nred petal length and petal width\nand let's also see the target names\ntarget names refers to the output\nall right and let's see what this would\nlook like\nso we basically have three classes over\nhere setosa\nversicolor and virginica so now let's\nconvert this into our data frame as of\nnow it's not in a data frame it's in a\nform of a numpy array right\nso let me bring this to our data frame\nso here it will be d is equal to\nso first off we have sepal length right\nso\nlet me copy that or we can also put this\nin a zip format but uh just for the\nsimplicity sake let me\njust copy this so the data over here\nwill be\ndata dot data and we want the first 50\nrows and the first column okay\nso this is for sepal length similarly\nwe're going to do it for petal length\nlet me remove this okay\nlet me give a comma over here fine and\nthe data over here will be\ndata dot data\nand now we're gonna have all the rows\nand this will be two fine\nand now after that we'll have species uh\nspecies over here basically refers to\nthe satoshi or seeker and all that\nso we'll have species\nokay so it'll be np dot array\nbasically i'm going to use list\ncomprehension here for\ni in data dot target\nso if i is greater than 0\nif this is the case then i want that\nparticular class okay so let me quickly\ngive you a brief what i'm doing\nso basically over here we have as you\ncan see we have four features that is\nsepal and sepal weight length and petal\nlength and pedal width right\nbut as we are trying to understand how\nthis thing work i'm not going to take\nthis\nentire data over here all the columns\nokay so instead of that i'll take this\nsepal length\nand petal length and we'll also keep it\nsimple by keeping it as two class\nclassification\nand now if i execute this\nand just put d over here\nso now let me convert this into a data\nframe okay\nso uh it's pretty simple so we'll all we\nneed to do is\nbf that is data frame is equal to pandas\ndot data frame and now we are going to\npass\na variable that is b\nand now if i just put here df\nso as you can see uh we have sepal and\npetal length and species which is equal\nto one\nokay so as you can see here we have\nspecies one and two\nif i wanted i could have changed to\nwhatever i want but yeah we can just\nkeep this for now\nand here one represents versicolor and\nuh two represents virginica all right so\nnow what i'm going to do is if you\nremember how\nbacking works first off we have a data\nset and then\nwhat i'm going to do is for that\nparticular data set we have to randomize\nit and that particular randomized data\nwould be sent for different different\nmodels okay so now we'll try to\nrandomize\nour data or you can also set it as\nshuffle\nso for this it will be like df is equal\nto df.sample\nand we want it to be df dot shape okay\nthe reason why i'm doing df.shape\nis i'm just providing the length over\nhere and if i see df now you'll see that\nit has been shuffled up\nso if you can see here we have all ones\nover here and two's in the next half\nor the next bottom but here you can see\neverything has been shuffled i can also\nsee it from this index values over here\nand now we will create a data set for\ntraining and then we'll also create a\ndata set for test\njust keep in mind that you know we'll\ncreate c\nwe have 50 of class 2 and 50 of class 1.\nso what i'm going to do here is i'll\ncreate a data set df\nunderscore train\nand this should be df dot i log\nand let's say we will take all the\nvalues from 0 to 60\nand i'll be having all the columns out\nof the 60 values we'll just take\nrandom 10 values okay so it'll be sample\n10.\nokay now if i print this df.train or df\nunderscore train\nso you'll see here that you know i get\n10 values\nbut these are randomized if i try to\nrerun this again\nyou know it will be a totally different\nvalue okay so let me\nkind of rerun this so as you can see now\nwe\ninitially it was one one but now it\nchanged so let me do it once again\nso as you can see it changes every time\nso similarly what i'm going to do is\nwe'll do it for test\nso will be df underscore test\nthis will also be equal to so what i'm\ngoing to do is\ni'll just copy this over here and paste\nit\nbut here we don't want the values from\n60 from 0 to 60\ni'll take the values from 61 to all the\nway to 100 okay\nand we want all the rows all right so\nthis is all there is about training and\ntest data set\nand now what i'm going to do is out of\nthis 10 values that is given to us by\ntraining data set\ni'm gonna take five values and i'm gonna\nprovide that as an input okay\nso for this i'll give it as df\nunderscore test test\nor you can this is just a variable name\nso it will be df underscore\ntrain and we'll randomly take 5 values\nand we'll keep the replacement as true\nreplacement as true\nmeans that you know the numbers can\nrepeat we can also have replacement as\nfalse but as of now we'll take\nreplacement as true\nall right so this is great this looks\npretty much great and now what i'm going\nto do is we'll create our x and y\nso x underscore test\nso this will be df underscore tt\ndot i log we want all the columns that\nis five columns\nand except the last one we want all the\ncolumns okay\nso basically we have we want all the\nrows and here\napart from the last column because the\nlast column represents\nour y value that is species right you\ncan also set as dependent variable\nand then i'll put it as values okay and\nsimilarly i'm going to put it for y test\nokay we want all our independent\nvariables and we want the dependent\nvariables just the last one\nokay so it will be -1 and then values\nso that this gives us in the form of a\nnumpy and let me just\ncreate this yeah so now what i'm going\nto do is we have finished the two stages\nfirst off we have if you remember right\nwe have the data stage where in whatever\nthe data we have we'll sample it up\nin the next stage we are supposed to\nprovide whatever the data we have\nto our models and whatever the data\nit goes inside the models would be\nrandom samples\nokay so there will be random samples so\nwhat i'm going to do is i'll just create\na function here\nso let's say def and we'll give the name\nof this function as evaluate\nand what this function accepts is a\nmodel name\nand apart from this model the model over\nhere represents the name of the model or\nthe object name\nand then we obviously have to provide\nthe input data that is x test\nor instead of excess we'll just give it\nas x and then y\nand what this model will do is what this\nfunction will do is it'll just fit\nwe want our x and y data all right\nso to make you understand better what\ni'm going to do is i'm also going to\nplot our model so\np l o t underscore tree\nand we'll plot a model in order to plot\nthis model\nuh we obviously have to import these\nlibraries so let me quickly do that up\nfor you\nso first off we'll have to import from\nsklearn\ndot tree import\ndecision tree right classifier and then\nwe'll also need plot tree\nokay so now we'll also import another\nlibrary that is from\nsklearn dot metrics\nimport now this is basically to see how\nwell our model is performing we can just\nuse accuracy score\nand now to see how our like how the\nvalues\nand the decision tree is being plot we\ncan just use from\nwe have to import this first off we have\nto download this before we do that\nso as this is a third party library we\nhave something called as\npip install ml extend\nall right and let me now execute this up\nokay so this is already present in our\ncode editor here\nso what i'm gonna do is from ml extend\ndot plotting import\nplot decision tree regions right so it\nwill just basically give\nwhere all we have plotted our decision\ntree right so plot decision tree regions\nand let me execute this up okay now\nwe'll come back to our function here\nokay this plot tree would plot whatever\nthe decision tree we have created\nwe want to show our plot so it will be\nplt dot\nshow now to see how our decision tree\nwould look like so we'll have\nplot underscore decision tree regions\nand for this we'll pass our x value y\nvalue\nthe name of our model that is model and\nthen\nwe can also pass something like legends\nso this would be just two and again\nafter this will be plt dot show\nnow let's also see the accuracy okay so\nby any chance if you try to like uh get\nthe predicted value that is wipe red\nso this would be nothing but model dot\npredict\nand whatever the test we have so it's\ngoing to be x test right\nall right just to give you a better\nenhancement what i'll do is\ni will just print out rx print\nthe actual value of y so y\ntest and now\ni would also like to print out the\npredicted value so print\nokay and then finally let's see the\naccuracy so we'll have\nprint accuracy score\nthis should be something like i will\njust use the function\naccuracy score and no will pass out our\nwhite test values\nand the predicted values and finally\nthis would just written\nas the model okay uh it would written as\nthe train model right mot here\nall right so we have to give comma over\nhere\nso the thing is this has to be within\nthe colon and we have to provide a comma\nsimilarly this has to be within this\nand now we'll provide a comma and let's\nexecute this once again\nfantastic so now what we're going to do\nis we are going to pass out\nsome values okay and you're going to\npass out the model or we're going to\ncreate the model and then pass\nx and y values so first off we'll say\nmodel one\nokay so decision tree dt1 or whatever it\nis you can give the name\nand we'll call it as decision tree\nclassifier and this goes here\nso for this we have to pass the x and y\nvalue right so\nwhat i'm gonna do is from here right so\nfrom\nfrom this df dot train data set so if\nyou can see over here\nfrom df dot train data set over here i'm\ngonna call my\nvalues i'll take just random five values\nso it will be\ndf underscore t so it'll be\ndf underscore train\nokay so this thing over here is gonna be\ntest right not train\nand now we're gonna do it for the train\nso let me execute this up okay so now\nwe'll do it for train over here\ndf train will just take out random 10\nvalues or eight values\nthe number of values that you want to\ntake is totally up to you so we'll have\neight\nand replacement will be true okay\nand now what i'm going to do is we need\nthe x and y values so it'll be x\ngreen so this will be df\nunderscore t dot ilock\nokay we want all the independent\nfeatures\nand the dependent features except the\nlast one\ndot values and similarly we'll do it for\ny\nso this would be df underscore t\ndot i lock all the rows\nand then ah just the last column dot\nvalues\nnow we'll just pass this inside our\nevaluate model here\nso what we'll do is we'll just give it\nas bag one\nokay this will be equal to evaluate uh\nthis is the function that we have\ncreated\nand in this function we have to pass our\nthe object of a model so it will be df\nthat i'm going to give\nand now i also will be passing out rx\nstrain\nand white rain okay and let's execute\nthis\noh yeah the reason why i'm getting this\nerror is because\nhere it says decision tree like richer\noh yeah this because over here model dot\nfit\nyeah the reason why we are getting this\nerror is because i'm passing here data\nframe\nit's supposed to be the decision tree\nclassifier right so\nyeah so let me quickly execute this up\nnow\nyeah the reason why we're getting this\nplt over here is because we haven't\nimported matplotlib\nso let me quickly get that import\nmatplotlib dot pipelot\nsplt and let's try to\nexecute this once again uh this\nparticular function\nand also this value here\nso as you can see here our model has\nperfectly predicted\nall the values right so if it says one\nit just means that it's hundred percent\nif you want me to show you that in a\nbetter way what i'm gonna do is i'll\nmultiply this\nover here by 100 okay\nso whatever the values were there all\nthe values were predicted right\nand this is how the decision tree had\nbeen plotted and this is the decision\ntree\nnow what i'm going to do is this is our\nfirst decision tree\nso let me just give here a comment\nnow just like this what i'm gonna do is\ni'm gonna create one more decision tree\nfor this all i'm gonna do is copy this\npart here\ni'm gonna copy the entire thing and\nwe'll just paste it here\nand we'll change the names second tree\nall right so out of 60 samples it can\ntake up any random eight samples\nokay and we'll just change this value\nhere from\nbag one to back two and this everything\nremains the same\nand let's execute this here okay so even\nthis is scoring hundred\nlet's see if our data set is same or not\nso let me just quickly\ngo through this all right so it's highly\nunusual for this to\ngive the same predictions but as we're\nusing decision tree obviously it's one\nof the most powerful\nmodel so yeah it's giving us the correct\npredictions and finally let's come down\nhere\nand this would be like the third tree\nokay so just like this we can confirm\none thing that all the data aren't same\nokay so as you can see here the\npositions of the data have\nchanged so obviously all the data's\naren't same it's just that the values\nhave been predicted correctly right\nso let's try re-running this once again\njust to see if we can get any\nwrong values okay so this is a perfect\nexample\nso as you can see here here we are\ngetting the accuracy as 100\nokay 100 so this because all the values\nhave been corrected perfectly\nand now if you come down to this you can\nsee the accuracy over here it's just 20\nokay that means only one value out of\nall has been predicted correctly\nall right so now this is a good example\nso\nthe predicted value over here or the\noutcome over here is going to be two\nfine and similarly this has given out\na correct prediction let me quickly run\nthis once again\nand as you can see here over here as\nwell we have one value which has been\npredicted wrong\nso this is a good example as you can see\none is hundred percent the other one\nis 8 20 and other one is 80. okay so\nwe have created three individual models\nand now the last step over here is to\nperform aggregation\nso performing aggregation\nyou say aggregation is all about giving\na vote okay\nso let's see what happens over here so\nfor this\nprint so we'll give something like\nprediction\none okay and now what i'm going to do is\nbag one because it's just a model right\nso bag one\ndot predict so let's say we'll predict\nthe test values right so we'll give some\nrandom values so it will be np dot\narray and over here we're going to pass\nout this sepal length\nand whatever the features we have\ndesigned that is separate length and\npetal length\nso let's say let's take some random\nvalue let's say 2.5\nand 4.9 okay\nand now we obviously have to reshape\nthis because we're just passing one\nvalue so it'll be\ndot reshape one comma two\nso this is going to be in the lower case\nit's a small typo that i've done\nokay so this model is gonna predict one\nso now what i'm gonna do is\ni'll just copy this up here and we'll do\nit for all the three bags\nso instead of bag one will give you as\nback two\nand back three all of them will be fed\nwith the same data and let's see what\neach of them will predict\nokay this is great all of the models are\npredicting one that means the final\noutput over here is gonna be one\nas the data set over here is small\nthat's why we are getting this accurate\nvalue\nif the data set was to be pretty huge we\nobviously won't be getting such an\naccurate value\nand apart from that let me quickly\nchange this\ntwo and three okay and if you try to\nrerun this again let's see if you are\nlucky or if you can get one wrong answer\nrerun this from the start so\nyet again we have got all the correct\npredictions okay\nso now what happens is as all the three\nvalues are one\nthe maximum voting would take place so\nthe final answer would be\none now consider if one of them would\nhave to give two\nright and then we have two of them as\none so what will happen is as the\nmaximum number of vote is one\nso the final output would be one so this\nis how backing algorithm works\nso moving ahead let us see another\ntechnique that we have discussed earlier\nthe another technique that we have\ndiscussed earlier was about voting right\nor stacking\nso the next one that we have seen was\nvoting\nor stacking so\nfine so now what we're going to do is\nlet's see another technique that's\nensemble technique that is stacking\nstacking is all about providing\ndifferent kind of models\nand then we'll perform aggregation just\nlike this okay\nso again i'll import let's see various\nlibraries that we can have\nso from sklearn dot neighbors so we'll\nbe using\nk nearest neighbors that is k n\nimport k neighbors classifier\nwe can also have some linear model like\nlogistic regression so from\nsklearn dot linear model\nimport logistic regression\nand apart from that let's say we want\nsomething on nave bass so we can have so\nfrom\nsk learn dot knife bass\nimport or multinomial knife base you can\nalso take gaussian knight base okay\nso multinomial knife base and we can\nalso have gaussian knife base\nand finally we will also take something\nlike decision tree so from sklearn\ndot tree import\ndecision tree classifier all right and\nlet's execute this\nso now we have to create a number of\nmodels that is m1\nso it will be here nearest neighbors\nokay\nclassifier and now we'll also have\nmodel like this m2\nso we'll have logistic regression then\nmodel three we can say we'll have\nmultinomial live base\nthen model four will be something like\nuh gaussian likewise\nand let's say our model 5\nthis would be a decision tree classifier\nokay so we have five models here now in\norder for you to work on decision right\nlike\nif you want to work on voting or\nstacking we have something called as\nvoting classifier so we have to import\nthat so to do that we'll have\nfrom sklearn dot\nand symbol or you can also set ensemble\nimport\nporting classifier okay and now we'll\ncreate a model so\nmodel will be equal to voting classifier\nwe'll call class and now within this we\nare gonna pass\na list of tuples okay so first off we'll\nhave a list\nand now we'll pass tuples so we'll have\nthe first model obviously does knn\nand we'll just pass the name of the\nmodel that is m1\nsimilarly we can do the second model is\nlogistic regression\nso we'll give lr and this would be m2\nlet me change this back to comma and not\ncolon fine\nand now we have the third one as\nmultinomial neighbours so\nmn and we'll give it as m3\nand then we have gaussian knife base gn\nso it will be g4 m4 that's a model 4\nand finally we'll give decision tree\nand this will be model five okay so\nbasically we are trying to pass a list\nof tuples let me give some space so that\nyou understand this\nokay and let me execute this so now to\ntrain our model so we'll have\nmodel dot train\nor it's going to be model outfit right\nso model.fit\nand now we're going to pass our x train\nand y train so let's\nload our data set so as we already have\nour value over here that is iris data\nset so i'm just gonna use that\nso what i'm gonna do is we'll just copy\nthis values here\nso basically for voting we don't have to\nperform randomization\nso i can copy this data frame so let me\njust\nsee whether this works so df we scroll\ndown\nand let's add a cell here and let's see\nwhat this df represents\nokay so this df represents all the\nvalues here right so basically what i\nneed is x test\nso x strain sorry so the x strain over\nhere would be something like\ntf dot ilock fine\ni need all the rows and the number of\ncolumns i need is\nthe first two right so except the last\none i need all and similarly for\nwhite test or white green so this will\nbe\ndf.i lock\nso i need all the rows and just the last\ncall\nokay we also need to import print test\nplate so let me quickly get that as\nwell from sklearn\ndot model selection import\nprint test split okay\nand let's quickly get create an object\nfor that\nso let me scroll down and let me just\ncopy this part here\nokay now instead of x over here i'm just\ngonna pass this value\ndot values and\nsimilarly here let me cut this\nand instead of y we'll just pass this\nvalue here\nokay this looks good now let's execute\nthe code\nand now we'll just have to fit our model\nright so we'll have to do\nx train and then you and white train\nall right so this is basically telling\nus you know what are the various values\nthat this took\nor the hyper parameters that were\ninvolved and now finally we'll see\nthe score that our model have seen so\nfor that we'll do\nmodel dot score and we'll just pass here\nextras and whitest\nso we just need the same value right so\nx train\nand then white train so as you can see\nhere we're getting a 91 percent accuracy\nright\nso if i multiply this by 100 so you'll\nsee we're getting 91 percent accuracy\nand this is on a training data set this\nis something which is expected\nnow let's see how much accuracy we can\nexpect on our test data set so the model\ndot score\nwe have x test and then we also have\nwhite test\nand let's execute this so as you can see\nhere we are getting an amazing score\nthat is 93 percent\nso this means that our model is working\nabsolutely fine\nokay so we do not have overfitting or\nunder fitting conditions over here\nand our model is working perfectly fine\nso this means that you know our model is\nyou know performing very well almost all\nthe values have been predicted fine\nso now that we have seen two of the\npopular ensemble technique that is\nbacking and voting let's now move ahead\nand see\nthe last algorithm that we have\ndiscussed in our slide that is boosting\nso let me quickly come here and give it\na comment\nso this would be boosting\nall right so over here what we're going\nto do is we're going to perform\nor we're going to create this boosting\nalgorithm so\none of the most popular boosting\ntechnique is add a boost classifier\nokay so add a boost algorithm so let's\nnow see how we can implement this using\nsklearn so\nthis is pretty simple and\nstraightforward that is from sklearn\ndot n symbol or ensemble import\nadd a boost and as you are performing\nclassification so it's going to be add a\nboost classifier\nand the thing about adaboost classifier\nis that it performs only\nbinary classification okay so as we\nalready have the data set present over\nhere what i'm going to do is we'll\ncreate a model right\nso we'll say add a boost classifier\nso it'll be a b c and we'll create an\nobject of this\nadd a boost classifier and let's give\nnumber of estimators here that is number\nof models that we want so an estimators\nwould be like\nfour and we'll give it as a random state\nah this would be zero\nand now what i want to do is i'll do abc\ndot fit\nand we'll just pass our x test value or\nsorry x train value and then white train\nvalue\nthe reason why i'm not importing\nexplicitly here is because we have\nalready imported the data set here right\nso it doesn't make sense importing it\nonce again so let me kind of\nfit this all right and now let's predict\nor now let's see how well our\nclassification is working so we'll give\nit as white thread\nthis would be abc dot predict\nand now we'll just pass here x test\nokay and now let's see the score over\nhere\nso we can just say it as abc\ndot score will let's say something like\nx test and white test\nso as you can see here we are getting\nthe value as 93 percent which is pretty\ngood\nand if you want to see how much about\nclassification we have done\nor how many classes have been predicted\nright what we can do is\nwe can use this function here\nthat is accuracy score so\naccuracy score here we're going to pass\nthe actual value that is\nwhite test and the predicted value that\nit will be wipe red\nokay and let's see what would be the\naccuracy here so we're getting the same\naccuracy basically we are\ncalculating almost all the values\ncorrectly all right so this is all there\nis about\nensemble techniques we have discussed\nthree of them that is bagging\nboosting and voting techniques alright\nguys with this we come to the end of a\nsession i hope you enjoyed and learned\nsomething new\nif you have any further queries please\ndo mention them in the comment box below\nuntil next time good bye and take care i\nhope you have enjoyed listening to this\nvideo\nplease be kind enough to like it and you\ncan comment\nany of your doubts and queries and we\nwill reply them\nat the earliest do look out for more\nvideos in our playlist\nand subscribe to edureka channel to\nlearn more\nhappy learning\nyou\n",
  "words": [
    "music",
    "hello",
    "everyone",
    "janet",
    "edureka",
    "welcome",
    "interesting",
    "session",
    "looking",
    "ensemble",
    "learning",
    "without",
    "ado",
    "let",
    "take",
    "look",
    "today",
    "agenda",
    "start",
    "session",
    "discussing",
    "exactly",
    "ensemble",
    "learning",
    "need",
    "following",
    "walking",
    "various",
    "techniques",
    "ensemble",
    "learning",
    "finally",
    "end",
    "session",
    "implementing",
    "ensemble",
    "learning",
    "machine",
    "learning",
    "model",
    "begin",
    "consider",
    "subscribing",
    "youtube",
    "channel",
    "stay",
    "updated",
    "training",
    "technologies",
    "also",
    "looking",
    "online",
    "training",
    "certification",
    "machine",
    "learning",
    "check",
    "link",
    "given",
    "description",
    "box",
    "alright",
    "let",
    "us",
    "understand",
    "exactly",
    "ensemble",
    "learning",
    "world",
    "statistics",
    "machine",
    "learning",
    "ensemble",
    "learning",
    "techniques",
    "attempts",
    "make",
    "performance",
    "predictive",
    "model",
    "better",
    "improving",
    "accuracy",
    "ensemble",
    "learning",
    "process",
    "using",
    "multiple",
    "machine",
    "learning",
    "models",
    "strategically",
    "constructed",
    "solve",
    "particular",
    "problem",
    "problem",
    "classification",
    "type",
    "regression",
    "type",
    "ensemble",
    "learning",
    "models",
    "three",
    "basic",
    "components",
    "first",
    "data",
    "set",
    "data",
    "jumbled",
    "sent",
    "machine",
    "learning",
    "model",
    "mixing",
    "data",
    "referred",
    "sampling",
    "either",
    "perform",
    "row",
    "sampling",
    "column",
    "sampling",
    "next",
    "group",
    "base",
    "learners",
    "base",
    "learners",
    "machine",
    "learning",
    "models",
    "either",
    "independent",
    "dependent",
    "every",
    "base",
    "model",
    "gives",
    "prediction",
    "accordance",
    "data",
    "fed",
    "finally",
    "output",
    "prediction",
    "base",
    "model",
    "combined",
    "final",
    "model",
    "decision",
    "made",
    "based",
    "majority",
    "vote",
    "looking",
    "predictions",
    "weights",
    "moving",
    "ahead",
    "might",
    "wondering",
    "already",
    "state",
    "models",
    "like",
    "decision",
    "tree",
    "svm",
    "need",
    "ensemble",
    "learning",
    "well",
    "see",
    "ensemble",
    "learning",
    "helps",
    "improve",
    "machine",
    "learning",
    "results",
    "combining",
    "several",
    "models",
    "approach",
    "allows",
    "prediction",
    "better",
    "predictive",
    "performance",
    "compared",
    "single",
    "model",
    "ensemble",
    "methods",
    "place",
    "first",
    "many",
    "prestigious",
    "machine",
    "learning",
    "competitions",
    "netflix",
    "competition",
    "kdd",
    "2009",
    "kaggle",
    "basically",
    "trying",
    "say",
    "ensembl",
    "methods",
    "meta",
    "algorithms",
    "combine",
    "several",
    "machine",
    "learning",
    "techniques",
    "one",
    "predictive",
    "model",
    "order",
    "decrease",
    "variance",
    "improving",
    "predictions",
    "one",
    "commonly",
    "important",
    "terms",
    "used",
    "ensemble",
    "learning",
    "bias",
    "variance",
    "let",
    "us",
    "understand",
    "detail",
    "starting",
    "bias",
    "bias",
    "error",
    "useful",
    "quantify",
    "much",
    "average",
    "predicted",
    "value",
    "different",
    "actual",
    "value",
    "high",
    "bias",
    "error",
    "means",
    "underperforming",
    "model",
    "keeps",
    "missing",
    "essential",
    "trends",
    "variance",
    "variance",
    "side",
    "quantifies",
    "much",
    "predictions",
    "made",
    "observation",
    "different",
    "high",
    "variance",
    "model",
    "simply",
    "overfit",
    "training",
    "population",
    "perform",
    "poorly",
    "observation",
    "beyond",
    "training",
    "data",
    "set",
    "see",
    "following",
    "diagram",
    "red",
    "spot",
    "represents",
    "training",
    "data",
    "set",
    "blue",
    "spot",
    "represent",
    "testing",
    "data",
    "set",
    "okay",
    "perfect",
    "model",
    "set",
    "low",
    "bias",
    "low",
    "variance",
    "see",
    "three",
    "charts",
    "feeding",
    "model",
    "something",
    "wherein",
    "perform",
    "well",
    "even",
    "training",
    "data",
    "set",
    "see",
    "extreme",
    "right",
    "hand",
    "side",
    "model",
    "hearted",
    "every",
    "component",
    "model",
    "would",
    "perform",
    "excellent",
    "training",
    "data",
    "set",
    "new",
    "data",
    "set",
    "test",
    "data",
    "set",
    "perform",
    "poorly",
    "best",
    "type",
    "model",
    "low",
    "variance",
    "low",
    "bias",
    "type",
    "model",
    "called",
    "right",
    "model",
    "happens",
    "kind",
    "error",
    "noise",
    "present",
    "either",
    "side",
    "classification",
    "regression",
    "task",
    "okay",
    "know",
    "bias",
    "variance",
    "let",
    "us",
    "move",
    "ahead",
    "understand",
    "various",
    "ensemble",
    "learning",
    "techniques",
    "quick",
    "reminder",
    "would",
    "like",
    "say",
    "essential",
    "know",
    "decision",
    "tree",
    "works",
    "right",
    "order",
    "understand",
    "decision",
    "tree",
    "works",
    "check",
    "eduraka",
    "content",
    "link",
    "provided",
    "description",
    "box",
    "right",
    "let",
    "us",
    "go",
    "ahead",
    "see",
    "different",
    "types",
    "ensemble",
    "methods",
    "see",
    "several",
    "different",
    "types",
    "ensemble",
    "learning",
    "models",
    "following",
    "three",
    "popularly",
    "used",
    "industry",
    "bagging",
    "boosting",
    "stacking",
    "stacking",
    "also",
    "referred",
    "voting",
    "let",
    "us",
    "see",
    "detail",
    "let",
    "us",
    "start",
    "understanding",
    "bagging",
    "based",
    "ensemble",
    "learning",
    "bagging",
    "one",
    "ensemble",
    "construction",
    "technique",
    "also",
    "known",
    "bootstrap",
    "aggregation",
    "bootstrap",
    "establishes",
    "foundation",
    "bagging",
    "techniques",
    "see",
    "bootstrap",
    "sampling",
    "techniques",
    "select",
    "observation",
    "population",
    "observation",
    "selection",
    "entirely",
    "random",
    "see",
    "observation",
    "chosen",
    "original",
    "population",
    "observation",
    "equally",
    "likely",
    "selected",
    "iteration",
    "bootstrapping",
    "process",
    "bootstrap",
    "samples",
    "formed",
    "separate",
    "models",
    "trained",
    "bootstrap",
    "samples",
    "real",
    "experiments",
    "bootstrap",
    "samples",
    "drawn",
    "training",
    "dataset",
    "sub",
    "models",
    "tested",
    "using",
    "testing",
    "data",
    "set",
    "final",
    "output",
    "prediction",
    "combined",
    "across",
    "projection",
    "sub",
    "models",
    "see",
    "training",
    "sample",
    "right",
    "perform",
    "column",
    "sampling",
    "well",
    "row",
    "sampling",
    "samples",
    "individually",
    "provided",
    "classifiers",
    "also",
    "regressions",
    "okay",
    "classifiers",
    "independent",
    "whatever",
    "output",
    "give",
    "finally",
    "passed",
    "ensembl",
    "classifier",
    "gives",
    "final",
    "predictions",
    "alright",
    "let",
    "us",
    "move",
    "next",
    "type",
    "voting",
    "based",
    "ensemble",
    "learning",
    "also",
    "call",
    "stacking",
    "see",
    "voting",
    "one",
    "straightforward",
    "ensemble",
    "learning",
    "techniques",
    "predictions",
    "multiple",
    "models",
    "combined",
    "model",
    "starts",
    "creating",
    "two",
    "separate",
    "models",
    "data",
    "set",
    "voting",
    "based",
    "ensemble",
    "model",
    "used",
    "wrap",
    "previous",
    "models",
    "aggregate",
    "predictions",
    "particular",
    "models",
    "voting",
    "based",
    "ensemble",
    "model",
    "constructed",
    "used",
    "make",
    "predictions",
    "new",
    "data",
    "predictions",
    "made",
    "sub",
    "models",
    "assigned",
    "weights",
    "stack",
    "aggregation",
    "technique",
    "used",
    "learn",
    "weight",
    "predictions",
    "best",
    "way",
    "possible",
    "okay",
    "see",
    "couple",
    "models",
    "like",
    "model",
    "model",
    "b",
    "model",
    "c",
    "model",
    "like",
    "something",
    "simple",
    "linear",
    "regression",
    "logistic",
    "regression",
    "something",
    "complicated",
    "svm",
    "decision",
    "tree",
    "random",
    "forest",
    "whatever",
    "model",
    "would",
    "like",
    "add",
    "okay",
    "models",
    "get",
    "data",
    "set",
    "okay",
    "whatever",
    "output",
    "predictions",
    "made",
    "gon",
    "na",
    "happen",
    "generalized",
    "model",
    "try",
    "vote",
    "okay",
    "model",
    "model",
    "b",
    "trying",
    "say",
    "belongs",
    "class",
    "1",
    "model",
    "c",
    "saying",
    "belongs",
    "class",
    "0",
    "happens",
    "generalized",
    "model",
    "consider",
    "output",
    "b",
    "maximum",
    "votes",
    "particular",
    "class",
    "would",
    "something",
    "called",
    "prediction",
    "okay",
    "stacking",
    "works",
    "moving",
    "ahead",
    "let",
    "us",
    "know",
    "understand",
    "boosting",
    "based",
    "ensemble",
    "learning",
    "see",
    "boosting",
    "form",
    "sequential",
    "learning",
    "technique",
    "okay",
    "algorithm",
    "works",
    "training",
    "model",
    "entire",
    "training",
    "set",
    "subsequent",
    "models",
    "considered",
    "fitting",
    "residual",
    "values",
    "error",
    "initial",
    "model",
    "way",
    "boosting",
    "attempts",
    "give",
    "high",
    "weightage",
    "observations",
    "poorly",
    "estimated",
    "previous",
    "models",
    "sequence",
    "models",
    "created",
    "predictions",
    "made",
    "models",
    "weighted",
    "accuracy",
    "score",
    "resultants",
    "combined",
    "create",
    "final",
    "estimation",
    "models",
    "typically",
    "based",
    "boosting",
    "something",
    "like",
    "extreme",
    "gradient",
    "boost",
    "gradient",
    "boosting",
    "add",
    "boost",
    "many",
    "see",
    "picture",
    "know",
    "basically",
    "sequential",
    "model",
    "unlike",
    "backing",
    "voting",
    "models",
    "totally",
    "independent",
    "next",
    "model",
    "subsequent",
    "model",
    "dependent",
    "upon",
    "previous",
    "model",
    "weight",
    "combinations",
    "model",
    "going",
    "final",
    "model",
    "okay",
    "see",
    "first",
    "training",
    "classifier",
    "two",
    "values",
    "negative",
    "side",
    "classified",
    "wrong",
    "one",
    "value",
    "classified",
    "wrong",
    "thing",
    "passed",
    "feedback",
    "next",
    "model",
    "see",
    "two",
    "objects",
    "two",
    "form",
    "correct",
    "class",
    "problem",
    "still",
    "remains",
    "three",
    "parts",
    "wrongly",
    "classified",
    "finally",
    "part",
    "correctly",
    "classified",
    "lot",
    "mess",
    "see",
    "data",
    "points",
    "classified",
    "correctly",
    "final",
    "model",
    "brief",
    "intuition",
    "techniques",
    "let",
    "quickly",
    "show",
    "implement",
    "models",
    "using",
    "python",
    "also",
    "let",
    "see",
    "implement",
    "using",
    "python",
    "library",
    "sklen",
    "okay",
    "let",
    "quickly",
    "jump",
    "code",
    "editor",
    "code",
    "editor",
    "would",
    "using",
    "today",
    "gon",
    "na",
    "google",
    "collab",
    "right",
    "google",
    "collab",
    "gon",
    "na",
    "start",
    "working",
    "backing",
    "techniques",
    "right",
    "let",
    "quickly",
    "give",
    "heading",
    "first",
    "import",
    "couple",
    "libraries",
    "sklearn",
    "dot",
    "data",
    "sets",
    "loading",
    "iris",
    "data",
    "set",
    "let",
    "quickly",
    "get",
    "scalar",
    "dot",
    "data",
    "set",
    "load",
    "going",
    "import",
    "load",
    "ids",
    "okay",
    "apart",
    "import",
    "pandas",
    "pd",
    "import",
    "numpy",
    "np",
    "far",
    "let",
    "order",
    "load",
    "data",
    "create",
    "data",
    "equal",
    "load",
    "ids",
    "let",
    "hit",
    "enter",
    "let",
    "see",
    "data",
    "would",
    "look",
    "like",
    "see",
    "three",
    "columns",
    "right",
    "column",
    "represents",
    "feature",
    "let",
    "see",
    "feature",
    "feature",
    "names",
    "okay",
    "first",
    "sepal",
    "sepal",
    "red",
    "petal",
    "length",
    "petal",
    "width",
    "let",
    "also",
    "see",
    "target",
    "names",
    "target",
    "names",
    "refers",
    "output",
    "right",
    "let",
    "see",
    "would",
    "look",
    "like",
    "basically",
    "three",
    "classes",
    "setosa",
    "versicolor",
    "virginica",
    "let",
    "convert",
    "data",
    "frame",
    "data",
    "frame",
    "form",
    "numpy",
    "array",
    "right",
    "let",
    "bring",
    "data",
    "frame",
    "equal",
    "first",
    "sepal",
    "length",
    "right",
    "let",
    "copy",
    "also",
    "put",
    "zip",
    "format",
    "uh",
    "simplicity",
    "sake",
    "let",
    "copy",
    "data",
    "data",
    "dot",
    "data",
    "want",
    "first",
    "50",
    "rows",
    "first",
    "column",
    "okay",
    "sepal",
    "length",
    "similarly",
    "going",
    "petal",
    "length",
    "let",
    "remove",
    "okay",
    "let",
    "give",
    "comma",
    "fine",
    "data",
    "data",
    "dot",
    "data",
    "gon",
    "na",
    "rows",
    "two",
    "fine",
    "species",
    "uh",
    "species",
    "basically",
    "refers",
    "satoshi",
    "seeker",
    "species",
    "okay",
    "np",
    "dot",
    "array",
    "basically",
    "going",
    "use",
    "list",
    "comprehension",
    "data",
    "dot",
    "target",
    "greater",
    "0",
    "case",
    "want",
    "particular",
    "class",
    "okay",
    "let",
    "quickly",
    "give",
    "brief",
    "basically",
    "see",
    "four",
    "features",
    "sepal",
    "sepal",
    "weight",
    "length",
    "petal",
    "length",
    "pedal",
    "width",
    "right",
    "trying",
    "understand",
    "thing",
    "work",
    "going",
    "take",
    "entire",
    "data",
    "columns",
    "okay",
    "instead",
    "take",
    "sepal",
    "length",
    "petal",
    "length",
    "also",
    "keep",
    "simple",
    "keeping",
    "two",
    "class",
    "classification",
    "execute",
    "put",
    "let",
    "convert",
    "data",
    "frame",
    "okay",
    "uh",
    "pretty",
    "simple",
    "need",
    "bf",
    "data",
    "frame",
    "equal",
    "pandas",
    "dot",
    "data",
    "frame",
    "going",
    "pass",
    "variable",
    "b",
    "put",
    "df",
    "see",
    "uh",
    "sepal",
    "petal",
    "length",
    "species",
    "equal",
    "one",
    "okay",
    "see",
    "species",
    "one",
    "two",
    "wanted",
    "could",
    "changed",
    "whatever",
    "want",
    "yeah",
    "keep",
    "one",
    "represents",
    "versicolor",
    "uh",
    "two",
    "represents",
    "virginica",
    "right",
    "going",
    "remember",
    "backing",
    "works",
    "first",
    "data",
    "set",
    "going",
    "particular",
    "data",
    "set",
    "randomize",
    "particular",
    "randomized",
    "data",
    "would",
    "sent",
    "different",
    "different",
    "models",
    "okay",
    "try",
    "randomize",
    "data",
    "also",
    "set",
    "shuffle",
    "like",
    "df",
    "equal",
    "want",
    "df",
    "dot",
    "shape",
    "okay",
    "reason",
    "providing",
    "length",
    "see",
    "df",
    "see",
    "shuffled",
    "see",
    "ones",
    "two",
    "next",
    "half",
    "next",
    "bottom",
    "see",
    "everything",
    "shuffled",
    "also",
    "see",
    "index",
    "values",
    "create",
    "data",
    "set",
    "training",
    "also",
    "create",
    "data",
    "set",
    "test",
    "keep",
    "mind",
    "know",
    "create",
    "c",
    "50",
    "class",
    "2",
    "50",
    "class",
    "going",
    "create",
    "data",
    "set",
    "df",
    "underscore",
    "train",
    "df",
    "dot",
    "log",
    "let",
    "say",
    "take",
    "values",
    "0",
    "60",
    "columns",
    "60",
    "values",
    "take",
    "random",
    "10",
    "values",
    "okay",
    "sample",
    "okay",
    "print",
    "df",
    "underscore",
    "train",
    "see",
    "know",
    "get",
    "10",
    "values",
    "randomized",
    "try",
    "rerun",
    "know",
    "totally",
    "different",
    "value",
    "okay",
    "let",
    "kind",
    "rerun",
    "see",
    "initially",
    "one",
    "one",
    "changed",
    "let",
    "see",
    "changes",
    "every",
    "time",
    "similarly",
    "going",
    "test",
    "df",
    "underscore",
    "test",
    "also",
    "equal",
    "going",
    "copy",
    "paste",
    "want",
    "values",
    "60",
    "0",
    "60",
    "take",
    "values",
    "61",
    "way",
    "100",
    "okay",
    "want",
    "rows",
    "right",
    "training",
    "test",
    "data",
    "set",
    "going",
    "10",
    "values",
    "given",
    "us",
    "training",
    "data",
    "set",
    "gon",
    "na",
    "take",
    "five",
    "values",
    "gon",
    "na",
    "provide",
    "input",
    "okay",
    "give",
    "df",
    "underscore",
    "test",
    "test",
    "variable",
    "name",
    "df",
    "underscore",
    "train",
    "randomly",
    "take",
    "5",
    "values",
    "keep",
    "replacement",
    "true",
    "replacement",
    "true",
    "means",
    "know",
    "numbers",
    "repeat",
    "also",
    "replacement",
    "false",
    "take",
    "replacement",
    "true",
    "right",
    "great",
    "looks",
    "pretty",
    "much",
    "great",
    "going",
    "create",
    "x",
    "x",
    "underscore",
    "test",
    "df",
    "underscore",
    "tt",
    "dot",
    "log",
    "want",
    "columns",
    "five",
    "columns",
    "except",
    "last",
    "one",
    "want",
    "columns",
    "okay",
    "basically",
    "want",
    "rows",
    "apart",
    "last",
    "column",
    "last",
    "column",
    "represents",
    "value",
    "species",
    "right",
    "also",
    "set",
    "dependent",
    "variable",
    "put",
    "values",
    "okay",
    "similarly",
    "going",
    "put",
    "test",
    "okay",
    "want",
    "independent",
    "variables",
    "want",
    "dependent",
    "variables",
    "last",
    "one",
    "okay",
    "values",
    "gives",
    "us",
    "form",
    "numpy",
    "let",
    "create",
    "yeah",
    "going",
    "finished",
    "two",
    "stages",
    "first",
    "remember",
    "right",
    "data",
    "stage",
    "whatever",
    "data",
    "sample",
    "next",
    "stage",
    "supposed",
    "provide",
    "whatever",
    "data",
    "models",
    "whatever",
    "data",
    "goes",
    "inside",
    "models",
    "would",
    "random",
    "samples",
    "okay",
    "random",
    "samples",
    "going",
    "create",
    "function",
    "let",
    "say",
    "def",
    "give",
    "name",
    "function",
    "evaluate",
    "function",
    "accepts",
    "model",
    "name",
    "apart",
    "model",
    "model",
    "represents",
    "name",
    "model",
    "object",
    "name",
    "obviously",
    "provide",
    "input",
    "data",
    "x",
    "test",
    "instead",
    "excess",
    "give",
    "x",
    "model",
    "function",
    "fit",
    "want",
    "x",
    "data",
    "right",
    "make",
    "understand",
    "better",
    "going",
    "also",
    "going",
    "plot",
    "model",
    "p",
    "l",
    "underscore",
    "tree",
    "plot",
    "model",
    "order",
    "plot",
    "model",
    "uh",
    "obviously",
    "import",
    "libraries",
    "let",
    "quickly",
    "first",
    "import",
    "sklearn",
    "dot",
    "tree",
    "import",
    "decision",
    "tree",
    "right",
    "classifier",
    "also",
    "need",
    "plot",
    "tree",
    "okay",
    "also",
    "import",
    "another",
    "library",
    "sklearn",
    "dot",
    "metrics",
    "import",
    "basically",
    "see",
    "well",
    "model",
    "performing",
    "use",
    "accuracy",
    "score",
    "see",
    "like",
    "values",
    "decision",
    "tree",
    "plot",
    "use",
    "import",
    "first",
    "download",
    "third",
    "party",
    "library",
    "something",
    "called",
    "pip",
    "install",
    "ml",
    "extend",
    "right",
    "let",
    "execute",
    "okay",
    "already",
    "present",
    "code",
    "editor",
    "gon",
    "na",
    "ml",
    "extend",
    "dot",
    "plotting",
    "import",
    "plot",
    "decision",
    "tree",
    "regions",
    "right",
    "basically",
    "give",
    "plotted",
    "decision",
    "tree",
    "right",
    "plot",
    "decision",
    "tree",
    "regions",
    "let",
    "execute",
    "okay",
    "come",
    "back",
    "function",
    "okay",
    "plot",
    "tree",
    "would",
    "plot",
    "whatever",
    "decision",
    "tree",
    "created",
    "want",
    "show",
    "plot",
    "plt",
    "dot",
    "show",
    "see",
    "decision",
    "tree",
    "would",
    "look",
    "like",
    "plot",
    "underscore",
    "decision",
    "tree",
    "regions",
    "pass",
    "x",
    "value",
    "value",
    "name",
    "model",
    "model",
    "also",
    "pass",
    "something",
    "like",
    "legends",
    "would",
    "two",
    "plt",
    "dot",
    "show",
    "let",
    "also",
    "see",
    "accuracy",
    "okay",
    "chance",
    "try",
    "like",
    "uh",
    "get",
    "predicted",
    "value",
    "wipe",
    "red",
    "would",
    "nothing",
    "model",
    "dot",
    "predict",
    "whatever",
    "test",
    "going",
    "x",
    "test",
    "right",
    "right",
    "give",
    "better",
    "enhancement",
    "print",
    "rx",
    "print",
    "actual",
    "value",
    "test",
    "would",
    "also",
    "like",
    "print",
    "predicted",
    "value",
    "print",
    "okay",
    "finally",
    "let",
    "see",
    "accuracy",
    "print",
    "accuracy",
    "score",
    "something",
    "like",
    "use",
    "function",
    "accuracy",
    "score",
    "pass",
    "white",
    "test",
    "values",
    "predicted",
    "values",
    "finally",
    "would",
    "written",
    "model",
    "okay",
    "uh",
    "would",
    "written",
    "train",
    "model",
    "right",
    "mot",
    "right",
    "give",
    "comma",
    "thing",
    "within",
    "colon",
    "provide",
    "comma",
    "similarly",
    "within",
    "provide",
    "comma",
    "let",
    "execute",
    "fantastic",
    "going",
    "going",
    "pass",
    "values",
    "okay",
    "going",
    "pass",
    "model",
    "going",
    "create",
    "model",
    "pass",
    "x",
    "values",
    "first",
    "say",
    "model",
    "one",
    "okay",
    "decision",
    "tree",
    "dt1",
    "whatever",
    "give",
    "name",
    "call",
    "decision",
    "tree",
    "classifier",
    "goes",
    "pass",
    "x",
    "value",
    "right",
    "gon",
    "na",
    "right",
    "df",
    "dot",
    "train",
    "data",
    "set",
    "see",
    "df",
    "dot",
    "train",
    "data",
    "set",
    "gon",
    "na",
    "call",
    "values",
    "take",
    "random",
    "five",
    "values",
    "df",
    "underscore",
    "df",
    "underscore",
    "train",
    "okay",
    "thing",
    "gon",
    "na",
    "test",
    "right",
    "train",
    "gon",
    "na",
    "train",
    "let",
    "execute",
    "okay",
    "train",
    "df",
    "train",
    "take",
    "random",
    "10",
    "values",
    "eight",
    "values",
    "number",
    "values",
    "want",
    "take",
    "totally",
    "eight",
    "replacement",
    "true",
    "okay",
    "going",
    "need",
    "x",
    "values",
    "x",
    "green",
    "df",
    "underscore",
    "dot",
    "ilock",
    "okay",
    "want",
    "independent",
    "features",
    "dependent",
    "features",
    "except",
    "last",
    "one",
    "dot",
    "values",
    "similarly",
    "would",
    "df",
    "underscore",
    "dot",
    "lock",
    "rows",
    "ah",
    "last",
    "column",
    "dot",
    "values",
    "pass",
    "inside",
    "evaluate",
    "model",
    "give",
    "bag",
    "one",
    "okay",
    "equal",
    "evaluate",
    "uh",
    "function",
    "created",
    "function",
    "pass",
    "object",
    "model",
    "df",
    "going",
    "give",
    "also",
    "passing",
    "rx",
    "strain",
    "white",
    "rain",
    "okay",
    "let",
    "execute",
    "oh",
    "yeah",
    "reason",
    "getting",
    "error",
    "says",
    "decision",
    "tree",
    "like",
    "richer",
    "oh",
    "yeah",
    "model",
    "dot",
    "fit",
    "yeah",
    "reason",
    "getting",
    "error",
    "passing",
    "data",
    "frame",
    "supposed",
    "decision",
    "tree",
    "classifier",
    "right",
    "yeah",
    "let",
    "quickly",
    "execute",
    "yeah",
    "reason",
    "getting",
    "plt",
    "imported",
    "matplotlib",
    "let",
    "quickly",
    "get",
    "import",
    "matplotlib",
    "dot",
    "pipelot",
    "splt",
    "let",
    "try",
    "execute",
    "uh",
    "particular",
    "function",
    "also",
    "value",
    "see",
    "model",
    "perfectly",
    "predicted",
    "values",
    "right",
    "says",
    "one",
    "means",
    "hundred",
    "percent",
    "want",
    "show",
    "better",
    "way",
    "gon",
    "na",
    "multiply",
    "100",
    "okay",
    "whatever",
    "values",
    "values",
    "predicted",
    "right",
    "decision",
    "tree",
    "plotted",
    "decision",
    "tree",
    "going",
    "first",
    "decision",
    "tree",
    "let",
    "give",
    "comment",
    "like",
    "gon",
    "na",
    "gon",
    "na",
    "create",
    "one",
    "decision",
    "tree",
    "gon",
    "na",
    "copy",
    "part",
    "gon",
    "na",
    "copy",
    "entire",
    "thing",
    "paste",
    "change",
    "names",
    "second",
    "tree",
    "right",
    "60",
    "samples",
    "take",
    "random",
    "eight",
    "samples",
    "okay",
    "change",
    "value",
    "bag",
    "one",
    "back",
    "two",
    "everything",
    "remains",
    "let",
    "execute",
    "okay",
    "even",
    "scoring",
    "hundred",
    "let",
    "see",
    "data",
    "set",
    "let",
    "quickly",
    "go",
    "right",
    "highly",
    "unusual",
    "give",
    "predictions",
    "using",
    "decision",
    "tree",
    "obviously",
    "one",
    "powerful",
    "model",
    "yeah",
    "giving",
    "us",
    "correct",
    "predictions",
    "finally",
    "let",
    "come",
    "would",
    "like",
    "third",
    "tree",
    "okay",
    "like",
    "confirm",
    "one",
    "thing",
    "data",
    "okay",
    "see",
    "positions",
    "data",
    "changed",
    "obviously",
    "data",
    "values",
    "predicted",
    "correctly",
    "right",
    "let",
    "try",
    "see",
    "get",
    "wrong",
    "values",
    "okay",
    "perfect",
    "example",
    "see",
    "getting",
    "accuracy",
    "100",
    "okay",
    "100",
    "values",
    "corrected",
    "perfectly",
    "come",
    "see",
    "accuracy",
    "20",
    "okay",
    "means",
    "one",
    "value",
    "predicted",
    "correctly",
    "right",
    "good",
    "example",
    "predicted",
    "value",
    "outcome",
    "going",
    "two",
    "fine",
    "similarly",
    "given",
    "correct",
    "prediction",
    "let",
    "quickly",
    "run",
    "see",
    "well",
    "one",
    "value",
    "predicted",
    "wrong",
    "good",
    "example",
    "see",
    "one",
    "hundred",
    "percent",
    "one",
    "8",
    "20",
    "one",
    "okay",
    "created",
    "three",
    "individual",
    "models",
    "last",
    "step",
    "perform",
    "aggregation",
    "performing",
    "aggregation",
    "say",
    "aggregation",
    "giving",
    "vote",
    "okay",
    "let",
    "see",
    "happens",
    "print",
    "give",
    "something",
    "like",
    "prediction",
    "one",
    "okay",
    "going",
    "bag",
    "one",
    "model",
    "right",
    "bag",
    "one",
    "dot",
    "predict",
    "let",
    "say",
    "predict",
    "test",
    "values",
    "right",
    "give",
    "random",
    "values",
    "np",
    "dot",
    "array",
    "going",
    "pass",
    "sepal",
    "length",
    "whatever",
    "features",
    "designed",
    "separate",
    "length",
    "petal",
    "length",
    "let",
    "say",
    "let",
    "take",
    "random",
    "value",
    "let",
    "say",
    "okay",
    "obviously",
    "reshape",
    "passing",
    "one",
    "value",
    "dot",
    "reshape",
    "one",
    "comma",
    "two",
    "going",
    "lower",
    "case",
    "small",
    "typo",
    "done",
    "okay",
    "model",
    "gon",
    "na",
    "predict",
    "one",
    "gon",
    "na",
    "copy",
    "three",
    "bags",
    "instead",
    "bag",
    "one",
    "give",
    "back",
    "two",
    "back",
    "three",
    "fed",
    "data",
    "let",
    "see",
    "predict",
    "okay",
    "great",
    "models",
    "predicting",
    "one",
    "means",
    "final",
    "output",
    "gon",
    "na",
    "one",
    "data",
    "set",
    "small",
    "getting",
    "accurate",
    "value",
    "data",
    "set",
    "pretty",
    "huge",
    "obviously",
    "wo",
    "getting",
    "accurate",
    "value",
    "apart",
    "let",
    "quickly",
    "change",
    "two",
    "three",
    "okay",
    "try",
    "rerun",
    "let",
    "see",
    "lucky",
    "get",
    "one",
    "wrong",
    "answer",
    "rerun",
    "start",
    "yet",
    "got",
    "correct",
    "predictions",
    "okay",
    "happens",
    "three",
    "values",
    "one",
    "maximum",
    "voting",
    "would",
    "take",
    "place",
    "final",
    "answer",
    "would",
    "one",
    "consider",
    "one",
    "would",
    "give",
    "two",
    "right",
    "two",
    "one",
    "happen",
    "maximum",
    "number",
    "vote",
    "one",
    "final",
    "output",
    "would",
    "one",
    "backing",
    "algorithm",
    "works",
    "moving",
    "ahead",
    "let",
    "us",
    "see",
    "another",
    "technique",
    "discussed",
    "earlier",
    "another",
    "technique",
    "discussed",
    "earlier",
    "voting",
    "right",
    "stacking",
    "next",
    "one",
    "seen",
    "voting",
    "stacking",
    "fine",
    "going",
    "let",
    "see",
    "another",
    "technique",
    "ensemble",
    "technique",
    "stacking",
    "stacking",
    "providing",
    "different",
    "kind",
    "models",
    "perform",
    "aggregation",
    "like",
    "okay",
    "import",
    "let",
    "see",
    "various",
    "libraries",
    "sklearn",
    "dot",
    "neighbors",
    "using",
    "k",
    "nearest",
    "neighbors",
    "k",
    "n",
    "import",
    "k",
    "neighbors",
    "classifier",
    "also",
    "linear",
    "model",
    "like",
    "logistic",
    "regression",
    "sklearn",
    "dot",
    "linear",
    "model",
    "import",
    "logistic",
    "regression",
    "apart",
    "let",
    "say",
    "want",
    "something",
    "nave",
    "bass",
    "sk",
    "learn",
    "dot",
    "knife",
    "bass",
    "import",
    "multinomial",
    "knife",
    "base",
    "also",
    "take",
    "gaussian",
    "knight",
    "base",
    "okay",
    "multinomial",
    "knife",
    "base",
    "also",
    "gaussian",
    "knife",
    "base",
    "finally",
    "also",
    "take",
    "something",
    "like",
    "decision",
    "tree",
    "sklearn",
    "dot",
    "tree",
    "import",
    "decision",
    "tree",
    "classifier",
    "right",
    "let",
    "execute",
    "create",
    "number",
    "models",
    "m1",
    "nearest",
    "neighbors",
    "okay",
    "classifier",
    "also",
    "model",
    "like",
    "m2",
    "logistic",
    "regression",
    "model",
    "three",
    "say",
    "multinomial",
    "live",
    "base",
    "model",
    "four",
    "something",
    "like",
    "uh",
    "gaussian",
    "likewise",
    "let",
    "say",
    "model",
    "5",
    "would",
    "decision",
    "tree",
    "classifier",
    "okay",
    "five",
    "models",
    "order",
    "work",
    "decision",
    "right",
    "like",
    "want",
    "work",
    "voting",
    "stacking",
    "something",
    "called",
    "voting",
    "classifier",
    "import",
    "sklearn",
    "dot",
    "symbol",
    "also",
    "set",
    "ensemble",
    "import",
    "porting",
    "classifier",
    "okay",
    "create",
    "model",
    "model",
    "equal",
    "voting",
    "classifier",
    "call",
    "class",
    "within",
    "gon",
    "na",
    "pass",
    "list",
    "tuples",
    "okay",
    "first",
    "list",
    "pass",
    "tuples",
    "first",
    "model",
    "obviously",
    "knn",
    "pass",
    "name",
    "model",
    "m1",
    "similarly",
    "second",
    "model",
    "logistic",
    "regression",
    "give",
    "lr",
    "would",
    "m2",
    "let",
    "change",
    "back",
    "comma",
    "colon",
    "fine",
    "third",
    "one",
    "multinomial",
    "neighbours",
    "mn",
    "give",
    "m3",
    "gaussian",
    "knife",
    "base",
    "gn",
    "g4",
    "m4",
    "model",
    "4",
    "finally",
    "give",
    "decision",
    "tree",
    "model",
    "five",
    "okay",
    "basically",
    "trying",
    "pass",
    "list",
    "tuples",
    "let",
    "give",
    "space",
    "understand",
    "okay",
    "let",
    "execute",
    "train",
    "model",
    "model",
    "dot",
    "train",
    "going",
    "model",
    "outfit",
    "right",
    "going",
    "pass",
    "x",
    "train",
    "train",
    "let",
    "load",
    "data",
    "set",
    "already",
    "value",
    "iris",
    "data",
    "set",
    "gon",
    "na",
    "use",
    "gon",
    "na",
    "copy",
    "values",
    "basically",
    "voting",
    "perform",
    "randomization",
    "copy",
    "data",
    "frame",
    "let",
    "see",
    "whether",
    "works",
    "df",
    "scroll",
    "let",
    "add",
    "cell",
    "let",
    "see",
    "df",
    "represents",
    "okay",
    "df",
    "represents",
    "values",
    "right",
    "basically",
    "need",
    "x",
    "test",
    "x",
    "strain",
    "sorry",
    "x",
    "strain",
    "would",
    "something",
    "like",
    "tf",
    "dot",
    "ilock",
    "fine",
    "need",
    "rows",
    "number",
    "columns",
    "need",
    "first",
    "two",
    "right",
    "except",
    "last",
    "one",
    "need",
    "similarly",
    "white",
    "test",
    "white",
    "green",
    "lock",
    "need",
    "rows",
    "last",
    "call",
    "okay",
    "also",
    "need",
    "import",
    "print",
    "test",
    "plate",
    "let",
    "quickly",
    "get",
    "well",
    "sklearn",
    "dot",
    "model",
    "selection",
    "import",
    "print",
    "test",
    "split",
    "okay",
    "let",
    "quickly",
    "get",
    "create",
    "object",
    "let",
    "scroll",
    "let",
    "copy",
    "part",
    "okay",
    "instead",
    "x",
    "gon",
    "na",
    "pass",
    "value",
    "dot",
    "values",
    "similarly",
    "let",
    "cut",
    "instead",
    "pass",
    "value",
    "okay",
    "looks",
    "good",
    "let",
    "execute",
    "code",
    "fit",
    "model",
    "right",
    "x",
    "train",
    "white",
    "train",
    "right",
    "basically",
    "telling",
    "us",
    "know",
    "various",
    "values",
    "took",
    "hyper",
    "parameters",
    "involved",
    "finally",
    "see",
    "score",
    "model",
    "seen",
    "model",
    "dot",
    "score",
    "pass",
    "extras",
    "whitest",
    "need",
    "value",
    "right",
    "x",
    "train",
    "white",
    "train",
    "see",
    "getting",
    "91",
    "percent",
    "accuracy",
    "right",
    "multiply",
    "100",
    "see",
    "getting",
    "91",
    "percent",
    "accuracy",
    "training",
    "data",
    "set",
    "something",
    "expected",
    "let",
    "see",
    "much",
    "accuracy",
    "expect",
    "test",
    "data",
    "set",
    "model",
    "dot",
    "score",
    "x",
    "test",
    "also",
    "white",
    "test",
    "let",
    "execute",
    "see",
    "getting",
    "amazing",
    "score",
    "93",
    "percent",
    "means",
    "model",
    "working",
    "absolutely",
    "fine",
    "okay",
    "overfitting",
    "fitting",
    "conditions",
    "model",
    "working",
    "perfectly",
    "fine",
    "means",
    "know",
    "model",
    "know",
    "performing",
    "well",
    "almost",
    "values",
    "predicted",
    "fine",
    "seen",
    "two",
    "popular",
    "ensemble",
    "technique",
    "backing",
    "voting",
    "let",
    "move",
    "ahead",
    "see",
    "last",
    "algorithm",
    "discussed",
    "slide",
    "boosting",
    "let",
    "quickly",
    "come",
    "give",
    "comment",
    "would",
    "boosting",
    "right",
    "going",
    "going",
    "perform",
    "going",
    "create",
    "boosting",
    "algorithm",
    "one",
    "popular",
    "boosting",
    "technique",
    "add",
    "boost",
    "classifier",
    "okay",
    "add",
    "boost",
    "algorithm",
    "let",
    "see",
    "implement",
    "using",
    "sklearn",
    "pretty",
    "simple",
    "straightforward",
    "sklearn",
    "dot",
    "n",
    "symbol",
    "ensemble",
    "import",
    "add",
    "boost",
    "performing",
    "classification",
    "going",
    "add",
    "boost",
    "classifier",
    "thing",
    "adaboost",
    "classifier",
    "performs",
    "binary",
    "classification",
    "okay",
    "already",
    "data",
    "set",
    "present",
    "going",
    "create",
    "model",
    "right",
    "say",
    "add",
    "boost",
    "classifier",
    "b",
    "c",
    "create",
    "object",
    "add",
    "boost",
    "classifier",
    "let",
    "give",
    "number",
    "estimators",
    "number",
    "models",
    "want",
    "estimators",
    "would",
    "like",
    "four",
    "give",
    "random",
    "state",
    "ah",
    "would",
    "zero",
    "want",
    "abc",
    "dot",
    "fit",
    "pass",
    "x",
    "test",
    "value",
    "sorry",
    "x",
    "train",
    "value",
    "white",
    "train",
    "value",
    "reason",
    "importing",
    "explicitly",
    "already",
    "imported",
    "data",
    "set",
    "right",
    "make",
    "sense",
    "importing",
    "let",
    "kind",
    "fit",
    "right",
    "let",
    "predict",
    "let",
    "see",
    "well",
    "classification",
    "working",
    "give",
    "white",
    "thread",
    "would",
    "abc",
    "dot",
    "predict",
    "pass",
    "x",
    "test",
    "okay",
    "let",
    "see",
    "score",
    "say",
    "abc",
    "dot",
    "score",
    "let",
    "say",
    "something",
    "like",
    "x",
    "test",
    "white",
    "test",
    "see",
    "getting",
    "value",
    "93",
    "percent",
    "pretty",
    "good",
    "want",
    "see",
    "much",
    "classification",
    "done",
    "many",
    "classes",
    "predicted",
    "right",
    "use",
    "function",
    "accuracy",
    "score",
    "accuracy",
    "score",
    "going",
    "pass",
    "actual",
    "value",
    "white",
    "test",
    "predicted",
    "value",
    "wipe",
    "red",
    "okay",
    "let",
    "see",
    "would",
    "accuracy",
    "getting",
    "accuracy",
    "basically",
    "calculating",
    "almost",
    "values",
    "correctly",
    "right",
    "ensemble",
    "techniques",
    "discussed",
    "three",
    "bagging",
    "boosting",
    "voting",
    "techniques",
    "alright",
    "guys",
    "come",
    "end",
    "session",
    "hope",
    "enjoyed",
    "learned",
    "something",
    "new",
    "queries",
    "please",
    "mention",
    "comment",
    "box",
    "next",
    "time",
    "good",
    "bye",
    "take",
    "care",
    "hope",
    "enjoyed",
    "listening",
    "video",
    "please",
    "kind",
    "enough",
    "like",
    "comment",
    "doubts",
    "queries",
    "reply",
    "earliest",
    "look",
    "videos",
    "playlist",
    "subscribe",
    "edureka",
    "channel",
    "learn",
    "happy",
    "learning"
  ],
  "keywords": [
    "ensemble",
    "learning",
    "let",
    "take",
    "look",
    "need",
    "techniques",
    "finally",
    "machine",
    "model",
    "training",
    "also",
    "us",
    "understand",
    "better",
    "accuracy",
    "using",
    "models",
    "particular",
    "classification",
    "type",
    "regression",
    "three",
    "first",
    "data",
    "set",
    "sampling",
    "perform",
    "column",
    "next",
    "base",
    "independent",
    "dependent",
    "prediction",
    "output",
    "final",
    "decision",
    "made",
    "based",
    "predictions",
    "ahead",
    "already",
    "like",
    "tree",
    "well",
    "see",
    "basically",
    "say",
    "one",
    "order",
    "variance",
    "used",
    "bias",
    "error",
    "much",
    "predicted",
    "value",
    "different",
    "means",
    "observation",
    "represents",
    "okay",
    "something",
    "right",
    "would",
    "test",
    "kind",
    "know",
    "works",
    "bagging",
    "boosting",
    "stacking",
    "voting",
    "technique",
    "bootstrap",
    "aggregation",
    "random",
    "samples",
    "whatever",
    "give",
    "classifier",
    "call",
    "two",
    "b",
    "logistic",
    "add",
    "get",
    "gon",
    "na",
    "try",
    "class",
    "algorithm",
    "values",
    "score",
    "create",
    "boost",
    "backing",
    "going",
    "classified",
    "wrong",
    "thing",
    "correctly",
    "quickly",
    "show",
    "import",
    "sklearn",
    "dot",
    "load",
    "apart",
    "equal",
    "columns",
    "sepal",
    "petal",
    "length",
    "frame",
    "copy",
    "put",
    "uh",
    "want",
    "rows",
    "similarly",
    "comma",
    "fine",
    "species",
    "use",
    "instead",
    "execute",
    "pretty",
    "pass",
    "df",
    "yeah",
    "reason",
    "underscore",
    "train",
    "60",
    "print",
    "100",
    "five",
    "provide",
    "name",
    "replacement",
    "x",
    "last",
    "function",
    "obviously",
    "fit",
    "plot",
    "come",
    "back",
    "predict",
    "white",
    "number",
    "bag",
    "getting",
    "percent",
    "good",
    "knife"
  ]
}