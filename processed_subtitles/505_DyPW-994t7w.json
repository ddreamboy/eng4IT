{
  "text": "you probably heard of the term transfer\nlearning a bunch of times already but\nwhat does it mean\nwhy do people use it and how can you get\nstarted let's answer all of those\nquestions in this video transfer\nlearning is taking all or part of a\nmodel that is already developed on a\ncertain task and using its learnings on\na whole new task the base model that is\nalready trained is called a pre-trained\nmodel and the practice of adjusting it\nto a whole new task is called fine\ntuning one example of this could be that\nyou make a really big model to detect\nobjects and images like a microphone a\ntable a computer a backpack etc and then\nyou find units to classify images of\nflowers into their respective species\nand this is exactly what we will build\nin the second part of this video with\nkeras okay but how does this all work so\nthere are a couple of ways how you can\nachieve transfer learning number one is\nyou can get a pre-trained model and only\nget rid of the output layer of this\npre-trained model and then you can add\nyour own output layer another option is\nto get rid of more layers of this model\nand add in more layers and also an\noutput layer of course how many layers\nyou get rid of and how many layers\nyou're going to add is going to depend\non how similar these two tasks are to\neach other after removing or adding some\nnew layers what you need to do is fine\ntune this model so basically train it\nwith the specialized data set that you\nhave let's see this on an example let's\nsay we have a cnn network very simple we\ntrain this model to\nrecognize faces in images let's say and\nnow we want to take this model and make\na more specialized model that can\nrecognize dog faces in images as you\nmight remember the deeper you go in your\ndeep neural network the higher level\nfeatures you are going to be able to\nrecognize\nso if the earlier layers in your model\ncan recognize lines straight lines\nhorizontal lines and maybe a little bit\nfurther you can recognize a circle or\ndifferent objects and maybe even further\nyou can recognize an eye feature a nose\nfeature an ear feature etc and probably\ntowards the end of your model the last\nlayers will be able to recognize either\npart of a human's face or all of a\nhuman's face and those are the layers\nthat we don't actually want because we\nwant to recognize dog faces so in this\ncase we want to keep the layers up until\nhere so we don't have to reinvent the\nwheel from the beginning we already have\nthat information parsed for us and we\nalso want to add a couple of new layers\nthat will learn how to recognize dog\nfaces given all the information that is\npassed to us after we set up the\narchitecture what we do is train our\nmodel with the dog images that we have\nand hopefully we will get a really good\nmodel that can recognize\ndog faces okay but why use transfer\nlearning at all why don't we just make a\nmodel from scratch and train it with the\ndata set of dog images that we have if\nyou have enough images of dogs of course\nthat would be the way to go but the\nthing transfer learning is solving is\nmainly a lack of data let's say we have\n1 million labeled photos featuring human\nfaces and only 5 000 featuring dog faces\nif you're only using the dog photos you\nwill not get very far with complex\narchitectures because they need a lot\nmore data to train but by using a\nsimilar task of recognizing human faces\nyou are giving your model a head start\neffectively exploiting the knowledge\ngained from a similar task on top of the\nlack of data problem transfer learning\nhelps us save time once a generalized\nmodel is built a lot of people can find\nunit for their specialized tasks and\nthrough this time saving and sharing of\ngeneralized models transfer learning\ncontributes to lowering the carbon\nfootprint of training models okay but\nhow can you get started with transfer\nlearning so the first step is to find a\npre-trained model luckily for us there\nare many places on the internet where\nyou can get pre-trained models some of\nthese are even built in in some of the\ndeep learning frameworks like tensorflow\nhub keras applications and pytorch\npre-trained models on top of this there\nare also some websites and apis you can\nuse to get pre-trained models one\nexample that is very popular is hugging\nface that most of the time hosts\ntransformer based models you can also go\nand download models from model zoo it\nmost of the time links to the model's\ngithub page one thing to note here is\nthat if you're downloading a model from\ngithub make sure you check their license\nso that you're not doing anything that's\nnot allowed with this model all right\nlet's build the example that we talked\nabout now so now we're going to do\ntransfer learning with the model called\nexception this model is pre-trained and\nis provided to us through the keras\napplications library it was originally\ntrained on 350 million images that\nincluded 17 000 classes our goal will be\nto change this model to classify photos\nof flowers into their species the data\nset we're going to use for that is\ncalled tf flowers there is a really nice\nand comprehensive list of data sets in\nthe tensorflow library\nif you want to learn more about your\ndata set you can always go here and kind\nof check it out what the photos look\nlike\nso here are some examples of what the\ndaisy class photos look like you can\nlearn more about the images if you click\non them for example their dimensions\ntheir mode etc\nyou can also learn more about the image\nquality\nmetadata etc so at first what we want to\ndo is to of course import the tensorflow\ndatasets library and the tensorflow\nlibrary and then i'm going to import the\ndata set\nwhen you set with info to true it also\ngives you some helpful information about\nthis data set so i can\nshow you what that looks like\nit basically includes the number of\nexamples that are in this data set the\nauthors of this data set the people who\ncreated this data set etc and also the\nlabels of course that are included in\nthis data set we also want to note this\nseparately so that's what we're going to\ndo in this next cell one thing you might\nrealize is that this data set only\nprovides us one split so one group of\nphotos it is not separated into training\ntesting and validation data sets so\nthat's why we have to do it ourselves\nhere next we have to make sure that our\nphotos are ready to be fed to the\nexception model so this model takes 224\nto 224 pixel images that's why we have\nto first resize them and then there is a\nvery nice and helpful pre-process input\nfunction that is again provided by keras\nand once we set this function all we\nhave to do is to make sure that all of\nour data has been run through this\nfunction and that's exactly what we do\nhere we set the batch size and then we\nalso run all of the different sections\nof this data set through the\npre-processing function so for the\nactual transfer learning part of this\ntutorial the first thing we want is the\nexception model and by getting the\nexception model what we're getting is\nall of its layers and all of its already\ntrained parameters but one thing that i\ndon't want is the top layer this top\nlayer includes the average pooling layer\nand the output layer that classifies the\nimages that it has instead of the output\nlayer or instead of the top layer of\nthis model i'm going to create my own\naverage layer and my own output layer\nand after i defined my layers i can\ncombine them all together to create the\nmodel that i want to fine-tune before we\nstart the fine-tuning training process\nwhat we want to do is to freeze the base\nmodel's layers freezing basically means\nthat during the fine tuning these\nparameters will not be touched they will\nnot be updated the only parameters that\nneed to be updated are the ones that we\njust created here i'm setting the\ntrainability of all of the layers inside\nthe base model to false so effectively\nthey're frozen next thing to do is to\ncompile this model and start fine-tuning\nit so just to go through the parameters\na little bit we are using gradient\ndescent learning grade is quite high\nbecause we want the last two layers that\nwe just created to learn quickly and i'm\nonly training this model for five epochs\nbecause i want the newly created top\nlayers to catch up with the rest of the\nmodel before you start running this one\nthing you can use in collab which will\nsave you a lot of time is to change your\nruntime to gpus the way you can do that\nis go and click run time\nand then change runtime type and select\ngpu here and that's that easy and after\nyou say save that means that now you can\nrun your model or train your model on\nthe gpu\nall right fine tuning is done for this\nmodel you might realize that after a\ncouple of epochs i have not actually\nmade that much progress in terms of\nvalidation loss and accuracy you can of\ncourse try training this a little bit\nlonger but that might also mean that\nyour top layers can actually perform\nwell now compared to the rest of the\nmodel and now you might need to train\nthe model holistically a little bit so\nfor that all you need to do is unfreeze\nthe previous layer so the base models\nlayers and train your model again\none thing you need to do before you\ncontinue with that is of course compile\nyour model again and\nideally you would set up way lower\nlearning rate so you're not going to\nmess with the parameters of the base\nmodel too much so let's train this and\nsee if we can see a performance\nincrease all right so fine tuning is\ndone again we definitely have seen some\nimprovement in the validation accuracy\nif you want to train it longer you could\nprobably get to even better accuracy\nalso but it is that easy to fine-tune a\npre-trained model all you have to do is\nselect your data set prepare your data\nset so that it fits the pre-trained\nmodel that you selected and import your\ndata import your model import your\npre-trained model make sure that you do\nnot include the top layers create your\nown top layers as many as you need and\nthen compile your model and train it\nthat's all you have to do if you have\nany questions about how this happened or\ntransfer learning in general or if you\nwant us to make a similar tutorial on\nother deep learning frameworks leave a\ncomment and let us know but for now\nthanks for watching and i will see you\nin the next video\nyou\n",
  "words": [
    "probably",
    "heard",
    "term",
    "transfer",
    "learning",
    "bunch",
    "times",
    "already",
    "mean",
    "people",
    "use",
    "get",
    "started",
    "let",
    "answer",
    "questions",
    "video",
    "transfer",
    "learning",
    "taking",
    "part",
    "model",
    "already",
    "developed",
    "certain",
    "task",
    "using",
    "learnings",
    "whole",
    "new",
    "task",
    "base",
    "model",
    "already",
    "trained",
    "called",
    "model",
    "practice",
    "adjusting",
    "whole",
    "new",
    "task",
    "called",
    "fine",
    "tuning",
    "one",
    "example",
    "could",
    "make",
    "really",
    "big",
    "model",
    "detect",
    "objects",
    "images",
    "like",
    "microphone",
    "table",
    "computer",
    "backpack",
    "etc",
    "find",
    "units",
    "classify",
    "images",
    "flowers",
    "respective",
    "species",
    "exactly",
    "build",
    "second",
    "part",
    "video",
    "keras",
    "okay",
    "work",
    "couple",
    "ways",
    "achieve",
    "transfer",
    "learning",
    "number",
    "one",
    "get",
    "model",
    "get",
    "rid",
    "output",
    "layer",
    "model",
    "add",
    "output",
    "layer",
    "another",
    "option",
    "get",
    "rid",
    "layers",
    "model",
    "add",
    "layers",
    "also",
    "output",
    "layer",
    "course",
    "many",
    "layers",
    "get",
    "rid",
    "many",
    "layers",
    "going",
    "add",
    "going",
    "depend",
    "similar",
    "two",
    "tasks",
    "removing",
    "adding",
    "new",
    "layers",
    "need",
    "fine",
    "tune",
    "model",
    "basically",
    "train",
    "specialized",
    "data",
    "set",
    "let",
    "see",
    "example",
    "let",
    "say",
    "cnn",
    "network",
    "simple",
    "train",
    "model",
    "recognize",
    "faces",
    "images",
    "let",
    "say",
    "want",
    "take",
    "model",
    "make",
    "specialized",
    "model",
    "recognize",
    "dog",
    "faces",
    "images",
    "might",
    "remember",
    "deeper",
    "go",
    "deep",
    "neural",
    "network",
    "higher",
    "level",
    "features",
    "going",
    "able",
    "recognize",
    "earlier",
    "layers",
    "model",
    "recognize",
    "lines",
    "straight",
    "lines",
    "horizontal",
    "lines",
    "maybe",
    "little",
    "bit",
    "recognize",
    "circle",
    "different",
    "objects",
    "maybe",
    "even",
    "recognize",
    "eye",
    "feature",
    "nose",
    "feature",
    "ear",
    "feature",
    "etc",
    "probably",
    "towards",
    "end",
    "model",
    "last",
    "layers",
    "able",
    "recognize",
    "either",
    "part",
    "human",
    "face",
    "human",
    "face",
    "layers",
    "actually",
    "want",
    "want",
    "recognize",
    "dog",
    "faces",
    "case",
    "want",
    "keep",
    "layers",
    "reinvent",
    "wheel",
    "beginning",
    "already",
    "information",
    "parsed",
    "us",
    "also",
    "want",
    "add",
    "couple",
    "new",
    "layers",
    "learn",
    "recognize",
    "dog",
    "faces",
    "given",
    "information",
    "passed",
    "us",
    "set",
    "architecture",
    "train",
    "model",
    "dog",
    "images",
    "hopefully",
    "get",
    "really",
    "good",
    "model",
    "recognize",
    "dog",
    "faces",
    "okay",
    "use",
    "transfer",
    "learning",
    "make",
    "model",
    "scratch",
    "train",
    "data",
    "set",
    "dog",
    "images",
    "enough",
    "images",
    "dogs",
    "course",
    "would",
    "way",
    "go",
    "thing",
    "transfer",
    "learning",
    "solving",
    "mainly",
    "lack",
    "data",
    "let",
    "say",
    "1",
    "million",
    "labeled",
    "photos",
    "featuring",
    "human",
    "faces",
    "5",
    "000",
    "featuring",
    "dog",
    "faces",
    "using",
    "dog",
    "photos",
    "get",
    "far",
    "complex",
    "architectures",
    "need",
    "lot",
    "data",
    "train",
    "using",
    "similar",
    "task",
    "recognizing",
    "human",
    "faces",
    "giving",
    "model",
    "head",
    "start",
    "effectively",
    "exploiting",
    "knowledge",
    "gained",
    "similar",
    "task",
    "top",
    "lack",
    "data",
    "problem",
    "transfer",
    "learning",
    "helps",
    "us",
    "save",
    "time",
    "generalized",
    "model",
    "built",
    "lot",
    "people",
    "find",
    "unit",
    "specialized",
    "tasks",
    "time",
    "saving",
    "sharing",
    "generalized",
    "models",
    "transfer",
    "learning",
    "contributes",
    "lowering",
    "carbon",
    "footprint",
    "training",
    "models",
    "okay",
    "get",
    "started",
    "transfer",
    "learning",
    "first",
    "step",
    "find",
    "model",
    "luckily",
    "us",
    "many",
    "places",
    "internet",
    "get",
    "models",
    "even",
    "built",
    "deep",
    "learning",
    "frameworks",
    "like",
    "tensorflow",
    "hub",
    "keras",
    "applications",
    "pytorch",
    "models",
    "top",
    "also",
    "websites",
    "apis",
    "use",
    "get",
    "models",
    "one",
    "example",
    "popular",
    "hugging",
    "face",
    "time",
    "hosts",
    "transformer",
    "based",
    "models",
    "also",
    "go",
    "download",
    "models",
    "model",
    "zoo",
    "time",
    "links",
    "model",
    "github",
    "page",
    "one",
    "thing",
    "note",
    "downloading",
    "model",
    "github",
    "make",
    "sure",
    "check",
    "license",
    "anything",
    "allowed",
    "model",
    "right",
    "let",
    "build",
    "example",
    "talked",
    "going",
    "transfer",
    "learning",
    "model",
    "called",
    "exception",
    "model",
    "provided",
    "us",
    "keras",
    "applications",
    "library",
    "originally",
    "trained",
    "350",
    "million",
    "images",
    "included",
    "17",
    "000",
    "classes",
    "goal",
    "change",
    "model",
    "classify",
    "photos",
    "flowers",
    "species",
    "data",
    "set",
    "going",
    "use",
    "called",
    "tf",
    "flowers",
    "really",
    "nice",
    "comprehensive",
    "list",
    "data",
    "sets",
    "tensorflow",
    "library",
    "want",
    "learn",
    "data",
    "set",
    "always",
    "go",
    "kind",
    "check",
    "photos",
    "look",
    "like",
    "examples",
    "daisy",
    "class",
    "photos",
    "look",
    "like",
    "learn",
    "images",
    "click",
    "example",
    "dimensions",
    "mode",
    "etc",
    "also",
    "learn",
    "image",
    "quality",
    "metadata",
    "etc",
    "first",
    "want",
    "course",
    "import",
    "tensorflow",
    "datasets",
    "library",
    "tensorflow",
    "library",
    "going",
    "import",
    "data",
    "set",
    "set",
    "info",
    "true",
    "also",
    "gives",
    "helpful",
    "information",
    "data",
    "set",
    "show",
    "looks",
    "like",
    "basically",
    "includes",
    "number",
    "examples",
    "data",
    "set",
    "authors",
    "data",
    "set",
    "people",
    "created",
    "data",
    "set",
    "etc",
    "also",
    "labels",
    "course",
    "included",
    "data",
    "set",
    "also",
    "want",
    "note",
    "separately",
    "going",
    "next",
    "cell",
    "one",
    "thing",
    "might",
    "realize",
    "data",
    "set",
    "provides",
    "us",
    "one",
    "split",
    "one",
    "group",
    "photos",
    "separated",
    "training",
    "testing",
    "validation",
    "data",
    "sets",
    "next",
    "make",
    "sure",
    "photos",
    "ready",
    "fed",
    "exception",
    "model",
    "model",
    "takes",
    "224",
    "224",
    "pixel",
    "images",
    "first",
    "resize",
    "nice",
    "helpful",
    "input",
    "function",
    "provided",
    "keras",
    "set",
    "function",
    "make",
    "sure",
    "data",
    "run",
    "function",
    "exactly",
    "set",
    "batch",
    "size",
    "also",
    "run",
    "different",
    "sections",
    "data",
    "set",
    "function",
    "actual",
    "transfer",
    "learning",
    "part",
    "tutorial",
    "first",
    "thing",
    "want",
    "exception",
    "model",
    "getting",
    "exception",
    "model",
    "getting",
    "layers",
    "already",
    "trained",
    "parameters",
    "one",
    "thing",
    "want",
    "top",
    "layer",
    "top",
    "layer",
    "includes",
    "average",
    "pooling",
    "layer",
    "output",
    "layer",
    "classifies",
    "images",
    "instead",
    "output",
    "layer",
    "instead",
    "top",
    "layer",
    "model",
    "going",
    "create",
    "average",
    "layer",
    "output",
    "layer",
    "defined",
    "layers",
    "combine",
    "together",
    "create",
    "model",
    "want",
    "start",
    "training",
    "process",
    "want",
    "freeze",
    "base",
    "model",
    "layers",
    "freezing",
    "basically",
    "means",
    "fine",
    "tuning",
    "parameters",
    "touched",
    "updated",
    "parameters",
    "need",
    "updated",
    "ones",
    "created",
    "setting",
    "trainability",
    "layers",
    "inside",
    "base",
    "model",
    "false",
    "effectively",
    "frozen",
    "next",
    "thing",
    "compile",
    "model",
    "start",
    "go",
    "parameters",
    "little",
    "bit",
    "using",
    "gradient",
    "descent",
    "learning",
    "grade",
    "quite",
    "high",
    "want",
    "last",
    "two",
    "layers",
    "created",
    "learn",
    "quickly",
    "training",
    "model",
    "five",
    "epochs",
    "want",
    "newly",
    "created",
    "top",
    "layers",
    "catch",
    "rest",
    "model",
    "start",
    "running",
    "one",
    "thing",
    "use",
    "collab",
    "save",
    "lot",
    "time",
    "change",
    "runtime",
    "gpus",
    "way",
    "go",
    "click",
    "run",
    "time",
    "change",
    "runtime",
    "type",
    "select",
    "gpu",
    "easy",
    "say",
    "save",
    "means",
    "run",
    "model",
    "train",
    "model",
    "gpu",
    "right",
    "fine",
    "tuning",
    "done",
    "model",
    "might",
    "realize",
    "couple",
    "epochs",
    "actually",
    "made",
    "much",
    "progress",
    "terms",
    "validation",
    "loss",
    "accuracy",
    "course",
    "try",
    "training",
    "little",
    "bit",
    "longer",
    "might",
    "also",
    "mean",
    "top",
    "layers",
    "actually",
    "perform",
    "well",
    "compared",
    "rest",
    "model",
    "might",
    "need",
    "train",
    "model",
    "holistically",
    "little",
    "bit",
    "need",
    "unfreeze",
    "previous",
    "layer",
    "base",
    "models",
    "layers",
    "train",
    "model",
    "one",
    "thing",
    "need",
    "continue",
    "course",
    "compile",
    "model",
    "ideally",
    "would",
    "set",
    "way",
    "lower",
    "learning",
    "rate",
    "going",
    "mess",
    "parameters",
    "base",
    "model",
    "much",
    "let",
    "train",
    "see",
    "see",
    "performance",
    "increase",
    "right",
    "fine",
    "tuning",
    "done",
    "definitely",
    "seen",
    "improvement",
    "validation",
    "accuracy",
    "want",
    "train",
    "longer",
    "could",
    "probably",
    "get",
    "even",
    "better",
    "accuracy",
    "also",
    "easy",
    "model",
    "select",
    "data",
    "set",
    "prepare",
    "data",
    "set",
    "fits",
    "model",
    "selected",
    "import",
    "data",
    "import",
    "model",
    "import",
    "model",
    "make",
    "sure",
    "include",
    "top",
    "layers",
    "create",
    "top",
    "layers",
    "many",
    "need",
    "compile",
    "model",
    "train",
    "questions",
    "happened",
    "transfer",
    "learning",
    "general",
    "want",
    "us",
    "make",
    "similar",
    "tutorial",
    "deep",
    "learning",
    "frameworks",
    "leave",
    "comment",
    "let",
    "us",
    "know",
    "thanks",
    "watching",
    "see",
    "next",
    "video"
  ],
  "keywords": [
    "probably",
    "transfer",
    "learning",
    "already",
    "people",
    "use",
    "get",
    "let",
    "video",
    "part",
    "model",
    "task",
    "using",
    "new",
    "base",
    "trained",
    "called",
    "fine",
    "tuning",
    "one",
    "example",
    "make",
    "really",
    "images",
    "like",
    "etc",
    "find",
    "flowers",
    "keras",
    "okay",
    "couple",
    "rid",
    "output",
    "layer",
    "add",
    "layers",
    "also",
    "course",
    "many",
    "going",
    "similar",
    "need",
    "basically",
    "train",
    "specialized",
    "data",
    "set",
    "see",
    "say",
    "recognize",
    "faces",
    "want",
    "dog",
    "might",
    "go",
    "deep",
    "lines",
    "little",
    "bit",
    "even",
    "feature",
    "human",
    "face",
    "actually",
    "information",
    "us",
    "learn",
    "way",
    "thing",
    "photos",
    "lot",
    "start",
    "top",
    "save",
    "time",
    "models",
    "training",
    "first",
    "tensorflow",
    "sure",
    "right",
    "exception",
    "library",
    "change",
    "import",
    "created",
    "next",
    "validation",
    "function",
    "run",
    "parameters",
    "create",
    "compile",
    "accuracy"
  ]
}