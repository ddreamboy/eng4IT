{
  "text": "hello there welcome to your tutorial on\nlenet 5 one of the pioneering\nconvolutional neural networks designed\nfor handwritten digit recognition in\nthis video we'll walk you through the\narchitecture of lanet 5 demonstrate how\nto implement it in Python and show you\nhow to train the model using Azure ml\nbefore we begin with anything I really\nwant to take some time to talk about the\nsignificance of lenet 5 lenet 5 is like\nthe hello world in the domain of CN n\nthat's convolutional neural network\nlenet 5 is a gradient based learning\nalgorithm which was introduced in 1998\nand it uses backward propagation which\nwas first introduced by itself in\n1989 to solve the very popular problem\nor dilemma of the time that stochastic\ngradient descent where the computational\nor the compute and the algorithm are in\na stalemate and was for a long time\nthought to be an unsolvable problem\nand it is thanks to lenet 5 that we have\ndeep neural networks as we know it today\nit was lenet 5 that proved that it was\npossible to build and train models with\nlayers and layers of depth and that is\nwhat we have or we know it today as\nneural networks deep neural\nnetworks so to Summit up lenet 5 is the\nfoundational step in the direction of\ndeep neural networks and it demonstrated\nthat it's possible to build depth in\nneural networks convolutional neural\nnetworks and for that it used backward\nback propagation in its gradient based\nlearning now let's talk about the\narchitecture of lenet 5 model so if we\nexclude the input layer we are left with\nseven layers which comprises lenet 5\nthree of them are convolutional layers\nwhich are basically kernels or filters\nthat perform the mathematical\nconvolutional operation\nand let's skip the details you can look\nthat up on convolutional operations in\nmathematics then we have two subsampling\nlayers which basically are used to\nreduce the dimensions of the image and\nwhy do we want to do that is we want to\nreduce the computational complexity\nbecause there are a lot of pixels and we\ndo not just want to compute uh\nbrainlessly we do want to reduce our\nsampling size uh we do call it in image\nprocessing the process of down sampling\nand that's what we do to reduce the cost\nof computation and then we have the\nfully connected networks whose role is\nto learn the complex patterns and make\nthe predictions that's the\noutput so we usually train our models on\na huge data set from msit that's the\nstandard and it consists of lots and\nlots of handwritten\ntraining uh data for data set so this is\na example of how lnet 8 Works visually\nif we were to do so we have L layer one\nthree and five as the convolutional\nlayers layer one being the input we are\nable to understand human human in a\nhuman manner that it's the number that\nwe are passing but as you go into depth\nlayer three and layer five the details\nthat are extracted from the neural\nnetwork are more computational and it\nstops making sense for\nus chello now let's get hands-on\nexperience on lenet 5 before we do that\nthere is a prequisite and that's that\nyou have your workspace ready in Azure\nmachine Learning Studio and in case you\ndo not have it uh there's a link in the\ndescription for a video which you can\ncheck out to set up your uh workspace it\nhardly takes 15 minutes and the video is\nhardly 6 minutes go through it and set\nit up and you ready to do the exercise\nwith me so I'm going to assume that you\nhave it ready so first of all we need a\ncompute on which we want to perform the\nmachine learning or training of the\nmodel so in the compute I already have\nmy compute ready and it's a GPU with\nthis specs you can also create this byck\nclicking on new select GPU and you can\nselect anyone I would uh I'm sticking\nwith a very cheap one but you can\naccording to your needs and your credit\nof course you can\nschedule and uh actually once you\nschedule uh it's uh it's their option\nyou can just review and create and\ncreate the resource for yourself so I\nalready have that so I'm not going to do\nthat so now we will head to notebook in\nauthoring section and here here uh we\nwill create a new\nfile and that's going to be a python\nnotebook so now I'm going to be very\nconcentrate about you and ensure that\nyou have a good experience while you\nfollow along with this video so I'm\ngoing to show you that the library that\nI have on my system so for this exercise\nwe will need torch library from Python\nand also torch Vision so\nfirst of all uh let's import CIS and\ncheck the environment uh that this\nnotebook is running\non and to do that we can just import CIS\nin Python and CIS stands for system and\nthen we can just print sis. executable\nand that will show us the environment\nthat this notebook is\npicking so this is the environment and\nuh now I I'll go to terminal from here\nso let's make sure we are on the right\ncomputer if you are if you have multiple\ncompute you just want to click on this\ndrop down and select your\ncompute so I'm going to check first of\nall the list of environments that exist\non this compute so the command for that\nis cond EnV list\nso we have five to six environments\nshowing up\nand Jupiter notebook is this one but are\nwe using this let's double check it with\nwhat we got on our\nnotebook so we are having SDK V2 and\nthat's not this\nsurprisingly uh\nwe have this right here so we are\ncurrently on Azure ml P30 and we want to\nmove to Azure ml Pi 310 SDK V2 so let's\npick this up and the command to move to\nthis environment is\ncond activate followed by the\nenvironment that we just\ncopied so now here it shows that we have\nsuccessfully moved to the environment we\nwere we wish to move and since we are\nnow in this environment we can and make\nthe library changes so it's very knively\nuh it's a KN mistake to pip install the\nlibrary in uh the default environment\nand it's not being reflected and you are\nscratching your heads what's happening\nso now that we are in that environment\nthat notebook is running on we can just\nmake sure that we are installing torch\nand torch vision for me it's already\ninstalled on my environment in this\ncomputer for for you it will be the\nfirst time and it will actually install\nit for me it's it's just showing that\num requirement already exists so it's\nnot installing uh let's go ahead and\ninstall torch Vision as well and we'll\nget a\nsimilar uh already installed no response\nand that's\nthere so now let's head back to our\nnotebook and put in the base code that's\nrequired so I'll just paste it and the\ncode is all about fetching the MN\ndata set\nand uh splitting it into training and\ntesting data sets so that we can\nactually train our model and then test\nhow it's performing and evaluate it give\nit a score so that's all being done here\nwe have downloaded all the data and it\nhas handwriting from all over the world\nand it's a huge huge data set and some\nof them frankly are really difficult for\neven me as a human to identify but let's\nsee how my model do\nso we do need to refresh our directory\nif we are expecting some new folders or\nfiles so let's\nsee uh there's a data folder MN and then\nwe\nhave uh we had we have images in\ncompressed format Let's Not Disturb\nthat uh so we are going to now Define\nour line 5 model in this section\nand to do that we the approach for the\nvideo will be I'll just paste the code\nand explain what I have written or it's\nit's pretty much very standard what we\nare doing is we are just um coding it\ncoding the picture of the architecture\nin this section so from the picture we\nhave input as 32 cross 32 then we have\nthe convolution with six feature maps of\n28 cross 28 and then next we have six\nfeature map maps of 14 cross 4 14 and so\non we have the layers so if we focus on\nlayer one we have neural network nn. con\nconvolution 2D so we are doing\nperforming 2D convolution and we have 1\ncomma 6 comma kernel size equal to 5\nstride equal to 1 padding equal to zero\nso stride is the movement of Kernel will\nbe by one pixel and padding will be zero\nso on the borders we are not excluding\nany pixels this is the first\nconvolutional layer with six feature\nMaps that's what six is and kernel size\nequal to 5 is that we are keeping it 5\ncross\n5 so interestingly you might be thinking\nwhy the kernel size is 5 cross 5 and not\n32 cross 32 or not 28 cross 28 in the\nnext convolutional n we have 2 cross two\nkernel size and then again we have five\ncross five what's happening\nwell uh the thing is that the way kernel\nkernel size is the operation we are\nperforming so we are having six kernels\nof 5 cross 5 which will on acting on top\nof 32 cross 32 which which is the input\nimage will make the output as size of 28\ncross 28 and when 28 cross 28 is fed to\n2 cross2 Cal size of six uh six of them\nit will become 14 cross 14 and how it\nhappens I'd love to show that but let's\nnot do it here it's related to the\noperation of convolution in mathematics\nagain other than that we also have tanh\nwhich is the activation function so we\nhave t uh curve which we use to either\nuh activate or meaning just we want the\noutput as one or zero decisive how\nconfident you are and we convert the\nvalue to one and zero depend uh using\nthe activation function right now as T\nand for output in the very last layer we\nwill be using softmax which is very\npopular for\nuh uh its implementation on the output\nspecifically we implement it softmax\nfunction which is a mathematical\nfunction as activation function in lots\nof machine learning models it has its\nsignificance and background which we\nwill skip sorry uh but that's the model\nthat we have and now we can proceed and\ngo ahead to train and test them so again\nI'm just going to pick up the code that\nI have already written on my local and\ndrop it on the notebook and execute\nit so this will take some time and let's\nrun it the first thing that you should\nobserve is that CPU is going to go from\n0 to 100% usage and that's because\ncomputation of training of these models\nis really complex if you don't feel like\nit's just the hello world of uh machine\nlearning CNN uh go ahead and try it on\nyour local uh you'll see your local\nheating up and all the fans getting\nwarmed up uh you can also try on Google\ncollab and you'll see it's much much\nslower than what we have here on Azure\nml Studio the reason being we had we\nhave a strong compute supporting this uh\nnotebook and we can always use a\nstronger compute we have the option\nright we we right now are using a very\nstandard compute with standard GPU but\nyou can always go for more expensive\nones which are much more powerful and\nthat's not the limit there you can uh\nright now we are using compute instance\nyou can use compute clusters which are\nbasically a cluster of compute and then\ntrain really really complex models on\nyour own sitting at home which you\ncouldn't not have imagined before this\nwithout this\nplatform uh so specifically if you are\ninto training complex models which could\nbe related to image image processing\nmodels like single image super\nresolution\num uh this is the platform that really\nreally empowers you so basically what\nI'm trying to say is I really love this\nplatform it really empowers me to try\nout my own models train them which I\nwould not have thought possible without\nuh at least not sitting at home and\npaying nothing so it comes with a trial\nversion where I can test things out and\nsee if it feels good um but since this\ntraining is taking time and we are\nseeing AO let's talk about what's\nhappening on the schol uh so Epoch is\nlike we train the model on our data set\ntraining set from uh input to output and\nthen we have back propagation algorithm\nwhich comes back and retrains the\nweights and uh with the complete\ntraining over we have the value of the\nweights that we obtained from\nfeedback and after the epoch we actually\nupdate the weights and then train again\ntrain again train again make those\nweight changes train again make those\nand that's basically building a stronger\nmore accurate model\nand we have the score of\n98.78% accuracy and that's great and\nwith that uh thank you for joining me on\nthis video I hope you learned something\nif you did do give give this video a\nthumbs up and subscribe for more such\ncontent thanks and have a good day\nbye-bye up next you can check out\nanother fun video about where we are\nbasically comparing azure ml model\ntraining experience with the Google\ncollab and see the differences in terms\nof compute performance\n",
  "words": [
    "hello",
    "welcome",
    "tutorial",
    "lenet",
    "5",
    "one",
    "pioneering",
    "convolutional",
    "neural",
    "networks",
    "designed",
    "handwritten",
    "digit",
    "recognition",
    "video",
    "walk",
    "architecture",
    "lanet",
    "5",
    "demonstrate",
    "implement",
    "python",
    "show",
    "train",
    "model",
    "using",
    "azure",
    "ml",
    "begin",
    "anything",
    "really",
    "want",
    "take",
    "time",
    "talk",
    "significance",
    "lenet",
    "5",
    "lenet",
    "5",
    "like",
    "hello",
    "world",
    "domain",
    "cn",
    "n",
    "convolutional",
    "neural",
    "network",
    "lenet",
    "5",
    "gradient",
    "based",
    "learning",
    "algorithm",
    "introduced",
    "1998",
    "uses",
    "backward",
    "propagation",
    "first",
    "introduced",
    "1989",
    "solve",
    "popular",
    "problem",
    "dilemma",
    "time",
    "stochastic",
    "gradient",
    "descent",
    "computational",
    "compute",
    "algorithm",
    "stalemate",
    "long",
    "time",
    "thought",
    "unsolvable",
    "problem",
    "thanks",
    "lenet",
    "5",
    "deep",
    "neural",
    "networks",
    "know",
    "today",
    "lenet",
    "5",
    "proved",
    "possible",
    "build",
    "train",
    "models",
    "layers",
    "layers",
    "depth",
    "know",
    "today",
    "neural",
    "networks",
    "deep",
    "neural",
    "networks",
    "summit",
    "lenet",
    "5",
    "foundational",
    "step",
    "direction",
    "deep",
    "neural",
    "networks",
    "demonstrated",
    "possible",
    "build",
    "depth",
    "neural",
    "networks",
    "convolutional",
    "neural",
    "networks",
    "used",
    "backward",
    "back",
    "propagation",
    "gradient",
    "based",
    "learning",
    "let",
    "talk",
    "architecture",
    "lenet",
    "5",
    "model",
    "exclude",
    "input",
    "layer",
    "left",
    "seven",
    "layers",
    "comprises",
    "lenet",
    "5",
    "three",
    "convolutional",
    "layers",
    "basically",
    "kernels",
    "filters",
    "perform",
    "mathematical",
    "convolutional",
    "operation",
    "let",
    "skip",
    "details",
    "look",
    "convolutional",
    "operations",
    "mathematics",
    "two",
    "subsampling",
    "layers",
    "basically",
    "used",
    "reduce",
    "dimensions",
    "image",
    "want",
    "want",
    "reduce",
    "computational",
    "complexity",
    "lot",
    "pixels",
    "want",
    "compute",
    "uh",
    "brainlessly",
    "want",
    "reduce",
    "sampling",
    "size",
    "uh",
    "call",
    "image",
    "processing",
    "process",
    "sampling",
    "reduce",
    "cost",
    "computation",
    "fully",
    "connected",
    "networks",
    "whose",
    "role",
    "learn",
    "complex",
    "patterns",
    "make",
    "predictions",
    "output",
    "usually",
    "train",
    "models",
    "huge",
    "data",
    "set",
    "msit",
    "standard",
    "consists",
    "lots",
    "lots",
    "handwritten",
    "training",
    "uh",
    "data",
    "data",
    "set",
    "example",
    "lnet",
    "8",
    "works",
    "visually",
    "l",
    "layer",
    "one",
    "three",
    "five",
    "convolutional",
    "layers",
    "layer",
    "one",
    "input",
    "able",
    "understand",
    "human",
    "human",
    "human",
    "manner",
    "number",
    "passing",
    "go",
    "depth",
    "layer",
    "three",
    "layer",
    "five",
    "details",
    "extracted",
    "neural",
    "network",
    "computational",
    "stops",
    "making",
    "sense",
    "us",
    "chello",
    "let",
    "get",
    "experience",
    "lenet",
    "5",
    "prequisite",
    "workspace",
    "ready",
    "azure",
    "machine",
    "learning",
    "studio",
    "case",
    "uh",
    "link",
    "description",
    "video",
    "check",
    "set",
    "uh",
    "workspace",
    "hardly",
    "takes",
    "15",
    "minutes",
    "video",
    "hardly",
    "6",
    "minutes",
    "go",
    "set",
    "ready",
    "exercise",
    "going",
    "assume",
    "ready",
    "first",
    "need",
    "compute",
    "want",
    "perform",
    "machine",
    "learning",
    "training",
    "model",
    "compute",
    "already",
    "compute",
    "ready",
    "gpu",
    "specs",
    "also",
    "create",
    "byck",
    "clicking",
    "new",
    "select",
    "gpu",
    "select",
    "anyone",
    "would",
    "uh",
    "sticking",
    "cheap",
    "one",
    "according",
    "needs",
    "credit",
    "course",
    "schedule",
    "uh",
    "actually",
    "schedule",
    "uh",
    "uh",
    "option",
    "review",
    "create",
    "create",
    "resource",
    "already",
    "going",
    "head",
    "notebook",
    "authoring",
    "section",
    "uh",
    "create",
    "new",
    "file",
    "going",
    "python",
    "notebook",
    "going",
    "concentrate",
    "ensure",
    "good",
    "experience",
    "follow",
    "along",
    "video",
    "going",
    "show",
    "library",
    "system",
    "exercise",
    "need",
    "torch",
    "library",
    "python",
    "also",
    "torch",
    "vision",
    "first",
    "uh",
    "let",
    "import",
    "cis",
    "check",
    "environment",
    "uh",
    "notebook",
    "running",
    "import",
    "cis",
    "python",
    "cis",
    "stands",
    "system",
    "print",
    "sis",
    "executable",
    "show",
    "us",
    "environment",
    "notebook",
    "picking",
    "environment",
    "uh",
    "go",
    "terminal",
    "let",
    "make",
    "sure",
    "right",
    "computer",
    "multiple",
    "compute",
    "want",
    "click",
    "drop",
    "select",
    "compute",
    "going",
    "check",
    "first",
    "list",
    "environments",
    "exist",
    "compute",
    "command",
    "cond",
    "env",
    "list",
    "five",
    "six",
    "environments",
    "showing",
    "jupiter",
    "notebook",
    "one",
    "using",
    "let",
    "double",
    "check",
    "got",
    "notebook",
    "sdk",
    "v2",
    "surprisingly",
    "uh",
    "right",
    "currently",
    "azure",
    "ml",
    "p30",
    "want",
    "move",
    "azure",
    "ml",
    "pi",
    "310",
    "sdk",
    "v2",
    "let",
    "pick",
    "command",
    "move",
    "environment",
    "cond",
    "activate",
    "followed",
    "environment",
    "copied",
    "shows",
    "successfully",
    "moved",
    "environment",
    "wish",
    "move",
    "since",
    "environment",
    "make",
    "library",
    "changes",
    "knively",
    "uh",
    "kn",
    "mistake",
    "pip",
    "install",
    "library",
    "uh",
    "default",
    "environment",
    "reflected",
    "scratching",
    "heads",
    "happening",
    "environment",
    "notebook",
    "running",
    "make",
    "sure",
    "installing",
    "torch",
    "torch",
    "vision",
    "already",
    "installed",
    "environment",
    "computer",
    "first",
    "time",
    "actually",
    "install",
    "showing",
    "um",
    "requirement",
    "already",
    "exists",
    "installing",
    "uh",
    "let",
    "go",
    "ahead",
    "install",
    "torch",
    "vision",
    "well",
    "get",
    "similar",
    "uh",
    "already",
    "installed",
    "response",
    "let",
    "head",
    "back",
    "notebook",
    "put",
    "base",
    "code",
    "required",
    "paste",
    "code",
    "fetching",
    "mn",
    "data",
    "set",
    "uh",
    "splitting",
    "training",
    "testing",
    "data",
    "sets",
    "actually",
    "train",
    "model",
    "test",
    "performing",
    "evaluate",
    "give",
    "score",
    "done",
    "downloaded",
    "data",
    "handwriting",
    "world",
    "huge",
    "huge",
    "data",
    "set",
    "frankly",
    "really",
    "difficult",
    "even",
    "human",
    "identify",
    "let",
    "see",
    "model",
    "need",
    "refresh",
    "directory",
    "expecting",
    "new",
    "folders",
    "files",
    "let",
    "see",
    "uh",
    "data",
    "folder",
    "mn",
    "uh",
    "images",
    "compressed",
    "format",
    "let",
    "disturb",
    "uh",
    "going",
    "define",
    "line",
    "5",
    "model",
    "section",
    "approach",
    "video",
    "paste",
    "code",
    "explain",
    "written",
    "pretty",
    "much",
    "standard",
    "um",
    "coding",
    "coding",
    "picture",
    "architecture",
    "section",
    "picture",
    "input",
    "32",
    "cross",
    "32",
    "convolution",
    "six",
    "feature",
    "maps",
    "28",
    "cross",
    "28",
    "next",
    "six",
    "feature",
    "map",
    "maps",
    "14",
    "cross",
    "4",
    "14",
    "layers",
    "focus",
    "layer",
    "one",
    "neural",
    "network",
    "nn",
    "con",
    "convolution",
    "2d",
    "performing",
    "2d",
    "convolution",
    "1",
    "comma",
    "6",
    "comma",
    "kernel",
    "size",
    "equal",
    "5",
    "stride",
    "equal",
    "1",
    "padding",
    "equal",
    "zero",
    "stride",
    "movement",
    "kernel",
    "one",
    "pixel",
    "padding",
    "zero",
    "borders",
    "excluding",
    "pixels",
    "first",
    "convolutional",
    "layer",
    "six",
    "feature",
    "maps",
    "six",
    "kernel",
    "size",
    "equal",
    "5",
    "keeping",
    "5",
    "cross",
    "5",
    "interestingly",
    "might",
    "thinking",
    "kernel",
    "size",
    "5",
    "cross",
    "5",
    "32",
    "cross",
    "32",
    "28",
    "cross",
    "28",
    "next",
    "convolutional",
    "n",
    "2",
    "cross",
    "two",
    "kernel",
    "size",
    "five",
    "cross",
    "five",
    "happening",
    "well",
    "uh",
    "thing",
    "way",
    "kernel",
    "kernel",
    "size",
    "operation",
    "performing",
    "six",
    "kernels",
    "5",
    "cross",
    "5",
    "acting",
    "top",
    "32",
    "cross",
    "32",
    "input",
    "image",
    "make",
    "output",
    "size",
    "28",
    "cross",
    "28",
    "28",
    "cross",
    "28",
    "fed",
    "2",
    "cross2",
    "cal",
    "size",
    "six",
    "uh",
    "six",
    "become",
    "14",
    "cross",
    "14",
    "happens",
    "love",
    "show",
    "let",
    "related",
    "operation",
    "convolution",
    "mathematics",
    "also",
    "tanh",
    "activation",
    "function",
    "uh",
    "curve",
    "use",
    "either",
    "uh",
    "activate",
    "meaning",
    "want",
    "output",
    "one",
    "zero",
    "decisive",
    "confident",
    "convert",
    "value",
    "one",
    "zero",
    "depend",
    "uh",
    "using",
    "activation",
    "function",
    "right",
    "output",
    "last",
    "layer",
    "using",
    "softmax",
    "popular",
    "uh",
    "uh",
    "implementation",
    "output",
    "specifically",
    "implement",
    "softmax",
    "function",
    "mathematical",
    "function",
    "activation",
    "function",
    "lots",
    "machine",
    "learning",
    "models",
    "significance",
    "background",
    "skip",
    "sorry",
    "uh",
    "model",
    "proceed",
    "go",
    "ahead",
    "train",
    "test",
    "going",
    "pick",
    "code",
    "already",
    "written",
    "local",
    "drop",
    "notebook",
    "execute",
    "take",
    "time",
    "let",
    "run",
    "first",
    "thing",
    "observe",
    "cpu",
    "going",
    "go",
    "0",
    "100",
    "usage",
    "computation",
    "training",
    "models",
    "really",
    "complex",
    "feel",
    "like",
    "hello",
    "world",
    "uh",
    "machine",
    "learning",
    "cnn",
    "uh",
    "go",
    "ahead",
    "try",
    "local",
    "uh",
    "see",
    "local",
    "heating",
    "fans",
    "getting",
    "warmed",
    "uh",
    "also",
    "try",
    "google",
    "collab",
    "see",
    "much",
    "much",
    "slower",
    "azure",
    "ml",
    "studio",
    "reason",
    "strong",
    "compute",
    "supporting",
    "uh",
    "notebook",
    "always",
    "use",
    "stronger",
    "compute",
    "option",
    "right",
    "right",
    "using",
    "standard",
    "compute",
    "standard",
    "gpu",
    "always",
    "go",
    "expensive",
    "ones",
    "much",
    "powerful",
    "limit",
    "uh",
    "right",
    "using",
    "compute",
    "instance",
    "use",
    "compute",
    "clusters",
    "basically",
    "cluster",
    "compute",
    "train",
    "really",
    "really",
    "complex",
    "models",
    "sitting",
    "home",
    "could",
    "imagined",
    "without",
    "platform",
    "uh",
    "specifically",
    "training",
    "complex",
    "models",
    "could",
    "related",
    "image",
    "image",
    "processing",
    "models",
    "like",
    "single",
    "image",
    "super",
    "resolution",
    "um",
    "uh",
    "platform",
    "really",
    "really",
    "empowers",
    "basically",
    "trying",
    "say",
    "really",
    "love",
    "platform",
    "really",
    "empowers",
    "try",
    "models",
    "train",
    "would",
    "thought",
    "possible",
    "without",
    "uh",
    "least",
    "sitting",
    "home",
    "paying",
    "nothing",
    "comes",
    "trial",
    "version",
    "test",
    "things",
    "see",
    "feels",
    "good",
    "um",
    "since",
    "training",
    "taking",
    "time",
    "seeing",
    "ao",
    "let",
    "talk",
    "happening",
    "schol",
    "uh",
    "epoch",
    "like",
    "train",
    "model",
    "data",
    "set",
    "training",
    "set",
    "uh",
    "input",
    "output",
    "back",
    "propagation",
    "algorithm",
    "comes",
    "back",
    "retrains",
    "weights",
    "uh",
    "complete",
    "training",
    "value",
    "weights",
    "obtained",
    "feedback",
    "epoch",
    "actually",
    "update",
    "weights",
    "train",
    "train",
    "train",
    "make",
    "weight",
    "changes",
    "train",
    "make",
    "basically",
    "building",
    "stronger",
    "accurate",
    "model",
    "score",
    "accuracy",
    "great",
    "uh",
    "thank",
    "joining",
    "video",
    "hope",
    "learned",
    "something",
    "give",
    "give",
    "video",
    "thumbs",
    "subscribe",
    "content",
    "thanks",
    "good",
    "day",
    "next",
    "check",
    "another",
    "fun",
    "video",
    "basically",
    "comparing",
    "azure",
    "ml",
    "model",
    "training",
    "experience",
    "google",
    "collab",
    "see",
    "differences",
    "terms",
    "compute",
    "performance"
  ],
  "keywords": [
    "hello",
    "lenet",
    "5",
    "one",
    "convolutional",
    "neural",
    "networks",
    "video",
    "architecture",
    "python",
    "show",
    "train",
    "model",
    "using",
    "azure",
    "ml",
    "really",
    "want",
    "time",
    "talk",
    "like",
    "world",
    "network",
    "gradient",
    "learning",
    "algorithm",
    "propagation",
    "first",
    "computational",
    "compute",
    "deep",
    "possible",
    "models",
    "layers",
    "depth",
    "back",
    "let",
    "input",
    "layer",
    "three",
    "basically",
    "operation",
    "reduce",
    "image",
    "uh",
    "size",
    "complex",
    "make",
    "output",
    "huge",
    "data",
    "set",
    "standard",
    "lots",
    "training",
    "five",
    "human",
    "go",
    "experience",
    "ready",
    "machine",
    "check",
    "going",
    "need",
    "already",
    "gpu",
    "also",
    "create",
    "new",
    "select",
    "actually",
    "notebook",
    "section",
    "good",
    "library",
    "torch",
    "vision",
    "cis",
    "environment",
    "right",
    "six",
    "move",
    "install",
    "happening",
    "um",
    "ahead",
    "code",
    "test",
    "performing",
    "give",
    "see",
    "much",
    "32",
    "cross",
    "convolution",
    "feature",
    "maps",
    "28",
    "next",
    "14",
    "kernel",
    "equal",
    "zero",
    "activation",
    "function",
    "use",
    "local",
    "try",
    "platform",
    "weights"
  ]
}