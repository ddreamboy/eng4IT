{
  "text": "hello and welcome to the session on time\nseries forecasting in this video we are\ngoing to talk about what time series\nforecasting is\nso this is what we are going to cover in\nthis video first of all why time series\nand then we'll talk about what exactly\nis time series data and then what are\nthe components of a time series data\nlike for example the trend seasonality\nand so on and then we will explain what\neach of these components are we'll also\ntalk about when we should not use time\nseries analysis and\nwe will then explain what is\nstationary data in terms of time series\nwhat is the significance of stationary\ndata and typically time series data is\nnot stationary so how to make time\nseries data stationary and then we will\ntake it through an example of a car\nsales data and we will show you how to\nsolve the time series or how to perform\nthe time series analysis\nmanually without using the tool and then\nwe will do in the second part we will\nactually use r and we will do the same\nthing once again in r okay so without\nany further delay let's get started and\nso why exactly do we need to do time\nseries analysis typically we would like\nto predict something in the future and\nit could be stock prices it could be the\nsales or\nanything that needs to be predicted into\nthe future that is when we\nuse time series analysis\nso it is\nas the name suggests it is forecasting\nand typically when we say predict it\nneed not be into the future in machine\nlearning and data analysis when we talk\nabout predicting we are not necessarily\ntalking about the future but in time\nseries analysis we typically predict the\nfuture so we have some past data and we\nwant to predict the future that is when\nwe perform time series analysis so what\nare some of the examples it could be\ndaily stock price the shares as we talk\nabout or it could be the interest rates\nweekly interest rates or sales figures\nof a company so these are some of the\nexamples where we use time series data\nwe have historical data which is\ndependent on time and then based on that\nwe create a model to predict the future\nso what exactly is\ntime series so time series data has time\nas one of the components as the name\nsuggests so in this example let's say\nthis is the stock price data and\none of the components so there are two\ncolumns here column b is\nprice and column a is basically the time\ninformation in this case the time is a\nday so that primarily the closing price\nof a particular stock has been recorded\non a daily basis so this is a time\nseries data and the time interval is\nobviously a day time series or time\nintervals can be daily weekly hourly or\neven sometimes there is something like a\nsensor data it could be every few\nmilliseconds or microseconds as well so\nthe size of the time intervals can vary\nbut they are fixed so if i'm saying that\nit is daily data then the interval is\nfixed as uh daily if i'm saying this\ndata is an hourly data then it is the\ndata is captured every year and so on so\nthe time intervals are fixed the\ninterval itself you can decide based on\nwhat kind of data we are capturing so\nthis is a graphical representation the\nprevious one here we saw the table\nrepresentation and this is how the plot\nthe data so on the y-axis is let's say\nthe price or the the stock price and\nx-axis is the time so against time if\nyou plot it this is how a time series\ngraph would look so as the name suggests\nwhat is time series data time series\ndata is basically a sequence of data\nthat is recorded over a specific\nintervals of time and based on the past\nvalues so if we want to do an analysis\nof time series past data we try to\nforecast a future and\nagain as the name suggests is time\nseries data which means that it is time\ndependent so time is one of the\ncomponents of this data time series data\nconsists of primarily four components\none is the trend then we have the\nseasonality then cyclicity and then last\nbut not least irregularity or the random\ncomponent sometimes is also referred to\nas a random component so let's see what\neach of these components are so what is\ntrend trend is overall\nchange or the pattern of the data which\nmeans that the data may be let me just\nuh pull up to pen and\nshow you so let's say you have a data\nset somewhat like this a time series\ndata set somewhat like this all right\nso what is the overall trend there is an\noverall\ntrend which is upward trend as we call\nit here right so it is not like it is\ncontinuously increasing there are times\nwhen it is dipping then there are times\nwhen it is increasing then it is\ndecreasing and so on but overall over a\nperiod of time from the time we start\nrecording to the time we end there is a\ntrend right there is an upward trend in\nthis case so the trend need not always\nbe upwards there could be a downward\ntrend as well so for example here there\nis a downward trend right so this is\nbasically what is a trend overall\nwhether the data is increasing or\ndecreasing all right then we have the\nnext component which is seasonality what\nis seasonality seasonality as the name\nsuggests once again changes over a\nperiod of time and periodic changes\nright so there is a certain pattern um\nlet's take the sales of warm clothes for\nexample so if we plot it along the\nmonths so let's say january february\nmarch april may july and then let's say\nit goes up to december okay so this is\nour\ndecember a d\ni will just mark it as t and then you\nagain have jan feb march and then you\nget another december okay and just for\nsimplicity let's mark these as decembers\nas the end of the year and then one more\ndecember\nokay so what will happen when if you are\ntalking about warm clothes what happens\nthe sales of warm clothes will increase\nprobably around december when it is cold\nand then they will come down and then\nagain\naround december again they will increase\nand then the sales will come down and\nthen there will be again an increase and\nthen they will come down and then again\nan increase and then they will come down\nlet's see this is the sales pattern so\nyou see here there is a trend as well\nthere is an upward trend right the sales\nare increasing over let's say these are\nmultiple years this is for year one this\nis for year two this is for year three\nand so on so for multiple years overall\nthe trend there is an upward trend the\nsales are increasing but it is not a\ncontinuous increase right so there is a\ncertain pattern so what is happening\nwhat is the pattern every\ndecember the sales are increasing or\nthey are peaking for that particular\nyear right then there is a new year\nagain when december approaches the sales\nare increasing again when december\napproaches the sales are increasing and\nso on and so forth so this is known as\nseasonality so there is a certain\nfluctuation\nwhich is which is periodic in nature so\nthis is known as seasonality then\ncyclicity what is cyclicity now\ncyclicity is somewhat similar to\nseasonality but here the duration\nbetween two cycles is much longer so\nseasonality typically is referred to as\nan annual kind of a sequence like for\nexample we saw here so it is pretty much\nlike every year in the month of december\nthe sales are increasing however\ncyclicity what happens is first of all\nthe duration is pretty much not fixed\nand the duration or the gap length of\ntime between two cycles can be much\nlonger so the recession is an example so\nwe had let's say recession in 2001 or\n2002 perhaps and then we had one in 2008\nand then we had probably in 2000 2012\nand so on and so forth so it is not like\nevery year this happens probably so\nthere is usually when we say recession\nthere is a slump and then it recovers\nand then there is a slump and then it\nrecovers and probably there is another\nbigger slump and so on right so you see\nhere this is similar to seasonality but\nfirst of all this length is much more\nthan a year\nright that is number one and it is not\nfixed as well it is not like every four\nyears or every six years that duration\nis not fixed so the\nduration can vary at the same time the\ngap between two cycles is much longer\ncompared to seasonality all right so\nthen what is irregularity irregularity\nis like the random component of the time\nseries data so there is like you have\npart which is the trend which tells\nwhether the overall it is increasing or\ndecreasing then you have cyclicity and\nseasonality which is like kind of a\nspecific pattern right\nthen there is a cyclicity which is again\na pattern but at much longer intervals\nplus there is a random component so\nwhich is not really which cannot be\naccounted for very easily right so there\nwill be a random component which can be\nreally random as the name suggests right\nso that is the irregularity component so\nthese are the various components of time\nseries data yes there are conditions\nwhere we cannot use time series analysis\nright so is it can we do time series\nanalysis with any kind of data no not\nreally so what are the situations where\nwe are\nwe cannot do time series analysis so\nthere will be some data which is\ncollected over a period of time but it's\nreally not changing so\nit will not really not make sense to\nperform any time series analysis over it\nright for example like this one so if we\ntake x as the time and y is the value of\nwhatever the output we are talking about\nand if the y value is constant there is\nreally no analysis that you can do\nleave alone time series analysis right\nso that is one another possibility is\nyes there is a change but it is changing\nas per a very fixed function like a sine\nwave or a cos wave again time series\nanalysis will not make sense in this\nkind of a situation because there is a\ndefinite pattern here there is a\ndefinite function that the data is\nfollowing so it will not make sense to\ndo a time series analysis\nnow before performing any time series\nanalysis\nthe data has to be stationary and\ntypically time series data is not\nstationary so in which case you need to\nmake the data stationary before we apply\nany models like arima model or any of\nthese right so what exactly is\nstationary data and what is meant by\nstationary data let us take a look first\nof all what is non-stationary data time\nseries data if you recall from one of my\nearlier slides we said that time series\ndata has the following four components\nthe trend seasonality cyclicity and\nrandom random component or irregularity\nright so if these components are present\nin time series data it is non-stationary\nwhich means that typically these\ncomponents will be present therefore\nmost of the time a time series data that\nis collected raw data is non-stationary\ndata so it has to be changed to\nstationary data before we apply any of\nthese algorithms\nall right so a non stationary time\nseries data would look like this which\nmeans like for example here there is an\nupward trend the seasonality component\nis there and\nalso the random component and so on so\nif the data is not stationary then the\ntime series forecasting will be affected\nso you cannot really perform a time\nseries forecasting on a non-stationary\ndata so how do we differentiate between\na stationary and a non-stationary time\nseries data typically or technically one\nis of course you can do it visually in\nnon-stationary data the the data will be\nmore flattish the seasonality will of\ncourse be there but the trend will not\nbe there so the data may if we plot that\nit may appear somewhat like this right\nit's a horizontal line along the\nhorizontal line you will see compared to\nthe original data which was there was an\nupward trend so it was changing somewhat\nlike this right so this is\nnon-stationary data and this is our\nstationary data would look visually what\ndoes this mean technically this means\nthat stationarity of the data depends on\na few things what the mean the variance\nand the covariance so these are the\nthree components on which the\nstationarity of the data depends so\nlet's take a look at what each of these\nare for stationary data the mean should\nnot be a function of time which means\nthat the mean should pretty much remain\nconstant over a period of time right so\nthere is there shouldn't be any change\nuh so this is how the stationary data\nwould look and this is how a\nnon-stationary data would look as shown\nin the previous slide as well so here\nthe mean is increasing that means there\nis an upward trend okay so that is one\npart of it and then the variance of the\nseries should not be also a function of\ntime so the variance also should be\npretty much common or\nshould be constant rather so this is a\nif we visually we take a look this is\nhow time series stationaries data would\nlook where the variance is not changing\nhere the variance is changing therefore\nthis is non-stationary and we cannot\napply type series forecasting on this\nkind of data similarly the covariance\nwhich is basically of the ith term and\nthe i plus m term should not be a\nfunction of time as well so covariance\nis nothing but not only the variance\nat the i-th term but the relation\nbetween the variance at the i-th term\nand the i plus m-m-th or the i-plus and\nthat term so as again once again\nvisually this is how it would look if\nthe covariance is also changing with\nrespect to time so these are the three\nall three components should be pretty\nmuch constant that is when you have\nstationary data and in order to perform\ntime series analysis the data should be\nstationary okay so let's take a look at\nthe concept of moving average or the\nmethod of moving average and let's see\nhow it works we'll do simple\ncalculations so let's say this is our\nsample data we have the data for three\nmonths january february march the sales\nin hundreds of in thousands rather not\nhundreds thousands of dollars is given\nhere and now we want to find the moving\naverage so how do we find the moving\naverage we call it as moving average\nthree so moving average three is nothing\nbut you take three of the values or the\nreadings add them up and uh divide by\nthree basically the way we take a mean\nor average of the three values so that\nis as simple as that so that's the\naverage first of all so what is moving\naverage moving averages if you now have\na series of data you keep taking the\nthree values the next three values and\nthen you take the average of that and\nthen the next three values and so on and\nso forth so that is how you take the\nmoving average so let's take a little\nmore detailed example of car sales so\nthis is how we have the car sales data\nfor the entire year let's say so rather\nfor four years so year one we have for\neach quarter quarter one two three four\nand then year two quarter one two three\nfour and so on and so forth so this is\nhow we have sales data of a particular\ncar let's say or a showroom and\nwe want to forecast for year five so we\nhave the data for four years we now want\nto forecast for the fifth year let's see\nhow it works first of all if we plot the\ndata as it is uh taken the raw data this\nis how it would look and uh what do you\nthink it is is it stationary no right\nbecause there is a trend upward trend so\nthis is not a stationary data so we um\nwe need to later we will see how to make\nit stationary but to start with just an\nexample we will not worry about it for\nnow we will just go ahead and manually\ndo the\nforecasting using what is known as\nmoving average method okay so we are not\napplying any algorithm or anything like\nthat in the next video we will see how\nto apply an algorithm how to make it\nstationary and so on all right so\nhere we see that all the three or four\ncomponents that we talked about um are\nthere there is a trend there is a\nseasonality and then of course there is\nsome random component as well cyclicity\nmay not be it is possible that cyclicity\nis not applicable in all the situations\nfor sales especially there may not be\nunless you're taking a sales for maybe\n20 30 years cyclicity may not come into\nplay so we will just consider uh\nprimarily the trend seasonality and\nirregularity right so random it is also\nknown as random irregularity right so we\nwere calling the random or irregularity\ncomponent so these are the three main\ncomponents typically in this case we\nwill talk about so this is the trend\ncomponent and\nwe will see how to do these calculations\nso let's take a look\nredraw the table including the time code\nwe will add another column which is the\ntime code and uh this is the column and\nwe'll just number it like one two three\nfour up to 16. the rest of the data\nremains the same okay so we will do the\ncalculations now now let us do the\nmoving average calculations um or ma4 as\nwe call it for each year so we take all\nthe four quarters and we take an average\nof that so if we add up these four\nvalues and divide by four you get the\nmoving average of 3.4 so we start by\nputting the value here so that will be\nfor the third quarter let's say one two\nthree the third quarter then we will go\non to the next one so we take the next\nfour values as you see here and take the\naverage of that which is the moving\naverage for the next quarter and so on\nand so forth now if we just do the\nmoving average it is not centered so\nwhat we do is we basically add one more\ncolumn and we calculate the centered\nmoving average as shown here so here\nwhat we do is we take the average of two\nvalues and then just adding these values\nhere so for example the first value for\nthe third quarter is actually the\naverage of the third and the fourth\nquarter so we have 3.5 now it gets\ncentered so similarly the next value\nwould be 3.6 plus 3.9 divided by 2 so\nwhich is 3.7 and so on and so forth okay\nso that is the centered moving average\nthis is done primarily to smoothen the\ndata so that there are not too many\nrough edges so that is what we do here\nso\nif we visualize this data now uh this is\nhow it looks right so\nif we take the centered moving average\nas you can see there is a gradual\nincrease if this was not the case if we\nhad not centered it the changes would\nhave been much sharper so\nthat is the basically the smoothing that\nwe are talking about now let's go and or\ndo the forecast for the fifth year so in\norder to do the forecast what we will do\nis we will take the centered moving\naverage as our baseline and then start\ndoing a few more calculations that are\nrequired in order to come up with the\nprediction so what we are going to do is\nwe are going to use this multiplicity or\nmultiplicative model in this case and\nthis is how it it looks so we take the\nproduct of seasonality and\nthe trend and the irregularity\ncomponents and we just multiply that and\nin order to get that this product of\nthese two we have basically the actual\nvalue divided by cma yt value divided by\ncma will give you the predicted value of\nyt is equal to the product of all three\ncomponents therefore\nt into y t is equal to y t by c m a so\nthis is like this is equal to y t right\nso therefore if we want st into y t the\nproduct of seasonality and irregularity\nit is equal to y t by c cma so that is\nhow we will work it out i also have an\nexcel sheet of the actual data so let me\njust pull that up all right so this is\nhow the data looks in excel as you can\nsee here year one quarter one two three\nfour here two quarter one two three four\nand so on and this is the sales data and\nthen this is the moving average as i\nmentioned this is how we calculate and\nthis is the centered moving average so\nthis is the primary component that we\nwill start working with and then we will\ncalculate since we want the product of\nsc into yt that is equal to yt by cma so\nif you see these values are nothing but\nthe yt value divided by cma so in this\ncase it is 4 by 3.5 which is 1.14\nsimilarly 4.5 by 3.7 1.22 and so on and\nso forth so we take we have the product\nas tm2i t and then the next step is to\ncalculate the average of\nrespective quarters so that is what we\nare doing here average of respective\nquarters and then we need to calculate\nthe decisionalized values so in order to\nget decisionalized value we need to\ndivide yt by\nst that was calculated so for example\nhere it is 2.8 by 0.9 so we got the\ndecisionalized value here and\nthen we get the trend and then we get\nthe predicted values so in order to get\nthe predicted value which is basically\nwe predict the values for known values\nas well like for example here one\nquarter one we know the value but now\nthat we have our model we predict\nourselves and see how close it is so we\npredicted as 2.89 whereas the actual\nvalue is 2.8 then we have 2.59 the\nactual value is 2.1 and so on just to\nsee how our model works and then\ncontinue that into the fifth year\nbecause for fifth year we don't have a\nreference value okay and if we plot this\nwe will come to know how well our\ncalculations are how well our manual\nmodel in this case we did not really use\na model but we did on our own manually\nso it will tell us the trend so for\nexample the predicted value is this gray\ncolor here and you can see that it is\nactually pretty much following the\nactual value which is the blue color\nright and the gray color is the\npredicted value so the wherever we know\nthe values up to year 4 we can see that\nour predicted values are following or\npretty much very close to the actual\nvalues and then from here onwards when\nthe year 5 starts the blue color line is\nnot there because we don't have the\nactual values only the predicted value\nso we can see that since it was\nfollowing the trend pretty much for the\nlast four years we can safely assume\nthat it has understood the pattern and\nit is predicting correctly for the next\none year the next four quarters right so\nthat is what we are doing here so these\nfour quarters we did not have actual\ndata but we have the predicted values so\nlet's go back and see how this is\nworking in this using the slides so this\nis we already saw this part and\ni think it was easier to see in the\nexcel sheet so we calculated the st i t\nthe product of s t and i t using the\nformula like here y by y t by c m a we\ngot that and then we got st which is\nbasically yt so this is the average of\nthe first quarters for all the four\nyears and\nsimilarly this is the average of the\nsecond quarter for all the four years\nand so on so these values are repeating\nthese are they are calculated only once\nthey get repeated as you can see here\nand\nthen we get the decisionalized data and\nthat is basically yt by st so we\ncalculated st here and we have yt so yt\nby st will give you the dc analyze data\nand\nwe have got rid of the seasonal and the\nirregular components so far now what we\nare left with is the trend and\nbefore we\nstart the time series forecasting time\nseries analysis as i mentioned earlier\nwe need to completely get rid of the\nnon-stationary components so we are\nstill left with the trend component so\nnow let us also remove the trend\ncomponent in order to do that we have to\nfind the or we have to calculate the\nintercept and slope of the data because\nthat is required to calculate the trend\nand uh how are we going to do that we\nwill actually use um what is known as a\nregression tool or analytics tool that\nis available in excel so you remember we\nhave our data in excel so let me take\nyou to the excel and\nhere we need to calculate the intercept\nand the slow in order to do that we have\nto use the regression mechanism and in\norder to use the regression mechanism we\nhave to use the analytics tool that\ncomes with excel so how do you\nactivate this tool so this is how you\nwould need to activate the tool uh from\nexcel you need to go to options\nand\nin options\nthere will be add-ins and\nin add-ins you will have um analysis\ntool back and you select this\nand\nyou just say go it will open up a box\nlike this you say analysis tool pack and\nyou say okay and now when you come back\nin to the regular view of excel in the\ndata tab you will see data analysis\nactivated so you need to go to file\noptions\nand add-ins\nand then analysis tool pack typically\nsince i've already added it it is coming\nat the top but it would\ncome under inactive application add-ins\nso when you're doing it for the first\ntime so don't use vba you just say\nanalysis tool back there are two options\none with vba like this one and one\nwithout vba so just use the one without\nvba and then instead of just saying okay\njust take care that you click on this go\nand not just okay so you say go then it\nwill give you these options only then\nyou select just the analysis tool pack\nand then you say okay all right so\nand then when you come back to the main\nview you click on data okay so this is\nyour normal home view perhaps so you\nneed to come to data and here is where\nyou will see data analysis available to\nyou and then if you click on that there\nare a bunch of possibilities what kind\nof data analysis you want to do if there\nare options are given right now we just\nwant to do regression because we want to\nfind the slope and the intercept so\nselect regression and you say ok\nand you will get these options for input\ny range and input x range input y range\nis the value yt so you just select this\nand you can select up to here and press\nenter and input x range you can for now\nyou start with uh the baseline or you\ncan also start with the d seasoned\nvalues so you can just click on these\nand say okay\ni have already calculated it so these\nare the intercept and the coefficients\nthat we are getting for these values and\nwe will actually use that to calculate\nour trend here right so which is in the\nj column so our trend is equal to\nintercept plus slope into the time code\nso\nthe intercept is\nout here as we can see in our slide as\nwell so if you see here this is our\nintercept and the lower value is the\nslope we have calculated here and it's\nshown in the slides as well so intercept\nso the formula is shown here so our\ntrend is equal to intercept plus slope\ninto time code time code is nothing but\nthis one t column a one two three four\nokay so that's how you calculate the\ntrend and that's how you use the data\nanalysis tool from excel using these two\nwe calculate the predicted values and\nusing this formula which is basically\ntrend is equal to intercept plus slope\ninto time code and then we can go and\nplot it see how it is\nlooking and therefore so we see here\nthat the predicted values are pretty\nclose to the actual values and\ntherefore we can safely assume that our\ncalculations which are like our manual\nmodel is working and hence we go ahead\nand predict for the fifth year so till\nfour years we know the actual value as\nwell so we can compare our model is\nperforming and for the fifth year we\ndon't have reference values so we can\nuse our equations to calculate the\nvalues or predict the values for the\nfifth year and we can go ahead and\nsafely calculate those values and when\nwe plot for the fifth year as well the\npredicted values we see that they are\npretty much they captured the pattern\nand we can safely assume that the\npredictions are fairly accurate as we\ncan also see from the graph in the excel\nsheet that we have already seen okay so\nlet's go and plot it so this is how the\nplot looks this is the cma or the\ncentred moving average the green color\nand then the blue color is the actual\ndata red color is the predicted value\npredicted by our hand crafted model okay\nso remember we did not use any regular\nforecasting model or any tool we have\ndone this manually and\nthe actual tool will be used in the next\nvideo this is just to give you an idea\nabout how behind the scenes or under the\nhood how forecasting works or time\nseries analysis how it is performed okay\nso it looks like it has captured the\ntrend properly so up to here is the\nknown difference we have reference and\nfrom here onwards is purely predicted\nand\nas i mentioned earlier we can safely\nassume that the values are accurate and\npredicted properly for the fifth year so\nlet's go ahead and implement a time\nseries forecast in r first of all we\nwill be using the arimo model to do the\nforecast of this time series data so let\nus try to understand what is arima model\nso arima is actually an acronym it\nstands for autoregressive integrated\nmoving average so that is what is arima\nmodel and it is specified by three\nparameters which is p d and q p stands\nfor auto regressive so let me just mark\nthis so there are three components here\nauto regressive integrated moving\naverage okay so these three parameters\ncorrespond to those three components so\nthe p stands for auto regressive d for\nintegrated and q for moving average so\nlet us see what exactly this is so these\nthree factors are p is the number of\nautoregressive terms or ar we will see\nthat in a little bit and d is how many\nlevels of differences that we need to do\nor differentiation we need to do and q\nis the number of lagged forecast errors\nso we'll see what exactly each of these\nare so ar is the number of\nautoregressive terms and which is\nbasically denoted by the p\nand then we have d which is for the\nnumber of times it has to be\ndifferentiated\nand then we have q which is for\nthe moving average so what exactly are\nterms so in terms of the regression\nmodel autoregressive components\nrefer to the prior values of the current\nvalue what we mean by that is here when\nwe talk about time series data focus on\nthe fact that there is regression so\nwhat exactly happens in regression we\ntry to do something like if it is simple\nlinear regression we do some equation\nlike y is equal to mx plus c where there\nare actually there are two variables one\nis the dependent variable and then there\nis an independent variable let me just\ncomplete this equation as well mx plus c\nright so this is a normal regression\ncurve or a simple regression curve now\nhere we are talking about auto\nregression or or autoregressive so\nautoregressive as the name suggests is\nregression of itself so which means that\nhere you have only one variable which is\nyour maybe the cost of the flights or\nwhatever it is right and the other\nvariable is basically time dependent and\ntherefore the value at any given time\nand that we will denote as y t for\nexample so there is no x here there is\nonly one variable and which is y and we\nsay y t which is basically the predicted\nvalue at a time interval t for example\nis dependent on the previous value so\nfor example there may be a one and then\ny t minus one and then there will be\nlike plus a 2 and right plus a 2 and y t\nminus 2 and\nall right and then plus a 3 into y t\nminus 3 all right so basically here what\nwe're saying is there's only one\nvariable here but there is a regression\ncomponent so we are doing a regression\non itself so that's how the term auto\nregression comes into play so only thing\nis that it is dependent on the previous\ntime values so there is a lag let's say\nthis is the first lag second lag third\nlag and so on so the current value which\nis y t is dependent on the previous time\nlag values so that is what is not a\nregression component so this is what is\nshown here for example in this case\ninstead of y we are calling it as x so\nthat's the same and this is represented\nby some equation of that sort depending\non how many lags we take so that is the\nar component and the term p is basically\ndetermines how many lags we are\nconsidering so that's the p4 now what is\nd d is the degree of differencing so\nhere differencing is like to for the\nnon-seasonal differences right so for\nexample if you take the values like this\nwhich are given for 5 4 6 and so on and\nso forth if you take the differencing of\none after another like for example 5\nminus 4 or 4 minus 5 the next value with\nthe previous value so 4 minus 5. so this\nis known as the first order differencing\nso the result is minus 1 similarly 6\nminus 4 is 2 7 minus 6 is 1. so this is\nfirst order differencing and\nhere we call it as d is equal to one\nokay and same way we can have second\norder third order and so on then the\nlast one is q q is the actually we call\nit moving average but in reality it is\nactually the error of the model so we\nalso sometimes represent as e t all\nright so now arima model works on the\nassumption that the data is stationary\nwhich means that the trend and\nseasonality of the data has been removed\nthat is correct okay so this we have\ndiscussed in the first part how what\nexactly is stationary data and how do we\nremove the non-stationary part of it now\nin order to test whether the data is\nstationary or not there are two\nimportant components that are considered\none is the autocorrelation function and\nthe other is the partial autocorrelation\nfunction so this is referred to as acf\nand tsef right so what is\nautocorrelation and what is the\ndefinition or the correlation is\nbasically the similarity between values\nof a same variable across observations\nas the name suggests now how do we\nactually find the autocorrelation\nfunction the value right so this is\nbasically done by plotting and\nautocorrelation function also tells you\nhow correlated points are with each\nother based on how many time steps they\nare separated by and so on that is\nbasically the time lag that we were\ntalking about and it is also used to\ndetermine how past and future data\npoints are related and the value of the\nautocorrelation function can vary from\nminus one to one so if we plot this is\nhow it would look autocorrelation\nfunction would look somewhat like this\nand there is actually a readily\navailable function in r so we will see\nthat and you can use that to plot your\nautocorrelation function okay so that is\nacf and we will see that in our r studio\nin a little bit and similarly you have\npartial autocorrelation function so\npartial autocorrelation function is the\ndegree of association between two\nvariables while adjusting the effect of\none or more additional variables so this\nagain can be measured and it can also be\nplotted and its value once again can go\nfrom -1 to 1 and it gives the partial\ncorrelation of time series with its own\nlagged values so lag again we have\ndiscussed in the previous couple of\nslides this is how a psef plot would\nlook in our studio we will see that as\nwell and once we get into the r studio\nand with that let's get into r studio\nand take a look at our use case before\nwe go into the code let's just quickly\nunderstand what exactly is the objective\nof this use case so we are going to\npredict some values or forecast some\nvalues and we have the data of the\nairline ticket sales of the previous\nyears and now we will try to find the or\npredict or forecast the values for the\nfuture years all right so\nwe will basically\nidentify the time series components like\ntrend seasonality and\nrandom behavior we will actually\nvisualize this in our studio and then we\nwill actually forecast the values based\non the past values or history data\nhistorical data so these are the steps\nthat we follow we will see in our studio\nin a little bit just quickly let's go\nthrough what are the steps we load the\ndata and it is a time series data and we\ntry to find out what class it belongs to\nthe data is actually air passengers data\nthat is already comes pre-loaded with\nrstudio so we will be using that and we\ncan take a look at the data and then\nwhat is the starting point what is the\nend point so these are all functions\nthat are really available we'll be using\nand then what is the frequency there's\nbasically frequency is 12 which is like\nyearly data right so every month the\ndata has been collected so for each year\nit is 12 and then we can check for many\nmissing values if there are any and then\nwe can take a look at the summary of the\ndata this is what we do in exploratory\ndata analysis and then we can plot the\ndata visualize the data how it is\nlooking and we will see how the data has\nsome trend seasonality and so on and so\nforth all right then we can take a look\nat the cycle of the data using the cycle\nfunction and we can see that it is every\nmonth that's the cycle and of every 12\nmonths\na new cycle begins so each month of the\nyear as\nthe data is available then we can do box\nplots to see for each month how the data\nis varying over the various 10 or 12\nyears that we will be looking at this\ndata and\nfrom\nexploratory data analysis we can\nidentify that there is a trend there is\na seasonality component and how the\nseasonality component varies also we can\nsee from the box plots and we can\ndecompose the data we can use the\ndecomposed function rather to see the\nvarious components like the seasonality\ntrend and the irregularity part okay so\nwe will see all of this in our studio\nthis is how they will look this is the\nonce you decompose and this is how you\nwill actually you can visualize the data\nthis is the actual data and this is the\ntrend as you can see it's going upwards\nthis is the seasonal component and this\nis your random or irregularity right so\nwe call it irregularity or we can also\ncall it random as you can see here yes\nso the data must have a constant\nvariance and mean which means that it is\nstationary before we start any analysis\ntime series analysis and we thought so\nbasically if it is stationary only then\nit is easy to model the data perform\ntime series analysis so we can then go\nahead and fit the model as we discussed\nearlier we'll be using arima model there\nare some techniques to find out what\nshould be the parameter so we will see\nthat when we go into rstudio so\nthe auto arima function basically tells\nus what should be the parameters right\nso these parameters are the p d and q\nthat we talked about that's what is\nbeing shown here so if we use auto arima\nit will basically take all possible\nvalues of this pdq these parameters and\nit will find out what is the best value\nand then it will\nrecommend so that is the advantage of\nusing auto arima all right so like in\nthis case it will tell us what if we use\nthis parameter trace we set the\nparameter trace is equal to true then it\nwill basically tell us what is the value\nof this aic which has to be minimum so\nthe lower the value the better so for\neach of these combinations of b d and q\nit will give us the values here and then\nit will recommend to us which is the\nbest model okay because whichever has\nthe lowest value of this aic it will\nrecommend that as your best pdq values\nso once we have that we can see that we\nwill basically we can potentially get a\nmodel or the equation model is nothing\nbut the equation and based on the\nparameters that we get and we can do\nsome diagnostics we can do some plotting\nto see how whether there is a plot for\nthe residuals so which shows the\nstationarity and then we can also take a\nlook at the acf and pscf we can plot the\nacf and psef and then we can do some\nforecasting for the future here so in\nthis case we have up to 1960 and then we\ncan see how we can forecast for the next\n10 years which is 1970 up to 1970 and\nonce we have done this can we validate\nthis model yes definitely we can\nvalidate this model and\nto validate the findings we use uh\njunkbox test and this is how you just\ncall box.test and then you pass these\nparameters and you will get the values\nthat will be returned which will tell us\nwhether this how accurate this model is\nhow accurate the connections are so the\nvalues of p are quite insignificant in\nthis case we will see that and that also\nindicates that our model is free of\nautocorrelation and that will basically\nbe it so let's go back and into our\nrstudio and\ngo through these steps in real time so\nwe have to import this library forecast\npackage is not installed you have to go\nhere and install the forecast package\nokay so that's the easy way to install\nrather than so click on this install i\nwill not do it now because i have\nalready installed so the first time\nthat's only one time then after that you\njust have to load it into memory and\nthen keep going so we will load this\ndata called air passengers so\nby calling this data method and if you\nsee the the data passengers is loaded\nhere and if we check for the class it is\na time series data ts data so we can\ncheck for the dates we can also view the\ndata in a little bit and start date is\n1949 and january\nand our end date is 1960 december\nand the frequency is 12 which is\nlike collected monthly so\nthat is the frequency which is uh 12\nhere and then we\ncheck if there are any missing values\nthere are no missing values and then we\ntake a look at the summary of the data\nthis is all exploratory data analysis\nand then if you just display the data\nthis is how it looks\nand then we need to decompose this data\nso we will kind of\nstore this in an object ts data and then\nuse that to decompose and store the new\nvalues let me just clear this for now\nand\nif we decompose basically as we have\nseen in the slides decomposing is\nbreaking it into the trend seasonality\nand the irregular or random components\nthen you can go ahead and plot it so\nwhen you plot it you can see here let me\nzoom this this is our original plot or\nobserved value as it is known as then we\nhave decomposed the three parts which is\nbasically the trend as you can see there\nis a poor trend then the seasonal\ncomponent so this is a some regularly\noccurring pattern and then there is a\nrandom value which is basically you\ncannot really give any equation or\nfunction or anything like that so that's\nwhat this plotting has done and then you\ncan actually plot them individually as\nwell so these are the individual plots\nfor the trend for the seasonal component\nand the random component all right so\nnow let's take a look at the original\ndata and see how the trend is in a way\nso if we do this linear regression line\nit will show that it is going upwards\nand we can also take a look at the cycle\nthat are there which is nothing but we\nhave a frequency of 12 right so the\ncycles will display that it is january\nfebruary to december and then back to\njanuary february and so on and so forth\nand if we do box plots for the monthly\ndata you will see that for each of the\nmonths right and over the 10 years that\nthe data that we have we will see that\nthere is a certain pattern right this is\nalso in a way to find the seasonality\ncomponent so\nwhile january february sales are\nrelatively low around july august the\nsales pick up so especially in july i\nthink the sales are the highest and this\nseems to be happening pretty much every\nyear right so this is every year in july\nthere seems to be a peak in the sales\nand then it goes down and slightly\nhigher in december and so on so that is\nagain part of our exploratory data\nanalysis and once again let's just plot\nthe data now as i said in order to fit\ninto an arima model we need the values\nof pd and q now one way of doing it is\nthere are multiple ways actually of\ndoing it the earlier method of doing it\nwas you draw the autocorrelation\nfunction plot and then partial\nautocorrelation function plot and then\nobserve that and where does this change\nand then identify what should be the\nvalues of p and q and so on now r really\nhas a very beautiful\nmethod which we can use to avoid all\nthat manual process that we used to do\nearlier so what r will do is there is a\nmethod called auto arima and if we just\ncall this auto arima method and it will\nbasically go and test the arima model\nfor all possible values of this\nparameters pdq and then it will suggest\nto you what should be the best model and\nit will return that best model with the\nright values of pd and q so you we as\ndata scientists don't have to do any\nmanual you know trial and error kind of\nstuff okay so we got the model now and\nuh this is the model it it has pdq\nvalues r211 pdq and this is the seasonal\npart of it so we can ignore it for now\nand so if we want to actually understand\nhow this has returned these values 2 1 1\nas the best one there is another\nfunctionality or feature where we can\nuse this trace function or trace\nparameter so if you pass to auto arima\nthe trace parameter what it will do is\nit will show you how it is doing this\ncalculation what is the value of the aic\nbasically asc is what you know defines\nthe accuracy of the model the lower the\nbetter okay so for each combination of\npdq it will show us the value of aic so\nlet's run it before instead of me\ntalking so much let's run this if we run\nauto arima with trace you see here there\nis a red mark here that means it is\nperforming it's executing this and here\nwe see the display right so it starts\nwith certain values of pdq and then it\nfinds that value is too high so it\nstarts with again with some 0 1 1 0 and\nso on and so forth and ultimately it\ntells us okay this is our best model you\nsee here it says this is our best model\n2 1 1. let's go back and see did we get\nthe same one yes we got the same one\nwhen we ran without trace as well right\nnow y is 2 1 1 let us see where is 2 1 1\nhere is our 2 1 1 and if you compare the\nvalues you see that 1 0 1 7 is pretty\nmuch the lowest value and therefore it\nis saying this is our best model all\nother values are higher so that's how\nyou kind of\nget your model and now that you have\nyour model what you have to do you need\nto predict the values right so before\nthat let us just do some tests of these\nvalues so for that you install t series\nagain if you are doing it for the first\ntime you would rather use this package\nand install and say t series and install\nit and then you just use this library\nfunction to load it into your memory all\nright so now that we got our model using\nauto arima let us go ahead and forecast\nand also test the model and also plot\nthe acf and pscf remember we talked\nabout this but we did not really use it\nwe don't have to use that but at least\nwe will visualize it and for some of the\nstuff we may need this t series\nlibrary so if you are doing this for the\nfirst time you may have to install it\nand my recommendation is don't use it in\nthe code you go here and install t\nseries and i will not do it now because\ni have already installed it but this is\na preferred method and once you install\nit you just load it using this library's\nfunction and then you can plot your\nresiduals and this is how the residuals\nlook and you can plot your acf and psef\nokay so this is how your psef looks and\nthis is how your acf looks for now there\nis really nothing else we need to do\nwith acf and psef is just to visualize\nhow that how it looks but as i mentioned\nearlier we were actually using these\nvisualizations of these graphs to\nidentify the values of p d and q and how\nthat was done it's\nout of scope of this video so we will\nleave it at that and\nthen we will forecast for the next 10\nyears how do we focus that so we call\nforecast and we pass the model and we\npass what is the level of accuracy that\nyou need which is 95 percent and for how\nmany periods right so basically we want\nfor 10 years which is like 10 into 12\ntime periods so that's what we are doing\nhere and now we can plot the forecast\nvalue so you see this is the original\nvalue up to i think 62 or whatever and\nthen it goes up to 72 this blue color is\nthe predicted value let's go and zoom it\nup so that we can see it better so from\nhere onwards your forecasting and you\ncan see that it looks like our model has\nkind of learned the pattern and this\npattern looks very similar to what we\nsee in the actual data now how do we\ntest our\nmodel so we can do what is known as a\nbox test and we pass our model here\nresiduals basically with different lags\nand from those values here the p values\nhere we find that they are reasonably\nlow p values which means our model is\nfairly accurate with that we come to the\nend of this video i hope you enjoyed\nthis thank you very much once again for\njoining and if you have any comments or\nquestions please put it at the bottom of\nthe video and preferably with some\ncontact information so that we can get\nback to you and you have a great day\nthank you once again bye\nhi there if you like this video\nsubscribe to the simply learn youtube\nchannel and click here to watch similar\nvideos turn it up and get certified\nclick here\n",
  "words": [
    "hello",
    "welcome",
    "session",
    "time",
    "series",
    "forecasting",
    "video",
    "going",
    "talk",
    "time",
    "series",
    "forecasting",
    "going",
    "cover",
    "video",
    "first",
    "time",
    "series",
    "talk",
    "exactly",
    "time",
    "series",
    "data",
    "components",
    "time",
    "series",
    "data",
    "like",
    "example",
    "trend",
    "seasonality",
    "explain",
    "components",
    "also",
    "talk",
    "use",
    "time",
    "series",
    "analysis",
    "explain",
    "stationary",
    "data",
    "terms",
    "time",
    "series",
    "significance",
    "stationary",
    "data",
    "typically",
    "time",
    "series",
    "data",
    "stationary",
    "make",
    "time",
    "series",
    "data",
    "stationary",
    "take",
    "example",
    "car",
    "sales",
    "data",
    "show",
    "solve",
    "time",
    "series",
    "perform",
    "time",
    "series",
    "analysis",
    "manually",
    "without",
    "using",
    "tool",
    "second",
    "part",
    "actually",
    "use",
    "r",
    "thing",
    "r",
    "okay",
    "without",
    "delay",
    "let",
    "get",
    "started",
    "exactly",
    "need",
    "time",
    "series",
    "analysis",
    "typically",
    "would",
    "like",
    "predict",
    "something",
    "future",
    "could",
    "stock",
    "prices",
    "could",
    "sales",
    "anything",
    "needs",
    "predicted",
    "future",
    "use",
    "time",
    "series",
    "analysis",
    "name",
    "suggests",
    "forecasting",
    "typically",
    "say",
    "predict",
    "need",
    "future",
    "machine",
    "learning",
    "data",
    "analysis",
    "talk",
    "predicting",
    "necessarily",
    "talking",
    "future",
    "time",
    "series",
    "analysis",
    "typically",
    "predict",
    "future",
    "past",
    "data",
    "want",
    "predict",
    "future",
    "perform",
    "time",
    "series",
    "analysis",
    "examples",
    "could",
    "daily",
    "stock",
    "price",
    "shares",
    "talk",
    "could",
    "interest",
    "rates",
    "weekly",
    "interest",
    "rates",
    "sales",
    "figures",
    "company",
    "examples",
    "use",
    "time",
    "series",
    "data",
    "historical",
    "data",
    "dependent",
    "time",
    "based",
    "create",
    "model",
    "predict",
    "future",
    "exactly",
    "time",
    "series",
    "time",
    "series",
    "data",
    "time",
    "one",
    "components",
    "name",
    "suggests",
    "example",
    "let",
    "say",
    "stock",
    "price",
    "data",
    "one",
    "components",
    "two",
    "columns",
    "column",
    "b",
    "price",
    "column",
    "basically",
    "time",
    "information",
    "case",
    "time",
    "day",
    "primarily",
    "closing",
    "price",
    "particular",
    "stock",
    "recorded",
    "daily",
    "basis",
    "time",
    "series",
    "data",
    "time",
    "interval",
    "obviously",
    "day",
    "time",
    "series",
    "time",
    "intervals",
    "daily",
    "weekly",
    "hourly",
    "even",
    "sometimes",
    "something",
    "like",
    "sensor",
    "data",
    "could",
    "every",
    "milliseconds",
    "microseconds",
    "well",
    "size",
    "time",
    "intervals",
    "vary",
    "fixed",
    "saying",
    "daily",
    "data",
    "interval",
    "fixed",
    "uh",
    "daily",
    "saying",
    "data",
    "hourly",
    "data",
    "data",
    "captured",
    "every",
    "year",
    "time",
    "intervals",
    "fixed",
    "interval",
    "decide",
    "based",
    "kind",
    "data",
    "capturing",
    "graphical",
    "representation",
    "previous",
    "one",
    "saw",
    "table",
    "representation",
    "plot",
    "data",
    "let",
    "say",
    "price",
    "stock",
    "price",
    "time",
    "time",
    "plot",
    "time",
    "series",
    "graph",
    "would",
    "look",
    "name",
    "suggests",
    "time",
    "series",
    "data",
    "time",
    "series",
    "data",
    "basically",
    "sequence",
    "data",
    "recorded",
    "specific",
    "intervals",
    "time",
    "based",
    "past",
    "values",
    "want",
    "analysis",
    "time",
    "series",
    "past",
    "data",
    "try",
    "forecast",
    "future",
    "name",
    "suggests",
    "time",
    "series",
    "data",
    "means",
    "time",
    "dependent",
    "time",
    "one",
    "components",
    "data",
    "time",
    "series",
    "data",
    "consists",
    "primarily",
    "four",
    "components",
    "one",
    "trend",
    "seasonality",
    "cyclicity",
    "last",
    "least",
    "irregularity",
    "random",
    "component",
    "sometimes",
    "also",
    "referred",
    "random",
    "component",
    "let",
    "see",
    "components",
    "trend",
    "trend",
    "overall",
    "change",
    "pattern",
    "data",
    "means",
    "data",
    "may",
    "let",
    "uh",
    "pull",
    "pen",
    "show",
    "let",
    "say",
    "data",
    "set",
    "somewhat",
    "like",
    "time",
    "series",
    "data",
    "set",
    "somewhat",
    "like",
    "right",
    "overall",
    "trend",
    "overall",
    "trend",
    "upward",
    "trend",
    "call",
    "right",
    "like",
    "continuously",
    "increasing",
    "times",
    "dipping",
    "times",
    "increasing",
    "decreasing",
    "overall",
    "period",
    "time",
    "time",
    "start",
    "recording",
    "time",
    "end",
    "trend",
    "right",
    "upward",
    "trend",
    "case",
    "trend",
    "need",
    "always",
    "upwards",
    "could",
    "downward",
    "trend",
    "well",
    "example",
    "downward",
    "trend",
    "right",
    "basically",
    "trend",
    "overall",
    "whether",
    "data",
    "increasing",
    "decreasing",
    "right",
    "next",
    "component",
    "seasonality",
    "seasonality",
    "seasonality",
    "name",
    "suggests",
    "changes",
    "period",
    "time",
    "periodic",
    "changes",
    "right",
    "certain",
    "pattern",
    "um",
    "let",
    "take",
    "sales",
    "warm",
    "clothes",
    "example",
    "plot",
    "along",
    "months",
    "let",
    "say",
    "january",
    "february",
    "march",
    "april",
    "may",
    "july",
    "let",
    "say",
    "goes",
    "december",
    "okay",
    "december",
    "mark",
    "jan",
    "feb",
    "march",
    "get",
    "another",
    "december",
    "okay",
    "simplicity",
    "let",
    "mark",
    "decembers",
    "end",
    "year",
    "one",
    "december",
    "okay",
    "happen",
    "talking",
    "warm",
    "clothes",
    "happens",
    "sales",
    "warm",
    "clothes",
    "increase",
    "probably",
    "around",
    "december",
    "cold",
    "come",
    "around",
    "december",
    "increase",
    "sales",
    "come",
    "increase",
    "come",
    "increase",
    "come",
    "let",
    "see",
    "sales",
    "pattern",
    "see",
    "trend",
    "well",
    "upward",
    "trend",
    "right",
    "sales",
    "increasing",
    "let",
    "say",
    "multiple",
    "years",
    "year",
    "one",
    "year",
    "two",
    "year",
    "three",
    "multiple",
    "years",
    "overall",
    "trend",
    "upward",
    "trend",
    "sales",
    "increasing",
    "continuous",
    "increase",
    "right",
    "certain",
    "pattern",
    "happening",
    "pattern",
    "every",
    "december",
    "sales",
    "increasing",
    "peaking",
    "particular",
    "year",
    "right",
    "new",
    "year",
    "december",
    "approaches",
    "sales",
    "increasing",
    "december",
    "approaches",
    "sales",
    "increasing",
    "forth",
    "known",
    "seasonality",
    "certain",
    "fluctuation",
    "periodic",
    "nature",
    "known",
    "seasonality",
    "cyclicity",
    "cyclicity",
    "cyclicity",
    "somewhat",
    "similar",
    "seasonality",
    "duration",
    "two",
    "cycles",
    "much",
    "longer",
    "seasonality",
    "typically",
    "referred",
    "annual",
    "kind",
    "sequence",
    "like",
    "example",
    "saw",
    "pretty",
    "much",
    "like",
    "every",
    "year",
    "month",
    "december",
    "sales",
    "increasing",
    "however",
    "cyclicity",
    "happens",
    "first",
    "duration",
    "pretty",
    "much",
    "fixed",
    "duration",
    "gap",
    "length",
    "time",
    "two",
    "cycles",
    "much",
    "longer",
    "recession",
    "example",
    "let",
    "say",
    "recession",
    "2001",
    "2002",
    "perhaps",
    "one",
    "2008",
    "probably",
    "2000",
    "2012",
    "forth",
    "like",
    "every",
    "year",
    "happens",
    "probably",
    "usually",
    "say",
    "recession",
    "slump",
    "recovers",
    "slump",
    "recovers",
    "probably",
    "another",
    "bigger",
    "slump",
    "right",
    "see",
    "similar",
    "seasonality",
    "first",
    "length",
    "much",
    "year",
    "right",
    "number",
    "one",
    "fixed",
    "well",
    "like",
    "every",
    "four",
    "years",
    "every",
    "six",
    "years",
    "duration",
    "fixed",
    "duration",
    "vary",
    "time",
    "gap",
    "two",
    "cycles",
    "much",
    "longer",
    "compared",
    "seasonality",
    "right",
    "irregularity",
    "irregularity",
    "like",
    "random",
    "component",
    "time",
    "series",
    "data",
    "like",
    "part",
    "trend",
    "tells",
    "whether",
    "overall",
    "increasing",
    "decreasing",
    "cyclicity",
    "seasonality",
    "like",
    "kind",
    "specific",
    "pattern",
    "right",
    "cyclicity",
    "pattern",
    "much",
    "longer",
    "intervals",
    "plus",
    "random",
    "component",
    "really",
    "accounted",
    "easily",
    "right",
    "random",
    "component",
    "really",
    "random",
    "name",
    "suggests",
    "right",
    "irregularity",
    "component",
    "various",
    "components",
    "time",
    "series",
    "data",
    "yes",
    "conditions",
    "use",
    "time",
    "series",
    "analysis",
    "right",
    "time",
    "series",
    "analysis",
    "kind",
    "data",
    "really",
    "situations",
    "time",
    "series",
    "analysis",
    "data",
    "collected",
    "period",
    "time",
    "really",
    "changing",
    "really",
    "make",
    "sense",
    "perform",
    "time",
    "series",
    "analysis",
    "right",
    "example",
    "like",
    "one",
    "take",
    "x",
    "time",
    "value",
    "whatever",
    "output",
    "talking",
    "value",
    "constant",
    "really",
    "analysis",
    "leave",
    "alone",
    "time",
    "series",
    "analysis",
    "right",
    "one",
    "another",
    "possibility",
    "yes",
    "change",
    "changing",
    "per",
    "fixed",
    "function",
    "like",
    "sine",
    "wave",
    "cos",
    "wave",
    "time",
    "series",
    "analysis",
    "make",
    "sense",
    "kind",
    "situation",
    "definite",
    "pattern",
    "definite",
    "function",
    "data",
    "following",
    "make",
    "sense",
    "time",
    "series",
    "analysis",
    "performing",
    "time",
    "series",
    "analysis",
    "data",
    "stationary",
    "typically",
    "time",
    "series",
    "data",
    "stationary",
    "case",
    "need",
    "make",
    "data",
    "stationary",
    "apply",
    "models",
    "like",
    "arima",
    "model",
    "right",
    "exactly",
    "stationary",
    "data",
    "meant",
    "stationary",
    "data",
    "let",
    "us",
    "take",
    "look",
    "first",
    "data",
    "time",
    "series",
    "data",
    "recall",
    "one",
    "earlier",
    "slides",
    "said",
    "time",
    "series",
    "data",
    "following",
    "four",
    "components",
    "trend",
    "seasonality",
    "cyclicity",
    "random",
    "random",
    "component",
    "irregularity",
    "right",
    "components",
    "present",
    "time",
    "series",
    "data",
    "means",
    "typically",
    "components",
    "present",
    "therefore",
    "time",
    "time",
    "series",
    "data",
    "collected",
    "raw",
    "data",
    "data",
    "changed",
    "stationary",
    "data",
    "apply",
    "algorithms",
    "right",
    "non",
    "stationary",
    "time",
    "series",
    "data",
    "would",
    "look",
    "like",
    "means",
    "like",
    "example",
    "upward",
    "trend",
    "seasonality",
    "component",
    "also",
    "random",
    "component",
    "data",
    "stationary",
    "time",
    "series",
    "forecasting",
    "affected",
    "really",
    "perform",
    "time",
    "series",
    "forecasting",
    "data",
    "differentiate",
    "stationary",
    "time",
    "series",
    "data",
    "typically",
    "technically",
    "one",
    "course",
    "visually",
    "data",
    "data",
    "flattish",
    "seasonality",
    "course",
    "trend",
    "data",
    "may",
    "plot",
    "may",
    "appear",
    "somewhat",
    "like",
    "right",
    "horizontal",
    "line",
    "along",
    "horizontal",
    "line",
    "see",
    "compared",
    "original",
    "data",
    "upward",
    "trend",
    "changing",
    "somewhat",
    "like",
    "right",
    "data",
    "stationary",
    "data",
    "would",
    "look",
    "visually",
    "mean",
    "technically",
    "means",
    "stationarity",
    "data",
    "depends",
    "things",
    "mean",
    "variance",
    "covariance",
    "three",
    "components",
    "stationarity",
    "data",
    "depends",
    "let",
    "take",
    "look",
    "stationary",
    "data",
    "mean",
    "function",
    "time",
    "means",
    "mean",
    "pretty",
    "much",
    "remain",
    "constant",
    "period",
    "time",
    "right",
    "change",
    "uh",
    "stationary",
    "data",
    "would",
    "look",
    "data",
    "would",
    "look",
    "shown",
    "previous",
    "slide",
    "well",
    "mean",
    "increasing",
    "means",
    "upward",
    "trend",
    "okay",
    "one",
    "part",
    "variance",
    "series",
    "also",
    "function",
    "time",
    "variance",
    "also",
    "pretty",
    "much",
    "common",
    "constant",
    "rather",
    "visually",
    "take",
    "look",
    "time",
    "series",
    "stationaries",
    "data",
    "would",
    "look",
    "variance",
    "changing",
    "variance",
    "changing",
    "therefore",
    "apply",
    "type",
    "series",
    "forecasting",
    "kind",
    "data",
    "similarly",
    "covariance",
    "basically",
    "ith",
    "term",
    "plus",
    "term",
    "function",
    "time",
    "well",
    "covariance",
    "nothing",
    "variance",
    "term",
    "relation",
    "variance",
    "term",
    "plus",
    "term",
    "visually",
    "would",
    "look",
    "covariance",
    "also",
    "changing",
    "respect",
    "time",
    "three",
    "three",
    "components",
    "pretty",
    "much",
    "constant",
    "stationary",
    "data",
    "order",
    "perform",
    "time",
    "series",
    "analysis",
    "data",
    "stationary",
    "okay",
    "let",
    "take",
    "look",
    "concept",
    "moving",
    "average",
    "method",
    "moving",
    "average",
    "let",
    "see",
    "works",
    "simple",
    "calculations",
    "let",
    "say",
    "sample",
    "data",
    "data",
    "three",
    "months",
    "january",
    "february",
    "march",
    "sales",
    "hundreds",
    "thousands",
    "rather",
    "hundreds",
    "thousands",
    "dollars",
    "given",
    "want",
    "find",
    "moving",
    "average",
    "find",
    "moving",
    "average",
    "call",
    "moving",
    "average",
    "three",
    "moving",
    "average",
    "three",
    "nothing",
    "take",
    "three",
    "values",
    "readings",
    "add",
    "uh",
    "divide",
    "three",
    "basically",
    "way",
    "take",
    "mean",
    "average",
    "three",
    "values",
    "simple",
    "average",
    "first",
    "moving",
    "average",
    "moving",
    "averages",
    "series",
    "data",
    "keep",
    "taking",
    "three",
    "values",
    "next",
    "three",
    "values",
    "take",
    "average",
    "next",
    "three",
    "values",
    "forth",
    "take",
    "moving",
    "average",
    "let",
    "take",
    "little",
    "detailed",
    "example",
    "car",
    "sales",
    "car",
    "sales",
    "data",
    "entire",
    "year",
    "let",
    "say",
    "rather",
    "four",
    "years",
    "year",
    "one",
    "quarter",
    "quarter",
    "one",
    "two",
    "three",
    "four",
    "year",
    "two",
    "quarter",
    "one",
    "two",
    "three",
    "four",
    "forth",
    "sales",
    "data",
    "particular",
    "car",
    "let",
    "say",
    "showroom",
    "want",
    "forecast",
    "year",
    "five",
    "data",
    "four",
    "years",
    "want",
    "forecast",
    "fifth",
    "year",
    "let",
    "see",
    "works",
    "first",
    "plot",
    "data",
    "uh",
    "taken",
    "raw",
    "data",
    "would",
    "look",
    "uh",
    "think",
    "stationary",
    "right",
    "trend",
    "upward",
    "trend",
    "stationary",
    "data",
    "um",
    "need",
    "later",
    "see",
    "make",
    "stationary",
    "start",
    "example",
    "worry",
    "go",
    "ahead",
    "manually",
    "forecasting",
    "using",
    "known",
    "moving",
    "average",
    "method",
    "okay",
    "applying",
    "algorithm",
    "anything",
    "like",
    "next",
    "video",
    "see",
    "apply",
    "algorithm",
    "make",
    "stationary",
    "right",
    "see",
    "three",
    "four",
    "components",
    "talked",
    "um",
    "trend",
    "seasonality",
    "course",
    "random",
    "component",
    "well",
    "cyclicity",
    "may",
    "possible",
    "cyclicity",
    "applicable",
    "situations",
    "sales",
    "especially",
    "may",
    "unless",
    "taking",
    "sales",
    "maybe",
    "20",
    "30",
    "years",
    "cyclicity",
    "may",
    "come",
    "play",
    "consider",
    "uh",
    "primarily",
    "trend",
    "seasonality",
    "irregularity",
    "right",
    "random",
    "also",
    "known",
    "random",
    "irregularity",
    "right",
    "calling",
    "random",
    "irregularity",
    "component",
    "three",
    "main",
    "components",
    "typically",
    "case",
    "talk",
    "trend",
    "component",
    "see",
    "calculations",
    "let",
    "take",
    "look",
    "redraw",
    "table",
    "including",
    "time",
    "code",
    "add",
    "another",
    "column",
    "time",
    "code",
    "uh",
    "column",
    "number",
    "like",
    "one",
    "two",
    "three",
    "four",
    "rest",
    "data",
    "remains",
    "okay",
    "calculations",
    "let",
    "us",
    "moving",
    "average",
    "calculations",
    "um",
    "ma4",
    "call",
    "year",
    "take",
    "four",
    "quarters",
    "take",
    "average",
    "add",
    "four",
    "values",
    "divide",
    "four",
    "get",
    "moving",
    "average",
    "start",
    "putting",
    "value",
    "third",
    "quarter",
    "let",
    "say",
    "one",
    "two",
    "three",
    "third",
    "quarter",
    "go",
    "next",
    "one",
    "take",
    "next",
    "four",
    "values",
    "see",
    "take",
    "average",
    "moving",
    "average",
    "next",
    "quarter",
    "forth",
    "moving",
    "average",
    "centered",
    "basically",
    "add",
    "one",
    "column",
    "calculate",
    "centered",
    "moving",
    "average",
    "shown",
    "take",
    "average",
    "two",
    "values",
    "adding",
    "values",
    "example",
    "first",
    "value",
    "third",
    "quarter",
    "actually",
    "average",
    "third",
    "fourth",
    "quarter",
    "gets",
    "centered",
    "similarly",
    "next",
    "value",
    "would",
    "plus",
    "divided",
    "2",
    "forth",
    "okay",
    "centered",
    "moving",
    "average",
    "done",
    "primarily",
    "smoothen",
    "data",
    "many",
    "rough",
    "edges",
    "visualize",
    "data",
    "uh",
    "looks",
    "right",
    "take",
    "centered",
    "moving",
    "average",
    "see",
    "gradual",
    "increase",
    "case",
    "centered",
    "changes",
    "would",
    "much",
    "sharper",
    "basically",
    "smoothing",
    "talking",
    "let",
    "go",
    "forecast",
    "fifth",
    "year",
    "order",
    "forecast",
    "take",
    "centered",
    "moving",
    "average",
    "baseline",
    "start",
    "calculations",
    "required",
    "order",
    "come",
    "prediction",
    "going",
    "going",
    "use",
    "multiplicity",
    "multiplicative",
    "model",
    "case",
    "looks",
    "take",
    "product",
    "seasonality",
    "trend",
    "irregularity",
    "components",
    "multiply",
    "order",
    "get",
    "product",
    "two",
    "basically",
    "actual",
    "value",
    "divided",
    "cma",
    "yt",
    "value",
    "divided",
    "cma",
    "give",
    "predicted",
    "value",
    "yt",
    "equal",
    "product",
    "three",
    "components",
    "therefore",
    "equal",
    "c",
    "like",
    "equal",
    "right",
    "therefore",
    "want",
    "st",
    "product",
    "seasonality",
    "irregularity",
    "equal",
    "c",
    "cma",
    "work",
    "also",
    "excel",
    "sheet",
    "actual",
    "data",
    "let",
    "pull",
    "right",
    "data",
    "looks",
    "excel",
    "see",
    "year",
    "one",
    "quarter",
    "one",
    "two",
    "three",
    "four",
    "two",
    "quarter",
    "one",
    "two",
    "three",
    "four",
    "sales",
    "data",
    "moving",
    "average",
    "mentioned",
    "calculate",
    "centered",
    "moving",
    "average",
    "primary",
    "component",
    "start",
    "working",
    "calculate",
    "since",
    "want",
    "product",
    "sc",
    "yt",
    "equal",
    "yt",
    "cma",
    "see",
    "values",
    "nothing",
    "yt",
    "value",
    "divided",
    "cma",
    "case",
    "4",
    "similarly",
    "forth",
    "take",
    "product",
    "tm2i",
    "next",
    "step",
    "calculate",
    "average",
    "respective",
    "quarters",
    "average",
    "respective",
    "quarters",
    "need",
    "calculate",
    "decisionalized",
    "values",
    "order",
    "get",
    "decisionalized",
    "value",
    "need",
    "divide",
    "yt",
    "st",
    "calculated",
    "example",
    "got",
    "decisionalized",
    "value",
    "get",
    "trend",
    "get",
    "predicted",
    "values",
    "order",
    "get",
    "predicted",
    "value",
    "basically",
    "predict",
    "values",
    "known",
    "values",
    "well",
    "like",
    "example",
    "one",
    "quarter",
    "one",
    "know",
    "value",
    "model",
    "predict",
    "see",
    "close",
    "predicted",
    "whereas",
    "actual",
    "value",
    "actual",
    "value",
    "see",
    "model",
    "works",
    "continue",
    "fifth",
    "year",
    "fifth",
    "year",
    "reference",
    "value",
    "okay",
    "plot",
    "come",
    "know",
    "well",
    "calculations",
    "well",
    "manual",
    "model",
    "case",
    "really",
    "use",
    "model",
    "manually",
    "tell",
    "us",
    "trend",
    "example",
    "predicted",
    "value",
    "gray",
    "color",
    "see",
    "actually",
    "pretty",
    "much",
    "following",
    "actual",
    "value",
    "blue",
    "color",
    "right",
    "gray",
    "color",
    "predicted",
    "value",
    "wherever",
    "know",
    "values",
    "year",
    "4",
    "see",
    "predicted",
    "values",
    "following",
    "pretty",
    "much",
    "close",
    "actual",
    "values",
    "onwards",
    "year",
    "5",
    "starts",
    "blue",
    "color",
    "line",
    "actual",
    "values",
    "predicted",
    "value",
    "see",
    "since",
    "following",
    "trend",
    "pretty",
    "much",
    "last",
    "four",
    "years",
    "safely",
    "assume",
    "understood",
    "pattern",
    "predicting",
    "correctly",
    "next",
    "one",
    "year",
    "next",
    "four",
    "quarters",
    "right",
    "four",
    "quarters",
    "actual",
    "data",
    "predicted",
    "values",
    "let",
    "go",
    "back",
    "see",
    "working",
    "using",
    "slides",
    "already",
    "saw",
    "part",
    "think",
    "easier",
    "see",
    "excel",
    "sheet",
    "calculated",
    "st",
    "product",
    "using",
    "formula",
    "like",
    "c",
    "got",
    "got",
    "st",
    "basically",
    "yt",
    "average",
    "first",
    "quarters",
    "four",
    "years",
    "similarly",
    "average",
    "second",
    "quarter",
    "four",
    "years",
    "values",
    "repeating",
    "calculated",
    "get",
    "repeated",
    "see",
    "get",
    "decisionalized",
    "data",
    "basically",
    "yt",
    "st",
    "calculated",
    "st",
    "yt",
    "yt",
    "st",
    "give",
    "dc",
    "analyze",
    "data",
    "got",
    "rid",
    "seasonal",
    "irregular",
    "components",
    "far",
    "left",
    "trend",
    "start",
    "time",
    "series",
    "forecasting",
    "time",
    "series",
    "analysis",
    "mentioned",
    "earlier",
    "need",
    "completely",
    "get",
    "rid",
    "components",
    "still",
    "left",
    "trend",
    "component",
    "let",
    "us",
    "also",
    "remove",
    "trend",
    "component",
    "order",
    "find",
    "calculate",
    "intercept",
    "slope",
    "data",
    "required",
    "calculate",
    "trend",
    "uh",
    "going",
    "actually",
    "use",
    "um",
    "known",
    "regression",
    "tool",
    "analytics",
    "tool",
    "available",
    "excel",
    "remember",
    "data",
    "excel",
    "let",
    "take",
    "excel",
    "need",
    "calculate",
    "intercept",
    "slow",
    "order",
    "use",
    "regression",
    "mechanism",
    "order",
    "use",
    "regression",
    "mechanism",
    "use",
    "analytics",
    "tool",
    "comes",
    "excel",
    "activate",
    "tool",
    "would",
    "need",
    "activate",
    "tool",
    "uh",
    "excel",
    "need",
    "go",
    "options",
    "options",
    "um",
    "analysis",
    "tool",
    "back",
    "select",
    "say",
    "go",
    "open",
    "box",
    "like",
    "say",
    "analysis",
    "tool",
    "pack",
    "say",
    "okay",
    "come",
    "back",
    "regular",
    "view",
    "excel",
    "data",
    "tab",
    "see",
    "data",
    "analysis",
    "activated",
    "need",
    "go",
    "file",
    "options",
    "analysis",
    "tool",
    "pack",
    "typically",
    "since",
    "already",
    "added",
    "coming",
    "top",
    "would",
    "come",
    "inactive",
    "application",
    "first",
    "time",
    "use",
    "vba",
    "say",
    "analysis",
    "tool",
    "back",
    "two",
    "options",
    "one",
    "vba",
    "like",
    "one",
    "one",
    "without",
    "vba",
    "use",
    "one",
    "without",
    "vba",
    "instead",
    "saying",
    "okay",
    "take",
    "care",
    "click",
    "go",
    "okay",
    "say",
    "go",
    "give",
    "options",
    "select",
    "analysis",
    "tool",
    "pack",
    "say",
    "okay",
    "right",
    "come",
    "back",
    "main",
    "view",
    "click",
    "data",
    "okay",
    "normal",
    "home",
    "view",
    "perhaps",
    "need",
    "come",
    "data",
    "see",
    "data",
    "analysis",
    "available",
    "click",
    "bunch",
    "possibilities",
    "kind",
    "data",
    "analysis",
    "want",
    "options",
    "given",
    "right",
    "want",
    "regression",
    "want",
    "find",
    "slope",
    "intercept",
    "select",
    "regression",
    "say",
    "ok",
    "get",
    "options",
    "input",
    "range",
    "input",
    "x",
    "range",
    "input",
    "range",
    "value",
    "yt",
    "select",
    "select",
    "press",
    "enter",
    "input",
    "x",
    "range",
    "start",
    "uh",
    "baseline",
    "also",
    "start",
    "seasoned",
    "values",
    "click",
    "say",
    "okay",
    "already",
    "calculated",
    "intercept",
    "coefficients",
    "getting",
    "values",
    "actually",
    "use",
    "calculate",
    "trend",
    "right",
    "j",
    "column",
    "trend",
    "equal",
    "intercept",
    "plus",
    "slope",
    "time",
    "code",
    "intercept",
    "see",
    "slide",
    "well",
    "see",
    "intercept",
    "lower",
    "value",
    "slope",
    "calculated",
    "shown",
    "slides",
    "well",
    "intercept",
    "formula",
    "shown",
    "trend",
    "equal",
    "intercept",
    "plus",
    "slope",
    "time",
    "code",
    "time",
    "code",
    "nothing",
    "one",
    "column",
    "one",
    "two",
    "three",
    "four",
    "okay",
    "calculate",
    "trend",
    "use",
    "data",
    "analysis",
    "tool",
    "excel",
    "using",
    "two",
    "calculate",
    "predicted",
    "values",
    "using",
    "formula",
    "basically",
    "trend",
    "equal",
    "intercept",
    "plus",
    "slope",
    "time",
    "code",
    "go",
    "plot",
    "see",
    "looking",
    "therefore",
    "see",
    "predicted",
    "values",
    "pretty",
    "close",
    "actual",
    "values",
    "therefore",
    "safely",
    "assume",
    "calculations",
    "like",
    "manual",
    "model",
    "working",
    "hence",
    "go",
    "ahead",
    "predict",
    "fifth",
    "year",
    "till",
    "four",
    "years",
    "know",
    "actual",
    "value",
    "well",
    "compare",
    "model",
    "performing",
    "fifth",
    "year",
    "reference",
    "values",
    "use",
    "equations",
    "calculate",
    "values",
    "predict",
    "values",
    "fifth",
    "year",
    "go",
    "ahead",
    "safely",
    "calculate",
    "values",
    "plot",
    "fifth",
    "year",
    "well",
    "predicted",
    "values",
    "see",
    "pretty",
    "much",
    "captured",
    "pattern",
    "safely",
    "assume",
    "predictions",
    "fairly",
    "accurate",
    "also",
    "see",
    "graph",
    "excel",
    "sheet",
    "already",
    "seen",
    "okay",
    "let",
    "go",
    "plot",
    "plot",
    "looks",
    "cma",
    "centred",
    "moving",
    "average",
    "green",
    "color",
    "blue",
    "color",
    "actual",
    "data",
    "red",
    "color",
    "predicted",
    "value",
    "predicted",
    "hand",
    "crafted",
    "model",
    "okay",
    "remember",
    "use",
    "regular",
    "forecasting",
    "model",
    "tool",
    "done",
    "manually",
    "actual",
    "tool",
    "used",
    "next",
    "video",
    "give",
    "idea",
    "behind",
    "scenes",
    "hood",
    "forecasting",
    "works",
    "time",
    "series",
    "analysis",
    "performed",
    "okay",
    "looks",
    "like",
    "captured",
    "trend",
    "properly",
    "known",
    "difference",
    "reference",
    "onwards",
    "purely",
    "predicted",
    "mentioned",
    "earlier",
    "safely",
    "assume",
    "values",
    "accurate",
    "predicted",
    "properly",
    "fifth",
    "year",
    "let",
    "go",
    "ahead",
    "implement",
    "time",
    "series",
    "forecast",
    "r",
    "first",
    "using",
    "arimo",
    "model",
    "forecast",
    "time",
    "series",
    "data",
    "let",
    "us",
    "try",
    "understand",
    "arima",
    "model",
    "arima",
    "actually",
    "acronym",
    "stands",
    "autoregressive",
    "integrated",
    "moving",
    "average",
    "arima",
    "model",
    "specified",
    "three",
    "parameters",
    "p",
    "q",
    "p",
    "stands",
    "auto",
    "regressive",
    "let",
    "mark",
    "three",
    "components",
    "auto",
    "regressive",
    "integrated",
    "moving",
    "average",
    "okay",
    "three",
    "parameters",
    "correspond",
    "three",
    "components",
    "p",
    "stands",
    "auto",
    "regressive",
    "integrated",
    "q",
    "moving",
    "average",
    "let",
    "us",
    "see",
    "exactly",
    "three",
    "factors",
    "p",
    "number",
    "autoregressive",
    "terms",
    "ar",
    "see",
    "little",
    "bit",
    "many",
    "levels",
    "differences",
    "need",
    "differentiation",
    "need",
    "q",
    "number",
    "lagged",
    "forecast",
    "errors",
    "see",
    "exactly",
    "ar",
    "number",
    "autoregressive",
    "terms",
    "basically",
    "denoted",
    "p",
    "number",
    "times",
    "differentiated",
    "q",
    "moving",
    "average",
    "exactly",
    "terms",
    "terms",
    "regression",
    "model",
    "autoregressive",
    "components",
    "refer",
    "prior",
    "values",
    "current",
    "value",
    "mean",
    "talk",
    "time",
    "series",
    "data",
    "focus",
    "fact",
    "regression",
    "exactly",
    "happens",
    "regression",
    "try",
    "something",
    "like",
    "simple",
    "linear",
    "regression",
    "equation",
    "like",
    "equal",
    "mx",
    "plus",
    "c",
    "actually",
    "two",
    "variables",
    "one",
    "dependent",
    "variable",
    "independent",
    "variable",
    "let",
    "complete",
    "equation",
    "well",
    "mx",
    "plus",
    "c",
    "right",
    "normal",
    "regression",
    "curve",
    "simple",
    "regression",
    "curve",
    "talking",
    "auto",
    "regression",
    "autoregressive",
    "autoregressive",
    "name",
    "suggests",
    "regression",
    "means",
    "one",
    "variable",
    "maybe",
    "cost",
    "flights",
    "whatever",
    "right",
    "variable",
    "basically",
    "time",
    "dependent",
    "therefore",
    "value",
    "given",
    "time",
    "denote",
    "example",
    "x",
    "one",
    "variable",
    "say",
    "basically",
    "predicted",
    "value",
    "time",
    "interval",
    "example",
    "dependent",
    "previous",
    "value",
    "example",
    "may",
    "one",
    "minus",
    "one",
    "like",
    "plus",
    "2",
    "right",
    "plus",
    "2",
    "minus",
    "2",
    "right",
    "plus",
    "3",
    "minus",
    "3",
    "right",
    "basically",
    "saying",
    "one",
    "variable",
    "regression",
    "component",
    "regression",
    "term",
    "auto",
    "regression",
    "comes",
    "play",
    "thing",
    "dependent",
    "previous",
    "time",
    "values",
    "lag",
    "let",
    "say",
    "first",
    "lag",
    "second",
    "lag",
    "third",
    "lag",
    "current",
    "value",
    "dependent",
    "previous",
    "time",
    "lag",
    "values",
    "regression",
    "component",
    "shown",
    "example",
    "case",
    "instead",
    "calling",
    "x",
    "represented",
    "equation",
    "sort",
    "depending",
    "many",
    "lags",
    "take",
    "ar",
    "component",
    "term",
    "p",
    "basically",
    "determines",
    "many",
    "lags",
    "considering",
    "p4",
    "degree",
    "differencing",
    "differencing",
    "like",
    "differences",
    "right",
    "example",
    "take",
    "values",
    "like",
    "given",
    "5",
    "4",
    "6",
    "forth",
    "take",
    "differencing",
    "one",
    "another",
    "like",
    "example",
    "5",
    "minus",
    "4",
    "4",
    "minus",
    "5",
    "next",
    "value",
    "previous",
    "value",
    "4",
    "minus",
    "known",
    "first",
    "order",
    "differencing",
    "result",
    "minus",
    "1",
    "similarly",
    "6",
    "minus",
    "4",
    "2",
    "7",
    "minus",
    "6",
    "first",
    "order",
    "differencing",
    "call",
    "equal",
    "one",
    "okay",
    "way",
    "second",
    "order",
    "third",
    "order",
    "last",
    "one",
    "q",
    "q",
    "actually",
    "call",
    "moving",
    "average",
    "reality",
    "actually",
    "error",
    "model",
    "also",
    "sometimes",
    "represent",
    "e",
    "right",
    "arima",
    "model",
    "works",
    "assumption",
    "data",
    "stationary",
    "means",
    "trend",
    "seasonality",
    "data",
    "removed",
    "correct",
    "okay",
    "discussed",
    "first",
    "part",
    "exactly",
    "stationary",
    "data",
    "remove",
    "part",
    "order",
    "test",
    "whether",
    "data",
    "stationary",
    "two",
    "important",
    "components",
    "considered",
    "one",
    "autocorrelation",
    "function",
    "partial",
    "autocorrelation",
    "function",
    "referred",
    "acf",
    "tsef",
    "right",
    "autocorrelation",
    "definition",
    "correlation",
    "basically",
    "similarity",
    "values",
    "variable",
    "across",
    "observations",
    "name",
    "suggests",
    "actually",
    "find",
    "autocorrelation",
    "function",
    "value",
    "right",
    "basically",
    "done",
    "plotting",
    "autocorrelation",
    "function",
    "also",
    "tells",
    "correlated",
    "points",
    "based",
    "many",
    "time",
    "steps",
    "separated",
    "basically",
    "time",
    "lag",
    "talking",
    "also",
    "used",
    "determine",
    "past",
    "future",
    "data",
    "points",
    "related",
    "value",
    "autocorrelation",
    "function",
    "vary",
    "minus",
    "one",
    "one",
    "plot",
    "would",
    "look",
    "autocorrelation",
    "function",
    "would",
    "look",
    "somewhat",
    "like",
    "actually",
    "readily",
    "available",
    "function",
    "r",
    "see",
    "use",
    "plot",
    "autocorrelation",
    "function",
    "okay",
    "acf",
    "see",
    "r",
    "studio",
    "little",
    "bit",
    "similarly",
    "partial",
    "autocorrelation",
    "function",
    "partial",
    "autocorrelation",
    "function",
    "degree",
    "association",
    "two",
    "variables",
    "adjusting",
    "effect",
    "one",
    "additional",
    "variables",
    "measured",
    "also",
    "plotted",
    "value",
    "go",
    "1",
    "gives",
    "partial",
    "correlation",
    "time",
    "series",
    "lagged",
    "values",
    "lag",
    "discussed",
    "previous",
    "couple",
    "slides",
    "psef",
    "plot",
    "would",
    "look",
    "studio",
    "see",
    "well",
    "get",
    "r",
    "studio",
    "let",
    "get",
    "r",
    "studio",
    "take",
    "look",
    "use",
    "case",
    "go",
    "code",
    "let",
    "quickly",
    "understand",
    "exactly",
    "objective",
    "use",
    "case",
    "going",
    "predict",
    "values",
    "forecast",
    "values",
    "data",
    "airline",
    "ticket",
    "sales",
    "previous",
    "years",
    "try",
    "find",
    "predict",
    "forecast",
    "values",
    "future",
    "years",
    "right",
    "basically",
    "identify",
    "time",
    "series",
    "components",
    "like",
    "trend",
    "seasonality",
    "random",
    "behavior",
    "actually",
    "visualize",
    "studio",
    "actually",
    "forecast",
    "values",
    "based",
    "past",
    "values",
    "history",
    "data",
    "historical",
    "data",
    "steps",
    "follow",
    "see",
    "studio",
    "little",
    "bit",
    "quickly",
    "let",
    "go",
    "steps",
    "load",
    "data",
    "time",
    "series",
    "data",
    "try",
    "find",
    "class",
    "belongs",
    "data",
    "actually",
    "air",
    "passengers",
    "data",
    "already",
    "comes",
    "rstudio",
    "using",
    "take",
    "look",
    "data",
    "starting",
    "point",
    "end",
    "point",
    "functions",
    "really",
    "available",
    "using",
    "frequency",
    "basically",
    "frequency",
    "12",
    "like",
    "yearly",
    "data",
    "right",
    "every",
    "month",
    "data",
    "collected",
    "year",
    "12",
    "check",
    "many",
    "missing",
    "values",
    "take",
    "look",
    "summary",
    "data",
    "exploratory",
    "data",
    "analysis",
    "plot",
    "data",
    "visualize",
    "data",
    "looking",
    "see",
    "data",
    "trend",
    "seasonality",
    "forth",
    "right",
    "take",
    "look",
    "cycle",
    "data",
    "using",
    "cycle",
    "function",
    "see",
    "every",
    "month",
    "cycle",
    "every",
    "12",
    "months",
    "new",
    "cycle",
    "begins",
    "month",
    "year",
    "data",
    "available",
    "box",
    "plots",
    "see",
    "month",
    "data",
    "varying",
    "various",
    "10",
    "12",
    "years",
    "looking",
    "data",
    "exploratory",
    "data",
    "analysis",
    "identify",
    "trend",
    "seasonality",
    "component",
    "seasonality",
    "component",
    "varies",
    "also",
    "see",
    "box",
    "plots",
    "decompose",
    "data",
    "use",
    "decomposed",
    "function",
    "rather",
    "see",
    "various",
    "components",
    "like",
    "seasonality",
    "trend",
    "irregularity",
    "part",
    "okay",
    "see",
    "studio",
    "look",
    "decompose",
    "actually",
    "visualize",
    "data",
    "actual",
    "data",
    "trend",
    "see",
    "going",
    "upwards",
    "seasonal",
    "component",
    "random",
    "irregularity",
    "right",
    "call",
    "irregularity",
    "also",
    "call",
    "random",
    "see",
    "yes",
    "data",
    "must",
    "constant",
    "variance",
    "mean",
    "means",
    "stationary",
    "start",
    "analysis",
    "time",
    "series",
    "analysis",
    "thought",
    "basically",
    "stationary",
    "easy",
    "model",
    "data",
    "perform",
    "time",
    "series",
    "analysis",
    "go",
    "ahead",
    "fit",
    "model",
    "discussed",
    "earlier",
    "using",
    "arima",
    "model",
    "techniques",
    "find",
    "parameter",
    "see",
    "go",
    "rstudio",
    "auto",
    "arima",
    "function",
    "basically",
    "tells",
    "us",
    "parameters",
    "right",
    "parameters",
    "p",
    "q",
    "talked",
    "shown",
    "use",
    "auto",
    "arima",
    "basically",
    "take",
    "possible",
    "values",
    "pdq",
    "parameters",
    "find",
    "best",
    "value",
    "recommend",
    "advantage",
    "using",
    "auto",
    "arima",
    "right",
    "like",
    "case",
    "tell",
    "us",
    "use",
    "parameter",
    "trace",
    "set",
    "parameter",
    "trace",
    "equal",
    "true",
    "basically",
    "tell",
    "us",
    "value",
    "aic",
    "minimum",
    "lower",
    "value",
    "better",
    "combinations",
    "b",
    "q",
    "give",
    "us",
    "values",
    "recommend",
    "us",
    "best",
    "model",
    "okay",
    "whichever",
    "lowest",
    "value",
    "aic",
    "recommend",
    "best",
    "pdq",
    "values",
    "see",
    "basically",
    "potentially",
    "get",
    "model",
    "equation",
    "model",
    "nothing",
    "equation",
    "based",
    "parameters",
    "get",
    "diagnostics",
    "plotting",
    "see",
    "whether",
    "plot",
    "residuals",
    "shows",
    "stationarity",
    "also",
    "take",
    "look",
    "acf",
    "pscf",
    "plot",
    "acf",
    "psef",
    "forecasting",
    "future",
    "case",
    "1960",
    "see",
    "forecast",
    "next",
    "10",
    "years",
    "1970",
    "1970",
    "done",
    "validate",
    "model",
    "yes",
    "definitely",
    "validate",
    "model",
    "validate",
    "findings",
    "use",
    "uh",
    "junkbox",
    "test",
    "call",
    "pass",
    "parameters",
    "get",
    "values",
    "returned",
    "tell",
    "us",
    "whether",
    "accurate",
    "model",
    "accurate",
    "connections",
    "values",
    "p",
    "quite",
    "insignificant",
    "case",
    "see",
    "also",
    "indicates",
    "model",
    "free",
    "autocorrelation",
    "basically",
    "let",
    "go",
    "back",
    "rstudio",
    "go",
    "steps",
    "real",
    "time",
    "import",
    "library",
    "forecast",
    "package",
    "installed",
    "go",
    "install",
    "forecast",
    "package",
    "okay",
    "easy",
    "way",
    "install",
    "rather",
    "click",
    "install",
    "already",
    "installed",
    "first",
    "time",
    "one",
    "time",
    "load",
    "memory",
    "keep",
    "going",
    "load",
    "data",
    "called",
    "air",
    "passengers",
    "calling",
    "data",
    "method",
    "see",
    "data",
    "passengers",
    "loaded",
    "check",
    "class",
    "time",
    "series",
    "data",
    "ts",
    "data",
    "check",
    "dates",
    "also",
    "view",
    "data",
    "little",
    "bit",
    "start",
    "date",
    "1949",
    "january",
    "end",
    "date",
    "1960",
    "december",
    "frequency",
    "12",
    "like",
    "collected",
    "monthly",
    "frequency",
    "uh",
    "12",
    "check",
    "missing",
    "values",
    "missing",
    "values",
    "take",
    "look",
    "summary",
    "data",
    "exploratory",
    "data",
    "analysis",
    "display",
    "data",
    "looks",
    "need",
    "decompose",
    "data",
    "kind",
    "store",
    "object",
    "ts",
    "data",
    "use",
    "decompose",
    "store",
    "new",
    "values",
    "let",
    "clear",
    "decompose",
    "basically",
    "seen",
    "slides",
    "decomposing",
    "breaking",
    "trend",
    "seasonality",
    "irregular",
    "random",
    "components",
    "go",
    "ahead",
    "plot",
    "plot",
    "see",
    "let",
    "zoom",
    "original",
    "plot",
    "observed",
    "value",
    "known",
    "decomposed",
    "three",
    "parts",
    "basically",
    "trend",
    "see",
    "poor",
    "trend",
    "seasonal",
    "component",
    "regularly",
    "occurring",
    "pattern",
    "random",
    "value",
    "basically",
    "really",
    "give",
    "equation",
    "function",
    "anything",
    "like",
    "plotting",
    "done",
    "actually",
    "plot",
    "individually",
    "well",
    "individual",
    "plots",
    "trend",
    "seasonal",
    "component",
    "random",
    "component",
    "right",
    "let",
    "take",
    "look",
    "original",
    "data",
    "see",
    "trend",
    "way",
    "linear",
    "regression",
    "line",
    "show",
    "going",
    "upwards",
    "also",
    "take",
    "look",
    "cycle",
    "nothing",
    "frequency",
    "12",
    "right",
    "cycles",
    "display",
    "january",
    "february",
    "december",
    "back",
    "january",
    "february",
    "forth",
    "box",
    "plots",
    "monthly",
    "data",
    "see",
    "months",
    "right",
    "10",
    "years",
    "data",
    "see",
    "certain",
    "pattern",
    "right",
    "also",
    "way",
    "find",
    "seasonality",
    "component",
    "january",
    "february",
    "sales",
    "relatively",
    "low",
    "around",
    "july",
    "august",
    "sales",
    "pick",
    "especially",
    "july",
    "think",
    "sales",
    "highest",
    "seems",
    "happening",
    "pretty",
    "much",
    "every",
    "year",
    "right",
    "every",
    "year",
    "july",
    "seems",
    "peak",
    "sales",
    "goes",
    "slightly",
    "higher",
    "december",
    "part",
    "exploratory",
    "data",
    "analysis",
    "let",
    "plot",
    "data",
    "said",
    "order",
    "fit",
    "arima",
    "model",
    "need",
    "values",
    "pd",
    "q",
    "one",
    "way",
    "multiple",
    "ways",
    "actually",
    "earlier",
    "method",
    "draw",
    "autocorrelation",
    "function",
    "plot",
    "partial",
    "autocorrelation",
    "function",
    "plot",
    "observe",
    "change",
    "identify",
    "values",
    "p",
    "q",
    "r",
    "really",
    "beautiful",
    "method",
    "use",
    "avoid",
    "manual",
    "process",
    "used",
    "earlier",
    "r",
    "method",
    "called",
    "auto",
    "arima",
    "call",
    "auto",
    "arima",
    "method",
    "basically",
    "go",
    "test",
    "arima",
    "model",
    "possible",
    "values",
    "parameters",
    "pdq",
    "suggest",
    "best",
    "model",
    "return",
    "best",
    "model",
    "right",
    "values",
    "pd",
    "q",
    "data",
    "scientists",
    "manual",
    "know",
    "trial",
    "error",
    "kind",
    "stuff",
    "okay",
    "got",
    "model",
    "uh",
    "model",
    "pdq",
    "values",
    "r211",
    "pdq",
    "seasonal",
    "part",
    "ignore",
    "want",
    "actually",
    "understand",
    "returned",
    "values",
    "2",
    "1",
    "1",
    "best",
    "one",
    "another",
    "functionality",
    "feature",
    "use",
    "trace",
    "function",
    "trace",
    "parameter",
    "pass",
    "auto",
    "arima",
    "trace",
    "parameter",
    "show",
    "calculation",
    "value",
    "aic",
    "basically",
    "asc",
    "know",
    "defines",
    "accuracy",
    "model",
    "lower",
    "better",
    "okay",
    "combination",
    "pdq",
    "show",
    "us",
    "value",
    "aic",
    "let",
    "run",
    "instead",
    "talking",
    "much",
    "let",
    "run",
    "run",
    "auto",
    "arima",
    "trace",
    "see",
    "red",
    "mark",
    "means",
    "performing",
    "executing",
    "see",
    "display",
    "right",
    "starts",
    "certain",
    "values",
    "pdq",
    "finds",
    "value",
    "high",
    "starts",
    "0",
    "1",
    "1",
    "0",
    "forth",
    "ultimately",
    "tells",
    "us",
    "okay",
    "best",
    "model",
    "see",
    "says",
    "best",
    "model",
    "2",
    "1",
    "let",
    "go",
    "back",
    "see",
    "get",
    "one",
    "yes",
    "got",
    "one",
    "ran",
    "without",
    "trace",
    "well",
    "right",
    "2",
    "1",
    "1",
    "let",
    "us",
    "see",
    "2",
    "1",
    "1",
    "2",
    "1",
    "1",
    "compare",
    "values",
    "see",
    "1",
    "0",
    "1",
    "7",
    "pretty",
    "much",
    "lowest",
    "value",
    "therefore",
    "saying",
    "best",
    "model",
    "values",
    "higher",
    "kind",
    "get",
    "model",
    "model",
    "need",
    "predict",
    "values",
    "right",
    "let",
    "us",
    "tests",
    "values",
    "install",
    "series",
    "first",
    "time",
    "would",
    "rather",
    "use",
    "package",
    "install",
    "say",
    "series",
    "install",
    "use",
    "library",
    "function",
    "load",
    "memory",
    "right",
    "got",
    "model",
    "using",
    "auto",
    "arima",
    "let",
    "us",
    "go",
    "ahead",
    "forecast",
    "also",
    "test",
    "model",
    "also",
    "plot",
    "acf",
    "pscf",
    "remember",
    "talked",
    "really",
    "use",
    "use",
    "least",
    "visualize",
    "stuff",
    "may",
    "need",
    "series",
    "library",
    "first",
    "time",
    "may",
    "install",
    "recommendation",
    "use",
    "code",
    "go",
    "install",
    "series",
    "already",
    "installed",
    "preferred",
    "method",
    "install",
    "load",
    "using",
    "library",
    "function",
    "plot",
    "residuals",
    "residuals",
    "look",
    "plot",
    "acf",
    "psef",
    "okay",
    "psef",
    "looks",
    "acf",
    "looks",
    "really",
    "nothing",
    "else",
    "need",
    "acf",
    "psef",
    "visualize",
    "looks",
    "mentioned",
    "earlier",
    "actually",
    "using",
    "visualizations",
    "graphs",
    "identify",
    "values",
    "p",
    "q",
    "done",
    "scope",
    "video",
    "leave",
    "forecast",
    "next",
    "10",
    "years",
    "focus",
    "call",
    "forecast",
    "pass",
    "model",
    "pass",
    "level",
    "accuracy",
    "need",
    "95",
    "percent",
    "many",
    "periods",
    "right",
    "basically",
    "want",
    "10",
    "years",
    "like",
    "10",
    "12",
    "time",
    "periods",
    "plot",
    "forecast",
    "value",
    "see",
    "original",
    "value",
    "think",
    "62",
    "whatever",
    "goes",
    "72",
    "blue",
    "color",
    "predicted",
    "value",
    "let",
    "go",
    "zoom",
    "see",
    "better",
    "onwards",
    "forecasting",
    "see",
    "looks",
    "like",
    "model",
    "kind",
    "learned",
    "pattern",
    "pattern",
    "looks",
    "similar",
    "see",
    "actual",
    "data",
    "test",
    "model",
    "known",
    "box",
    "test",
    "pass",
    "model",
    "residuals",
    "basically",
    "different",
    "lags",
    "values",
    "p",
    "values",
    "find",
    "reasonably",
    "low",
    "p",
    "values",
    "means",
    "model",
    "fairly",
    "accurate",
    "come",
    "end",
    "video",
    "hope",
    "enjoyed",
    "thank",
    "much",
    "joining",
    "comments",
    "questions",
    "please",
    "put",
    "bottom",
    "video",
    "preferably",
    "contact",
    "information",
    "get",
    "back",
    "great",
    "day",
    "thank",
    "bye",
    "hi",
    "like",
    "video",
    "subscribe",
    "simply",
    "learn",
    "youtube",
    "channel",
    "click",
    "watch",
    "similar",
    "videos",
    "turn",
    "get",
    "certified",
    "click"
  ],
  "keywords": [
    "time",
    "series",
    "forecasting",
    "video",
    "going",
    "talk",
    "first",
    "exactly",
    "data",
    "components",
    "like",
    "example",
    "trend",
    "seasonality",
    "also",
    "use",
    "analysis",
    "stationary",
    "typically",
    "make",
    "take",
    "sales",
    "perform",
    "using",
    "tool",
    "part",
    "actually",
    "r",
    "okay",
    "let",
    "get",
    "need",
    "would",
    "predict",
    "future",
    "could",
    "predicted",
    "name",
    "suggests",
    "say",
    "talking",
    "want",
    "price",
    "dependent",
    "based",
    "model",
    "one",
    "two",
    "column",
    "basically",
    "case",
    "every",
    "well",
    "fixed",
    "uh",
    "year",
    "kind",
    "previous",
    "plot",
    "look",
    "values",
    "forecast",
    "means",
    "four",
    "cyclicity",
    "irregularity",
    "random",
    "component",
    "see",
    "overall",
    "pattern",
    "may",
    "somewhat",
    "right",
    "upward",
    "call",
    "increasing",
    "start",
    "next",
    "um",
    "january",
    "december",
    "another",
    "increase",
    "come",
    "years",
    "three",
    "forth",
    "known",
    "much",
    "pretty",
    "number",
    "plus",
    "really",
    "changing",
    "value",
    "function",
    "arima",
    "us",
    "earlier",
    "therefore",
    "mean",
    "variance",
    "shown",
    "rather",
    "similarly",
    "term",
    "nothing",
    "order",
    "moving",
    "average",
    "method",
    "calculations",
    "find",
    "way",
    "quarter",
    "fifth",
    "go",
    "ahead",
    "code",
    "quarters",
    "third",
    "centered",
    "calculate",
    "2",
    "done",
    "many",
    "visualize",
    "looks",
    "product",
    "actual",
    "cma",
    "yt",
    "give",
    "equal",
    "st",
    "excel",
    "4",
    "calculated",
    "got",
    "know",
    "color",
    "back",
    "already",
    "intercept",
    "slope",
    "regression",
    "options",
    "click",
    "autoregressive",
    "parameters",
    "p",
    "q",
    "auto",
    "equation",
    "variable",
    "minus",
    "lag",
    "1",
    "test",
    "autocorrelation",
    "acf",
    "studio",
    "12",
    "10",
    "pdq",
    "best",
    "trace",
    "install"
  ]
}