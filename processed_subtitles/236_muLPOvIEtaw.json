{
  "text": "AI ethics are something that's on\neveryone's mind these days so how do\nEnterprises determine if their AI\nsolution is at risk of Crossing some\nsort of ethical boundary the first thing\nwe want to do is come up with a set of\nguidelines or rules that we're going to\nfollow whenever we are creating or\ninteracting with AI systems so I'll give\nyou IBM's Three core principles as an\nexample number one artificial\nintelligence is meant to augment human\nintelligence it's not here to replace\nus two data and insights belong to their\ncreator so if we are using customers\ndata for anything that is it's still\ntheir data not\nours number\nthree solutions have to be transparent\nand explainable and what this means is\nthat we need visibility into who is\ntraining the system what data they're\nusing to train the system and then also\nhow all of this is going to effect an\nalgorithm's recommendations to the end\nuser so now we have our rules how do we\ndetermine if we are actually following\nthem or breaking any sort of guidelines\nso there are a few different design\nthinking activities that you could try\none of them is called dichotomy mapping\nand basically what this means is that\nfirst we're going to list all of the\nfeatures of our solution and then we're\ngoing to list the benefits and what\nthey're meant to be used for so I'll\ngive you an example let's say a hotel\nhas a recommendation system for their\nusers that will determine maybe what\nroom they get or if we leave any kind of\ntreats for them in their room if\nsomeone's going skydiving maybe we give\nthem a room on a higher floor um we list\nall of these benefits out and obviously\nthese things are great for the customer\nright they're getting a great experience\nbut then the next thing we need to do is\nactually\nlook at these features and determine can\nthis cause harm in any way so in this\ncase we would want to look at is this\ndata being sold to advertisers is it\nsecure something else if we have\ndifferently abled users are they able to\nuse the interface are they being\nincluded in the algorithm once we've got\nour rules we've got our activities we've\ndefined some issues that maybe we need\nto work on what do we do next we fix\nit the first thing we're going to do is\nImplement a set of guard rails and these\nare basically just rules that your AI\nsystem has to follow um in this case\nit's going to be we do not sell to\nadvertisers that is a guard\nR next let's talk about the data that\nwe're using to train this AI system as I\nmentioned before if we're not using a\ndiverse set of data then we're actually\nnot going to be able to accommodate all\nof our users the next thing we could do\nis look at some open source tooling so\nIBM actually has one called AI fairness\n360 and it's actually going to help you\nmitigate and detect bias in your machine\nlearning models there may be other tools\nthat help you with adhering to privacy\nregulations or even detecting\nuncertainty in your models so now that\nwe have our rules we know how to\nidentify problems and then how to fix\nthem AI is all of our responsibility we\nhave to make sure that the AI that we're\ncreating and using is safe secure and\nand built by humans with humans in mind\nif you like this video and want to see\nmore please like And subscribe if you\nhave any questions or just want to share\nyour thoughts about AI ethics please\nleave a comment\nbelow\n",
  "words": [
    "ai",
    "ethics",
    "something",
    "everyone",
    "mind",
    "days",
    "enterprises",
    "determine",
    "ai",
    "solution",
    "risk",
    "crossing",
    "sort",
    "ethical",
    "boundary",
    "first",
    "thing",
    "want",
    "come",
    "set",
    "guidelines",
    "rules",
    "going",
    "follow",
    "whenever",
    "creating",
    "interacting",
    "ai",
    "systems",
    "give",
    "ibm",
    "three",
    "core",
    "principles",
    "example",
    "number",
    "one",
    "artificial",
    "intelligence",
    "meant",
    "augment",
    "human",
    "intelligence",
    "replace",
    "us",
    "two",
    "data",
    "insights",
    "belong",
    "creator",
    "using",
    "customers",
    "data",
    "anything",
    "still",
    "data",
    "number",
    "three",
    "solutions",
    "transparent",
    "explainable",
    "means",
    "need",
    "visibility",
    "training",
    "system",
    "data",
    "using",
    "train",
    "system",
    "also",
    "going",
    "effect",
    "algorithm",
    "recommendations",
    "end",
    "user",
    "rules",
    "determine",
    "actually",
    "following",
    "breaking",
    "sort",
    "guidelines",
    "different",
    "design",
    "thinking",
    "activities",
    "could",
    "try",
    "one",
    "called",
    "dichotomy",
    "mapping",
    "basically",
    "means",
    "first",
    "going",
    "list",
    "features",
    "solution",
    "going",
    "list",
    "benefits",
    "meant",
    "used",
    "give",
    "example",
    "let",
    "say",
    "hotel",
    "recommendation",
    "system",
    "users",
    "determine",
    "maybe",
    "room",
    "get",
    "leave",
    "kind",
    "treats",
    "room",
    "someone",
    "going",
    "skydiving",
    "maybe",
    "give",
    "room",
    "higher",
    "floor",
    "um",
    "list",
    "benefits",
    "obviously",
    "things",
    "great",
    "customer",
    "right",
    "getting",
    "great",
    "experience",
    "next",
    "thing",
    "need",
    "actually",
    "look",
    "features",
    "determine",
    "cause",
    "harm",
    "way",
    "case",
    "would",
    "want",
    "look",
    "data",
    "sold",
    "advertisers",
    "secure",
    "something",
    "else",
    "differently",
    "abled",
    "users",
    "able",
    "use",
    "interface",
    "included",
    "algorithm",
    "got",
    "rules",
    "got",
    "activities",
    "defined",
    "issues",
    "maybe",
    "need",
    "work",
    "next",
    "fix",
    "first",
    "thing",
    "going",
    "implement",
    "set",
    "guard",
    "rails",
    "basically",
    "rules",
    "ai",
    "system",
    "follow",
    "um",
    "case",
    "going",
    "sell",
    "advertisers",
    "guard",
    "r",
    "next",
    "let",
    "talk",
    "data",
    "using",
    "train",
    "ai",
    "system",
    "mentioned",
    "using",
    "diverse",
    "set",
    "data",
    "actually",
    "going",
    "able",
    "accommodate",
    "users",
    "next",
    "thing",
    "could",
    "look",
    "open",
    "source",
    "tooling",
    "ibm",
    "actually",
    "one",
    "called",
    "ai",
    "fairness",
    "360",
    "actually",
    "going",
    "help",
    "mitigate",
    "detect",
    "bias",
    "machine",
    "learning",
    "models",
    "may",
    "tools",
    "help",
    "adhering",
    "privacy",
    "regulations",
    "even",
    "detecting",
    "uncertainty",
    "models",
    "rules",
    "know",
    "identify",
    "problems",
    "fix",
    "ai",
    "responsibility",
    "make",
    "sure",
    "ai",
    "creating",
    "using",
    "safe",
    "secure",
    "built",
    "humans",
    "humans",
    "mind",
    "like",
    "video",
    "want",
    "see",
    "please",
    "like",
    "subscribe",
    "questions",
    "want",
    "share",
    "thoughts",
    "ai",
    "ethics",
    "please",
    "leave",
    "comment"
  ],
  "keywords": [
    "ai",
    "ethics",
    "something",
    "mind",
    "determine",
    "solution",
    "sort",
    "first",
    "thing",
    "want",
    "set",
    "guidelines",
    "rules",
    "going",
    "follow",
    "creating",
    "give",
    "ibm",
    "three",
    "example",
    "number",
    "one",
    "intelligence",
    "meant",
    "data",
    "using",
    "means",
    "need",
    "system",
    "train",
    "algorithm",
    "actually",
    "activities",
    "could",
    "called",
    "basically",
    "list",
    "features",
    "benefits",
    "let",
    "users",
    "maybe",
    "room",
    "leave",
    "um",
    "great",
    "next",
    "look",
    "case",
    "advertisers",
    "secure",
    "able",
    "got",
    "fix",
    "guard",
    "help",
    "models",
    "humans",
    "like",
    "please"
  ]
}