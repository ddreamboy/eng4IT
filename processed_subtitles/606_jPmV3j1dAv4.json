{
  "text": "Hello world! It's Siraj.\nAnd let's visualise a dataset of eating habits to see what we can learn from it, shall we?\nThere's some really hard scientific questions out there: Are we alone in the universe?\nWhat is consciousness? What is dark matter really?\nQuestions like these, have multi-million dollar payouts\nand have been troubling scientists for hundreds of years!\nWhat guess what, -- whaaat? --\nWe very likely already have the answers to them!\nThe problem is that they aren't in plain sight - they are hidden in data.\nThe former leader of the US government effort to sequence the human genome said that it took\nseveral years of effort, a huge team of researchers, and fifty million dollars\nto find the gene responsible for cystic fibrosis in A'n'I.\nBut that same project could now be accomplished in a few days by a good grad student.\nYou watching this right now, yes you, can make a Nobel worthy break through with just your laptop!\nThe data you need is freely available. You just have to discover the hidden relationships in it.\nThe field of dimensionality reduction, is all about disovering non-linear, non-local relationships in data\nthat are not obvious in the original feature space.\nIf we reduce the number of dimensions in some data, we can visualise it because a projection in 2D or 3D space\ncan be plotted really easily, unless you use PhP.\nTraining a data model on a data set with many dimensions\nusually requires vast time and space complexity. It also often leads to overfitting.\nNot all the features we have available to us are relevant to our problem.\nIf we reduce the dimensions, we can reduce the noise - the unnecessary parts of the data\nand find those that are, surprisingly, very closely related.\nAnd once in a smaller subspace, we can more easily apply simple learning algorithms to it.\nWe can divide dimensionality reduction into two different topics: feature selection and feature extraction.\nSelection is all about finding the most relevant features to a problem.\nIt can be based on our intuition as in: Which features do we think would be the most relevant?\nOr we could let a model, one of the best features by itself.\n*angelic singing*\nExtraction means finding new features after transforming the data from a high dimensional space\nto a lower dimensional space.\nWall performed the latter technique called principle component analysis.\nOur data set is going to be a record of the seventeen types of food that the average person consumes\nper week, for every country in the UK.\nSo we've got seventeen features/dimensions, let's see what kind of insights we can get from this data.\nPCA transforms variables into a new set of variables, which are a linear combination of the original variables.\nThese new variables are known as principle components.\nPCA is an orthogonal, liner transformation that transforms data to a new coordinate system\nsuch that the greatest variance by some projection of the data lies on the first principle component.\nThe second greatest variance, on the second component, and so on.\nThe variance is the measure of how spread out the data is.\nIf I were to measure the variance of the height of a team of basketball players, it would be pretty low.\nBut if I added a group of primary school children to the mix, the variance would be pretty high.\nOur first step is to standardise the data\nPCA is a variance maximising exercise: It projects the original data onto a direction which maximises variance.\nIf we were to graph a small dataset that shows the amount of variance for the different principle components,\nit'll seem like only one component explains all the variance in the data - like Putin at the G20 Summit.\nBut if we standardise the data first, then we'll see that the other components do indeed contribute to the variance aswell.\nStandardising means putting the data on the same unit scale. For us, that would be grams for everything\nnot a combination of kilograms and grams.\nThat means the data should have a mean of zero, and a variance of one.\nA mean is just the average value of all Xs in the set X.\nWhich we can find by dividing the sum of all the data points by the number of them.\nThe way we calculate variance, is by computing the standard deviation, squared.\nThe standard deviation is the square root of the average distance of data-points to the mean.\nIt's used to tell how measurements for a group are spread out from the mean.\nOnce our data is standardised, we're going to perform Eigen decomposition.\nSo if your mumma is so fat she's not embeddable in 3' space,\nEigen pairs will help fix that.\nEigen is a German word that roughly translates to characteristic.\nAnd in linear algebra, an Eigen vector is a vector that doesn't change its direction\nunder the associated linear transformation.\n*sick beats*\n*sick beats*\nDecompose my soul and you'll find an Eigen pair\n*sick beats*\n*sick beats*\nDecompose my soul: a vector, value pair\n*sick beats*\nDecompose my soul\nAnother way of putting it, is that if we have a non-zero vector: V\nThen it's an Eigen vector of square matrix A, if AV is a scalar multiple of V.\nSo the lambda scalar is an Eigen value, or characteristic value, associated with the Eigen vector V.\nEigen values are the coefficients attatched to Eigen vectors that give the axis magnitude.\nIf we had a sheer mapping and displaced every point in a fixed direction,\nnotice how the red arrow changes direction, but the blue arrow doesn't!\nThe blue arrow is the Eigen vector of the mapping because it doesn't change direction\nand its length is unchanged.\nIts Eigen value is 1.\nBoth terms are important in many fields, especially physics\nsince they can help measure the stability of rotating bodies and oscillations of vibrating systems.\nMany problems can be modelled with linear transformations.\nAnd Eigen vectors give very simple solutions.\nThere are way too many dimensions in this painting.\nThere definitely are, but speaking of both, I prefer PCA.\nWhy?\nSeveral reasons but, I mean, PCA is deterministic, t-SNE isn't.\nSo the correct answer is guaranteed.\nAnd it makes data plottable on a 2D graph. Which--\nSo we could even paint it ourselves.\nI'm down to paint some 2D later!\nLet's datify a canvas!\nIf we had a system of linear diffrential equations,\nfor example, to measure how the growth of the population of two species, X and Y, affect one-another -\nlike if one is the predator of another. Solving this system directly is complicated,\nbut if we could introduce two new variables, Z and W, which depend lineally on X\nwe can decouple the system so instead we are dealing with two independent functions.\nThe Eigen vectors and Eigen values for this matrix of coefficients do just this.\nThey decouple the ways in which a linear transformation acts into a number of independent actions\nalong separate directions that can be dealt with independently.\nSo we will need to construct a co-variance matrix.\nThen we will perform Eigen decomposition on that matrix.\nA matrix is just a table of values; a co-variance matrix is symmetric so the table\nhas the same heading across the top as it does along the sides.\nIt describes the variance of the data and the co-variance among the variables.\nCo-variance is the measure of how two variables change with respect to each other.\nIt's positive when variables show similar behaviour, and negative otherwise.\nPCA tries to draw a straight line through data like linear regression.\nEach straight line is a principle component: a relationship between an independent and dependent variable.\nThe number of principle components equals the number of dimensions\nin the data, and PCA's job is to prioritise them.\nIf two variables change together, it's very likely because one is acting on the other\nor they're both subject to the same hidden force.\nPerforming Eigen decomposition on our co-variance matrix\nhelps us find the hidden forces at work in our data\nsince we can't eyeball inter-variable relationships in high dimensional space.\nWhen calculating the co-variance matrix, the mean vector that's used to help do so\nis one where each value represents a sample mean of a feature column in the data set.\nOnce we have our Eigen pairs, we want to select the principle components.\nWe need to decide which ones can be dropped - and that's where our Eigen values come in.\nWe'll rank the Eigen values from highest to lowest.\nThe lowest ones bare the least info about the distribution of the data\nso we can drop a number of them like they're... cold.\nNext we will construct a projection matrix.\nThis is just a matrix of our concatenated, top K Eigen vectors.\nWe can choose how many dimensions we want for our subspace\nby choosing that amount of Eigen vectors to construct our D by K\ndimensional Eigen vector matrix: W.\nLastly we will use this projection matrix to transform our samples onto the subspace\nvia. a simple dot product operation.\nIf we project our data onto a one dimensional space then we can already see something interesting.\nNotice, how Northern Ireland is a major outlier.\nIt makes sense, according to the data, [that] the Northern Irish consume way more potatoes and alcohol\nand way too few healthy options.\nThe same thing happens if we graph both components:\nWe can see relations between data-points that we wouldn't otherwise.\nTo summarise, principle component analysis is a technique that transforms a dataset\nonto a lower dimensional subspace so we can visualise\nand find hidden relationships  in it.\nThe principle components are Eigen vectors couples with Eigen values.\nThey describe the direction in the original feature space\nwith the greatest variance in the data.\nAnd the variance is a measure of how spread out some data is.\nThe winner of last weeks coding challenge is Ong Ja Rui.\nHe implemented a self-organising feature map for colours and for handwritten digits.\nReally efficient code and well documented.\nGreat job Ong, Wizard of the Week.\nAnd the runner up is Hammad Shaikh, who developed a super detailed Jupiter notebook\non self-organising maps for class size effects on students.\nThis weeks coding challenge is to perform PCA\nfrom scratch, on a dataset of your choice.\nPost your GitHub link in the comments and I'll give the winners a shoutout next week.\n*outro music*\nPlease subscribe for more programming videos\n*outro music*\nand for now, I've got to release a music video.\n*outro music*\nSo, thanks for watching!\n",
  "words": [
    "hello",
    "world",
    "siraj",
    "let",
    "visualise",
    "dataset",
    "eating",
    "habits",
    "see",
    "learn",
    "shall",
    "really",
    "hard",
    "scientific",
    "questions",
    "alone",
    "universe",
    "consciousness",
    "dark",
    "matter",
    "really",
    "questions",
    "like",
    "dollar",
    "payouts",
    "troubling",
    "scientists",
    "hundreds",
    "years",
    "guess",
    "whaaat",
    "likely",
    "already",
    "answers",
    "problem",
    "plain",
    "sight",
    "hidden",
    "data",
    "former",
    "leader",
    "us",
    "government",
    "effort",
    "sequence",
    "human",
    "genome",
    "said",
    "took",
    "several",
    "years",
    "effort",
    "huge",
    "team",
    "researchers",
    "fifty",
    "million",
    "dollars",
    "find",
    "gene",
    "responsible",
    "cystic",
    "fibrosis",
    "project",
    "could",
    "accomplished",
    "days",
    "good",
    "grad",
    "student",
    "watching",
    "right",
    "yes",
    "make",
    "nobel",
    "worthy",
    "break",
    "laptop",
    "data",
    "need",
    "freely",
    "available",
    "discover",
    "hidden",
    "relationships",
    "field",
    "dimensionality",
    "reduction",
    "disovering",
    "relationships",
    "data",
    "obvious",
    "original",
    "feature",
    "space",
    "reduce",
    "number",
    "dimensions",
    "data",
    "visualise",
    "projection",
    "2d",
    "3d",
    "space",
    "plotted",
    "really",
    "easily",
    "unless",
    "use",
    "php",
    "training",
    "data",
    "model",
    "data",
    "set",
    "many",
    "dimensions",
    "usually",
    "requires",
    "vast",
    "time",
    "space",
    "complexity",
    "also",
    "often",
    "leads",
    "overfitting",
    "features",
    "available",
    "us",
    "relevant",
    "problem",
    "reduce",
    "dimensions",
    "reduce",
    "noise",
    "unnecessary",
    "parts",
    "data",
    "find",
    "surprisingly",
    "closely",
    "related",
    "smaller",
    "subspace",
    "easily",
    "apply",
    "simple",
    "learning",
    "algorithms",
    "divide",
    "dimensionality",
    "reduction",
    "two",
    "different",
    "topics",
    "feature",
    "selection",
    "feature",
    "extraction",
    "selection",
    "finding",
    "relevant",
    "features",
    "problem",
    "based",
    "intuition",
    "features",
    "think",
    "would",
    "relevant",
    "could",
    "let",
    "model",
    "one",
    "best",
    "features",
    "angelic",
    "singing",
    "extraction",
    "means",
    "finding",
    "new",
    "features",
    "transforming",
    "data",
    "high",
    "dimensional",
    "space",
    "lower",
    "dimensional",
    "space",
    "wall",
    "performed",
    "latter",
    "technique",
    "called",
    "principle",
    "component",
    "analysis",
    "data",
    "set",
    "going",
    "record",
    "seventeen",
    "types",
    "food",
    "average",
    "person",
    "consumes",
    "per",
    "week",
    "every",
    "country",
    "uk",
    "got",
    "seventeen",
    "let",
    "see",
    "kind",
    "insights",
    "get",
    "data",
    "pca",
    "transforms",
    "variables",
    "new",
    "set",
    "variables",
    "linear",
    "combination",
    "original",
    "variables",
    "new",
    "variables",
    "known",
    "principle",
    "components",
    "pca",
    "orthogonal",
    "liner",
    "transformation",
    "transforms",
    "data",
    "new",
    "coordinate",
    "system",
    "greatest",
    "variance",
    "projection",
    "data",
    "lies",
    "first",
    "principle",
    "component",
    "second",
    "greatest",
    "variance",
    "second",
    "component",
    "variance",
    "measure",
    "spread",
    "data",
    "measure",
    "variance",
    "height",
    "team",
    "basketball",
    "players",
    "would",
    "pretty",
    "low",
    "added",
    "group",
    "primary",
    "school",
    "children",
    "mix",
    "variance",
    "would",
    "pretty",
    "high",
    "first",
    "step",
    "standardise",
    "data",
    "pca",
    "variance",
    "maximising",
    "exercise",
    "projects",
    "original",
    "data",
    "onto",
    "direction",
    "maximises",
    "variance",
    "graph",
    "small",
    "dataset",
    "shows",
    "amount",
    "variance",
    "different",
    "principle",
    "components",
    "seem",
    "like",
    "one",
    "component",
    "explains",
    "variance",
    "data",
    "like",
    "putin",
    "g20",
    "summit",
    "standardise",
    "data",
    "first",
    "see",
    "components",
    "indeed",
    "contribute",
    "variance",
    "aswell",
    "standardising",
    "means",
    "putting",
    "data",
    "unit",
    "scale",
    "us",
    "would",
    "grams",
    "everything",
    "combination",
    "kilograms",
    "grams",
    "means",
    "data",
    "mean",
    "zero",
    "variance",
    "one",
    "mean",
    "average",
    "value",
    "xs",
    "set",
    "find",
    "dividing",
    "sum",
    "data",
    "points",
    "number",
    "way",
    "calculate",
    "variance",
    "computing",
    "standard",
    "deviation",
    "squared",
    "standard",
    "deviation",
    "square",
    "root",
    "average",
    "distance",
    "mean",
    "used",
    "tell",
    "measurements",
    "group",
    "spread",
    "mean",
    "data",
    "standardised",
    "going",
    "perform",
    "eigen",
    "decomposition",
    "mumma",
    "fat",
    "embeddable",
    "3",
    "space",
    "eigen",
    "pairs",
    "help",
    "fix",
    "eigen",
    "german",
    "word",
    "roughly",
    "translates",
    "characteristic",
    "linear",
    "algebra",
    "eigen",
    "vector",
    "vector",
    "change",
    "direction",
    "associated",
    "linear",
    "transformation",
    "sick",
    "beats",
    "sick",
    "beats",
    "decompose",
    "soul",
    "find",
    "eigen",
    "pair",
    "sick",
    "beats",
    "sick",
    "beats",
    "decompose",
    "soul",
    "vector",
    "value",
    "pair",
    "sick",
    "beats",
    "decompose",
    "soul",
    "another",
    "way",
    "putting",
    "vector",
    "v",
    "eigen",
    "vector",
    "square",
    "matrix",
    "av",
    "scalar",
    "multiple",
    "lambda",
    "scalar",
    "eigen",
    "value",
    "characteristic",
    "value",
    "associated",
    "eigen",
    "vector",
    "eigen",
    "values",
    "coefficients",
    "attatched",
    "eigen",
    "vectors",
    "give",
    "axis",
    "magnitude",
    "sheer",
    "mapping",
    "displaced",
    "every",
    "point",
    "fixed",
    "direction",
    "notice",
    "red",
    "arrow",
    "changes",
    "direction",
    "blue",
    "arrow",
    "blue",
    "arrow",
    "eigen",
    "vector",
    "mapping",
    "change",
    "direction",
    "length",
    "unchanged",
    "eigen",
    "value",
    "terms",
    "important",
    "many",
    "fields",
    "especially",
    "physics",
    "since",
    "help",
    "measure",
    "stability",
    "rotating",
    "bodies",
    "oscillations",
    "vibrating",
    "systems",
    "many",
    "problems",
    "modelled",
    "linear",
    "transformations",
    "eigen",
    "vectors",
    "give",
    "simple",
    "solutions",
    "way",
    "many",
    "dimensions",
    "painting",
    "definitely",
    "speaking",
    "prefer",
    "pca",
    "several",
    "reasons",
    "mean",
    "pca",
    "deterministic",
    "correct",
    "answer",
    "guaranteed",
    "makes",
    "data",
    "plottable",
    "2d",
    "graph",
    "could",
    "even",
    "paint",
    "paint",
    "2d",
    "later",
    "let",
    "datify",
    "canvas",
    "system",
    "linear",
    "diffrential",
    "equations",
    "example",
    "measure",
    "growth",
    "population",
    "two",
    "species",
    "x",
    "affect",
    "like",
    "one",
    "predator",
    "another",
    "solving",
    "system",
    "directly",
    "complicated",
    "could",
    "introduce",
    "two",
    "new",
    "variables",
    "z",
    "w",
    "depend",
    "lineally",
    "x",
    "decouple",
    "system",
    "instead",
    "dealing",
    "two",
    "independent",
    "functions",
    "eigen",
    "vectors",
    "eigen",
    "values",
    "matrix",
    "coefficients",
    "decouple",
    "ways",
    "linear",
    "transformation",
    "acts",
    "number",
    "independent",
    "actions",
    "along",
    "separate",
    "directions",
    "dealt",
    "independently",
    "need",
    "construct",
    "matrix",
    "perform",
    "eigen",
    "decomposition",
    "matrix",
    "matrix",
    "table",
    "values",
    "matrix",
    "symmetric",
    "table",
    "heading",
    "across",
    "top",
    "along",
    "sides",
    "describes",
    "variance",
    "data",
    "among",
    "variables",
    "measure",
    "two",
    "variables",
    "change",
    "respect",
    "positive",
    "variables",
    "show",
    "similar",
    "behaviour",
    "negative",
    "otherwise",
    "pca",
    "tries",
    "draw",
    "straight",
    "line",
    "data",
    "like",
    "linear",
    "regression",
    "straight",
    "line",
    "principle",
    "component",
    "relationship",
    "independent",
    "dependent",
    "variable",
    "number",
    "principle",
    "components",
    "equals",
    "number",
    "dimensions",
    "data",
    "pca",
    "job",
    "prioritise",
    "two",
    "variables",
    "change",
    "together",
    "likely",
    "one",
    "acting",
    "subject",
    "hidden",
    "force",
    "performing",
    "eigen",
    "decomposition",
    "matrix",
    "helps",
    "us",
    "find",
    "hidden",
    "forces",
    "work",
    "data",
    "since",
    "ca",
    "eyeball",
    "relationships",
    "high",
    "dimensional",
    "space",
    "calculating",
    "matrix",
    "mean",
    "vector",
    "used",
    "help",
    "one",
    "value",
    "represents",
    "sample",
    "mean",
    "feature",
    "column",
    "data",
    "set",
    "eigen",
    "pairs",
    "want",
    "select",
    "principle",
    "components",
    "need",
    "decide",
    "ones",
    "dropped",
    "eigen",
    "values",
    "come",
    "rank",
    "eigen",
    "values",
    "highest",
    "lowest",
    "lowest",
    "ones",
    "bare",
    "least",
    "info",
    "distribution",
    "data",
    "drop",
    "number",
    "like",
    "cold",
    "next",
    "construct",
    "projection",
    "matrix",
    "matrix",
    "concatenated",
    "top",
    "k",
    "eigen",
    "vectors",
    "choose",
    "many",
    "dimensions",
    "want",
    "subspace",
    "choosing",
    "amount",
    "eigen",
    "vectors",
    "construct",
    "k",
    "dimensional",
    "eigen",
    "vector",
    "matrix",
    "lastly",
    "use",
    "projection",
    "matrix",
    "transform",
    "samples",
    "onto",
    "subspace",
    "via",
    "simple",
    "dot",
    "product",
    "operation",
    "project",
    "data",
    "onto",
    "one",
    "dimensional",
    "space",
    "already",
    "see",
    "something",
    "interesting",
    "notice",
    "northern",
    "ireland",
    "major",
    "outlier",
    "makes",
    "sense",
    "according",
    "data",
    "northern",
    "irish",
    "consume",
    "way",
    "potatoes",
    "alcohol",
    "way",
    "healthy",
    "options",
    "thing",
    "happens",
    "graph",
    "components",
    "see",
    "relations",
    "would",
    "otherwise",
    "summarise",
    "principle",
    "component",
    "analysis",
    "technique",
    "transforms",
    "dataset",
    "onto",
    "lower",
    "dimensional",
    "subspace",
    "visualise",
    "find",
    "hidden",
    "relationships",
    "principle",
    "components",
    "eigen",
    "vectors",
    "couples",
    "eigen",
    "values",
    "describe",
    "direction",
    "original",
    "feature",
    "space",
    "greatest",
    "variance",
    "data",
    "variance",
    "measure",
    "spread",
    "data",
    "winner",
    "last",
    "weeks",
    "coding",
    "challenge",
    "ong",
    "ja",
    "rui",
    "implemented",
    "feature",
    "map",
    "colours",
    "handwritten",
    "digits",
    "really",
    "efficient",
    "code",
    "well",
    "documented",
    "great",
    "job",
    "ong",
    "wizard",
    "week",
    "runner",
    "hammad",
    "shaikh",
    "developed",
    "super",
    "detailed",
    "jupiter",
    "notebook",
    "maps",
    "class",
    "size",
    "effects",
    "students",
    "weeks",
    "coding",
    "challenge",
    "perform",
    "pca",
    "scratch",
    "dataset",
    "choice",
    "post",
    "github",
    "link",
    "comments",
    "give",
    "winners",
    "shoutout",
    "next",
    "week",
    "outro",
    "music",
    "please",
    "subscribe",
    "programming",
    "videos",
    "outro",
    "music",
    "got",
    "release",
    "music",
    "video",
    "outro",
    "music",
    "thanks",
    "watching"
  ],
  "keywords": [
    "let",
    "visualise",
    "dataset",
    "see",
    "really",
    "questions",
    "like",
    "years",
    "likely",
    "already",
    "problem",
    "hidden",
    "data",
    "us",
    "effort",
    "several",
    "team",
    "find",
    "project",
    "could",
    "watching",
    "need",
    "available",
    "relationships",
    "dimensionality",
    "reduction",
    "original",
    "feature",
    "space",
    "reduce",
    "number",
    "dimensions",
    "projection",
    "2d",
    "easily",
    "use",
    "model",
    "set",
    "many",
    "features",
    "relevant",
    "subspace",
    "simple",
    "two",
    "different",
    "selection",
    "extraction",
    "finding",
    "would",
    "one",
    "means",
    "new",
    "high",
    "dimensional",
    "lower",
    "technique",
    "principle",
    "component",
    "analysis",
    "going",
    "seventeen",
    "average",
    "week",
    "every",
    "got",
    "pca",
    "transforms",
    "variables",
    "linear",
    "combination",
    "components",
    "transformation",
    "system",
    "greatest",
    "variance",
    "first",
    "second",
    "measure",
    "spread",
    "pretty",
    "group",
    "standardise",
    "onto",
    "direction",
    "graph",
    "amount",
    "putting",
    "grams",
    "mean",
    "value",
    "way",
    "standard",
    "deviation",
    "square",
    "used",
    "perform",
    "eigen",
    "decomposition",
    "pairs",
    "help",
    "characteristic",
    "vector",
    "change",
    "associated",
    "sick",
    "beats",
    "decompose",
    "soul",
    "pair",
    "another",
    "matrix",
    "scalar",
    "values",
    "coefficients",
    "vectors",
    "give",
    "mapping",
    "notice",
    "arrow",
    "blue",
    "since",
    "makes",
    "paint",
    "x",
    "decouple",
    "independent",
    "along",
    "construct",
    "table",
    "top",
    "otherwise",
    "straight",
    "line",
    "job",
    "want",
    "ones",
    "lowest",
    "next",
    "k",
    "northern",
    "weeks",
    "coding",
    "challenge",
    "ong",
    "outro",
    "music"
  ]
}