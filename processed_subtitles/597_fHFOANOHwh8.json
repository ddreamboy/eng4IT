{
  "text": "[Music]\nhello guys today we are going to do a\nlot of amazing things with respect to\neda so\nso zomato\ndata set\nexploratory data analysis right\nwe are going to complete this today\nso before we start please make sure that\nyou download the data set inside my data\nset i have so many things i'll just show\nyou you'll be having files like country\ncode dot xlx zomato dot csv\nfile ball json file to json file three\njson file position file file json\ntoday the data set that we are going to\nuse is jomato dataset uh i have found\nout this particular data set from kaggle\nso i put this\nentire link over here github link so you\ncan download the data set from here also\nyou can download it from the print\ncomment\nso let's go first of all i'm just going\nto import\nsome basic libraries\nimport partners spd\nimport numpy\nas\nnp import matplotlib\ndot pi plot as plt\nand one more library that i am going to\nuse is something called a c bond and\nfinally we will be using matlab inline\nso that the images or any visualization\ngets displayed here itself i'll keep it\nrestricted to all these things and\nunderstand the main thing the main thing\nis that whenever you are performing eda\nthat is exploratory data analysis\nyou really need to think about the data\nwhat the data is basically seeing or\ntelling you right that is most important\nso whenever you have a specific data set\neven though if you don't have much\ndomain knowledge\nsome basic information definitely you'll\nbe able to capture it so what we are\ngoing to do over here is that till now\nwe have actually\nimported all the libraries now let's go\nahead and first of all let's download\nthe data set from here so here you can\nsee that there is a data set called as\nzomato.csv\ncountrycode.xlx and there are multiple\njson file\nnow why this json file was given guys\nbecause this json file is in the form of\nthis json format okay\nthis format has been converted already\ninto zomato.csv now how it has been com\nconverted you really need to write a\npython script to convert this we will\nnot see this right now but in the later\nstages i will also show you how we can\nconvert this json file\ninto\nzomato.csv that part we will do it in\nthe later stages in the upcoming classes\nbut today we have one xlxx file one csv\nfile we'll try to combine this file also\nwe'll try to see what all information\nyou have in this specific file so let's\nstart\nso first of all as usual i'll just write\ndf my data set and i'll write\npd dot read underscore csv and i will\nread the data set which is\nzomato.csv now when you are actually\nimporting this zomato.csb the other\nthing that you need to see is over here\nis that if i just execute it like this\nso here i will be getting some errors it\nsays that utf-8 codec can't decode byte\n0 xed in position 7 0 7 4 7 0 4\nwhenever you get this kind of error\nalways remember that you have to use\nsome kind of encoding format now in this\ncase what encoding you will be using if\nyou probably go and see in read\nunderscore csv and press shift tab here\nyou will be able to see lot of options\nso one options i'll see over here\nencoding encoding somewhere it will be\nor you can see the parameters you can\nsearch the parameters over here with\nrespect to encoding\nwhat you need to put over there you can\nplay with three to four different values\nbut understand you need to have utf and\neight encoding so for this what i'm\ngoing to do i'm going to use an encoding\nand remember this encoding i did not\nunderstand i did not use directly in the\nfirst instance but i used after\nexploring some of the things over here\nwith respect to the kind of error so\nencoding here i'm going to use latin\ndash one you have different different\nencodings again utf-8 encoding uh you\ncan just check out the documentation\nover there so i'm just going to use\nlatin one and then i'm going to\nbasically say df.head now if you go and\nsee over here these are all my data sets\nthat are available over here\nit's a huge data set with respect to the\nnumber of columns\nbut understand this is how we read the\ndata set over here\nand with respect to this you can check\nit out all the features and all but now\none\nthing that we have done is that we have\nimported all the data set over here in\ninside my df let's go to the next step\nnow\nso this is my data set over here that is\npresent now the next step what i'm\nactually going to do i'm just going to\nsee what all columns i have inside my\ndata set so now this is in the basic eda\npart so over here you have restaurant id\nrestaurant name country code city\naddress locality\nlocality verbose longitude latitude\nquestions average cost for two currency\nand many more features are actually\npresent over here just go and search for\npandas documentation\nanytime you have any kind of queries\nwith respect to what encoding you have\nto write and all you can just directly\nsearch for it\nyou can search from here when you search\nfrom here anyhow anywhere you will be\nable to see it why encoding is used why\nutf-8 is used from here you have to\nexplore it over here you can see\nencoding as none right white is\nbasically used\njust click on this try to understand\nthat specific keyword now the next thing\nover here let's go ahead and let's see\none more way of understanding about the\ndata set is like df.info\nif you write df.info here you will be\nable to see\nwhat all columns are there\nwhether this column is normal or null\nwhether it is what is the data type of\nthis here you can see in 64. in 64 is\nspecifically for integer variables\nwhenever you see objects in pandas in\ndata frame object basically means\nstrings it can it can also mean like it\nis maybe a categorical variable it may\nbe a text variable it can be anything\nover here so here you can basically see\nall those things you also have float\nuh you have objects objects wherever\nobjects is there just consider that it\nmay be a categorical variable it may be\nan integer variable it may be a text\ndata initially always you do this you\ntry to find out what are the columns try\nto find out what are the\nimportant information about the columns\nwith respect to the data type now coming\nto the next step now let's see what we\ncan further do what what\nactual information we can actually come\nup with this there is also an inbuilt\nkeyword which is called as describe\nso this is a basic inbuilt function\nwhich is called a describe which will\nactually help you to find out all the\nspecific information now one key\nimportant information from this is that\nhere you will be able to see that all\nthe features that are basically taken\ninside this describe function right\nthese are only integer features you will\nnot be able to find out any categorical\nfeatures any text features any object\nfeatures over there so here definitely\nsee with respect to any feature that you\nsee restaurant id if i go and see\nrestaurant id it is in 64. if i go and\nsee country code it is basically uh int\n64. if i go ahead with longitude it is\nalways float or in 64c over here\nlongitude latitude float64 so all these\nvalues that you are actually able to see\nover here this is completely based on\nyour\nuh integer variables because whatever\nthing you are doing like count mean\nstandard deviation mean you have to\nbasically find it out in the integer and\nnumerical variable now i'll just give\nyou a basic information in data analysis\nthe first thing that i would like to\nfind out is that we'll try to find out\nmissing values\nfirst of all always it is very much\nimportant in our data set do we have\nmissing values the second thing that we\nmay probably do\nuh check\nexplore\nabout the numerical variables\nthird i would like to definitely explore\nabout\ncategorical variables these are some\nbasic things because i need to know that\nhow many categories are there how many\nnumerical variables are there the fourth\nmajor thing that we probably do is that\nfinding relationship between features\nlet's go ahead and try to find out what\nare the missing values in order to find\nout the missing values you can basically\nwrite df dot\nis null\ndot sum\nso if i go and search over here you will\nbe able to see that with respect to\nevery feature it is just saying that how\nmany features are basically having null\nvalue here you can see that 0 0 is there\n0 is there 0 is there\nwhat about duplicates i'll talk about\nduplicates also so here you can see in\ncity 0 is there address 0 is there\nlocality 0 is there locality verbose\nzero is their longitude latitude zero is\nthere but in cosines you can see that\nthere are nine missing values remaining\nall you have zero missing values so here\nin cosines you can see that there are\nnine missing values if you want to do\nanything with respect to the missing\nvalues you basically have to work on\nthis specific feature now can i find out\nany relationship with respect to cosines\nwith any other\ntarget variables or any other\nindependent features okay that we will\ntry to do but right now you have got\nthis specific information that that many\nnumber of missing values are there now\nthis is one way in another way i will\njust write a simple code which will\nactually tell me all the informations\nall the features that has missing values\nover here so what i can basically do\ni'll say that\nfeatures\nfor\nfeatures\nso i'll write df.columns\ni want to check which all variables has\nmissing values so i'm saying that for\nevery features in df.column\ngo and check if df of columns\ndf of columns which is represented by\nfeature\ndot is null\ndot sum\nis greater than one\nso this is basically a list\ncomprehension so here what i'm saying is\nthat features for features\nin df.columns that basically means we\nare using this temporary variable called\nas features which will iterate through\ndf.columns and then i will say that if\nthat specific feature is null\nor dot sum is greater than 1\ni should not write greater than 1 but\ninstead i can write greater than 0 also\nso if i go and execute it here\nyou can see that i am having cosines so\ndefinitely i am able to get what is the\nspecific thing with respect to this that\ni am able to see the null value now\nlet's go to the next step with respect\nto\nis uh with respect to heat map can we\nplot something so for heat map i will\nbasically be using snh dot heat map and\nhere i'll basically put the condition\nwhich says that df dot is null\nand here i will say that in y\nbecause my second parameter is white\ntick labels if i go and press shift tab\nover here always try to see this feature\nand with respect to this particular\nfeature whatever i am actually using x\nstick label is there why tick label is\nthere right now i don't want to show\nmuch things in y so i will just keep it\nas false\nbecause i am focusing only on df with\nrespect to that then i can also use c\nbar it is also another feature over\nthere you can understand by just seeing\nthe documentation what all things it can\ndo\nand then i will use a c map\nand inside this cmap i can use any one\ni'll basically search for it over here\nyou can see\nhere more options is not visible you can\ngo to the c bond documentation page and\nbasically take out that specific\ninformation so here i'm going to use a\ncmap which is called as varidis\nso here obviously i'm not able to see\nthat nine records because it may be\nsomewhere\nprobably i won't be able to see that\nprobably in this specific thing i should\nhave that right\nlet's see\nsum sum cosines has 9 okay the total\nnumber of let's say total number of\ndf\ndot\nthey are around nine five five one rows\nso because of that it is not getting\nvisible over here\nvery small number of nand values so that\nis the reason we cannot see it but if\nthere are many many you can definitely\ncheck it out so we have we have\nunderstood about the missing values and\nwe have seen that now i have already\ntold you that there is another data set\nwhich is called as country code now\nlet's try to see that what this data set\nbasically have so i'm going to write df\ndot underscore country and i'm going to\nsay pd.read underscore csv\nand i'm going to use\nand then i'm going to basically write\ndf.country dot head\nit is giving me an error let's see what\nis the error\nokay here also some problems with\nrespect to invalid continuation byte i\ncannot use read underscore csv i have to\nuse read underscore excel because it is\nan excel file otherwise again you have\nto use that same encoding things to make\nit work how to deal with missing values\nuh that i will try to show you in\nfeature engineering so here you have\nthis one country code country code xls\nso what you have over here see\ncountry code country two features if i\ngo and probably see my df dot columns do\nwe have country code over here here also\ncountry code are there can we combine\nthese two data frames so what we will do\nin order to combine we will be using\npd.merge\nso merge is a function which will\nactually help us to combine\nin the left i will give my another data\nset in the right i can give another data\nset\nso here i'll give df and here i'll give\ndf\ndf underscore country but let's see\nanother feature\nso there will be one feature which will\nbasically say on\nthis on basically says that on which\nfeature you are basically going to\ncombine that two tables so here i'm just\ngoing to say on is equal to\ni'm going to copy this country code so\nhere i've come copied this country code\nand then it'll basically left as how\nand here there is also one more keyword\nwhich is called as how\nthis how will basically specify whether\nyou have to focus on\nleft table or right table so here\nprobably somewhere you will be able to\nsee this is how whether you want a left\njoin the right join or inner join but\nright now i want to really focus on my\nleft hand side of table which is df\nbecause this has the entire data set in\nthe right hand side i just have one\nadditional column that is country name\nso in order to combine it what i'm\nactually going to do i'm just going to\nfocus on left\nso here is my left and once you see this\nyou will be able to see that i will be\nable to get all the records\nand somewhere you'll also be able to see\ncountry see in the last thing country is\ngetting added i will just save this in\nmy final data frame which is called as\nfinal underscore df so this is my final\nunderscore df and now if you go and\nprobably see final underscore df dot\nhead\nand if you check the first two records\nyou will be able to find out everything\nso finally final underscore df is my\nentire data set now let's go ahead\ninside the data set and try to explore\nwhat all things we have there is also\nanother way to check data types\nif you want to check data types you just\nhave to write something like this\nfinal underscore df dot d types so there\nis also d types which will actually help\nyou to just get the data types\ninformation\nso just use dot d types and there you\nwill be able to see the entire data type\nthis on is basically used to match on\nwhich column you are basically going to\ncombine just like how you do left join\nright join\non on a specific column if you if you\nhave seen my sequel of my videos i have\nalready uploaded let's go to the next\nstep now\nlet's try to do something amazing and\nnow let's try to explore something from\nthe data now understand one thing is\nthat\nif i go and see this data there are\nfeatures like\nokay let's let's open this let's open\nthis final underscore\ndf dot columns\nhere you'll be able to see there are\nfeatures like country code city address\nlocality locality verbs longitude\nlatitude cuisines average cost for two\ncurrency this this this are there let's\npick up something okay let's pick up\nprobably let's see that i i just want to\nfind out something okay and mainly\nunderstand whatever things i will do\nright now i will make sure that i'll\nwrite observations for those so what i'm\nactually going to do over here is that\nlet's say that i'm going to use\nsomething like this final\nunderscore df\ndot\ncountry\ndot\nvalue underscore count what i'm actually\ndoing over here i'm just trying to find\nout how many different countries are\nthere and with respect to this\nparticular countries so in this records\nright with respect to a specific\ncountries how many records are there so\nin india you will be able to see 8652\nrecords\nin united states you'll be able to see\n434 united kingdom 80 60 60 60 60. so\nfrom this what kind of observation do\nyou feel that you can come up with\ncan you say that zomato is mostly\navailable in india itself obviously in\nusa they just have a website\nwhich they will recommend some kind of\nrestaurants\nbut\njust understand one thing over here is\nthat in india the main base of zomato is\nthere so maximum number of transactions\nthat may probably be happening is in\nindia right i hope everybody is able to\nunderstand right so from this this\ninformation you are able to get\nnow if i write dot index\nnow with respect to the dot index you'll\nbe able to see i'm able to get all the\ncountries name with respect to that\nspecific records okay\nso let me just save this probably in a\nvariable which is like country names\ni'll tell you why i'm doing it\neverything will make understand\ncompletely after this i'm going to plot\nsome pie chart i'm going to plot some\nchart now similarly if i use the same\nthing\nand if i execute it\nwith dot index you will be able to see\nthat i'm getting this country names but\nwith dot value counts i will also be\nable to get\ndot value counts\ni'll be able to get\nsorry countries dot sorry value count\nstart valuable\ndot values\nlet's see\ndot v a l values okay so with respect to\ndot values i'm actually getting all the\nnumber of records for that particular\ncountry name now this two i have the\nreason why i'm doing this here is that\nbecause i'm going to create some pie\nchart\nnow how do we create a flight chart so\nyou use plot.pi\nand\nwith respect to this\nyou use plot.pi\nand with respect to this you can\nactually put out all your variables so\ni'm going to press shift tab\ni need to have my x variable\nif i am actually putting plot uh pi pie\nchart over here i definitely have to use\nthis\nnow over here in the x value i will try\nto use my names or values whatever\nthings you want let's say that i want to\nuse my values so here i will store this\nas my country\nvalue so i'm going to put this entirely\nover here in the x axis because i want\nto see in the pie chart\nwhich country has the maximum\ntransactions or maximum\nonline orders or maximum kind of orders\nover here so i'm going to use this as my\nx axis so this is my x axis in plot.pi\nso here if you expand it here you will\nbe able to see it and then you have\nlabels this is important okay labels is\nbasically to give the labels on top of\nit so i'm just going to use labels is\nequal to i'm going to assign this value\nto something like country name okay\ncountry name so these two things are\nthere now if i execute it here you will\nbe able to see that i'm getting a plot\nnow this plot looks really bad because\nobviously the percentage of the\ninformation spread towards the different\ndifferent countries is very less so it\nis like jumbled up complete so what i am\ngoing to do is that i am just going to\nsay\nwhich are the top five countries\ntop five countries or top three\ncountries the top three countries that\nuses zomato that is based on your\ntransaction right so what i'm going to\ndo here i'm just going to use colon 3\nhere also i'm going to use colon 3\ncolon 3.\nso that basically says from entire all\nthe values over here i'm just going to\ntake the top three values at top three\ncountries and i'm going to just display\nnow it looks good now which is the top\nthree countries that is basically using\nindia united states and united kingdom\nright so i hope you are able to\nunderstand over here with respect to the\npie chart like how is my data\ndistributed and over here definitely\nwith respect to zomatos no matter the\nbase companies in india so obviously you\ncan come to a conclusion that maximum\nnumber of transactions will happen in\nindia now one more thing that i probably\nwant to add is something called as\npercentage because i need to see some\npercentage also right that would be\npretty much amazing right\nso what i'm actually going to do over\nhere there will be a parameter which is\ncalled as percentage also and that\nparameter is something called auto\npercentage so i will use this auto\npercentage\nand i'm going to use one\nproperty\nif i want to see one property over here\nwhat will i assign to this you can\nassign one format and that format i can\nbasically write something like this this\nbasically says that after this after the\ndecimal two values will be mentioned\nwhen it is getting converted into\npercentage so i'm just going to remove\nthis double quotes\nand this will definitely work then play\nwith it if i write if i remove this two\nwhat will happen if i remove this\nif i remove f what will happen just try\nto play with it now if i execute it here\nyou can see now\n94.39 percentage\nis basically the orders are from india\n4.73 transaction is from united states\n0.87 is from\nunited kingdom so here you need to write\nyour\nobservation now tell me suggest me what\nobservation should i write over here\nfrom this diagram what kind of\nobservation that you can see you just\nneed to add this particular property\nto get the percentage values\ntell me what is the percent observation\nthat you will write\nzomato\nmaximum\nrecords\nor transactions\nare from\nindia\nokay\nand then\nafter that\nusa\nand then united kingdoms\nyou have to write your observation in\nyour own words here i have just written\nsomething\nbut just try to write so here obser\nzomata maximum records the transaction\nare from india after that usa and then\nunited states\nunited kingdom sorry so this is my first\nobservation that i have been able to\ntake from this pie chart\nmajor business is happening in india you\ncan say and all a lot of things can come\nokay everybody is clear with this i hope\nit's very simple till here okay\nnow\nlet's go with respect to the next one\nthat is numerical variables\nhow do we identify how many numerical\nvariables are there how many numerical\nvariables are forget about numerical\nvariable let's do some exact\nrelationship\nnumerical variables we can check it\ncheck it in later stages\nbut i want to really do more observation\nthings more relationships things so that\ni will be able to see something now if i\ngo and write final underscore df dot\ncolumns\nif i execute this here you can see some\namazing features which is called as\naggregating rating because i want to\nalso see with respect to the rating from\nwhich country more rating is actually\ncoming and i want to see this data which\nis called as rating color rating text\nand all okay so what i'm actually going\nto do\ni'll just write a small query\nfinal underscore df dot\ngroup by i am going to use a group by\noperation\nand with respect to a group by operation\nhere i am going to use features\nwhich is called as aggregate rating\naggregate rating and then i will also\nuse the rating color\nsee this everybody rating color i'm\ngoing very slowly guys very very slowly\ni think you can write it down i am\nwriting each and every line of code\nrating color\nand then i'm also going to use rating\ntext\nrating test so i'm basically going to uh\ngroup by this three main features\nand after this i'm also going to do one\nthing so if i group by this\nand probably execute\ni'll be getting an error let's see what\nis the error rating text so it should be\nrating small t\nso if i execute here you can see that it\nis now a data frame group by object\nnow if i write dot size\nso if you if i execute this dot size\nhere you will be able to see all the\nvalues like white\nnot rated this this this this are there\nand similarly good good good very good\nsee over here one thing you can see that\nwhen the rating color is white that\nbasically means your aggregate rating is\n0.0\nif your rating is red then it is\nbasically showing 1.8\n1.9 is also red 2.0 is also red 2.1 is\nalso red like this 2.4 is also red so\nall these are red red basically means it\nis poor it is poor so this ratings are\npoor with respect to this aggregate\nrating you can see that it is poor if i\ngo with respect to the next one which is\nin orange color here you can see that\nthese are my all average ratings from\n2.5 to 3.4 then you have from 3.5 to 3.9\nthat is another rating over here here\nyou can also see that these are good\nright so it is displayed in yellow color\nor the text is written in yellow color\nthat like the rating colors are there\nand then from 4.0 to 4.9 we have very\ngood and excellent so this information i\nknow i have actually able to find it out\nso i'll also can write my uh\ni'll try to write my own observation\nover here now what i'm actually going to\ndo over here is that after i do this\ni'll convert this into data frame now in\norder to convert this into data frame\nwhat i will do is that i will just write\nreset underscore index\nand this is an invalid error the reason\nit is an invalid error because i have to\ncontinue over here\nreset underscore index and then i'm\nbasically going to just say that rename\nor if i just execute this let's see what\ni'll get so here you can get see that\ni'm getting this particular things and\nthis is my zero value since i have done\ngroup by\nwith respect to 0.0 ratings i have 2148\nrecords then with respect to 1.8 i have\none record 1.92 records 2.07 records\nover here 0 is coming so instead of this\n0 i'll try to rename it with different\ncolumn so here i'm just going to use\nafter reset index dot rename\nand here i'm going to basically use\ncolumns\nis equal to\nand i'm going to name it to 0 colon\nlet's say i'm using rating count\nnow let's do one thing\nnow see what i've done after doing reset\nindex i'm using rename function\nand i'm saying wherever the columns is 0\nchange it to rating count\nso once i execute this\nyou can see that i'm getting one error\nbecause i have not closed it i will\nclose it now\nso here i've closed it and here\nwith this\nand now here you can see that i'm\nactually able to see this everybody you\njust write down this code i know many\npeople will get stuck over here\nnow we we'll do multiple things with\nrespect to this so what are the\nimportant information that i'm actually\nable to get from here\nare they correlated we'll try to find\nout don't worry right now i've still not\ngone into correlation those are some\ninbuilt directly you're using inbuilt i\ndon't want to go into inbuilt right now\nnow over here main features everybody\nhas written this final underscore df dot\ngroup by aggregate rating rating color\nrating text dot size dot reset index dot\nrename\ncolumns you are renaming from 0 to\nrating count\nso here you can see that aggregate\nrating is there rating color is there\nrating text is there rating count is\nthere so all these informations you have\nwith yourself right all these amazing\ninformation you have over here\nnow let's go to the next step\nnow what i'm actually going to do over\nhere is that i have my rating count\ninformation\nreset index basically means it will just\nreset this index\nthis index\nby default whatever index is coming you\nhave to reset that\nso i hope everybody has done this\nnow i will just save this in a variable\nthis variable will play a very important\nrole guys now\nso i'm giving you another one minute\nplease write it down so ratings is equal\nto this one\nef\nfinal underscore\ndf dot\nguys please write it down\nif anybody is not write it written down\nthen again i am going to share it to you\nhere\nplease write them down this particular\ncode because it will be very much\nimportant\nnow i have all these things if you go\nand see\nratings\nso here you have all the values average\nrating rating color rating text and\nwriting now let's go ahead let's go\nahead and let's plot some amazing\nbeautiful diagrams now i want to really\nfind out\nthis all relationship with respect to\ndifferent different countries\nwith respect to different different\nproblem statements with respect to this\nhow see how as a data analyst data\nscientist you have to think okay this is\nmy data set okay probably what what type\nof visualization i can draw from this\nbecause i want to do some kind of edn\nokay what what kind of things i can do\nabout this just by seeing the data i can\ndefinitely come up with one conclusion\nis that\naround 2148 ratings have zero rating\nmaximum number of people have actually\ngiven zero ratings that basically means\nthey have not rated\nthe app or the entire zomato app itself\nright so here what we are focusing on we\nare trying to understand okay maximum\nnumber of ratings zero basically means\nperson has not given any ratings right\nso here you can see rating text is not\nrated right people who are giving\nratings you can see poor average good\nalong with that colors are also given so\ncan we plot this in an amazing way so\nthat we can understand in a visualized\nway also so let's go ahead\nfrom this i can come up with conclusions\nagain i'll write conclusions\nconclusions is very much important\nobservations i can also say observation\nso this is my observation from this data\nset\nthe first observation is that\nthe first observation is that\nwhenever the rating is from\n4\nto 4.9\nor let's say from 4.9 to 4 sorry 4.5 to\n4.9 so here i'm going to write the\nobservation when rating\nis between\n4.5 to 4.9\nthis indicates what does it indicate it\nindicates that it is excellent\nprobably the foot that was delivered was\nbasically excellent second thing that we\ncan come up with this observation is\nthat\nhere you can see that from\nfrom\n3.5 to 3.9\nwhen the rating\nwhen\nwhen ratings\nare between\n3.5 to 3.9\nhere you can basically say that\nit is very good\ni hope 3.9 only right\nno 4.0\nto 4.5 extremely sorry i missed that\n4.0 to\n4.4\nthe ratings are very good the third\nthing that i can come up with is that if\nthe rating is between\n3.5\nto\n3.9\nhere the rating is\ngood\nso this is my observation because i can\ndefinitely see from the data right and\nremaining all please go ahead and write\nit down okay\nso another observation from 2.5 to 2.9\nit is average\nso i'm just going to come copy this\n2.5 to 3.0 or 2.9\nwait wait wait wait average 3.0 to 3.4\nis average so 3.0 to\n3.4 is average\nso this is my next observation and fifth\ni will go ahead and write\nwhen the rating\n[Music]\n6 i'm going to write when the rating\nwhen the rating is between\n2.5\nto 2.9\nand it is 2.0\nto 2.4\nright so 2.9 how much it is average\nagain this is also average\nuh 2.0 to 2.4 is poor\nright\nso these are some of my observation just\ncomplete down all the observations that\nyou can find out from this and one more\nthing that you can see that zero rating\nhas been given by many of the people\nright so these are all my observations\nwith respect to this but if i am writing\nobservation it is better that we also\ndraw some kind of diagrams now here i'm\ngoing to basically draw a diagram so\nthis is my ratings so here i'm going to\nuse aggregate rating let's say that this\nis my writing dot head\nso here i have aggregate hitting rating\ncolor rating text rating count so i'm\ngoing to use now c bond bar plot let's\nsee can we visualize with the help of\nbar plot something in this so here i'm\nbasically going to use\nuh in bar plot always understand what\nall features you have so here you have x\ny we data order we order everything is\nthere but what i am going to do i am\njust going to do a simple bar plot\nso here in the x axis i am going to\nbasically use\naggregate rating\nso i'm going to use aggregate rating\nin the y i'm basically going to use\nrating count\nlet's say that i'm going to see the\nrelationship between\naggregating rating aggregate aggregate\nrating and rating count see this is my\naggregate rating and this is my rating\ncount i want to basically draw a bar\nplot and basically check how the graphs\nlook like okay so the third parameter\nhere i am going to basically use data is\nequal to ratings so once i write this\nand execute it here you can basically\ncheck out how beautiful it looks now the\ndiagram looks smaller so what i'm\nactually going to do i'm just going to\nput one\nsimple settings to increase the diagram\nso that you'll be able to see it in a\nbetter way okay and that settings is\nbasically there in the matplotlib so i'm\ngoing to use something like this\nand there is another setting which is\ncalled as\nmatplotlib dot rc params figure dot\nfigure size here you can give with\nrespect to width and height i am now\ngiving 12 6.\nso here\nmatplotlib okay import matplotlib i'm\njust going to write it down\nso now here you can see the diagram\nlooks quite bigger\nnow if i probably go and execute the\nheat map over here again\nlet's see whether it will change or not\nso now you can see this values right the\nmissing values once i made the diagram\nlittle bit bigger\nyou can see this i've done it now what\nis this missing code that we have missed\nwith respect to increasing the figure\nsize just write matplotlib dot rc parent\nso with respect to any parameter that\nyou want to change you can basically use\nthis here i have set it to 12 comma 6\nnow once you see this diagram from this\ndiagram you can definitely find out a\nlot of information this diagram looks\nsuper cool\nzero rating is more than 2000 over here\nthen you can see 2.2 2.3 2.9\ncomplete it looks like a gaussian curve\nright\nwhenever you have a gaussian curve you\nget a good sense of feeling\nyes\nnow let's do one thing\nover here you can see that rating color\nis also there so it is always a good way\nthat we should also color this aggregate\nrating with the help of colors that is\ngiven over here\nso this is the code everybody write it\ndown\nx aggregate ratings y rating count\nnow as i said okay i have this coloring\ntext rating color i have this white red\nand all should we use this colors over\nhere also and probably try to get in the\nform of colors and then try to see it so\nthat also will try to do it okay so to\nget the colors uh what i'm actually\ngoing to do i'm just going to copy the\nsame thing entirely there is one more\nparameter which is called as hui\nso if i write hui\nis equal to\nrating color\nif i write this\nand execute it\nyou will be able to see\nc o h\norange color green color red color and\nall but understand whatever color is\nthat this is not matching right\nwhite looks like blue so this is\nwherever you can see blue right it is\nbasically showing you zero rating but\naccording to this white red why this\nzero should have white color right\nso what i'm actually going to do over\nhere is that we have to map the colors\nalso now how to map the colors we will\ntry to see so mapping the colors let's\nsee over here so mapping i'm going to\nbasically use palette\nand inside this palette i'm going to\nbasically use different different colors\nso the first color that i want to show\nover here is something called as white\nthe second color that i want to show is\nred\nthe third color that i want to show is\norange\nit should be in the list okay the fourth\ncolor that i want to show in in yellow\nthe fifth color that i want to show is\nin green\nthe sixth color also i want to show it\nin green so here is what i have written\nin palette this palette is a feature\nthat is present or\nis an attribute that is present in bar\nplot where you can give your own colors\nas it is required based on your\nrequirement so once i execute this now\nlet's see some error is there has no\nokay pellet spelling is wrong i guess it\nshould be tte\np a l e t t e palette\nso once i execute this\nand let's see now\nso now you can see that i'm getting the\nperfect color\nright white is white then red\nthen orange then this then this then\nthis now from this also\nwhat kind of observation you can\nbasically get\nright what kind of observation\nmaximum number see i'll again write\nobservation first of all you write down\nthe code everybody\nyou'll be able to see that i'm getting\nthe colors but just go ahead and write\ndown the code and quickly see that what\ntype of graphs we are able to get over\nhere\nwhite is invisible don't worry it's fine\nyou want to make it in different color\nthen make it instead of white use it\nblue\nnow here you have this right\nnow from this what kind of observations\nwe can actually\nget\nso observations i'll write it on over\nhere again\nobservation\nfirst observation that i would like to\nmake\nnot rated basically means this blue\ncolor\ncount is very high\nthen\nthe second thing is that\nnow\nsecond observation that you can see that\nmaximum number of ratings\nare between\n2.5\nto 3.4\nmaximum number of ratings are between\nthis\nso definitely these two observations you\ncan basically find it out\nthis two observation you can definitely\nfind it out clear everybody these two\nobservations we can basically fight it\noff now just imagine that if you have\nsome ratings as missing then what do you\ndo\nsuppose let's say that a person has\nrated but you have some missing values\nnow\ncan't you think that now probably you\ncan use the values between 2.5 to 3.4 as\nan average\nright so this is what\ntype of observations you can basically\nhave this is what because maximum number\nof observations or ratings are between\n2.5 to 3.5 so you will try to find out\nthe average between them and then try to\nget it\nso i hope you are having fun guys\nclearly able to understand\nnow the next step\nwe will also see right now we have just\nseen with respect to aggregate rating\nand rating count i probably also want to\nuse with respect to just the coloring\npart this rating color i want to plot\nthis as a count plot so count plot let's\nplot it so i'm going to use snh dot\ncount plot\nand here i'm basically going to use x is\nequal to\nrating\ncolor okay\nin count plot\nwe basically use this for plotting with\nrespect to categorical variables so here\nalso you basically give an x and y value\nand we value so here i'm giving x value\nand then i'm also going to give my data\nwhich is my ratings\nand then again i can give my palette\nover here with the same list\nthat i have actually defined over here\npalette the color should be same right\nso that is the reason i'm just going to\ncopy this entirely\nand paste it over here\nso once i execute it here you will be\nable to see\ni'm getting\nevery time i write the wrong spelling so\nhere you can see\nwhite\nred orange yellow green\ndark green\nthis is with not respect to count guys\ndon't worry okay this y y axis here you\nare able to see over here but understand\nin rating what you have\nwhat you have you basically have\nsomething like this right so white is\nonly one record\nred is so many records right this is my\nred they are around five records then\norange they are around seven to eight\nrecords\nright yellow there are on this many\nrecords green they are this many records\ndon't consider that this count is\nbasically your rating count no this is\nthe frequency how frequently it is\nbasically present in this uh data frame\nnow let's go ahead and do some more\nin-depth\nin-depth analysis in depth now you will\nget more confused now i'll give you a\nquestion please try it out from your\nside okay\nfind\nthe countries\nthat has given\nfind the countries or country name a\ncountry's country countries name\nthat has given\nzero rating\nnow this is my one of my query for you\nall\ntry to do it and i'll wait\ni'll wait for you all\nlet's let's try to do something guys you\nshould be getting some queries at least\nvery important interview question as a\ndata analyst find the country name\ncountry's name that is that has given\nzero ratings\nplease do it everybody\ni'll be waiting for you\nthat has given zero rating how do you do\nit\nyou will definitely get more confused\nthat is where a data analyst will come\nfind the country's names that has been\ngiven\nthat has given zero rating\ni'll also try till then\nfinal underscore df dot columns\nso\ni need to basically get\nall the country name so country name is\nobviously there\nokay and\nthose who are given zero ratings if zero\nrating is there\nprobably i can identify with zero\nratings i can identify with\naggregate rating\nor\ni can also identify with rating color\nokay so two parameters i can definitely\nfind out with\nso what i'm going to do over here is\nthat i'm just going to say rating color\nlet's use rating color\nrating color\nif i say if the rating color is equal to\nwhite\nwhite is capital or small\nwhite is capital\nso if i execute this here i'll be\ngetting like this false false true true\nso\ni'll just write final underscore df\nso here so many information i'm getting\nnow\ncity city so many records are there\nbut i don't think so this is right\nbecause here i may see different rating\nalso\nso here what i will do i'll do group by\nand here i will specify my country\nso if i execute this this is my data\nframe so here again i'll be doing\ndot size\ndot reset index\nif i execute this now i'm able to get it\nbrazil five different zero ratings is\ngiven india two one three one three nine\nzero ratings has been given\nunited kingdom one united states three\nso again what is observations that you\ncan basically say\nso here write down the observations\nagain\nnow here observations are what\nright\njust the say observation\nmaximum\nnumber of\nzero\nratings are from\nindian customers right\nno no it's not about imbalanced data set\nin this case\nbecause if you see the data set right\nover here two one three nine\nzero ratings see out of the total\nratings how much is the total rating\nthat we saw\ntwo one four eight\nright and from them if you try to see\ntwo one three nine\nit's a huge number\nthis is not getting used for models guys\nbecause we don't know what we need to\npredict right now we are just analyzing\nthe data taking out information from\nthat data\nokay next question next question to you\nfind out\nwhich currency\nwhich currency\nis used by which country\nso this is my next question to you all\nif you probably go and see final\nunderscore df.head\nyou will be able to see this specific\nthing\nso sorry dot columns i will just write\nit as dot columns\nso here you have um\nlet's say where it is currency is there\nokay\ncurrency is there so\njust try to do this\nfind out which currency is used by which\ncountry if you want all the list of\nrecords what you'll do so\nwhat i'm actually going to do now\ni'm going to use final underscore df\nthere are two\ni i want basically country with respect\nto currency so what i'm actually going\nto write over here i'm going to\nbasically say country\ncomma currency\nand then i'm going to basically use\ngroup by again\nand group by will again be based on\nthese two groups\nthat is country and currency\ndot\nsize dot reset\nreset index\nreset index is used in many ways\nso here you can see i'm actually getting\naustralia\ndollar\nbrazil brazilian rail canada dollars\nindian indian rupees\num indonesia rupay new zealand and all\nso two things one is group by dot size\ndot reset index that's it\nyou don't have to do group by by\neverything you have to just focus on two\nrecords two features\nthat is this and that\nnow here one more feature is there see\nhas online delivery or not\nso my next question to you all\nfor those people who have done this\nthe next question is that\nwhich\ncountries\ndo have\nonline deliveries\nonline deliveries option\nso india has two four two three uae has\ntwo eight amazing\nthat's nice\nthat basically means that the online\ndelivery is only available in india and\nus but let's say that i want to find out\nuh all the countries that has or has not\nokay i will just use this code\nso reset index that's it so what he has\ndone is that\nhe's basically used uh\ntwo features has online delivery country\ngroup by has online delivery country\nand size dot reset index so here you can\nbasically see that australia it does not\nhave any brazil no online delivery\ncanada no online delivery\nwhy india\nhow come india is again coming over here\nwhy india is getting repeated again\nokay in india also probably in some of\nthe reasons online delivery may not be\nthere perfect\nin india in some of the regions you will\nnot be finding online zomato delivery\navailable okay so because of that some\nrecords you will not be able to see so\nbut here you can see main two countries\nthat has online delivery is india and\nuae\nso obviously make some observation from\nthis and try to find out\nso here i'm basically going to basically\nsay observations\nagain\nwhat is my observations over here\ni will basically say\nnumber one\nmy first observation is that\nonline deliveries\nare available in\nindia and\nyou a\n[Music]\ndone\ndhamal\nnext question\nnow the next type that i am actually\nfocusing on is that i'll give you one\nquestion like how we did with respect to\nthe countries\nhow we did with respect to the country\nsimilarly try to find out or create a\npie chart\nfor cities distribution\ni hope everybody is understanding the\nquestion\nso here if i write final underscore\ndf.columns\nyou will be able to see there is also a\ncity\nnow i want to create a pie chart\nwith respect to this specific cities\nagain the same thing like how we did it\nfor country so i'll go up\ni'll go up\nand i'll copy this two things let's see\nso here is one\nhere instead of writing country i will\nwrite it as city\nthen this is my values this is my index\nso this is my countries cities that from\nwhere the order has happened and i'll\ntry to draw a plot\npie plot okay so here i'll say plt dot\npi\nand here i'm going to give two things\none is with respect to\nvalues and then with respect to index\nfinal underscore df country.values i\nhope this works\nfine x x and y\ni have to basically given this as labels\nokay\nlabels\nor let me make it little bit easy for\nyou\nlet it make easy for you okay city\nvalues\ni'm going to save it in this city labels\ni'm going to save it in this\nand this will basically be using index\nso i've executed this so this will go\nwith city values\nand this entirely will go with respect\nto\ncity labels so i let's say that i want\nto\nget the top five cities\nfor cities which issue for top five city\ndistribution\ntop five city distribution so here i\nwill just use\ncolon five\nand here also i'll be using colon try\nso once i execute this here you will be\nable to see this\nthe first\noh it's coming as india why\ncity labels\ndot dot by city value city labels why\nwhy why why why\n[Music]\ni think there is some mistake\nplot pie\nfinal underscore\noh i have to use city\nmistaken mistaken\ni had copied right so you should not do\ncopy and paste a lot\ndon't do copy paste\nso new delhi has the maximum number of\ntransaction\ngurgaon noida gaziabad and faridabar why\nnot bangalore i think in the data set\nbangalore is not given\nafter this i'll also add one auto\npercentage\nand here i can basically specify 1.2\nf\nso if i go and see this here you'll be\nable to see percentage\nso maximum number of transaction is\nbasically happening from new delhi\nso guys overall how was the session\neverybody\none assignment for you\nso\nassignment\nfind the\ntop 10\nquestions\nquestions basically means food okay\nput item so this will be for you\njust do it one assignment and remaining\nall i think i have done it\nnow in this data set i had never used\nthis data set for doing machine learning\nmodeling i needed this data set to find\nout what all information i can capture\nfrom it and finally i was able to do so\nmany things right i i did not worry\nabout distribution and all that is the\npart when we\nactually create a model with respect to\nthe data set at that point of time we do\nso i hope you liked this particular\nsession it was fun it was comedy it was\ninten it was good\ncan we group the other cities under rest\nyes obviously you can do it\nright\ntomorrow\nanother amazing day another amazing data\nset\nso that we will be working on it and\ndefinitely you'll be able to learn a lot\nas i said\nright\nvisit the website guys because here i'm\ngoing to give the entire\nmaterials\nhave you seen my website how do you like\nto rate my website guys\nso this i created in three to four hours\nprobably i'll also start showing you how\nto create websites\nso this entirely i created three to four\nhours so everything will get updated in\nthis article also\nsee this\nthis live session is going on right now\ncurrently see\nall the materials will get uploaded over\nhere data set materials\nso please make sure you do this\nand yeah\nstart exploring it\nokay guys so thank you keep on rocking\ni'll see you all in tomorrow's video and\nyes i will see you in tomorrow's session\ntomorrow we'll have more in-depth\nsession thank you everybody bye bye take\ncare thank you guys i hope everybody has\ndownloaded the data set you'll have this\ntwo data set one is test and train right\ni'll talk about the problem statement\nand today we are also going to do\nfeature engineering\nand both these things right as usual\ntoday we are going to do\nblack friday\ndata set i'll talk about the agenda\neverything\neda and feature engineering we are going\nto do both of this and we will keep our\nmodel ready for model training\nready\nmeans cleaning doing everything\ncleaning\n[Music]\nand preparing the data\nfor\nmodel training we are going to do this\ntoday so this is the two things that we\nare going to do this is the agenda\nso after doing this\nyou can basically use any kind of model\nand start working on it\nso quickly what are the basic library\nthat is required start\nuploading it\nwrite import pandas as pd i'll talk\nabout the problem statement what exactly\nis this\nimport numpy\nas np\nimport\nmatplot\nlib dot pi plot as plt\nimport\nc bond as\nsns and then\nmatplotlib dot pi plot as plt yeah sorry\nin line so this is basically given in\nkaggle okay\nso in kaggle whenever you get a specific\ndata set what do you have to do train\nand test\nthat all steps i'll show you so that you\ncan also participate in kaggle so let's\ngo ahead and let's go ahead with first\nof all importing the data site always\nmake sure that you write the comment\nso importing the data set the data set\nis already given to you so let's say i'm\ngoing to name it as df train because i\nhave two data set one is train and one\nis test data so this df train i'm just\ngoing to write pd dot read csv\nand i'm just going to give my data set\nname\nblack friday train dot underscore train\ndot csv i have renamed the name guys for\nyou it will be train dot csv okay\nand then if i probably write df\nunderscore train dot shape\ni will be able to\nsee it\nor if i write df.head i'll be able to\nsee it\nso i'll talk about the data what this\ndata is basically about uh so this data\nis an e-commerce data\nso\npeople who have bought some kind of\nproducts\nand based on that we need to predict\nwhat is the purchase capacity again\nunderstand\ni'm just going to basically talk about\nthe problem statement\nhere we want to build a model i'm just\ngoing to\nput the problem statement over here\nlet's say i'm going to put a problem\nstatement over here\neverybody read the problem statement\nanyhow i will be giving you all these\nthings materials everything\nin the github don't worry\nso\ni'll also put the data set link over\nhere\ndata set link\nso data set link is this\ndata set link and this will get saved\nover here so what is the problem\nstatement so this is the problem\nstatement that we are going to focus on\nso the problem statement is that a\nretail company abc private limited wants\nto understand the customer purchase\nbehavior is an e-commerce data set data\nset is also very huge so it will be very\ngood to work on it against various\nproducts of different categories they\nhave shared purchase summary of various\ncustomers for selected high volume\nproducts from last month\nthe data set also contains customer\ndemographics like age gender marital\nstatus city type stay in the current\ncity product details product id and\nproduct category and total purchase\namount from last month so\nover here now they want to build a now\nthey want to build a model to predict\nthe purchase amount of customer against\nvarious product that will help them to\ncreate a personalized offer for customer\nagainst different products\nso this is the problem statement over\nhere the problem statement is very\nsimple you need to create a model to\npredict the purchase amount of a\ncustomer against various products right\nso suppose if i have if i give this\ninformation like this product with this\nproduct information these all things i\ngive then we should create a model that\nwill be able to\npredict this purchasing capacity\nright so this is the entire information\nregarding the problem statement okay\nso this is what we are going to do\ninteresting we'll solve the problem here\nonly in front of me so i have\nread\nthe training data set the next step that\nyou have to do is basically start\nreading the\ntest data set now train data set test\ndata set see whenever you are given\ntrain and test obviously what initially\nyou have to do you have to combine them\nin a kaggle computation always remember\nto combine them so that all the data\npre-processing that we can do we can\nperform on both the data set so here i\nam going to now import\nthe test data\nright so here i am going to say df\nunderscore test\nis equal to pd dot read underscore csv\nand here i'm going to basically write\nblack friday dot csv\ndf underscore test dot head\nin the test data you will not be able to\nfind the output variable variable so\nhere you can see\nonly take product category 3 is there\nhere additional purchase column is there\nright\nso now if you want to combine the train\nand test data how do you do it the next\nstatement is merge\nboth\ntrain and test data so how do you merge\nboth train and test data\nwe can use pandas dot merge\ncan we use pandas.merge or pandas.concat\nor panda does append what what you want\nto use\nlet me try it some different way now\nhere i'm basically going to say df1 dot\nappend there is an append function\nsorry df underscore train\ndot append\nand df underscore test\nso what will append basically do\nyou can see the definition over here\nappend rows of other to the end of the\ncaller returning a new object right so\ni'm just going to do this there is also\none more parameter that i see with\nrespect to sort so sort by default is\nfalse right so i'm just going to execute\nthis\nand then i'm basically going to store\nthis inside my df\nso this is my df dot head now\nyou can also append it in different\ndifferent ways i have no problem\nokay it is up to you\nso this is the first step that we have\nactually merge also you can do\nbut again understand we have to append\nit at the bottom right we are not\nmerging it like this\nso merge\nif you want to do with words if it is\npossible with merge try to do it\ninstead of writing merge here i could\nalso add written append\nmerge also you can do it okay\nso this was the next step now let's go\nto the next step everybody\nso basic basic\ncode that we have seen already right one\nis df.info\nwe can check out this one here we can\nunderstand that how many different types\nof features are here\nso obviously int is there object is\nthere object is there object is the int\nis the object intent float float float\nis there so definitely when you see\nproduct id it will be a combination of\nboth integer and\ndifferent values so it is basically an\nobject then you have gender obviously it\nhas male and females so categories that\nis an object age is basically an object\nwhy age is an object because here you\nwill be able to see age is given in some\nrange 0 to 17 0 to 17 55 plus so this i\ncan consider it as categorical variables\ni'll also show you how to solve that\nparticular problem also but i hope\neverybody has got our understanding till\nhere the next statement that we are\ngoing to basically find out is something\ncalled\ndf.describe just to find out like what\nis the percentile values and all so here\nis just a basic information\nthat we are going to differ now tell me\num\nwhich which column do you think out of\nthis is just waste you can directly\nblindly you can delete it\nsee over here there is a column which is\ncalled as user id user id\nis just a unique id over here\nso you can definitely go ahead and\ndelete it okay user id will be of no use\nproduct category everything other will\nbe getting used don't worry about that\nbut user id is definitely not useful so\ni am going to delete it so what i am\nactually going to do i am going to\nbasically write df.drop\ndf.drop this is a statement which will\nbasically use to drop the feature and\nhere i can give any number of features\nany number of features\nwith respect to my feature name so\nfeature name is nothing but user\nunderscore id\nso i'm just going to copy this paste it\nover here user underscore id and here\none very much important parameter if i\nsee in df.drop is access\naccess is equal to 0 basically means\nhorizontally right row wise access is\nequal to 1 basically means vertically\nright column wise so we really need to\ndrop it column wise so here i'm going to\nbasically say it has access is equal to\n1 and here i'm going to specify in place\nis equal to true\nthe in place is equal to true what it\nwill do is that it will remove that user\nid and it will update automatically into\nthe df value so if i go and probably\nexecute it and now if i go ahead and see\ndf.head you will be able to see that\ni'm actually able to see my product id\ngender\nall the other information perfect\nso here we have basically done this we\nhave dropped the user id we have df.head\nwe have everything ready now let's go\nahead towards the data preprocessing\nside now tell me how many categorical\nvariables are there\nhow many categorical variables are there\njust by seeing this one you have gender\none you have age\none you have occupation city stay in\ncurrent city this this but before that\ni also need to make sure that how many\nnumber of missing values are there for\nthe missing values i may do something\nwhich i will show you in the later\nstages but let's focus on fixing the\ncategorical features right now so how\nmany category features are there you see\nover here gender is there age is there\ncity category is also there so we will\ntry to fix this category features\nbecause our model will definitely not be\nable to understand\nuh how my categorical features will be\nthere or not\nmarital status is already numbers\nbut let's see what all things will\nbasically be there\nso\nlet us go ahead and take up age and try\nto solve this convert this categorical\ninto\na\ncategory into a numerical will try to do\nthat okay\nso\nfirst of all let's focus on this\nand let's go ahead\nnow tell me with respect to gender i\nhave male and female right with respect\nto gender i have male and female now\nwhat should i do in order to probably in\nmale and female what kind of encoding i\ncan definitely use so if i write pd dot\nget underscore dummies\nand if i give my df of\ngender\nif i execute it here i will be able to\nget either\nmale or female so here am i actually\ngetting ones or zeros right one is\nbasically given to f\nzero is basically given to male okay so\neither in this way you can do it but\nagain see what is the problem here if i\nconvert in this way then i have to\ncreate another data frame then i have to\nadd this data frame over here then\ndelete this gender column can i do\nsomething within the data set itself\nwhere probably i can directly convert\nthis wherever the f is zero sorry\nwherever the gender is f i am going to\nconvert this into 0 or 1 whether\nm whether the gender is male i am going\nto convert it to 0 to 1. so how we are\ngoing to do that guys\nhow we are going to do that\nyes i can definitely use drop drop\nunderscore first is equal to 1 i can\ndefinitely use over here\nbut understand i don't want to do in\nthis way because i have to save this\nsomewhere then i have to add a column\nover here i don't want to do in that way\ni want to find i want to find out a way\nwhere directly i have to do it over here\nitself in this particular data frame\nitself so how do i do it so for this i\nwill be using a code simple code so i'll\nwrite df of\ngender\nand here i will say df of gender\ndot map\nmap method what it does is that see what\ndoes map method do\nmap method will basically map with\nrespect to the conditions that i am\ngiving over here so here if i say my\nfirst condition is that wherever i get\nfemale i'm going to convert it into 0\nand wherever i get male i'm just going\nto convert it into one\nmany people ask me when i'm\nteaching what is the map functionality\nin python so here you can see easily\nwithin this particular data set you will\nbe able to see it over here now if i\nwrite df dot head\nand if i probably see this\nyou will be able to see now gender will\nbe zeros and ones so everybody write\ndown this code okay one more way is that\ndirectly i assign this to\ndf of\ndf of gender right so this way also you\ncan do it\nso both the ways whichever way you feel\nyou want to do it just do it both the\nways it will work\nis not ranking guys zeros and ones are\nnot ranking one two three four five six\nis basically ranking\nuh zahida sen says do we have to apply\nfeature engineering on training set only\non touch data no on both on both you\nhave to apply i'll show you how you have\nto apply both\nokay perfect so everybody has done this\nright\nso this is with respect to handling the\ncategorical feature\nhandling\ncategorical feature\nage\nsorry gender\nso this is done\nnow let's go to the next step now the\nnext step what i'm actually going to do\ngender is done now we also need to\nhandle age\nhandle\ncategorical feature\nage now why i am specifically saying age\nbecause here you go and see\nage is what age is also a categorical\nfeature see 0 to 17 0 to 17 55 plus so\nfirst thing i will try to execute\nsomething like this\ni will write\ndf of h\ndot uni\nso this will basically give me how many\nunique values are there in age like 0 to\n17 55 plus 26 35 46 50 51 55 36 45 18 to\n25\nnow if i have in this particular unique\nway now tell me how should i convert\nthis categorical feature into some\nnumerical features so here also i can\nactually do encoding so the type of\nencoding what i will probably be doing\nmany people will again get confused over\nhere so why why you are doing like this\nso i'll just tell you so here also i'm\ngoing to use df.h\ni'll assign it to df of age\nright\ntwo things i can definitely do one is\ndirectly get\ndummies\nyou can directly do\npd.getgrammys see this if i write pd dot\nget underscore dummies\nright and if i give it for df of age\ni'll be able to get like this right\nand if i drop\ndrop\nfirst is equal to true then i will be\nable to get like this then what i can do\ni can save with this column name\nand i can put it inside my data frame\ni can do this okay\nbut just imagine something guys here a\ndomain knowledge will definitely come\none very important thing\ndo you think like shopping 0 to 17 years\nit will be very less right in an\ne-commerce website it will be very very\nless right whereas if i say 26 to 35 it\nmay be more\nand where i say 18 to 25 it may be more\n15 to 55 it may be more\n55 plus it may be very less right or 46\nto 50 it may be also very very less so\nhere what we will do is that we'll just\nnot try to convert this into dummies\nlet's do some ordinal encoding only\nlet's let's give some rank to it okay\nlet's let's give some directly some\nvalues like 0 1 2 3 4 5 why i'm saying\nto give 0 1 2 3 4 5 because\nif i'm training the model\nmy model maths will definitely be able\nto understand right my model maths will\ndefinitely be able to understand with\nrespect to the values that we are given\nlike zero one two three four five\nwhatever values i am actually given with\nrespect to the other features my model\nwill definitely be able to understand\nthis is also called as target guiding so\nwe will do something like this okay but\nthis this will definitely not work this\nis not a very good practice also so here\ni'm just going to comment it out and\nthis will definitely not work\ninstead\nwhat i will actually give is that\ni will say\nuh let's apply the same map function\nwhich i had applied over here so here\ni'm going to basically give it this way\nmap function\nand i'm just going to basically put it\ninside this\nhere definitely i'll say age\nthis h\nand\nmapping i will do for 0 to 17 first\nlet's say for 0 to 17 i am actually\ngiving some numbers let's say i'm giving\nit over here as 1\nbecause at least some value should be\nthere then 18 to 25 in the sorted order\ni'll try to give 18 to 25 my second one\nand here i will give it h2\nthen third one again in the sorted order\n26 to 35\ni will give it over here\nbecause see my model when i'm training\nmy model it will be able to understand\nthis is called as target guiding target\nordinal encoding then\nwhat we have 36 to 45\ni hope i'm doing it right\ncolon here i'm actually going to give it\nas 4.\nand then after 36 to 45 i have 46 to 50\n46 to 50 i have\n5\nand then i will be writing 51 to 55\nand i will say\nit as 6\nand then\n55\ni'll say it as seven\nlabel encoding can also be done\nlabel encoding will also work\nperfect label encoding will also work\nbut again\nunderstand\nfor this again you have to for label\nencoding you have to import a library\nand then perform it here also you can do\nthis way you will become\ngood at maths\ndon't put zero guys see as i said i as\ni'm saying right there will be some\nmathematical equations that will be\nhappening so if you want to do label\nencoding how you'll do\nlabel encoding\nin python let's see some articles uh i\nhave some article from geeksforgreek\nso\n[Music]\nlet's see so i have to basically\nupload this entire thing right this\nentire code\nsee entire code by using pre-processing\nlabel encoder and all but i don't want\nto do it because as i get a new data set\nover there also i should be able to\napply all these things right so here\ni'll just copy this\nfrom sklearn you can see over here\nright\nand then you can basically do it with\nrespect to df dot\nage\nand df.h so you can execute this\nand automatically it will work\ndo not hesitate to google\nit is up to you\nright\nit is up to you\nso you can also do this in this way this\nis the second technique\nso i have already done this now if i\nprobably go and see my df dot head\nyou will be able to see in age also i'll\nbe okay i have not executed data\nso i have executed it now if i go and\nsee my df.head you will be able to see\none two three four like that you will be\nable to see\nsee there will be hundred of ways label\nencoder fit transform for the test data\nyou have to do transform\nbut here i've actually combined it so\nthis is not a good practice\nfor this case\nsuppose if i'm doing for trained data or\ntouch data i will just transform it no\nneed to give any any any weightage guys\narvinds see\nour machine learning model will\nautomatically understand so one more\ncategory that i have actually we have\nactually seen\nis something called as city categories\nsee oh yes city category is also there\nso for this i will just use pd dot get\ndummies if you want pd dot get dummies\nand then you can basically combine them\nbut in order to do that also\nwhat you will do so here i can basically\nsay that pd dot\nget dummies\nand then i'm basically going to give my\ndf off\ncity name is city category so\nfixing\ncategorical\ncategorical\ncity underscore category\ndot get dummies df or city category and\nhere i'm going to basically say\ndrop first is equal to true\nso here i have all my values so i'm just\ngoing to save this in one variable where\ni am going to say df\nunderscore city\nlet's say\nso df underscore city is this one\ndot head\nnow i have to combine this entire cities\nwith this df okay which i have actually\nshown you\nbefore\nand now\ni hope everybody has done till here so\nthis two features will now get compiled\nto this data set\nnow in order to get combined into this\nparticular data set what i will write is\nthat i will say\npd.concat\nand then here i'm basically going to\ngive df\nand df underscore city\nand when i'm doing concatenation i also\nhave to give my axis value as 1\nso this i will save it in my df\nand this will basically be my df.head\nso if i go probably in the last year you\nwill be able to see b and c\nnow i don't require this city category i\ncan drop the city category but i hope\neverybody is able to understand\nso why drop underscore first is equal to\ntrue because always understand if i have\nthree categories\ntwo categories is sufficient to\nrepresent all the three categories now\nlet me go to the next step let me\nquickly\ndrop\nso drop\ni'll i'm just going to write drop\ncity category\nbecause i don't require this feature now\nright\ni don't require this feature city\ncategory right\nso i'm just going to do df.drop and here\ni'm just going to basically say\nuh my category name which is city\ncategory\nbut again i understand here your access\nwill be one\nso\nwhat is the error not found in access\nwhy\nokay it is city underscore category guys\nunderstand why we are doing this because\nany new data will come we have to again\nfollow this entire thing\nokay this is entire steps you have to\nfollow whatever things we have actually\ndone this encoding everything will be\ndone so here you can see df dot drop\ncity category axis is equal to 1 that\nparticular feature is gone so what i am\nactually going to do to make this\noperation permanently i'm going to use\nin place\nis equal to true\nso if i now go and probably check\ndf.head\nhere it is entirely\nso bc is there this is there\nso we have fixed all these things still\nhere\nwe have\ndone a better work till here\nnow let's go and check the missing\nvalues\nmissing values\ncity category is a category feature uh\npt category one is another is age and\none is uh gender so three categories we\nhave fixed up\naxis is equal to one basically means\ncolumn wise we are adding or we are\nappending that specific data frame\nin this axis is equal to one basically\nmeans we are deleting the column\nguys again i have told you eda basics\nthe prerequisite is that you need to\nknow python\nyou need to know some basic things\nif you are not knowing it\ndifficult now with respect to diff uh\ndf dot is null missing values what i'm\nactually going to do i'm just going to\ndo sum\ndf dot is null dot sum\nthis is also function now here you can\nsee product category has so many null\nvalues\npurchase also has so many null values\nproduct category 2 has so many null\nvalues product category 3 has so many\nnull values purchase has so many null\nvalues\namazing\nnow whenever null values are there\npeople will get shocked what to do now\neverybody will get shocked what to do\nnow\nokay categories are there should we\nreplace categories with something just\ntell me\npurchase y null are there because this\nis the test data the null values that\nare present that is the test data that\nshould be null only but this two we\nshould definitely fix it up right\nwe should this two we should definitely\nfix it up so what i'm actually going to\ndo will focus on\nfocus on\nreplacing\nmissing values\nfocus on replacing missing values\nnow when i focus on replacing the\nmissing values what i'm going to do i'm\ngoing to basically replace the missing\nvalues for this two feature so we have\nto do some kind of data exploration for\nthese two features so what i'm actually\ngoing to do i'm going to basically write\ndf dot\nproduct category now tell me guys\nif i write dot\nunique\ntell me what kind of feature this\nbecomes what kind of features this\nbecomes\nor if i write\ndot underscore door underscore2.unic\nwhat kind of features this will become\nwill this become a discrete feature\ndiscrete categorical discrete continuous\nfeature\nor whether this will become a continuous\nfeature this will become a discrete\nfeature guys see discrete because this\nis only getting repeated\nthis will only get repeated so for the\npeople who have attended my start\nsession will definitely know this right\nso they will be definitely focusing on\nand they'll be knowing this entire thing\nokay so over here here you you can\nspecifically see that this will be a\ndiscrete feature okay this will entirely\nbe a discrete feature now in a discrete\nfeature if i have a nand value what is\nthe best way to replace the missing\nvalues tell\nme quickly now this this this should be\na lot of discussions that needs to be\ndone on this\nso\ntell me what should be a better way to\nreplace the missing values what i will\nalso do is that i'll make your work\nlittle bit easy i will also write\nproduct category 2 and i will say value\ncounts\nvalue counts basically will give me\nall the values that are present with\nrespect to this okay\nvalue underscore counts so here you can\nsee eight is basically having this many\nvalues\nfour is basically having this many\nrecords six is having this many records\nwhat do you think if i want to replace\nthe nand values what is the best way to\nreplace in this feature\nso here what we will do with respect to\nany categorical features or discrete\nfeature the best way is to replace\nthe missing value\nmissing value\nwith mode so in order to replace the\nmissing value\nwith mode okay mean don't use mean guys\nbecause mean will create a new category\naltogether so in order to replace the\nmode that is very much simple\nand how do you do it just let me know\nhow do you replace\nthat with mode tell me guys\nso first of all\ni'll write a simple code for you\ni will say\ndf of\nproduct\nproduct\nproduct category two okay\nplease think over it try to write the\ncode guys okay\nso here i will definitely use something\ncalled as fill name fill in a function\nis already there which i have also\nmentioned or explained in my\nlot of lectures so i'll say dot fill n a\nand here i'm basically going to say df\nof\nproduct category\nto\ndot mode right see if i if i basically\njust copy this entire thing okay\nand if i write df of product category\ndot mode\nwhat will be the output that i will get\ni will get this 2 output 8.0 so if i\nwant to find out the mode what i have to\ndo i have to basically write something\nlike this\nfor this right\nnow here i'm getting two values one is\nzero and one is eight point zero so this\nbecomes a series now in order to pick up\nthis value i can basically use indexing\nso if i use this then i'll be getting\n8.0 okay so here what i'm going to do\nafter this i'm going to basically just\ncopy this entire thing over here\ndot mode\nso once i do this this will get\nreflected over here\nand now\nif i probably write df of\nproduct\ncategory 2 dot\nis null\ndot sum\nso here you can see that now my values\nare 0 that basically means the\nreplacement has happened\nclear\ninteresting problem the data set is also\nquite huge\nnow similarly what i'll do for\nproduct category 3 because there are 54\n000\nokay so we will also do it for product\ncategory 3.\nokay product\nproduct\ncategory 3\ncategory\n3\nreplace missing values\nagain i'm going to paste it over here\ni'm just going to write dot three\nunderscore three dot unique so here also\ni see 1417 this this is there if i want\nto also want to see how what is the\nvalue counts\ni can basically write dot value counts\ndot value counts\nso here is all my values with respect to\nthis particular value counts okay\nso\nlet's go ahead and replace it\nreplace with missing values with modes\nand\nagain i'm going to going to copy\nplease playing the missing value so here\nit is\nokay i'm going to just use it with\nproduct category 3\nso now if i execute it\nnow if i go and probably see my df.head\nokay so here it is everything\nso product categories three this this is\nfixed\nwhy shouldn't we just remove\nproduct categories the reason is that\nbecause\nif i go and see df dot shape\nhere you have around 7 lakh 83 000\nrecords\nand around 5 lakhs records are basically\nmissing\nif you see over here\nfive lakhs two lakhs are there you\ncannot just drop it okay\nprobably that may be an important\ninformation\nso you said for purchase column then\nmissing values are fine because it is\nfor test data but train test split is\nrandom no titration we don't just do\nrandom we do cross validation\nlet's go to the next step\nanything that is left\none more category is this one right stay\nin current years\nso what do you think we should do for\nthis so here if i say\nhashtag\nstay for current years right stay in\ncurrent city years\nso if i write df of\nstate current city yes\nif i write dot unique\nso here i am having 2 4 plus 3 1 0 okay\nso what we can actually do we can also\nconsider this as 4 only right because\nanyhow if it is 4 plus also it will be\ntreated as 4 it can be treated as 4 if\nit is value is also increasing it is\nfine right so what we can do is that we\ncan replace this 4 plus with 4. now tell\nme how to do it\nso i will write tf of\nstay in current\nyears\ndot htr dot replace\nand then i'm actually going to replace\nplus with\nwith blank right\nso if i do this i will probably be able\nto find out all these things\nright\nso this entirely i can save it inside my\ndf dot\nstay in current\nso if i execute over here done\nsome warning is there but it's okay\nso here you can see this\nnow i don't have four plus i've fixed it\nanother category any more categories\ntoday we are just focusing on solving\ncategories\nnow\nlet's do one thing okay\nnow even though we are basically\nchecking categories we are we are\nbasically checking other other things\nover here right if i probably just go\nand write df.info\nso here we we are seeing that product id\nis an object that is fine\ngender it has an integer that is fine\nage is an integer occupation is an\ninteger stay in current city years is\nalso an object\nbut here you can see that i am having\nvalues like 2 2 4 4 4. so we need to\nconvert this object into integers that\nis a major step\nthat we have to actually do so what we\nare actually going to do over here is\nthat we have to convert this\nwhich is an object into integers so how\nto do that\nso convert\nbecause this kind of task also you may\nbe getting\nconvert object\ninto integers can quick anybody tell me\nhow to do it\nit's very simple\nhere i'm just going to write df of\nstay in current city years is equal to\ndf off\nstay in current city years dot as type\nas type integer\nif i do this\ndone\nnow if i write df dot head\nor df dot info you will be able to see\nthis\nso here you can see\nstain current is basically assigned in\n32 you can also assign in 64 by\nproviding in 64 directly over here okay\nthere are two more columns which has b\nand c as u u int 8\nq intake what is u intent\nu int 8\nit is an 8 bit assigned integer ranging\nbetween 0 to 255 decimals it's okay you\ncan also convert that into in type\nso if you want to convert that into in\ntype i will just use this two quotes\nso what i will do here i will say b and\nc right so df of b\nis equal to df of b\ndot as type\nint\nand same thing i can copy and paste it\nfor dfr\nc\nhello execute it\nnow if i go and probably see my df.info\nyou will be able to see this\nnow\nonce we have done this the best\nvisualization what i feel\nvisualization\nis present in cbot\nwhich is called as\nsns dot pair plot\nif i give pair plot and just give df\nsee what is the amazing diagram\nbut it will take lot of time because\nthere are so many data points\nalong with that so many data sets\nokay it is giving me an error let's say\nwhat is the error\ncannot reindex from a duplicate access\ndf dot\nduplicate\npoints why this error has come\nit's okay see if there is something like\na product type right\nthat will\nactually get removed in the pair plot\nthat is the\nreason why do we use this\nwill give an error\ni'll have a look on to this okay don't\nworry\ntill then let's see some other\nvisualization diagrams okay\ntill then let's see other visualization\ndiagrams\nso i i'll just have a look why that\nprobably is not coming but i can\ndefinitely use another plot like bar\nplot\nlet's say that i'm using bar plot and i\nwant to basically compare\nage with respect to purchase so this\nwill actually help you to find out\nwho has\npurchased more or who has purchased less\nand here there is a gender over here so\ni'm just going to use a hui as gender\nokay i've done some observation over\nhere and data is equal to df\nokay\nso let's execute this\nso this is the diagram that you are\ngetting\nso age\none two three four five so which you can\nbasically map with it\nbut definitely you can see that even 55\nplus\nwith respect to genders so from this\nobservation\nif gender zero\nzero what we have replaced with male\nright\ngender uh zero we had replaced with\nfemale or male\nvery gender very gender\ni think for male for female we have made\nit to zero yeah\nso from this definitely you can come up\nwith some conclusion that whether female\nhas bought more or male has bought more\nbut over here with respect to the\npurchases maximum amount of purchases\nyou can see that uh mail has a huge\npurchase\nwith respect to the orders also we'll\ntry to see will with respect to\ndifferent different orders\nthis is nothing but visualization of age\nversus purchase so please write down\nyour observations what do you feel with\nrespect to this kind of things\npurchasing of goods of each range of age\nare almost equal\nbut we can conclude definitely that the\npurchasing percentage of purchasing\ngoods of men over women is high\nright is this possible\nno\n[Laughter]\npurchasing of\nmen over\nmen is high\nthen women\nso this is the observation that i have\ndone\nwhich is not at all\npossible right\nbut data does not lie right\nso definitely\nall the other purchases with respect to\nthe ages are uniform but purchasing of\nmen is higher than women\nyeah\nnice\ni like it\nso this is my first observation\nlet's say with respect to purchase we'll\ntry to visualize the occupation okay so\nvisualization of\npurchase\nwith occupation\nso i'm just going to copy the same thing\nand i'm going to paste it over here\nso here i'm just going to say it as\noccupation\nah let's see the diagram\nthis will be quite huge because it will\nbe stuffed right\noccupations are many right\noccupations are money so you can just go\nand check out which all occupations are\nthere at 20 different occupations so\nfrom this data set you will be able to\nfind it out the initial data set\nand you can make some observations from\nthis\nlet's see what is occupation\noccupation with this some categories are\nmapped okay so with respect to this\ni'll i'd suggest that this is also\nuniform\nit won't affect a lot let's compare\nwhether product category 1\nproduct category one versus persist like\nmany people have bought product category\none because if you go and see the data\nset then we'll be able to see it over\nthere so i'm just going to copy this\nwith the bar plot\ni'm going to write it over here\nand i'm going to basically write product\ncategory one product so let's see\nproduct category one how many people\nhave bought\nwith respect to the purchases so that\namount will be shown\nso here you can see this is the graph\nwith respect to product category 1.\nsimilarly let's see with respect to\nproduct category 2 i don't know whether\nwe'll be able to see it or not\nin the same thing we can see it\ntwo graphs\ntwo graphs will not be able to see it i\nguess\nnow it is coming\nno only one is coming\nokay i will remove this i think it will\nreplace\nin that same order\nokay\nso i will just execute this product\ncategory one\nand then this will be my product\ncategory two\nand the next one is my product category\n3\nbut observe this and come up with some\nconclusion guys\nhere you can see with respect to 12 000\nis there here till 14 to 16 000 product\ncategory 2 is sold what more whereas\nproduct category 1 is bought the most\nright it is still 20 000 right\nso definitely that information you can\ntake it out from this particular graph\nany other graphs that you want to\npropose but you can definitely use this\ntell me guys is this mo is this data set\ngood for the model or not now\nbecause the type of database processing\nwe have done\ni think we are good to do it right\nwe are good to do it we can also drop\nproduct id\nwe can also drop product id\nnow let's probably do the one last thing\nokay\nthat is feature scaling\nokay feature scaling\nthis will now become my df underscore\ntest\nand then\ni can remove\ndf dot purchase dot is null\nsee wherever the purchase in the\npurchase column it is null right that\nall belongs to the test data so i'm just\ntrying to find out\napart from is null how do i find out\nif it is not null\nso if you use like this\nso here by this you will be able to see\nthis and here you can basically write df\nrun train\nso now you have your df draw train and\ndf underscore test\nso df underscore train and test you have\nnow let's go to the feature scaling\nin the future scaling how do you do it\nwe basically apply standard scalar as a\nfeature scaling so for that it's very\nmuch simple\nfrom\nsklearn\ndot\npre-processing\ni'm going to import standard scalar\nand then i'm going to write sc is equal\nto standard scalar\nand on my trained data set always\nremember\ndf underscore test\nokay before that if you want to do train\ntest split definitely go ahead and do it\ni don't have any problem so i can\ndefinitely write df underscore train\nyou can do that x train x test y train y\ntest it's up to you okay\nso\nuh before this let me write one code\nwhere we will do the train test plate\nfor the training data so here what i am\ngoing to do scale on\ntrain test split okay it is always good\nto google it and copy and paste and do\nit instead of writing it okay\nso i'm just going to copy this\nand paste it over here\nyou also do that same thing don't tell\nme krish bring me the\nqueries or answers so here i'm just\ngoing to change it but before that let\nme\nwrite from sk learn dot\nmodel selection import\ntrend test split\nokay so here will basically be my\ndf underscore test\nmy x\nso my x will basically be df underscore\ntrain colon minus 1\ni hope so it works\nso x dot\nhead\njust make our x and y axis so that it\nwill get our independent and dependent\nfeature so this is my x similarly for my\ny what i will do\ni will also create my y where i'll write\nd f off\ncolon no minus one will basically give\nmy\nokay minus one is not there okay colon\nminus one colon\ncolon\nhow do we get the last column\nno df of\ncolon minus one will give you the entire\nthing\ndouble colon minus one\nso this will basically give your last\nvalue\nno it is not giving\ndouble colon no just a second\ni can basically say it as df of\npurchase\nright\nso this is my y value\ncolon comma minus 1 will also work\ncolon comma minus 1 will also work\njust give me a second guys\nyeah\nso this is my x and y\nnow what i'm going to do give it to my x\nand y here\nand here i will\nget a error why\non input variable inconsistent number of\nsamples comma 36 why\ni made some mistake\nx dot shape\nlet's see\nthis is basically having 12 rows that is\nfine\nwhat is this having\ny dot shape\nhey how come difference is there\nmy mistake\nit should be\ndf underscore\ntrain\nthat was the mistake that i made\nfine now it will work\nnow i've got the same answer here i'll\nbasically go and execute it\nextra next test x comma y\nd f underscore train that i have written\nbut still i'm getting this error why\na scalar node model import train test\nsplit this this x comma y is there\ny is also here\ny dot shape also i might be able to get\nit\nsame\noh one extra record is there hook up\none extra record how come\npurchase is not the last column your\nscreen is not visible properly looking\nhazy\nthen please reload it okay\noh purchase is not the last column\nthat is the problem\nso i made one mistake over here\nso what i will do is that i can\nbasically say\ndf dot train dot drop\nof purchase\nwith axis is equal to 1 now this will\ndefinitely work\nthis is done\nso i have all my features over here\nif i do x dot shape now i have 11\ncolumns\nthen df underscore train this is there\nthis is the perfect perfect perfectness\nit happens i'll google it it happens\nnow it is fixed see\nnow df underscore train instead of\nwriting like this now i'm going to do\nfit\nand\nfit transform on xtrain so finally i\nwill write\nsc.fit fit underscore transform\nand here i'm basically going to write x\nunderscore train\nwhich will basically give me x\nunderscore train is equal to this one\nx underscore test is equal to\nsc dot\ntransform on\nx underscore y transform think over it\nso let's execute this\nand again it gives me an error why could\nnot okay let's drop one last thing\nfrom this\ni think i could have dropped in df.train\nonly and df.test only so that drop it\nthat will be an assignment to you all\ni'm going to drop the\nproduct id\nin place is equal to true\ni don't want to get killed right now\nx underscore test\nproduct id this is this\ndone\nfinished so\n92 lines of code more than 100 lines of\ncode i've written in front of you\ndid the complete analysis\nnow this is your data set go and train\nyour model the next step is basically\ntrain your\nmodel that's it\nif you want to\nsee correlation and all\nokay so here i will just name this file\nas\nblack friday\nand\nfeature engineering everything i'll be\ngiving you i will be uploading this in\nmy github so that\nyou will be able to find it out\njust a second i'm doing it i'm uploading\nit okay guys so just uh reload the page\nand uh yes you will be able to see the\nfile in the description so tomorrow also\nwe are going to take up any other\ndifferent data set and then we are\ntrying to see that how things are going\njust reload the data set and tomorrow\nwe'll continue the session\nuh thank you everyone for joining and\nyes i hope you liked it so thank you\nhave a great day bye bye guys keep on\nrocking\nwe'll see you tomorrow hello guys i hope\neverybody is able to hear me out\nso from that today we are basically\ngoing to solve\nflight\nprice\nprediction\nand here we are basically going to do\neda\neda plus feature engineering\nso data set here i'm actually giving you\nthe data set\nso if you go and see the data set the\ndata set looks something like this data\ntrain test set okay\ntwo xls file\nwill be there\nso you have to download these two files\nif you want to download make sure that\ngo to this download it\nright as a zip file and inside flight\nprediction we have this specific data\nset\nthese two data set we are going to take\nit up data train and test underscore set\nand this problem statement was given\nthis flat price prediction problem\nstatement was given in a hackathon that\nwe are going to basically solve over\nhere and let's start so initially we'll\nstart with importing some basic\nlibraries\nimporting basic libraries\nquickly do it which all libraries we\nrequire already we have done in study\nsession i'll write import pandas as pd\nimport numpy\nas np\nthen import\nmatplotlib\nmatplotlib dot\npi plot\nas plt\nand then import\nc bond\nas a sns\nimport cbon as a sns and then probably\nwe will also be importing\nwill write matpotlib inline\nnow guys many people usually ask me what\nis this used for matplotlib inline\nsee suppose if you want to probably show\nthe diagram within this\nwithout writing plot dot show\nso you can basically go with respect to\nthis one matplotlib inline so as soon as\nyou plot anything you don't have to\nwrite plot dot show and automatically it\nwill get shown over here itself\nso uh\nnow why i have specifically taken this\ndata set because if we go and see this\ndata set\nthere is something very amazing about\nthis data set because it also has\ndate time information okay\nso date time information you have to\nreally be careful whenever you are\nworking at it so that is the reason why\ni have specifically taken this uh\nbecause i wanted to show you different\ndifferent domain problem statements kind\nof data so that you will be able to see\nokay what are challenges you may\nprobably face into it so as usual what\ni'm actually going to do first of all uh\ni'm going to just\nimport the training data set\nwhich i will write pd.read underscore\ncsv\nread underscore excel so let me just\nexecute this one first\nso read the data set like this\nand here i'm basically going to give my\ndatatrain.xls\nand if i go and probably see my train\nunderscore df.head you will be able to\nsee this specific data set\nso here you have airline date of journey\nsource destination\nroute\nif it is given like this bangalore to\ndelhi\ndeparture time arrival time duration\ntotal stops\nadditional info price\nso after this what we have to probably\ndo is that\nsame thing i'll do it for the test data\nset so here i'm going to basically do it\nfor test data set\nso test\nuh test underscore df\nand specifically here i will write\ntest xls\nthis is the file name\nand if i want to\ndisplay test df.head so here is my test\ndata only one column will not be there\nwhich is this last column that you can\nsee that is price\nso this both are done\ni hope everybody is done\nnow as usual after importing\ni did not try\ntraining the model see if if you are\ngetting model score bad like 12 13 with\nthe help of linear regression\nor other algorithms try different\nalgorithms right like other algorithms\nare also there like decision tree\nregressor random forest regressor\nright you have xgb boost regressor\nno one tried that i don't know you're\njust saying 12\nand 13 for linear and lasso and you're\njust keeping quite that is the problem\nwith you all\nyou know where i've taught all the\nmachine learning algorithms previously\nwhy you don't want to try with other\nmachine learning algorithm obviously\nlinear regression creates a straight\nline and there you have so many features\nso your accuracy will be bad see if you\ndon't get this much common sense then at\nthat point of time i think\ntrust me for cracking interviews it will\nbecome difficult how you will work in\nthe real world industry\nso if you go and use different different\nalgorithms so i i always tell you do\nhyper parameter tuning on top of it i i\njust did linear regression sir rich sir\ni got 12 percent not tell me what to do\ni don't want to do anything\nlike that you'll learn tomorrow you'll\ngiven a problem statement how you'll do\nthat\nat that time krishnak will not come\nright\nso\nlet's do one thing first of all i'm just\ngoing to combine\nthis\ntrain df and test df into another\nvariable called as final df so what i'm\ngoing to do in order to combine i'll\njust write trend df dot append\nand then i'll write test df\ncomma\nand\nndf dot append\nof test df so test df is my this data\nset and train df is this data set so\nonce i will do this\ni can go and finally write final\nunderscore df.head\nso this what i'm doing i'm combining\nboth the train and test\nremember\nif i go and see the tail path if i go\nand see the tail part\nthen you will be able to see that\nyou will have some nan values in the\nprices this is because of the test data\nset okay so this much i think you will\nbe able to do it\nappending the data set which is getting\nconverted into this one now see the\nfeatures looks quite complex over here\nbecause the feature that you have is\nlike airlines you have date of journey\nsource destination\nroute then departure time then arrival\ntime you know arrival time then you have\nduration then you have\ntotal stops then you have additional\ninfo\nvery you different different types of\ncolumns are there so lot of feature\nengineering is basically required and\nhere i'm just going to focus more on\nfeature engineering because we have done\nextensive eda now let's go ahead and try\nto do feature engineering on each and\nevery field okay\nnow the first field that you may\nprobably see over here is something\ncalled a date of journey\nnow in this date of journey you have\nobviously\nyou have a day you have months and you\nhave year and probably just let me just\nwrite final underscore df.info\nso here you can basically see that date\nof journey is also an object so date of\njourney is an object that basically\nmeans it is in the string format so we\nhave to convert that into a date time\nformat now this after converting\nprobably into a date time format what i\nwill do is that\ni i need to pick up this specific\ninformation like day and this will\nbasically be my month and this may\nprobably be my year so this technique\nfrom this particular field i have to\ncreate three more fields which will\nspecify my day\nmonth and year so here what do we say to\nthis is that we are trying to create a\nderived feature now tell me guys from\ndate of journey how do i create these\nthree fields anyone you can actually try\nit out and you can basically\nlet me know you can try it out you can\nsay some code how we should go ahead\nwith doing it so here basically i'm\nstarting my future engineering process\nand what i told that first i will try to\ntake out or derive some features like\nfrom this i will definitely be able to\ntake out day month and year how do we do\nit\nso for that what i am actually going to\ndo it in a very simple way i'm basically\ngoing to say that final underscore df\nand i will try to create three features\nas i said one feature will basically be\nmy\nmonth\nor date first i'll start with date\nso one feature will be this\nthe next feature that i'm actually going\nto create is with respect to month\nand the third feature that we are\nprobably going to create\nis with respect to ear so this three\nfeature we need to derive and we need to\ncreate and how do we do it we already\nknow that i have a feature which is\ncalled as date of journey right now from\nthis date of journey i basically have to\nsplit okay split by using what character\nsplit by using this specific character\nthat is this forward slash if i do\nprobably split then i will basically be\nable to get three important information\none is this six zero six and 2019 now in\nthe case of date i need to focus on the\nfirst index that is the zeroth index\nthen in in the case of month i need to\nfocus on the first index and in case of\n2019 i need to focus on the second index\nso that is what i'm actually going to do\nover here so i'm basically going to\nwrite over here dot str\ndot split because i have to convert that\ninto an str\nor if i need to basically do the split\nand after doing the split if i copy this\nand if i run this code let's see what\nwill happen\nyou will be able to see over here if i\nwrite 0 that basically means i will be\nable to get this all entire information\nokay so here you can see that if i write\nstring\nsorry\nhere i have written 0 then also i'm\ngetting this specific information what i\nwill do i'll also use one keyword called\ndot htr of zero so here you can see that\ni'm able to get all the dates\nokay so this is all my dates that i'm\nactually able to get so\nin order to get the dates i'm just going\nto use this and in forward i'm just\ngoing to write dot htr of 0\nso this is the this is the process that\nwe can basically use to take out the\ndate\nno need to convert into date or time\nalso because once we get that we'll\nconvert that into an integer\nthen\nif i'm doing for forecasting kind of\ntask\nat that point of time i may use it then\nfor the month i need to just change the\nindex to 1\nand for this i need to change the index\nto 2.\nso here i will be able to get date month\nand year now if i execute you will be\nable to see this\nfinal underscore df dot head\nand head i'll just see the top two\nrecords here somewhere at the end you\nwill be able to see date month and year\nis created\nthis also works well you can apply a\nlambda function which is very very good\nso i'm just going to ping or copy paste\nthis code over here this is also a very\ngood technique how to do it definitely\nyou can also do it with using this\nso he has given this specific technique\nwhere he has specifically used lambda\nfunction this will also definitely work\nso i hope everybody is able to\nunderstand till here okay so either of\nthis code you can basically use\nand you can actually go ahead and do it\nbut this is a very good technique of\napplying a lambda function very nice\nmeans efficient coding\nokay it's all about googling and trying\nto find out a better way\nthat will definitely work\nokay now let's see in the next step what\nwe have to do simple it is that\nwe have to basically also make sure that\nwe convert that into\nan integer right so integer also we need\nto convert that date month date month\nand year so in order to do this uh it's\nvery simple how do i do it i will just\nwrite\nfinal underscore df\nis equal to\nfinal underscore df\nof\ndate\nand i'm actually going to convert this\ninto as type\nend okay\nthen i'll copy this probably\ni'll paste it i'll paste it i'll do it\nfor\nmonth\nand\nbut one mistake i'm definitely making\nover here i have to apply this to\nthe same feature right\nso i'm just going to copy this here\nhere\nhere i'll just make this to month\nand i'll just make this to here\nso once we do this and once we execute\nthis has got executed now if i write\nfinal underscore dot df.info\nand if i see\nso here you can see date month and year\nis now in 32\nin 32\nprice is already float 64 but we are\nstarting to focus on different different\nfeatures\nso uh we have done this uh let's go to\nthe next feature now\nwhich one do you want to catch hold of\nthe next feature since you have done it\nwe'll do one more step is that we will\ntry to drop this particular feature now\ni don't require date of journey right\nnow so what i'm actually going to do now\ni'll just write\nfinal underscore df dot drop\nand here i'm basically going to give my\nfeature name which is\ndate off\ni'll just copy this\ndate of journey\nwith\naccess is equal to 1\nuh in place is equal to true this we\nhave already seen\nyesterday now if i go and probably see\nmy final underscore df\ndot head of one\nthen here you can see month and year are\nthere date is also there but you don't\nhave any date of journey\nnow let's go to the next feature next\nfeature\nsee this is how we have to catch one\nfeature at a time and probably\ndo need the necessary changes okay\nso the next feature basically uh we will\ngo with respect to\nroute\nlet's say what we can do for this route\nalso will try to understand\nokay arrival time\nroute\nokay route uh\nlet's wait for some time for route let's\nfocus on the arrival time or departure\ntime\nokay so let's do one thing\nlet's focus on arrival or departure time\nfirst we'll focus on something and then\nsimilar type of fields always remember\nwhen you are probably doing feature\nengineering try to catch up similar\ntypes of field which we basically have\nto do again and again let's go ahead and\ntake up arrival time now from this\narrival time\nwhat you can do is that obviously you\ndon't require this information like 22\nmarch\nif i probably go and see around 10\nrecords\nso here you will be able to see that\nwherever there is this gap\nthis space\nhow we can split it let's see\nif we are using some space over here\nwe can definitely get something\nokay uh if you are using this space and\nprobably trying to split it i will\nprobably be able to get the arrival time\nmy arrival time should be in such a way\nthat i should be only able to get this\nfirst four\nimportant information\nthink over it because i don't require\nthis 10 june and all because there is\ndate for that i don't require that i\nneed to focus only on this first four\nvalues so how do i do it so i will write\nfinal underscore df\nof arrival time\ndot\nstr\ndot split\nif i split with the help of\nan empty braces and if i write dot htr\nor if i just execute this here you will\nbe able to see like this\nright\nso out of all these things i just need\nto pick up the first value see in the\nfirst value i will be able to get all\nthe important information\nokay like 4 25 7 15 only the first one i\nneed to focus on so to get the first one\ni will just use indexing of htr of 0\nand if i execute this now i will be able\nto get this particular value\nto do the same thing there is also one\namazing code which can be done using\nthis lambda function\nso here you can see dot apply lambda\nthis this\nokay if i execute it\nsorry final underscore df\nand execute it here you can also see\nthat i'm getting the same information\nso what i'm actually going to do i'm\ngoing to use this particular code and\nmake that changes in final underscore df\nof\narrival time\nany one of the code you can basically\nuse and you can do it\nmore new new things you can basically\nget it in order to do it\none thing that i forgot to check whether\nit has null value or not\nso\nprice basically has null values it's\nokay that is for the test data route has\none null value\ntotal stops has one null value\nroute\nthat basically means route in that\nspecific it may be the same row it may\nbe the other row but total stops has one\nnull value and this has one null value\neverybody clear\nnow\nfrom this arrival time\nwe still have to\ntake out the hour\nand we still have to take out the\nwhat we need to take out from this\narrival time guys hour and minutes right\nso that specific thing i will do next\nstep\nso here i'm actually going to write\nfinal underscore df\nwith the same\nlambda function or in in an easy way you\ncan basically do the split\nand here i will actually create two more\nfeatures\narrival underscore hour\nis equal to\nfinal underscore df\narrival underscore\ntime\nthen you can use dot apply lambda or you\ncan also do dot\nhtr dot split\nand this split will now happen with\ncolon right because within the hours and\nthis one colon is there\nso i'm going to split with the help of\ncolon\nright\nso when i split with the help of colon\nit will be dot htr dot split dot\nhtr of 0 if i write like this it will\nbecome my hour\nand similarly if i want to\nknow the arrival\nminutes\nthen i can basically write like this\nand here\ni will just write htr of one\ndone\nand if i go and probably see now final\nunderscore df\ndot head of one\nyou will be able to see this one\nand here you have arrival of hour and\nminute\nremember this is still in\nobject type so i also need to convert\nthis into an integer type so same thing\nif i go up i had written that specific\ncode how to do it i'll just copy this\none like this\nokay i will copy the code over here and\nkeep it over here and here i am going to\nbasically write arrival of hour\nand convert this into in type\nand arrival minute\nand convert this into in type\nso two steps one is converting into n\ntype is also done over here along with\nthis so if i execute it\nyou will be able to now see that\nif i write final underscore df dot info\nnow you will be able to see that there\nare integer values added\nin arrival hour and arrival mean minutes\nso this is the code that i have actually\nwritten\nand then after that you can drop the\narrival time\nso\nhere i will write final underscore\ndf.drop\narrival time\narrival underscore time\ncomma axis is equal to\n1\nin place\nis equal to true\nstep by step we are doing it in a nice\nway\nso i hope everybody is able to think\nso now if i probably go and see my final\nunderscore df dot head of one record\nhere you will be able to see these\nthings are also there\nokay uh what about\ndeparture time i hope everybody will be\nable to do the same thing for the\ndeparture time just do it because\ndeparture is also having the same format\nso i'm just going to copy all the code\npaste it over here\npaste this also over here\nnow paste this to line also over here\nand finally\npaste this also over here\nand keep it with respect to\narrival time like that we had departure\ntime right\nso i'm going to write departure\ntime right depth time\ni'm going to copy this everywhere\npaste\npaste\npaste\nand here i'm going to basically write\nthe pt hour\npept minutes\nthis i don't require\ndept\nhour\nand this will be my dept minute\nso just by doing this i think everybody\nwill be able to understand that we are\ngoing to change it now\nyes that will also work on herod\ndone\noh error is coming let's see\nwith base 10 20 to 10.\n[Music]\noops\nthis should be department of hour\nand department of\nmaine\nso i don't have to execute this again\nso\ni will just\nremove this\npaste it away well done\nso it's final underscore df\ndot info now you will be able to see two\nmore features getting added and it will\nbe department of our\nand this one both will be there\nperfect we have done this now we have to\ntake care of all these other things\nright airline and all are actually there\nso her departure is done\nnow let's catch up route\nnow inside this you will be able to see\nroute\nis basically having this information\nlike bangalore to delhi\nbangalore to delhi okay\nsee anyhow over here you will be able to\nsee that uh even though i basically find\nout like what is the route like route\none two three four\nmaximum to maximum over here you can see\nthat there are\ntwo places like bangalore is the origin\ndelhi is the destination here you have\nfour different different places that\nbasically means first you are going from\nkolkata to ixr then ixr to bbi then bbi\nto bangalore so total number of stops\nyou have is two over here in this\nparticular case you just have one stop\nso what we will do is that we will try\nto\ncapture the route one route to all the\nall the places away over here in the\nsource and destination you just have two\nvalues\nright number of\nstops you have to one like that you have\nright so it is better that we get this\nspecific information very much clearly\nso that we actually\nbe able to see route 1 route 2 route 3\nroute 4 like that right so\none thing that you need to know over\nhere is that\nyou may definitely get\nnull values you may definitely get null\nvalues a lot of null values you may be\ngetting\nbut understand null values will be there\nfor like if i want to capture for route\n4 definitely null values will be there\nokay\ninstead of this also what we can do we\ncan also delete this and we can just\nfocus on this total number of stops\nright total stops like total underscore\nstops we can also focus on this\nparticular values also so what do you\nthink should we do\nshould we delete this specific feature\ndirectly\nand just focus on\nbecause we have the source and the\ndestination and obviously we have number\nof stops\nbut\ni just think like as a person right we\nreally need to focus on two things okay\nfirst of all is that if probably i'm\ngoing from kolkata to bangalore and\nthese two places are going then the\nprice might increase drastically\nokay just not based on the top of the\nnumber of stops now in this particular\ncase you can see from delhi to cok right\nhere you have lucknow and bombay lucknow\nin bombay\nyou feel that probably more price will\nbe taken place over there\nso\njust see what you need to do we can\ndefinitely drop this route you can just\nfocus on total stops but before focusing\non total stops what i'm actually going\nto write i'm going to basically say\nfinal underscore\ntotal\ntotal stops\ndot\nunique\nif i write unique\nlet's see how many total stops are there\nso here you have\nnon-stops non-stop basically means\nprobably\nuh it's like just a single stop\nhere you can see here you can basically\nreplace this with 0 here you can replace\nwith 2 here you can replace with 1\n3 this nand value if i try to see that\nthere is one null value i guess\nis null\ndot sum\nso here you can see one nand value you\ncan replace it\nuh\nwhich one is\nrequired with respect to that okay so\nso everybody focus on doing what we will\ntry to convert this into and map these\nvalues with 0 1 2 3 4 5 like that\ntell me someone tell me the code\namazing\nso rishi has already written the code so\nrishi has basically said something like\nthis by using the map\nso here is my final underscore df\nfinal underscore df\nso final disco df total stops total\nstops dot map non-stop is equal to zero\none stop is equal to 1 2 stops is equal\nto 2\n3 is this\nfor nan also if you want to place place\nit out because there is only one nand\nvalue so for nan also i will make sure\nthat\ni can directly see right which is that\nspecific record\nwait\ni can definitely see which is that\nspecific record for nan just a second\ndf of\ntotal\nsorry\nfinal underscore df\ntotal stops dot\num what i can do is that dot is null\ndot\nis null\nand here i can basically write final\nunderscore df and i'll try to take out\nthis specific values\nso here you can see route is nan but the\ntotal number of stops is also nan\nso total number of stops is also nan\nroute is also nan\nso here you can see from delhi to cochin\nokay delhi to coaching i don't think so\nthere will be a direct flight\nbut which value do you want to replace\nwith since it is just a single record\ni think it won't matter that much so let\nme do one thing let me just replace it\nwith one stop\nor\njust common sense i think for coaching\nbangalore coaching at least one stop is\nrequired\nso like this i will just try to change\nit\ndelete the coaching sorry\nso i have got executed now okay and now\nif i go and probably see my final\nunderscore df\ndot head you will be able to see the\nspecific values\nand\nhere you can see total stops has been\nconverted into integer floating value\nnow we can drop this route column so\nfinal underscore df drop\nroute\ni'm going to drop route from axis is\nequal to 1\nand in place is equal to true\nbecause i don't definitely require 2 2\ninformation right\nso finally you can see final underscore\ndf dot head\nhere you have all the values\namazing\nnow what is the next thing that you\nshould probably want to do guys\ni've deleted everything right so we have\ndepartment department\ndeparture hour also we have dropped\ntotal stops is also there\nlet's catch up any other one you want to\ndo\nadditional info that all will be our\nnormal uh\nfeature engineering like transformation\nencoding we can do any special character\nif you if it is there somewhere probably\nwe have to catch hold of that so if i\nwrite final underscore df\nand if i go ahead with additional info\nadditional info dot\nunique how many unique values are there\nso here you can see this many unique\nvalues are there this can be converted\ninto\nuh\none hot encoded format because there are\nless number of records\nlet me just check\nmore anything that we can do with this\ndata set anyone who wants to do some\nmore things who wants to play with this\ndata set who wants to\ntear apart the specific data set\nlet me just see df dot\nfinal underscore df dot\ninfo now here you will be able to see\nall this are there additional\ninformation object that is fine\nduration is still there\nokay\ncan we do something like convert this\nduration into something else\nnah duration into minutes i'm basically\nneed to convert duration into minutes\nright so this this this this this i can\nbasically apply a mathematical formula\num\ni will just take this let's say\ncome on try it out guys\ntry it out\nso here i'm basically going to write\nduration\noh this way\n2 hours 50 minutes can be mentioned as\n2.50 this will also be a good way\num\nbut what if i convert\nduration into minutes that would\nactually\nbe amazing okay\nso here i'm basically going to say\nduration\nokay if i do split of zero that\nbasically means i'm getting my answer as\nuh htr of zero\nsplit no\nif i use this blank space i'll be\ngetting two hours okay\ntwo hours two hours\nand probably have to further split it\ndown\ni have to further split it down\nbecause h is there\nokay h is there this is becoming a\nseries right now\nif i do dot split\nwith respect to h\nokay series does not have a split\nperfect\nso if i have like this\nduration two minutes sir can you run\nsplit it down with h\njust start replace dot replace will work\nover here\nsee this becomes a series right now okay\nif i execute this\nand i'm actually getting something like\nthis okay\nthen if i write htr of\nzero\ncomma zero\nno\nthis will also not work zero\nzero zero zero\ncome on anybody\nspring dot replace\num this is a series okay\nthis is a series\nthis is a series guys understand we\ncannot do\nstring dot something like that see if i\ngo and probably see the type of this\nthis will definitely become a series\nsee it is a series\ni can search in the google\nokay search in the google\nseries\nsplit\npandas\nseries pandas provide method to split uh\nseries series hdr dot split\nstr.split\nagain i have to do dot htr dot split\nokay so here i'm going to basically\nwrite htr dot\nsplit\nand here i'm going to basically use h\nsee i'm getting it right\nand then i can basically again write htr\nof 0\nso here i'm actually getting all the\nvalues\nthis should be multiplied\nthis should be converted into an integer\nno this will actually be\nokay\nso here i'm actually able to get all\nthis information\nokay\nthis will basically give me the hours\nif i want to convert this into\nminutes\nokay if i want to basically convert this\ninto minutes what i have to do\nnow this is entirely series if i want to\nconvert this into minutes\nas type\nyeah as type can work\ndot ask type\nand\nno\nerror is coming probably\nno it will not work but\nhtr 0 will work\nso let's consider that i am converting\nthis into df of\nduration\nunderscore hour\nis equal to this one\nduration of hour\nfinal underscore df\nif i execute this\nfinal underscore\ndf\ndot head\nso duration hour i have actually got\nso with the help of duration hour we\nwill be able to do it okay\nbut you also have to get the minutes\nbecause minutes are also very important\nbut before that what i'm actually going\nto do i'm basically going to write\nour final df for\ndot info\nbecause i want to check\nwhether\nthere's still an object right so what\ni'm actually going to do\ni'm basically going to convert this as\ntype\nokay\nfinal underscore df\nhey guys for me also same thing i am\nalso facing the same difficulty what you\nface\nright but we need to think of an\napproach\nif you are able to think as an approach\nobviously that will get solved\nuh what is the error\nfor end there is 5m\nsomewhere\nsomewhere 5m is there\ni hope i have done the syntax correct\ndefinitely 5 m is there somewhere\n5 ohm value is there\nfinal\nfinal underscore df of duration\nw is equal to\n5m\nfinal underscore df\nokay five minutes okay duration is also\nthere for five minutes\nokay this is the problem\nbut how how come five minutes\nmumbai to hyderabad will take only five\nminutes\nhow this is possible\nit is better we drop this we drop this\nfeatures\nright\nif i just use this\nis equal to this one\nnot possible right so\nhow how this will be possible\nso tell me if you want to remove this\nwhat you have to do\nalt\nhalt duration okay\nall duration\nthat is the total duration right\nyeah we have to probably drop these\nrecords right\nokay tell me how to drop these records\nnow\ndrop row axis zero\nokay perfect so if i write final\nunderscore df dot drop\nand here i'm basically going to give my\nindex number\nuh should i use i lock to drop it\nbecause here it will ask for labels so\nsuppose if i give six four five\nseven four comma axis is equal to zero\nyou'll be able to see that it will get\nexecuted\nright it is getting executed then\nlet's say n place is equal to one\nand same thing i will probably do it for\ntwo six six zero\ntwo six six zero\nonce a plane\nreceive type as input for argument in\nplace expected type boolean\noh in place is equal to true\nso executed this is working fine now if\ni go and see this one i'm actually\ngetting empty now okay\nso\ni have actually fixed this i will\nconvert this into as in type done\nand then i will multiply this all by 60.\nmultiply by\n60\nso here you can see i'm actually able to\nget this in the form of minutes\nor\nlet it be an hour only then no problem\nif you don't want to do also it is fine\nat least hours will increase but if you\nare considering the minute part also so\ntry to use that\nokay and try to convert that that is\njust given to you as an assignment\nplease try to do for the minutes also\ntry to get that specific data what i\nhave done for minutes okay\neverybody you have to basically do it\nokay don't say that chris you did not do\nin the class so we are not going to do\ndon't do it so here you have integer\ninteger integer integer\nprice is float additional info is object\nthen you have duration now we can drop\nthe duration\nfinal underscore df dot drop\nokay duration\nwith axis is equal to 1\nokay and then in place\nis equal to 2\nso this is done why why why capital d\ncapital d capital d\nokay duration done\nand then finally we have final\nunderscore df dot\nhead of\none so here you can see i have all these\nthings remaining all have been converted\nremaining all are category features so\nin order to do for the category features\none we need to do simple we will try to\nfirst of all see with respect to\nairlines\nso\nuh\nairline\ndot\nunique if i try to see this\nhow many are this specific airline\nfinal underscore df\nfinal underscore df so here you can see\nonly this many airlines are there so we\nwill try to do label encoding for all of\nthem now in order to do the label\nencoding\ni will write from sk learn\ndot pre-processing\ndot pre-processing import\nlabel encoder\nmany people are saying right krish why\nyou are doing get dummies get dummies\ncan also be done but since\nwe\ntry to work with train and test data so\nit is better to use the transform\ntechniques right\nso here i'm going to basically use label\nencoder\nis equal to label encoder\nokay\nso label encoder is there\nand then finally you do it for every\ndata set that you want like airline\nsource destination\nand additional info so this four\nfeatures so here you have final\nunderscore df\nand here you can basically write\nairline\nairline\nokay\nlabel encoder\ndot fit underscore transform\nand here i'm basically going to give my\nfeature\nthat is final underscore dm\non\nairline right so like this i have\nwritten for this now you do it for other\nfeature also like this same way\nhow many features are there for right\nthen you have source\nsource you can put it over here\nthen you have destination\nand then finally you have additional\ninfo\nonce you do this done\nand this is your final underscore df dot\nshape if i try to see there on 14\ncolumns which is good enough\nand if i want to probably see my\nfinal disco day dot\nhead of first two records\nthen you can see all these things\nperfect\nokay i've done just done label encoding\nyou can also do\nother type of encoding that is one hot\nencoding\nit's okay guys i've done label encoding\nnow one more step you can do is one hot\nencoding\nfrom sk learn dot\npre-processing import\none hot encoder just do it no\nkevin uh don't do it with get dummies\nbecause see whenever we have a test data\nwe need to transform that test data\nright so we can save this\nencoder in the form of pickle file\nright\nso one hot encoder so o h e\ni'll write it as one hot encoder\nand then you can do the same thing\nwhere you're specifically saying\nthis\nokay airline\nohe dot fit transform\nokay\nand then you have all the necessary\nother information\ndone\nokay\ndo it\nokay i'm getting some error what is the\nerror\nexpected a 2d array\nexpected a 2d array over here\nreshape your data\nokay i understood what is the problem\nwhat is the problem i understood\n[Music]\nhow to give it as\nwait i will execute it in front of you\ntill then just see what is the error\nthat we are getting in this i have\nunderstood the error\nof it transform c if i execute this i\nwill be getting an expected 2d array\ndot\nit is okay this is a series dot dot dot\ndot dot dot dot\no h e transform n p dot treble\nyeah\nnp dot rival okay\nbut i don't think so this will work\nthere will be an error\nexpected a 2d array instead of getting\none\ni can understand this i should not give\nthis in the form of series\nokay that is the problem\ni should definitely not give in the form\nof series\nso if i write\nfinal\nunderscore df of airline\nso here you can see that i'm getting in\nthe form of series this should not be in\nthe form of series\nuse two brackets\nlike this using\noh but then it becomes something else\nhere\nthe double cases we are getting\ncompressed sparse row format\np dot array df of airline\nokay one way i can basically do over\nhere is like np dot array\nfinal object dot\nreshape\nminus 1 comma 1\nsame thing we are getting\nlet's try this\nairlines\ndoors\nso here will be source\nhere will be destination\nand uh\nthere will be additional info\nbut i hope you are able to understand\nfirst one is ambiguous using get shape\nof zero\nah this is one hot encoding we are doing\nalready encoding is done\nwait wait wait wait let's see\nfinal underscore df\ndot head\nso this is one hot encoding so if i\nprobably search for\none hot encoding\nsql on\nlet's see the documentation\nyou are encoding many times\nno i did not encode many times i just\nencoded one time right\nso after encoding that value get has got\nconverted to this right now\nif you go and see final underscore df\nfinal underscore df dot\ninfo so here you will be able to see\nthat\nthis is all converted into integer types\nokay\ni know i i should not had done this\nencoding separately like this fit\ntransform instead of this i could have\nfocused on\none hot encoder it would have done it\ncompletely\nbut it's okay let's do one thing then\nsimple\nif this is not working\ni'm just going to do a very simple thing\nso i'm i'm basically going to do final\nunderscore df\nof airline\ndot\nget underscore dummies\nget under the dummies is not there\nokay\npd dot get dummies right\nsometimes syntax it's very difficult to\nremember all the syntax\ndf of airline\nfinal df\nso let's go ahead and do this\nand then you will be able to get it\ntry to create a different data frame\nlet's say this is df1\nthen i will create another data frame\nwhich is df2\nhere i will say pd.get underscore\ndummies\nand then here basically write it as\nother column final underscore df of\nthe next column that you wanted which\none is the column that you are working\non\nsource\ndestination and additional info\nthen combine those data frame\ntrain data this is also nice\nwill it work like this\nthis is also a very good way\nsee one single line they have written\nthis will be my final underscore df\ncolumns are airline source destination\nand additional info\nsources\nadditional info also\nand probably this will definitely work\nso what all things he has done is\nwritten pd dot get dummies final\nunderscore df columns with this all name\ndrop first is equal to true if i execute\nit here is all the values that you will\nbe able to get it thank you all have a\ngreat day ahead and\n",
  "words": [
    "music",
    "hello",
    "guys",
    "today",
    "going",
    "lot",
    "amazing",
    "things",
    "respect",
    "eda",
    "zomato",
    "data",
    "set",
    "exploratory",
    "data",
    "analysis",
    "right",
    "going",
    "complete",
    "today",
    "start",
    "please",
    "make",
    "sure",
    "download",
    "data",
    "set",
    "inside",
    "data",
    "set",
    "many",
    "things",
    "show",
    "files",
    "like",
    "country",
    "code",
    "dot",
    "xlx",
    "zomato",
    "dot",
    "csv",
    "file",
    "ball",
    "json",
    "file",
    "json",
    "file",
    "three",
    "json",
    "file",
    "position",
    "file",
    "file",
    "json",
    "today",
    "data",
    "set",
    "going",
    "use",
    "jomato",
    "dataset",
    "uh",
    "found",
    "particular",
    "data",
    "set",
    "kaggle",
    "put",
    "entire",
    "link",
    "github",
    "link",
    "download",
    "data",
    "set",
    "also",
    "download",
    "print",
    "comment",
    "let",
    "go",
    "first",
    "going",
    "import",
    "basic",
    "libraries",
    "import",
    "partners",
    "spd",
    "import",
    "numpy",
    "np",
    "import",
    "matplotlib",
    "dot",
    "pi",
    "plot",
    "plt",
    "one",
    "library",
    "going",
    "use",
    "something",
    "called",
    "c",
    "bond",
    "finally",
    "using",
    "matlab",
    "inline",
    "images",
    "visualization",
    "gets",
    "displayed",
    "keep",
    "restricted",
    "things",
    "understand",
    "main",
    "thing",
    "main",
    "thing",
    "whenever",
    "performing",
    "eda",
    "exploratory",
    "data",
    "analysis",
    "really",
    "need",
    "think",
    "data",
    "data",
    "basically",
    "seeing",
    "telling",
    "right",
    "important",
    "whenever",
    "specific",
    "data",
    "set",
    "even",
    "though",
    "much",
    "domain",
    "knowledge",
    "basic",
    "information",
    "definitely",
    "able",
    "capture",
    "going",
    "till",
    "actually",
    "imported",
    "libraries",
    "let",
    "go",
    "ahead",
    "first",
    "let",
    "download",
    "data",
    "set",
    "see",
    "data",
    "set",
    "called",
    "multiple",
    "json",
    "file",
    "json",
    "file",
    "given",
    "guys",
    "json",
    "file",
    "form",
    "json",
    "format",
    "okay",
    "format",
    "converted",
    "already",
    "com",
    "converted",
    "really",
    "need",
    "write",
    "python",
    "script",
    "convert",
    "see",
    "right",
    "later",
    "stages",
    "also",
    "show",
    "convert",
    "json",
    "file",
    "part",
    "later",
    "stages",
    "upcoming",
    "classes",
    "today",
    "one",
    "xlxx",
    "file",
    "one",
    "csv",
    "file",
    "try",
    "combine",
    "file",
    "also",
    "try",
    "see",
    "information",
    "specific",
    "file",
    "let",
    "start",
    "first",
    "usual",
    "write",
    "df",
    "data",
    "set",
    "write",
    "pd",
    "dot",
    "read",
    "underscore",
    "csv",
    "read",
    "data",
    "set",
    "actually",
    "importing",
    "thing",
    "need",
    "see",
    "execute",
    "like",
    "getting",
    "errors",
    "says",
    "codec",
    "ca",
    "decode",
    "byte",
    "0",
    "xed",
    "position",
    "7",
    "0",
    "7",
    "4",
    "7",
    "0",
    "4",
    "whenever",
    "get",
    "kind",
    "error",
    "always",
    "remember",
    "use",
    "kind",
    "encoding",
    "format",
    "case",
    "encoding",
    "using",
    "probably",
    "go",
    "see",
    "read",
    "underscore",
    "csv",
    "press",
    "shift",
    "tab",
    "able",
    "see",
    "lot",
    "options",
    "one",
    "options",
    "see",
    "encoding",
    "encoding",
    "somewhere",
    "see",
    "parameters",
    "search",
    "parameters",
    "respect",
    "encoding",
    "need",
    "put",
    "play",
    "three",
    "four",
    "different",
    "values",
    "understand",
    "need",
    "utf",
    "eight",
    "encoding",
    "going",
    "going",
    "use",
    "encoding",
    "remember",
    "encoding",
    "understand",
    "use",
    "directly",
    "first",
    "instance",
    "used",
    "exploring",
    "things",
    "respect",
    "kind",
    "error",
    "encoding",
    "going",
    "use",
    "latin",
    "dash",
    "one",
    "different",
    "different",
    "encodings",
    "encoding",
    "uh",
    "check",
    "documentation",
    "going",
    "use",
    "latin",
    "one",
    "going",
    "basically",
    "say",
    "go",
    "see",
    "data",
    "sets",
    "available",
    "huge",
    "data",
    "set",
    "respect",
    "number",
    "columns",
    "understand",
    "read",
    "data",
    "set",
    "respect",
    "check",
    "features",
    "one",
    "thing",
    "done",
    "imported",
    "data",
    "set",
    "inside",
    "df",
    "let",
    "go",
    "next",
    "step",
    "data",
    "set",
    "present",
    "next",
    "step",
    "actually",
    "going",
    "going",
    "see",
    "columns",
    "inside",
    "data",
    "set",
    "basic",
    "eda",
    "part",
    "restaurant",
    "id",
    "restaurant",
    "name",
    "country",
    "code",
    "city",
    "address",
    "locality",
    "locality",
    "verbose",
    "longitude",
    "latitude",
    "questions",
    "average",
    "cost",
    "two",
    "currency",
    "many",
    "features",
    "actually",
    "present",
    "go",
    "search",
    "pandas",
    "documentation",
    "anytime",
    "kind",
    "queries",
    "respect",
    "encoding",
    "write",
    "directly",
    "search",
    "search",
    "search",
    "anyhow",
    "anywhere",
    "able",
    "see",
    "encoding",
    "used",
    "used",
    "explore",
    "see",
    "encoding",
    "none",
    "right",
    "white",
    "basically",
    "used",
    "click",
    "try",
    "understand",
    "specific",
    "keyword",
    "next",
    "thing",
    "let",
    "go",
    "ahead",
    "let",
    "see",
    "one",
    "way",
    "understanding",
    "data",
    "set",
    "like",
    "write",
    "able",
    "see",
    "columns",
    "whether",
    "column",
    "normal",
    "null",
    "whether",
    "data",
    "type",
    "see",
    "64",
    "specifically",
    "integer",
    "variables",
    "whenever",
    "see",
    "objects",
    "pandas",
    "data",
    "frame",
    "object",
    "basically",
    "means",
    "strings",
    "also",
    "mean",
    "like",
    "maybe",
    "categorical",
    "variable",
    "may",
    "text",
    "variable",
    "anything",
    "basically",
    "see",
    "things",
    "also",
    "float",
    "uh",
    "objects",
    "objects",
    "wherever",
    "objects",
    "consider",
    "may",
    "categorical",
    "variable",
    "may",
    "integer",
    "variable",
    "may",
    "text",
    "data",
    "initially",
    "always",
    "try",
    "find",
    "columns",
    "try",
    "find",
    "important",
    "information",
    "columns",
    "respect",
    "data",
    "type",
    "coming",
    "next",
    "step",
    "let",
    "see",
    "actual",
    "information",
    "actually",
    "come",
    "also",
    "inbuilt",
    "keyword",
    "called",
    "describe",
    "basic",
    "inbuilt",
    "function",
    "called",
    "describe",
    "actually",
    "help",
    "find",
    "specific",
    "information",
    "one",
    "key",
    "important",
    "information",
    "able",
    "see",
    "features",
    "basically",
    "taken",
    "inside",
    "describe",
    "function",
    "right",
    "integer",
    "features",
    "able",
    "find",
    "categorical",
    "features",
    "text",
    "features",
    "object",
    "features",
    "definitely",
    "see",
    "respect",
    "feature",
    "see",
    "restaurant",
    "id",
    "go",
    "see",
    "restaurant",
    "id",
    "go",
    "see",
    "country",
    "code",
    "basically",
    "uh",
    "int",
    "go",
    "ahead",
    "longitude",
    "always",
    "float",
    "64c",
    "longitude",
    "latitude",
    "float64",
    "values",
    "actually",
    "able",
    "see",
    "completely",
    "based",
    "uh",
    "integer",
    "variables",
    "whatever",
    "thing",
    "like",
    "count",
    "mean",
    "standard",
    "deviation",
    "mean",
    "basically",
    "find",
    "integer",
    "numerical",
    "variable",
    "give",
    "basic",
    "information",
    "data",
    "analysis",
    "first",
    "thing",
    "would",
    "like",
    "find",
    "try",
    "find",
    "missing",
    "values",
    "first",
    "always",
    "much",
    "important",
    "data",
    "set",
    "missing",
    "values",
    "second",
    "thing",
    "may",
    "probably",
    "uh",
    "check",
    "explore",
    "numerical",
    "variables",
    "third",
    "would",
    "like",
    "definitely",
    "explore",
    "categorical",
    "variables",
    "basic",
    "things",
    "need",
    "know",
    "many",
    "categories",
    "many",
    "numerical",
    "variables",
    "fourth",
    "major",
    "thing",
    "probably",
    "finding",
    "relationship",
    "features",
    "let",
    "go",
    "ahead",
    "try",
    "find",
    "missing",
    "values",
    "order",
    "find",
    "missing",
    "values",
    "basically",
    "write",
    "df",
    "dot",
    "null",
    "dot",
    "sum",
    "go",
    "search",
    "able",
    "see",
    "respect",
    "every",
    "feature",
    "saying",
    "many",
    "features",
    "basically",
    "null",
    "value",
    "see",
    "0",
    "0",
    "0",
    "0",
    "duplicates",
    "talk",
    "duplicates",
    "also",
    "see",
    "city",
    "0",
    "address",
    "0",
    "locality",
    "0",
    "locality",
    "verbose",
    "zero",
    "longitude",
    "latitude",
    "zero",
    "cosines",
    "see",
    "nine",
    "missing",
    "values",
    "remaining",
    "zero",
    "missing",
    "values",
    "cosines",
    "see",
    "nine",
    "missing",
    "values",
    "want",
    "anything",
    "respect",
    "missing",
    "values",
    "basically",
    "work",
    "specific",
    "feature",
    "find",
    "relationship",
    "respect",
    "cosines",
    "target",
    "variables",
    "independent",
    "features",
    "okay",
    "try",
    "right",
    "got",
    "specific",
    "information",
    "many",
    "number",
    "missing",
    "values",
    "one",
    "way",
    "another",
    "way",
    "write",
    "simple",
    "code",
    "actually",
    "tell",
    "informations",
    "features",
    "missing",
    "values",
    "basically",
    "say",
    "features",
    "features",
    "write",
    "want",
    "check",
    "variables",
    "missing",
    "values",
    "saying",
    "every",
    "features",
    "go",
    "check",
    "df",
    "columns",
    "df",
    "columns",
    "represented",
    "feature",
    "dot",
    "null",
    "dot",
    "sum",
    "greater",
    "one",
    "basically",
    "list",
    "comprehension",
    "saying",
    "features",
    "features",
    "basically",
    "means",
    "using",
    "temporary",
    "variable",
    "called",
    "features",
    "iterate",
    "say",
    "specific",
    "feature",
    "null",
    "dot",
    "sum",
    "greater",
    "1",
    "write",
    "greater",
    "1",
    "instead",
    "write",
    "greater",
    "0",
    "also",
    "go",
    "execute",
    "see",
    "cosines",
    "definitely",
    "able",
    "get",
    "specific",
    "thing",
    "respect",
    "able",
    "see",
    "null",
    "value",
    "let",
    "go",
    "next",
    "step",
    "respect",
    "uh",
    "respect",
    "heat",
    "map",
    "plot",
    "something",
    "heat",
    "map",
    "basically",
    "using",
    "snh",
    "dot",
    "heat",
    "map",
    "basically",
    "put",
    "condition",
    "says",
    "df",
    "dot",
    "null",
    "say",
    "second",
    "parameter",
    "white",
    "tick",
    "labels",
    "go",
    "press",
    "shift",
    "tab",
    "always",
    "try",
    "see",
    "feature",
    "respect",
    "particular",
    "feature",
    "whatever",
    "actually",
    "using",
    "x",
    "stick",
    "label",
    "tick",
    "label",
    "right",
    "want",
    "show",
    "much",
    "things",
    "keep",
    "false",
    "focusing",
    "df",
    "respect",
    "also",
    "use",
    "c",
    "bar",
    "also",
    "another",
    "feature",
    "understand",
    "seeing",
    "documentation",
    "things",
    "use",
    "c",
    "map",
    "inside",
    "cmap",
    "use",
    "one",
    "basically",
    "search",
    "see",
    "options",
    "visible",
    "go",
    "c",
    "bond",
    "documentation",
    "page",
    "basically",
    "take",
    "specific",
    "information",
    "going",
    "use",
    "cmap",
    "called",
    "varidis",
    "obviously",
    "able",
    "see",
    "nine",
    "records",
    "may",
    "somewhere",
    "probably",
    "wo",
    "able",
    "see",
    "probably",
    "specific",
    "thing",
    "right",
    "let",
    "see",
    "sum",
    "sum",
    "cosines",
    "9",
    "okay",
    "total",
    "number",
    "let",
    "say",
    "total",
    "number",
    "df",
    "dot",
    "around",
    "nine",
    "five",
    "five",
    "one",
    "rows",
    "getting",
    "visible",
    "small",
    "number",
    "nand",
    "values",
    "reason",
    "see",
    "many",
    "many",
    "definitely",
    "check",
    "understood",
    "missing",
    "values",
    "seen",
    "already",
    "told",
    "another",
    "data",
    "set",
    "called",
    "country",
    "code",
    "let",
    "try",
    "see",
    "data",
    "set",
    "basically",
    "going",
    "write",
    "df",
    "dot",
    "underscore",
    "country",
    "going",
    "say",
    "underscore",
    "csv",
    "going",
    "use",
    "going",
    "basically",
    "write",
    "dot",
    "head",
    "giving",
    "error",
    "let",
    "see",
    "error",
    "okay",
    "also",
    "problems",
    "respect",
    "invalid",
    "continuation",
    "byte",
    "use",
    "read",
    "underscore",
    "csv",
    "use",
    "read",
    "underscore",
    "excel",
    "excel",
    "file",
    "otherwise",
    "use",
    "encoding",
    "things",
    "make",
    "work",
    "deal",
    "missing",
    "values",
    "uh",
    "try",
    "show",
    "feature",
    "engineering",
    "one",
    "country",
    "code",
    "country",
    "code",
    "xls",
    "see",
    "country",
    "code",
    "country",
    "two",
    "features",
    "go",
    "probably",
    "see",
    "df",
    "dot",
    "columns",
    "country",
    "code",
    "also",
    "country",
    "code",
    "combine",
    "two",
    "data",
    "frames",
    "order",
    "combine",
    "using",
    "merge",
    "function",
    "actually",
    "help",
    "us",
    "combine",
    "left",
    "give",
    "another",
    "data",
    "set",
    "right",
    "give",
    "another",
    "data",
    "set",
    "give",
    "df",
    "give",
    "df",
    "df",
    "underscore",
    "country",
    "let",
    "see",
    "another",
    "feature",
    "one",
    "feature",
    "basically",
    "say",
    "basically",
    "says",
    "feature",
    "basically",
    "going",
    "combine",
    "two",
    "tables",
    "going",
    "say",
    "equal",
    "going",
    "copy",
    "country",
    "code",
    "come",
    "copied",
    "country",
    "code",
    "basically",
    "left",
    "also",
    "one",
    "keyword",
    "called",
    "basically",
    "specify",
    "whether",
    "focus",
    "left",
    "table",
    "right",
    "table",
    "probably",
    "somewhere",
    "able",
    "see",
    "whether",
    "want",
    "left",
    "join",
    "right",
    "join",
    "inner",
    "join",
    "right",
    "want",
    "really",
    "focus",
    "left",
    "hand",
    "side",
    "table",
    "df",
    "entire",
    "data",
    "set",
    "right",
    "hand",
    "side",
    "one",
    "additional",
    "column",
    "country",
    "name",
    "order",
    "combine",
    "actually",
    "going",
    "going",
    "focus",
    "left",
    "left",
    "see",
    "able",
    "see",
    "able",
    "get",
    "records",
    "somewhere",
    "also",
    "able",
    "see",
    "country",
    "see",
    "last",
    "thing",
    "country",
    "getting",
    "added",
    "save",
    "final",
    "data",
    "frame",
    "called",
    "final",
    "underscore",
    "df",
    "final",
    "underscore",
    "df",
    "go",
    "probably",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "check",
    "first",
    "two",
    "records",
    "able",
    "find",
    "everything",
    "finally",
    "final",
    "underscore",
    "df",
    "entire",
    "data",
    "set",
    "let",
    "go",
    "ahead",
    "inside",
    "data",
    "set",
    "try",
    "explore",
    "things",
    "also",
    "another",
    "way",
    "check",
    "data",
    "types",
    "want",
    "check",
    "data",
    "types",
    "write",
    "something",
    "like",
    "final",
    "underscore",
    "df",
    "dot",
    "types",
    "also",
    "types",
    "actually",
    "help",
    "get",
    "data",
    "types",
    "information",
    "use",
    "dot",
    "types",
    "able",
    "see",
    "entire",
    "data",
    "type",
    "basically",
    "used",
    "match",
    "column",
    "basically",
    "going",
    "combine",
    "like",
    "left",
    "join",
    "right",
    "join",
    "specific",
    "column",
    "seen",
    "sequel",
    "videos",
    "already",
    "uploaded",
    "let",
    "go",
    "next",
    "step",
    "let",
    "try",
    "something",
    "amazing",
    "let",
    "try",
    "explore",
    "something",
    "data",
    "understand",
    "one",
    "thing",
    "go",
    "see",
    "data",
    "features",
    "like",
    "okay",
    "let",
    "let",
    "open",
    "let",
    "open",
    "final",
    "underscore",
    "df",
    "dot",
    "columns",
    "able",
    "see",
    "features",
    "like",
    "country",
    "code",
    "city",
    "address",
    "locality",
    "locality",
    "verbs",
    "longitude",
    "latitude",
    "cuisines",
    "average",
    "cost",
    "two",
    "currency",
    "let",
    "pick",
    "something",
    "okay",
    "let",
    "pick",
    "probably",
    "let",
    "see",
    "want",
    "find",
    "something",
    "okay",
    "mainly",
    "understand",
    "whatever",
    "things",
    "right",
    "make",
    "sure",
    "write",
    "observations",
    "actually",
    "going",
    "let",
    "say",
    "going",
    "use",
    "something",
    "like",
    "final",
    "underscore",
    "df",
    "dot",
    "country",
    "dot",
    "value",
    "underscore",
    "count",
    "actually",
    "trying",
    "find",
    "many",
    "different",
    "countries",
    "respect",
    "particular",
    "countries",
    "records",
    "right",
    "respect",
    "specific",
    "countries",
    "many",
    "records",
    "india",
    "able",
    "see",
    "8652",
    "records",
    "united",
    "states",
    "able",
    "see",
    "434",
    "united",
    "kingdom",
    "80",
    "60",
    "60",
    "60",
    "kind",
    "observation",
    "feel",
    "come",
    "say",
    "zomato",
    "mostly",
    "available",
    "india",
    "obviously",
    "usa",
    "website",
    "recommend",
    "kind",
    "restaurants",
    "understand",
    "one",
    "thing",
    "india",
    "main",
    "base",
    "zomato",
    "maximum",
    "number",
    "transactions",
    "may",
    "probably",
    "happening",
    "india",
    "right",
    "hope",
    "everybody",
    "able",
    "understand",
    "right",
    "information",
    "able",
    "get",
    "write",
    "dot",
    "index",
    "respect",
    "dot",
    "index",
    "able",
    "see",
    "able",
    "get",
    "countries",
    "name",
    "respect",
    "specific",
    "records",
    "okay",
    "let",
    "save",
    "probably",
    "variable",
    "like",
    "country",
    "names",
    "tell",
    "everything",
    "make",
    "understand",
    "completely",
    "going",
    "plot",
    "pie",
    "chart",
    "going",
    "plot",
    "chart",
    "similarly",
    "use",
    "thing",
    "execute",
    "dot",
    "index",
    "able",
    "see",
    "getting",
    "country",
    "names",
    "dot",
    "value",
    "counts",
    "also",
    "able",
    "get",
    "dot",
    "value",
    "counts",
    "able",
    "get",
    "sorry",
    "countries",
    "dot",
    "sorry",
    "value",
    "count",
    "start",
    "valuable",
    "dot",
    "values",
    "let",
    "see",
    "dot",
    "v",
    "l",
    "values",
    "okay",
    "respect",
    "dot",
    "values",
    "actually",
    "getting",
    "number",
    "records",
    "particular",
    "country",
    "name",
    "two",
    "reason",
    "going",
    "create",
    "pie",
    "chart",
    "create",
    "flight",
    "chart",
    "use",
    "respect",
    "use",
    "respect",
    "actually",
    "put",
    "variables",
    "going",
    "press",
    "shift",
    "tab",
    "need",
    "x",
    "variable",
    "actually",
    "putting",
    "plot",
    "uh",
    "pi",
    "pie",
    "chart",
    "definitely",
    "use",
    "x",
    "value",
    "try",
    "use",
    "names",
    "values",
    "whatever",
    "things",
    "want",
    "let",
    "say",
    "want",
    "use",
    "values",
    "store",
    "country",
    "value",
    "going",
    "put",
    "entirely",
    "x",
    "axis",
    "want",
    "see",
    "pie",
    "chart",
    "country",
    "maximum",
    "transactions",
    "maximum",
    "online",
    "orders",
    "maximum",
    "kind",
    "orders",
    "going",
    "use",
    "x",
    "axis",
    "x",
    "axis",
    "expand",
    "able",
    "see",
    "labels",
    "important",
    "okay",
    "labels",
    "basically",
    "give",
    "labels",
    "top",
    "going",
    "use",
    "labels",
    "equal",
    "going",
    "assign",
    "value",
    "something",
    "like",
    "country",
    "name",
    "okay",
    "country",
    "name",
    "two",
    "things",
    "execute",
    "able",
    "see",
    "getting",
    "plot",
    "plot",
    "looks",
    "really",
    "bad",
    "obviously",
    "percentage",
    "information",
    "spread",
    "towards",
    "different",
    "different",
    "countries",
    "less",
    "like",
    "jumbled",
    "complete",
    "going",
    "going",
    "say",
    "top",
    "five",
    "countries",
    "top",
    "five",
    "countries",
    "top",
    "three",
    "countries",
    "top",
    "three",
    "countries",
    "uses",
    "zomato",
    "based",
    "transaction",
    "right",
    "going",
    "going",
    "use",
    "colon",
    "3",
    "also",
    "going",
    "use",
    "colon",
    "3",
    "colon",
    "basically",
    "says",
    "entire",
    "values",
    "going",
    "take",
    "top",
    "three",
    "values",
    "top",
    "three",
    "countries",
    "going",
    "display",
    "looks",
    "good",
    "top",
    "three",
    "countries",
    "basically",
    "using",
    "india",
    "united",
    "states",
    "united",
    "kingdom",
    "right",
    "hope",
    "able",
    "understand",
    "respect",
    "pie",
    "chart",
    "like",
    "data",
    "distributed",
    "definitely",
    "respect",
    "zomatos",
    "matter",
    "base",
    "companies",
    "india",
    "obviously",
    "come",
    "conclusion",
    "maximum",
    "number",
    "transactions",
    "happen",
    "india",
    "one",
    "thing",
    "probably",
    "want",
    "add",
    "something",
    "called",
    "percentage",
    "need",
    "see",
    "percentage",
    "also",
    "right",
    "would",
    "pretty",
    "much",
    "amazing",
    "right",
    "actually",
    "going",
    "parameter",
    "called",
    "percentage",
    "also",
    "parameter",
    "something",
    "called",
    "auto",
    "percentage",
    "use",
    "auto",
    "percentage",
    "going",
    "use",
    "one",
    "property",
    "want",
    "see",
    "one",
    "property",
    "assign",
    "assign",
    "one",
    "format",
    "format",
    "basically",
    "write",
    "something",
    "like",
    "basically",
    "says",
    "decimal",
    "two",
    "values",
    "mentioned",
    "getting",
    "converted",
    "percentage",
    "going",
    "remove",
    "double",
    "quotes",
    "definitely",
    "work",
    "play",
    "write",
    "remove",
    "two",
    "happen",
    "remove",
    "remove",
    "f",
    "happen",
    "try",
    "play",
    "execute",
    "see",
    "percentage",
    "basically",
    "orders",
    "india",
    "transaction",
    "united",
    "states",
    "united",
    "kingdom",
    "need",
    "write",
    "observation",
    "tell",
    "suggest",
    "observation",
    "write",
    "diagram",
    "kind",
    "observation",
    "see",
    "need",
    "add",
    "particular",
    "property",
    "get",
    "percentage",
    "values",
    "tell",
    "percent",
    "observation",
    "write",
    "zomato",
    "maximum",
    "records",
    "transactions",
    "india",
    "okay",
    "usa",
    "united",
    "kingdoms",
    "write",
    "observation",
    "words",
    "written",
    "something",
    "try",
    "write",
    "obser",
    "zomata",
    "maximum",
    "records",
    "transaction",
    "india",
    "usa",
    "united",
    "states",
    "united",
    "kingdom",
    "sorry",
    "first",
    "observation",
    "able",
    "take",
    "pie",
    "chart",
    "major",
    "business",
    "happening",
    "india",
    "say",
    "lot",
    "things",
    "come",
    "okay",
    "everybody",
    "clear",
    "hope",
    "simple",
    "till",
    "okay",
    "let",
    "go",
    "respect",
    "next",
    "one",
    "numerical",
    "variables",
    "identify",
    "many",
    "numerical",
    "variables",
    "many",
    "numerical",
    "variables",
    "forget",
    "numerical",
    "variable",
    "let",
    "exact",
    "relationship",
    "numerical",
    "variables",
    "check",
    "check",
    "later",
    "stages",
    "want",
    "really",
    "observation",
    "things",
    "relationships",
    "things",
    "able",
    "see",
    "something",
    "go",
    "write",
    "final",
    "underscore",
    "df",
    "dot",
    "columns",
    "execute",
    "see",
    "amazing",
    "features",
    "called",
    "aggregating",
    "rating",
    "want",
    "also",
    "see",
    "respect",
    "rating",
    "country",
    "rating",
    "actually",
    "coming",
    "want",
    "see",
    "data",
    "called",
    "rating",
    "color",
    "rating",
    "text",
    "okay",
    "actually",
    "going",
    "write",
    "small",
    "query",
    "final",
    "underscore",
    "df",
    "dot",
    "group",
    "going",
    "use",
    "group",
    "operation",
    "respect",
    "group",
    "operation",
    "going",
    "use",
    "features",
    "called",
    "aggregate",
    "rating",
    "aggregate",
    "rating",
    "also",
    "use",
    "rating",
    "color",
    "see",
    "everybody",
    "rating",
    "color",
    "going",
    "slowly",
    "guys",
    "slowly",
    "think",
    "write",
    "writing",
    "every",
    "line",
    "code",
    "rating",
    "color",
    "also",
    "going",
    "use",
    "rating",
    "text",
    "rating",
    "test",
    "basically",
    "going",
    "uh",
    "group",
    "three",
    "main",
    "features",
    "also",
    "going",
    "one",
    "thing",
    "group",
    "probably",
    "execute",
    "getting",
    "error",
    "let",
    "see",
    "error",
    "rating",
    "text",
    "rating",
    "small",
    "execute",
    "see",
    "data",
    "frame",
    "group",
    "object",
    "write",
    "dot",
    "size",
    "execute",
    "dot",
    "size",
    "able",
    "see",
    "values",
    "like",
    "white",
    "rated",
    "similarly",
    "good",
    "good",
    "good",
    "good",
    "see",
    "one",
    "thing",
    "see",
    "rating",
    "color",
    "white",
    "basically",
    "means",
    "aggregate",
    "rating",
    "rating",
    "red",
    "basically",
    "showing",
    "also",
    "red",
    "also",
    "red",
    "also",
    "red",
    "like",
    "also",
    "red",
    "red",
    "red",
    "basically",
    "means",
    "poor",
    "poor",
    "ratings",
    "poor",
    "respect",
    "aggregate",
    "rating",
    "see",
    "poor",
    "go",
    "respect",
    "next",
    "one",
    "orange",
    "color",
    "see",
    "average",
    "ratings",
    "another",
    "rating",
    "also",
    "see",
    "good",
    "right",
    "displayed",
    "yellow",
    "color",
    "text",
    "written",
    "yellow",
    "color",
    "like",
    "rating",
    "colors",
    "good",
    "excellent",
    "information",
    "know",
    "actually",
    "able",
    "find",
    "also",
    "write",
    "uh",
    "try",
    "write",
    "observation",
    "actually",
    "going",
    "convert",
    "data",
    "frame",
    "order",
    "convert",
    "data",
    "frame",
    "write",
    "reset",
    "underscore",
    "index",
    "invalid",
    "error",
    "reason",
    "invalid",
    "error",
    "continue",
    "reset",
    "underscore",
    "index",
    "basically",
    "going",
    "say",
    "rename",
    "execute",
    "let",
    "see",
    "get",
    "get",
    "see",
    "getting",
    "particular",
    "things",
    "zero",
    "value",
    "since",
    "done",
    "group",
    "respect",
    "ratings",
    "2148",
    "records",
    "respect",
    "one",
    "record",
    "records",
    "records",
    "0",
    "coming",
    "instead",
    "0",
    "try",
    "rename",
    "different",
    "column",
    "going",
    "use",
    "reset",
    "index",
    "dot",
    "rename",
    "going",
    "basically",
    "use",
    "columns",
    "equal",
    "going",
    "name",
    "0",
    "colon",
    "let",
    "say",
    "using",
    "rating",
    "count",
    "let",
    "one",
    "thing",
    "see",
    "done",
    "reset",
    "index",
    "using",
    "rename",
    "function",
    "saying",
    "wherever",
    "columns",
    "0",
    "change",
    "rating",
    "count",
    "execute",
    "see",
    "getting",
    "one",
    "error",
    "closed",
    "close",
    "closed",
    "see",
    "actually",
    "able",
    "see",
    "everybody",
    "write",
    "code",
    "know",
    "many",
    "people",
    "get",
    "stuck",
    "multiple",
    "things",
    "respect",
    "important",
    "information",
    "actually",
    "able",
    "get",
    "correlated",
    "try",
    "find",
    "worry",
    "right",
    "still",
    "gone",
    "correlation",
    "inbuilt",
    "directly",
    "using",
    "inbuilt",
    "want",
    "go",
    "inbuilt",
    "right",
    "main",
    "features",
    "everybody",
    "written",
    "final",
    "underscore",
    "df",
    "dot",
    "group",
    "aggregate",
    "rating",
    "rating",
    "color",
    "rating",
    "text",
    "dot",
    "size",
    "dot",
    "reset",
    "index",
    "dot",
    "rename",
    "columns",
    "renaming",
    "0",
    "rating",
    "count",
    "see",
    "aggregate",
    "rating",
    "rating",
    "color",
    "rating",
    "text",
    "rating",
    "count",
    "informations",
    "right",
    "amazing",
    "information",
    "let",
    "go",
    "next",
    "step",
    "actually",
    "going",
    "rating",
    "count",
    "information",
    "reset",
    "index",
    "basically",
    "means",
    "reset",
    "index",
    "index",
    "default",
    "whatever",
    "index",
    "coming",
    "reset",
    "hope",
    "everybody",
    "done",
    "save",
    "variable",
    "variable",
    "play",
    "important",
    "role",
    "guys",
    "giving",
    "another",
    "one",
    "minute",
    "please",
    "write",
    "ratings",
    "equal",
    "one",
    "ef",
    "final",
    "underscore",
    "df",
    "dot",
    "guys",
    "please",
    "write",
    "anybody",
    "write",
    "written",
    "going",
    "share",
    "please",
    "write",
    "particular",
    "code",
    "much",
    "important",
    "things",
    "go",
    "see",
    "ratings",
    "values",
    "average",
    "rating",
    "rating",
    "color",
    "rating",
    "text",
    "writing",
    "let",
    "go",
    "ahead",
    "let",
    "go",
    "ahead",
    "let",
    "plot",
    "amazing",
    "beautiful",
    "diagrams",
    "want",
    "really",
    "find",
    "relationship",
    "respect",
    "different",
    "different",
    "countries",
    "respect",
    "different",
    "different",
    "problem",
    "statements",
    "respect",
    "see",
    "data",
    "analyst",
    "data",
    "scientist",
    "think",
    "okay",
    "data",
    "set",
    "okay",
    "probably",
    "type",
    "visualization",
    "draw",
    "want",
    "kind",
    "edn",
    "okay",
    "kind",
    "things",
    "seeing",
    "data",
    "definitely",
    "come",
    "one",
    "conclusion",
    "around",
    "2148",
    "ratings",
    "zero",
    "rating",
    "maximum",
    "number",
    "people",
    "actually",
    "given",
    "zero",
    "ratings",
    "basically",
    "means",
    "rated",
    "app",
    "entire",
    "zomato",
    "app",
    "right",
    "focusing",
    "trying",
    "understand",
    "okay",
    "maximum",
    "number",
    "ratings",
    "zero",
    "basically",
    "means",
    "person",
    "given",
    "ratings",
    "right",
    "see",
    "rating",
    "text",
    "rated",
    "right",
    "people",
    "giving",
    "ratings",
    "see",
    "poor",
    "average",
    "good",
    "along",
    "colors",
    "also",
    "given",
    "plot",
    "amazing",
    "way",
    "understand",
    "visualized",
    "way",
    "also",
    "let",
    "go",
    "ahead",
    "come",
    "conclusions",
    "write",
    "conclusions",
    "conclusions",
    "much",
    "important",
    "observations",
    "also",
    "say",
    "observation",
    "observation",
    "data",
    "set",
    "first",
    "observation",
    "first",
    "observation",
    "whenever",
    "rating",
    "4",
    "let",
    "say",
    "4",
    "sorry",
    "going",
    "write",
    "observation",
    "rating",
    "indicates",
    "indicate",
    "indicates",
    "excellent",
    "probably",
    "foot",
    "delivered",
    "basically",
    "excellent",
    "second",
    "thing",
    "come",
    "observation",
    "see",
    "rating",
    "ratings",
    "basically",
    "say",
    "good",
    "hope",
    "right",
    "extremely",
    "sorry",
    "missed",
    "ratings",
    "good",
    "third",
    "thing",
    "come",
    "rating",
    "rating",
    "good",
    "observation",
    "definitely",
    "see",
    "data",
    "right",
    "remaining",
    "please",
    "go",
    "ahead",
    "write",
    "okay",
    "another",
    "observation",
    "average",
    "going",
    "come",
    "copy",
    "wait",
    "wait",
    "wait",
    "wait",
    "average",
    "average",
    "average",
    "next",
    "observation",
    "fifth",
    "go",
    "ahead",
    "write",
    "rating",
    "music",
    "6",
    "going",
    "write",
    "rating",
    "rating",
    "right",
    "much",
    "average",
    "also",
    "average",
    "uh",
    "poor",
    "right",
    "observation",
    "complete",
    "observations",
    "find",
    "one",
    "thing",
    "see",
    "zero",
    "rating",
    "given",
    "many",
    "people",
    "right",
    "observations",
    "respect",
    "writing",
    "observation",
    "better",
    "also",
    "draw",
    "kind",
    "diagrams",
    "going",
    "basically",
    "draw",
    "diagram",
    "ratings",
    "going",
    "use",
    "aggregate",
    "rating",
    "let",
    "say",
    "writing",
    "dot",
    "head",
    "aggregate",
    "hitting",
    "rating",
    "color",
    "rating",
    "text",
    "rating",
    "count",
    "going",
    "use",
    "c",
    "bond",
    "bar",
    "plot",
    "let",
    "see",
    "visualize",
    "help",
    "bar",
    "plot",
    "something",
    "basically",
    "going",
    "use",
    "uh",
    "bar",
    "plot",
    "always",
    "understand",
    "features",
    "x",
    "data",
    "order",
    "order",
    "everything",
    "going",
    "going",
    "simple",
    "bar",
    "plot",
    "x",
    "axis",
    "going",
    "basically",
    "use",
    "aggregate",
    "rating",
    "going",
    "use",
    "aggregate",
    "rating",
    "basically",
    "going",
    "use",
    "rating",
    "count",
    "let",
    "say",
    "going",
    "see",
    "relationship",
    "aggregating",
    "rating",
    "aggregate",
    "aggregate",
    "rating",
    "rating",
    "count",
    "see",
    "aggregate",
    "rating",
    "rating",
    "count",
    "want",
    "basically",
    "draw",
    "bar",
    "plot",
    "basically",
    "check",
    "graphs",
    "look",
    "like",
    "okay",
    "third",
    "parameter",
    "going",
    "basically",
    "use",
    "data",
    "equal",
    "ratings",
    "write",
    "execute",
    "basically",
    "check",
    "beautiful",
    "looks",
    "diagram",
    "looks",
    "smaller",
    "actually",
    "going",
    "going",
    "put",
    "one",
    "simple",
    "settings",
    "increase",
    "diagram",
    "able",
    "see",
    "better",
    "way",
    "okay",
    "settings",
    "basically",
    "matplotlib",
    "going",
    "use",
    "something",
    "like",
    "another",
    "setting",
    "called",
    "matplotlib",
    "dot",
    "rc",
    "params",
    "figure",
    "dot",
    "figure",
    "size",
    "give",
    "respect",
    "width",
    "height",
    "giving",
    "12",
    "matplotlib",
    "okay",
    "import",
    "matplotlib",
    "going",
    "write",
    "see",
    "diagram",
    "looks",
    "quite",
    "bigger",
    "probably",
    "go",
    "execute",
    "heat",
    "map",
    "let",
    "see",
    "whether",
    "change",
    "see",
    "values",
    "right",
    "missing",
    "values",
    "made",
    "diagram",
    "little",
    "bit",
    "bigger",
    "see",
    "done",
    "missing",
    "code",
    "missed",
    "respect",
    "increasing",
    "figure",
    "size",
    "write",
    "matplotlib",
    "dot",
    "rc",
    "parent",
    "respect",
    "parameter",
    "want",
    "change",
    "basically",
    "use",
    "set",
    "12",
    "comma",
    "6",
    "see",
    "diagram",
    "diagram",
    "definitely",
    "find",
    "lot",
    "information",
    "diagram",
    "looks",
    "super",
    "cool",
    "zero",
    "rating",
    "2000",
    "see",
    "complete",
    "looks",
    "like",
    "gaussian",
    "curve",
    "right",
    "whenever",
    "gaussian",
    "curve",
    "get",
    "good",
    "sense",
    "feeling",
    "yes",
    "let",
    "one",
    "thing",
    "see",
    "rating",
    "color",
    "also",
    "always",
    "good",
    "way",
    "also",
    "color",
    "aggregate",
    "rating",
    "help",
    "colors",
    "given",
    "code",
    "everybody",
    "write",
    "x",
    "aggregate",
    "ratings",
    "rating",
    "count",
    "said",
    "okay",
    "coloring",
    "text",
    "rating",
    "color",
    "white",
    "red",
    "use",
    "colors",
    "also",
    "probably",
    "try",
    "get",
    "form",
    "colors",
    "try",
    "see",
    "also",
    "try",
    "okay",
    "get",
    "colors",
    "uh",
    "actually",
    "going",
    "going",
    "copy",
    "thing",
    "entirely",
    "one",
    "parameter",
    "called",
    "hui",
    "write",
    "hui",
    "equal",
    "rating",
    "color",
    "write",
    "execute",
    "able",
    "see",
    "c",
    "h",
    "orange",
    "color",
    "green",
    "color",
    "red",
    "color",
    "understand",
    "whatever",
    "color",
    "matching",
    "right",
    "white",
    "looks",
    "like",
    "blue",
    "wherever",
    "see",
    "blue",
    "right",
    "basically",
    "showing",
    "zero",
    "rating",
    "according",
    "white",
    "red",
    "zero",
    "white",
    "color",
    "right",
    "actually",
    "going",
    "map",
    "colors",
    "also",
    "map",
    "colors",
    "try",
    "see",
    "mapping",
    "colors",
    "let",
    "see",
    "mapping",
    "going",
    "basically",
    "use",
    "palette",
    "inside",
    "palette",
    "going",
    "basically",
    "use",
    "different",
    "different",
    "colors",
    "first",
    "color",
    "want",
    "show",
    "something",
    "called",
    "white",
    "second",
    "color",
    "want",
    "show",
    "red",
    "third",
    "color",
    "want",
    "show",
    "orange",
    "list",
    "okay",
    "fourth",
    "color",
    "want",
    "show",
    "yellow",
    "fifth",
    "color",
    "want",
    "show",
    "green",
    "sixth",
    "color",
    "also",
    "want",
    "show",
    "green",
    "written",
    "palette",
    "palette",
    "feature",
    "present",
    "attribute",
    "present",
    "bar",
    "plot",
    "give",
    "colors",
    "required",
    "based",
    "requirement",
    "execute",
    "let",
    "see",
    "error",
    "okay",
    "pellet",
    "spelling",
    "wrong",
    "guess",
    "tte",
    "p",
    "l",
    "e",
    "e",
    "palette",
    "execute",
    "let",
    "see",
    "see",
    "getting",
    "perfect",
    "color",
    "right",
    "white",
    "white",
    "red",
    "orange",
    "also",
    "kind",
    "observation",
    "basically",
    "get",
    "right",
    "kind",
    "observation",
    "maximum",
    "number",
    "see",
    "write",
    "observation",
    "first",
    "write",
    "code",
    "everybody",
    "able",
    "see",
    "getting",
    "colors",
    "go",
    "ahead",
    "write",
    "code",
    "quickly",
    "see",
    "type",
    "graphs",
    "able",
    "get",
    "white",
    "invisible",
    "worry",
    "fine",
    "want",
    "make",
    "different",
    "color",
    "make",
    "instead",
    "white",
    "use",
    "blue",
    "right",
    "kind",
    "observations",
    "actually",
    "get",
    "observations",
    "write",
    "observation",
    "first",
    "observation",
    "would",
    "like",
    "make",
    "rated",
    "basically",
    "means",
    "blue",
    "color",
    "count",
    "high",
    "second",
    "thing",
    "second",
    "observation",
    "see",
    "maximum",
    "number",
    "ratings",
    "maximum",
    "number",
    "ratings",
    "definitely",
    "two",
    "observations",
    "basically",
    "find",
    "two",
    "observation",
    "definitely",
    "find",
    "clear",
    "everybody",
    "two",
    "observations",
    "basically",
    "fight",
    "imagine",
    "ratings",
    "missing",
    "suppose",
    "let",
    "say",
    "person",
    "rated",
    "missing",
    "values",
    "ca",
    "think",
    "probably",
    "use",
    "values",
    "average",
    "right",
    "type",
    "observations",
    "basically",
    "maximum",
    "number",
    "observations",
    "ratings",
    "try",
    "find",
    "average",
    "try",
    "get",
    "hope",
    "fun",
    "guys",
    "clearly",
    "able",
    "understand",
    "next",
    "step",
    "also",
    "see",
    "right",
    "seen",
    "respect",
    "aggregate",
    "rating",
    "rating",
    "count",
    "probably",
    "also",
    "want",
    "use",
    "respect",
    "coloring",
    "part",
    "rating",
    "color",
    "want",
    "plot",
    "count",
    "plot",
    "count",
    "plot",
    "let",
    "plot",
    "going",
    "use",
    "snh",
    "dot",
    "count",
    "plot",
    "basically",
    "going",
    "use",
    "x",
    "equal",
    "rating",
    "color",
    "okay",
    "count",
    "plot",
    "basically",
    "use",
    "plotting",
    "respect",
    "categorical",
    "variables",
    "also",
    "basically",
    "give",
    "x",
    "value",
    "value",
    "giving",
    "x",
    "value",
    "also",
    "going",
    "give",
    "data",
    "ratings",
    "give",
    "palette",
    "list",
    "actually",
    "defined",
    "palette",
    "color",
    "right",
    "reason",
    "going",
    "copy",
    "entirely",
    "paste",
    "execute",
    "able",
    "see",
    "getting",
    "every",
    "time",
    "write",
    "wrong",
    "spelling",
    "see",
    "white",
    "red",
    "orange",
    "yellow",
    "green",
    "dark",
    "green",
    "respect",
    "count",
    "guys",
    "worry",
    "okay",
    "axis",
    "able",
    "see",
    "understand",
    "rating",
    "basically",
    "something",
    "like",
    "right",
    "white",
    "one",
    "record",
    "red",
    "many",
    "records",
    "right",
    "red",
    "around",
    "five",
    "records",
    "orange",
    "around",
    "seven",
    "eight",
    "records",
    "right",
    "yellow",
    "many",
    "records",
    "green",
    "many",
    "records",
    "consider",
    "count",
    "basically",
    "rating",
    "count",
    "frequency",
    "frequently",
    "basically",
    "present",
    "uh",
    "data",
    "frame",
    "let",
    "go",
    "ahead",
    "analysis",
    "depth",
    "get",
    "confused",
    "give",
    "question",
    "please",
    "try",
    "side",
    "okay",
    "find",
    "countries",
    "given",
    "find",
    "countries",
    "country",
    "name",
    "country",
    "country",
    "countries",
    "name",
    "given",
    "zero",
    "rating",
    "one",
    "query",
    "try",
    "wait",
    "wait",
    "let",
    "let",
    "try",
    "something",
    "guys",
    "getting",
    "queries",
    "least",
    "important",
    "interview",
    "question",
    "data",
    "analyst",
    "find",
    "country",
    "name",
    "country",
    "name",
    "given",
    "zero",
    "ratings",
    "please",
    "everybody",
    "waiting",
    "given",
    "zero",
    "rating",
    "definitely",
    "get",
    "confused",
    "data",
    "analyst",
    "come",
    "find",
    "country",
    "names",
    "given",
    "given",
    "zero",
    "rating",
    "also",
    "try",
    "till",
    "final",
    "underscore",
    "df",
    "dot",
    "columns",
    "need",
    "basically",
    "get",
    "country",
    "name",
    "country",
    "name",
    "obviously",
    "okay",
    "given",
    "zero",
    "ratings",
    "zero",
    "rating",
    "probably",
    "identify",
    "zero",
    "ratings",
    "identify",
    "aggregate",
    "rating",
    "also",
    "identify",
    "rating",
    "color",
    "okay",
    "two",
    "parameters",
    "definitely",
    "find",
    "going",
    "going",
    "say",
    "rating",
    "color",
    "let",
    "use",
    "rating",
    "color",
    "rating",
    "color",
    "say",
    "rating",
    "color",
    "equal",
    "white",
    "white",
    "capital",
    "small",
    "white",
    "capital",
    "execute",
    "getting",
    "like",
    "false",
    "false",
    "true",
    "true",
    "write",
    "final",
    "underscore",
    "df",
    "many",
    "information",
    "getting",
    "city",
    "city",
    "many",
    "records",
    "think",
    "right",
    "may",
    "see",
    "different",
    "rating",
    "also",
    "group",
    "specify",
    "country",
    "execute",
    "data",
    "frame",
    "dot",
    "size",
    "dot",
    "reset",
    "index",
    "execute",
    "able",
    "get",
    "brazil",
    "five",
    "different",
    "zero",
    "ratings",
    "given",
    "india",
    "two",
    "one",
    "three",
    "one",
    "three",
    "nine",
    "zero",
    "ratings",
    "given",
    "united",
    "kingdom",
    "one",
    "united",
    "states",
    "three",
    "observations",
    "basically",
    "say",
    "write",
    "observations",
    "observations",
    "right",
    "say",
    "observation",
    "maximum",
    "number",
    "zero",
    "ratings",
    "indian",
    "customers",
    "right",
    "imbalanced",
    "data",
    "set",
    "case",
    "see",
    "data",
    "set",
    "right",
    "two",
    "one",
    "three",
    "nine",
    "zero",
    "ratings",
    "see",
    "total",
    "ratings",
    "much",
    "total",
    "rating",
    "saw",
    "two",
    "one",
    "four",
    "eight",
    "right",
    "try",
    "see",
    "two",
    "one",
    "three",
    "nine",
    "huge",
    "number",
    "getting",
    "used",
    "models",
    "guys",
    "know",
    "need",
    "predict",
    "right",
    "analyzing",
    "data",
    "taking",
    "information",
    "data",
    "okay",
    "next",
    "question",
    "next",
    "question",
    "find",
    "currency",
    "currency",
    "used",
    "country",
    "next",
    "question",
    "probably",
    "go",
    "see",
    "final",
    "underscore",
    "able",
    "see",
    "specific",
    "thing",
    "sorry",
    "dot",
    "columns",
    "write",
    "dot",
    "columns",
    "um",
    "let",
    "say",
    "currency",
    "okay",
    "currency",
    "try",
    "find",
    "currency",
    "used",
    "country",
    "want",
    "list",
    "records",
    "actually",
    "going",
    "going",
    "use",
    "final",
    "underscore",
    "df",
    "two",
    "want",
    "basically",
    "country",
    "respect",
    "currency",
    "actually",
    "going",
    "write",
    "going",
    "basically",
    "say",
    "country",
    "comma",
    "currency",
    "going",
    "basically",
    "use",
    "group",
    "group",
    "based",
    "two",
    "groups",
    "country",
    "currency",
    "dot",
    "size",
    "dot",
    "reset",
    "reset",
    "index",
    "reset",
    "index",
    "used",
    "many",
    "ways",
    "see",
    "actually",
    "getting",
    "australia",
    "dollar",
    "brazil",
    "brazilian",
    "rail",
    "canada",
    "dollars",
    "indian",
    "indian",
    "rupees",
    "um",
    "indonesia",
    "rupay",
    "new",
    "zealand",
    "two",
    "things",
    "one",
    "group",
    "dot",
    "size",
    "dot",
    "reset",
    "index",
    "group",
    "everything",
    "focus",
    "two",
    "records",
    "two",
    "features",
    "one",
    "feature",
    "see",
    "online",
    "delivery",
    "next",
    "question",
    "people",
    "done",
    "next",
    "question",
    "countries",
    "online",
    "deliveries",
    "online",
    "deliveries",
    "option",
    "india",
    "two",
    "four",
    "two",
    "three",
    "uae",
    "two",
    "eight",
    "amazing",
    "nice",
    "basically",
    "means",
    "online",
    "delivery",
    "available",
    "india",
    "us",
    "let",
    "say",
    "want",
    "find",
    "uh",
    "countries",
    "okay",
    "use",
    "code",
    "reset",
    "index",
    "done",
    "basically",
    "used",
    "uh",
    "two",
    "features",
    "online",
    "delivery",
    "country",
    "group",
    "online",
    "delivery",
    "country",
    "size",
    "dot",
    "reset",
    "index",
    "basically",
    "see",
    "australia",
    "brazil",
    "online",
    "delivery",
    "canada",
    "online",
    "delivery",
    "india",
    "come",
    "india",
    "coming",
    "india",
    "getting",
    "repeated",
    "okay",
    "india",
    "also",
    "probably",
    "reasons",
    "online",
    "delivery",
    "may",
    "perfect",
    "india",
    "regions",
    "finding",
    "online",
    "zomato",
    "delivery",
    "available",
    "okay",
    "records",
    "able",
    "see",
    "see",
    "main",
    "two",
    "countries",
    "online",
    "delivery",
    "india",
    "uae",
    "obviously",
    "make",
    "observation",
    "try",
    "find",
    "basically",
    "going",
    "basically",
    "say",
    "observations",
    "observations",
    "basically",
    "say",
    "number",
    "one",
    "first",
    "observation",
    "online",
    "deliveries",
    "available",
    "india",
    "music",
    "done",
    "dhamal",
    "next",
    "question",
    "next",
    "type",
    "actually",
    "focusing",
    "give",
    "one",
    "question",
    "like",
    "respect",
    "countries",
    "respect",
    "country",
    "similarly",
    "try",
    "find",
    "create",
    "pie",
    "chart",
    "cities",
    "distribution",
    "hope",
    "everybody",
    "understanding",
    "question",
    "write",
    "final",
    "underscore",
    "able",
    "see",
    "also",
    "city",
    "want",
    "create",
    "pie",
    "chart",
    "respect",
    "specific",
    "cities",
    "thing",
    "like",
    "country",
    "go",
    "go",
    "copy",
    "two",
    "things",
    "let",
    "see",
    "one",
    "instead",
    "writing",
    "country",
    "write",
    "city",
    "values",
    "index",
    "countries",
    "cities",
    "order",
    "happened",
    "try",
    "draw",
    "plot",
    "pie",
    "plot",
    "okay",
    "say",
    "plt",
    "dot",
    "pi",
    "going",
    "give",
    "two",
    "things",
    "one",
    "respect",
    "values",
    "respect",
    "index",
    "final",
    "underscore",
    "df",
    "hope",
    "works",
    "fine",
    "x",
    "x",
    "basically",
    "given",
    "labels",
    "okay",
    "labels",
    "let",
    "make",
    "little",
    "bit",
    "easy",
    "let",
    "make",
    "easy",
    "okay",
    "city",
    "values",
    "going",
    "save",
    "city",
    "labels",
    "going",
    "save",
    "basically",
    "using",
    "index",
    "executed",
    "go",
    "city",
    "values",
    "entirely",
    "go",
    "respect",
    "city",
    "labels",
    "let",
    "say",
    "want",
    "get",
    "top",
    "five",
    "cities",
    "cities",
    "issue",
    "top",
    "five",
    "city",
    "distribution",
    "top",
    "five",
    "city",
    "distribution",
    "use",
    "colon",
    "five",
    "also",
    "using",
    "colon",
    "try",
    "execute",
    "able",
    "see",
    "first",
    "oh",
    "coming",
    "india",
    "city",
    "labels",
    "dot",
    "dot",
    "city",
    "value",
    "city",
    "labels",
    "music",
    "think",
    "mistake",
    "plot",
    "pie",
    "final",
    "underscore",
    "oh",
    "use",
    "city",
    "mistaken",
    "mistaken",
    "copied",
    "right",
    "copy",
    "paste",
    "lot",
    "copy",
    "paste",
    "new",
    "delhi",
    "maximum",
    "number",
    "transaction",
    "gurgaon",
    "noida",
    "gaziabad",
    "faridabar",
    "bangalore",
    "think",
    "data",
    "set",
    "bangalore",
    "given",
    "also",
    "add",
    "one",
    "auto",
    "percentage",
    "basically",
    "specify",
    "f",
    "go",
    "see",
    "able",
    "see",
    "percentage",
    "maximum",
    "number",
    "transaction",
    "basically",
    "happening",
    "new",
    "delhi",
    "guys",
    "overall",
    "session",
    "everybody",
    "one",
    "assignment",
    "assignment",
    "find",
    "top",
    "10",
    "questions",
    "questions",
    "basically",
    "means",
    "food",
    "okay",
    "put",
    "item",
    "one",
    "assignment",
    "remaining",
    "think",
    "done",
    "data",
    "set",
    "never",
    "used",
    "data",
    "set",
    "machine",
    "learning",
    "modeling",
    "needed",
    "data",
    "set",
    "find",
    "information",
    "capture",
    "finally",
    "able",
    "many",
    "things",
    "right",
    "worry",
    "distribution",
    "part",
    "actually",
    "create",
    "model",
    "respect",
    "data",
    "set",
    "point",
    "time",
    "hope",
    "liked",
    "particular",
    "session",
    "fun",
    "comedy",
    "inten",
    "good",
    "group",
    "cities",
    "rest",
    "yes",
    "obviously",
    "right",
    "tomorrow",
    "another",
    "amazing",
    "day",
    "another",
    "amazing",
    "data",
    "set",
    "working",
    "definitely",
    "able",
    "learn",
    "lot",
    "said",
    "right",
    "visit",
    "website",
    "guys",
    "going",
    "give",
    "entire",
    "materials",
    "seen",
    "website",
    "like",
    "rate",
    "website",
    "guys",
    "created",
    "three",
    "four",
    "hours",
    "probably",
    "also",
    "start",
    "showing",
    "create",
    "websites",
    "entirely",
    "created",
    "three",
    "four",
    "hours",
    "everything",
    "get",
    "updated",
    "article",
    "also",
    "see",
    "live",
    "session",
    "going",
    "right",
    "currently",
    "see",
    "materials",
    "get",
    "uploaded",
    "data",
    "set",
    "materials",
    "please",
    "make",
    "sure",
    "yeah",
    "start",
    "exploring",
    "okay",
    "guys",
    "thank",
    "keep",
    "rocking",
    "see",
    "tomorrow",
    "video",
    "yes",
    "see",
    "tomorrow",
    "session",
    "tomorrow",
    "session",
    "thank",
    "everybody",
    "bye",
    "bye",
    "take",
    "care",
    "thank",
    "guys",
    "hope",
    "everybody",
    "downloaded",
    "data",
    "set",
    "two",
    "data",
    "set",
    "one",
    "test",
    "train",
    "right",
    "talk",
    "problem",
    "statement",
    "today",
    "also",
    "going",
    "feature",
    "engineering",
    "things",
    "right",
    "usual",
    "today",
    "going",
    "black",
    "friday",
    "data",
    "set",
    "talk",
    "agenda",
    "everything",
    "eda",
    "feature",
    "engineering",
    "going",
    "keep",
    "model",
    "ready",
    "model",
    "training",
    "ready",
    "means",
    "cleaning",
    "everything",
    "cleaning",
    "music",
    "preparing",
    "data",
    "model",
    "training",
    "going",
    "today",
    "two",
    "things",
    "going",
    "agenda",
    "basically",
    "use",
    "kind",
    "model",
    "start",
    "working",
    "quickly",
    "basic",
    "library",
    "required",
    "start",
    "uploading",
    "write",
    "import",
    "pandas",
    "pd",
    "talk",
    "problem",
    "statement",
    "exactly",
    "import",
    "numpy",
    "np",
    "import",
    "matplot",
    "lib",
    "dot",
    "pi",
    "plot",
    "plt",
    "import",
    "c",
    "bond",
    "sns",
    "matplotlib",
    "dot",
    "pi",
    "plot",
    "plt",
    "yeah",
    "sorry",
    "line",
    "basically",
    "given",
    "kaggle",
    "okay",
    "kaggle",
    "whenever",
    "get",
    "specific",
    "data",
    "set",
    "train",
    "test",
    "steps",
    "show",
    "also",
    "participate",
    "kaggle",
    "let",
    "go",
    "ahead",
    "let",
    "go",
    "ahead",
    "first",
    "importing",
    "data",
    "site",
    "always",
    "make",
    "sure",
    "write",
    "comment",
    "importing",
    "data",
    "set",
    "data",
    "set",
    "already",
    "given",
    "let",
    "say",
    "going",
    "name",
    "df",
    "train",
    "two",
    "data",
    "set",
    "one",
    "train",
    "one",
    "test",
    "data",
    "df",
    "train",
    "going",
    "write",
    "pd",
    "dot",
    "read",
    "csv",
    "going",
    "give",
    "data",
    "set",
    "name",
    "black",
    "friday",
    "train",
    "dot",
    "underscore",
    "train",
    "dot",
    "csv",
    "renamed",
    "name",
    "guys",
    "train",
    "dot",
    "csv",
    "okay",
    "probably",
    "write",
    "df",
    "underscore",
    "train",
    "dot",
    "shape",
    "able",
    "see",
    "write",
    "able",
    "see",
    "talk",
    "data",
    "data",
    "basically",
    "uh",
    "data",
    "data",
    "people",
    "bought",
    "kind",
    "products",
    "based",
    "need",
    "predict",
    "purchase",
    "capacity",
    "understand",
    "going",
    "basically",
    "talk",
    "problem",
    "statement",
    "want",
    "build",
    "model",
    "going",
    "put",
    "problem",
    "statement",
    "let",
    "say",
    "going",
    "put",
    "problem",
    "statement",
    "everybody",
    "read",
    "problem",
    "statement",
    "anyhow",
    "giving",
    "things",
    "materials",
    "everything",
    "github",
    "worry",
    "also",
    "put",
    "data",
    "set",
    "link",
    "data",
    "set",
    "link",
    "data",
    "set",
    "link",
    "data",
    "set",
    "link",
    "get",
    "saved",
    "problem",
    "statement",
    "problem",
    "statement",
    "going",
    "focus",
    "problem",
    "statement",
    "retail",
    "company",
    "abc",
    "private",
    "limited",
    "wants",
    "understand",
    "customer",
    "purchase",
    "behavior",
    "data",
    "set",
    "data",
    "set",
    "also",
    "huge",
    "good",
    "work",
    "various",
    "products",
    "different",
    "categories",
    "shared",
    "purchase",
    "summary",
    "various",
    "customers",
    "selected",
    "high",
    "volume",
    "products",
    "last",
    "month",
    "data",
    "set",
    "also",
    "contains",
    "customer",
    "demographics",
    "like",
    "age",
    "gender",
    "marital",
    "status",
    "city",
    "type",
    "stay",
    "current",
    "city",
    "product",
    "details",
    "product",
    "id",
    "product",
    "category",
    "total",
    "purchase",
    "amount",
    "last",
    "month",
    "want",
    "build",
    "want",
    "build",
    "model",
    "predict",
    "purchase",
    "amount",
    "customer",
    "various",
    "product",
    "help",
    "create",
    "personalized",
    "offer",
    "customer",
    "different",
    "products",
    "problem",
    "statement",
    "problem",
    "statement",
    "simple",
    "need",
    "create",
    "model",
    "predict",
    "purchase",
    "amount",
    "customer",
    "various",
    "products",
    "right",
    "suppose",
    "give",
    "information",
    "like",
    "product",
    "product",
    "information",
    "things",
    "give",
    "create",
    "model",
    "able",
    "predict",
    "purchasing",
    "capacity",
    "right",
    "entire",
    "information",
    "regarding",
    "problem",
    "statement",
    "okay",
    "going",
    "interesting",
    "solve",
    "problem",
    "front",
    "read",
    "training",
    "data",
    "set",
    "next",
    "step",
    "basically",
    "start",
    "reading",
    "test",
    "data",
    "set",
    "train",
    "data",
    "set",
    "test",
    "data",
    "set",
    "see",
    "whenever",
    "given",
    "train",
    "test",
    "obviously",
    "initially",
    "combine",
    "kaggle",
    "computation",
    "always",
    "remember",
    "combine",
    "data",
    "perform",
    "data",
    "set",
    "going",
    "import",
    "test",
    "data",
    "right",
    "going",
    "say",
    "df",
    "underscore",
    "test",
    "equal",
    "pd",
    "dot",
    "read",
    "underscore",
    "csv",
    "going",
    "basically",
    "write",
    "black",
    "friday",
    "dot",
    "csv",
    "df",
    "underscore",
    "test",
    "dot",
    "head",
    "test",
    "data",
    "able",
    "find",
    "output",
    "variable",
    "variable",
    "see",
    "take",
    "product",
    "category",
    "3",
    "additional",
    "purchase",
    "column",
    "right",
    "want",
    "combine",
    "train",
    "test",
    "data",
    "next",
    "statement",
    "merge",
    "train",
    "test",
    "data",
    "merge",
    "train",
    "test",
    "data",
    "use",
    "pandas",
    "dot",
    "merge",
    "use",
    "panda",
    "append",
    "want",
    "use",
    "let",
    "try",
    "different",
    "way",
    "basically",
    "going",
    "say",
    "df1",
    "dot",
    "append",
    "append",
    "function",
    "sorry",
    "df",
    "underscore",
    "train",
    "dot",
    "append",
    "df",
    "underscore",
    "test",
    "append",
    "basically",
    "see",
    "definition",
    "append",
    "rows",
    "end",
    "caller",
    "returning",
    "new",
    "object",
    "right",
    "going",
    "also",
    "one",
    "parameter",
    "see",
    "respect",
    "sort",
    "sort",
    "default",
    "false",
    "right",
    "going",
    "execute",
    "basically",
    "going",
    "store",
    "inside",
    "df",
    "df",
    "dot",
    "head",
    "also",
    "append",
    "different",
    "different",
    "ways",
    "problem",
    "okay",
    "first",
    "step",
    "actually",
    "merge",
    "also",
    "understand",
    "append",
    "bottom",
    "right",
    "merging",
    "like",
    "merge",
    "want",
    "words",
    "possible",
    "merge",
    "try",
    "instead",
    "writing",
    "merge",
    "could",
    "also",
    "add",
    "written",
    "append",
    "merge",
    "also",
    "okay",
    "next",
    "step",
    "let",
    "go",
    "next",
    "step",
    "everybody",
    "basic",
    "basic",
    "code",
    "seen",
    "already",
    "right",
    "one",
    "check",
    "one",
    "understand",
    "many",
    "different",
    "types",
    "features",
    "obviously",
    "int",
    "object",
    "object",
    "object",
    "int",
    "object",
    "intent",
    "float",
    "float",
    "float",
    "definitely",
    "see",
    "product",
    "id",
    "combination",
    "integer",
    "different",
    "values",
    "basically",
    "object",
    "gender",
    "obviously",
    "male",
    "females",
    "categories",
    "object",
    "age",
    "basically",
    "object",
    "age",
    "object",
    "able",
    "see",
    "age",
    "given",
    "range",
    "0",
    "17",
    "0",
    "17",
    "55",
    "plus",
    "consider",
    "categorical",
    "variables",
    "also",
    "show",
    "solve",
    "particular",
    "problem",
    "also",
    "hope",
    "everybody",
    "got",
    "understanding",
    "till",
    "next",
    "statement",
    "going",
    "basically",
    "find",
    "something",
    "called",
    "find",
    "like",
    "percentile",
    "values",
    "basic",
    "information",
    "going",
    "differ",
    "tell",
    "um",
    "column",
    "think",
    "waste",
    "directly",
    "blindly",
    "delete",
    "see",
    "column",
    "called",
    "user",
    "id",
    "user",
    "id",
    "unique",
    "id",
    "definitely",
    "go",
    "ahead",
    "delete",
    "okay",
    "user",
    "id",
    "use",
    "product",
    "category",
    "everything",
    "getting",
    "used",
    "worry",
    "user",
    "id",
    "definitely",
    "useful",
    "going",
    "delete",
    "actually",
    "going",
    "going",
    "basically",
    "write",
    "statement",
    "basically",
    "use",
    "drop",
    "feature",
    "give",
    "number",
    "features",
    "number",
    "features",
    "respect",
    "feature",
    "name",
    "feature",
    "name",
    "nothing",
    "user",
    "underscore",
    "id",
    "going",
    "copy",
    "paste",
    "user",
    "underscore",
    "id",
    "one",
    "much",
    "important",
    "parameter",
    "see",
    "access",
    "access",
    "equal",
    "0",
    "basically",
    "means",
    "horizontally",
    "right",
    "row",
    "wise",
    "access",
    "equal",
    "1",
    "basically",
    "means",
    "vertically",
    "right",
    "column",
    "wise",
    "really",
    "need",
    "drop",
    "column",
    "wise",
    "going",
    "basically",
    "say",
    "access",
    "equal",
    "1",
    "going",
    "specify",
    "place",
    "equal",
    "true",
    "place",
    "equal",
    "true",
    "remove",
    "user",
    "id",
    "update",
    "automatically",
    "df",
    "value",
    "go",
    "probably",
    "execute",
    "go",
    "ahead",
    "see",
    "able",
    "see",
    "actually",
    "able",
    "see",
    "product",
    "id",
    "gender",
    "information",
    "perfect",
    "basically",
    "done",
    "dropped",
    "user",
    "id",
    "everything",
    "ready",
    "let",
    "go",
    "ahead",
    "towards",
    "data",
    "preprocessing",
    "side",
    "tell",
    "many",
    "categorical",
    "variables",
    "many",
    "categorical",
    "variables",
    "seeing",
    "one",
    "gender",
    "one",
    "age",
    "one",
    "occupation",
    "city",
    "stay",
    "current",
    "city",
    "also",
    "need",
    "make",
    "sure",
    "many",
    "number",
    "missing",
    "values",
    "missing",
    "values",
    "may",
    "something",
    "show",
    "later",
    "stages",
    "let",
    "focus",
    "fixing",
    "categorical",
    "features",
    "right",
    "many",
    "category",
    "features",
    "see",
    "gender",
    "age",
    "city",
    "category",
    "also",
    "try",
    "fix",
    "category",
    "features",
    "model",
    "definitely",
    "able",
    "understand",
    "uh",
    "categorical",
    "features",
    "marital",
    "status",
    "already",
    "numbers",
    "let",
    "see",
    "things",
    "basically",
    "let",
    "us",
    "go",
    "ahead",
    "take",
    "age",
    "try",
    "solve",
    "convert",
    "categorical",
    "category",
    "numerical",
    "try",
    "okay",
    "first",
    "let",
    "focus",
    "let",
    "go",
    "ahead",
    "tell",
    "respect",
    "gender",
    "male",
    "female",
    "right",
    "respect",
    "gender",
    "male",
    "female",
    "order",
    "probably",
    "male",
    "female",
    "kind",
    "encoding",
    "definitely",
    "use",
    "write",
    "pd",
    "dot",
    "get",
    "underscore",
    "dummies",
    "give",
    "df",
    "gender",
    "execute",
    "able",
    "get",
    "either",
    "male",
    "female",
    "actually",
    "getting",
    "ones",
    "zeros",
    "right",
    "one",
    "basically",
    "given",
    "f",
    "zero",
    "basically",
    "given",
    "male",
    "okay",
    "either",
    "way",
    "see",
    "problem",
    "convert",
    "way",
    "create",
    "another",
    "data",
    "frame",
    "add",
    "data",
    "frame",
    "delete",
    "gender",
    "column",
    "something",
    "within",
    "data",
    "set",
    "probably",
    "directly",
    "convert",
    "wherever",
    "f",
    "zero",
    "sorry",
    "wherever",
    "gender",
    "f",
    "going",
    "convert",
    "0",
    "1",
    "whether",
    "whether",
    "gender",
    "male",
    "going",
    "convert",
    "0",
    "going",
    "guys",
    "going",
    "yes",
    "definitely",
    "use",
    "drop",
    "drop",
    "underscore",
    "first",
    "equal",
    "1",
    "definitely",
    "use",
    "understand",
    "want",
    "way",
    "save",
    "somewhere",
    "add",
    "column",
    "want",
    "way",
    "want",
    "find",
    "want",
    "find",
    "way",
    "directly",
    "particular",
    "data",
    "frame",
    "using",
    "code",
    "simple",
    "code",
    "write",
    "df",
    "gender",
    "say",
    "df",
    "gender",
    "dot",
    "map",
    "map",
    "method",
    "see",
    "map",
    "method",
    "map",
    "method",
    "basically",
    "map",
    "respect",
    "conditions",
    "giving",
    "say",
    "first",
    "condition",
    "wherever",
    "get",
    "female",
    "going",
    "convert",
    "0",
    "wherever",
    "get",
    "male",
    "going",
    "convert",
    "one",
    "many",
    "people",
    "ask",
    "teaching",
    "map",
    "functionality",
    "python",
    "see",
    "easily",
    "within",
    "particular",
    "data",
    "set",
    "able",
    "see",
    "write",
    "df",
    "dot",
    "head",
    "probably",
    "see",
    "able",
    "see",
    "gender",
    "zeros",
    "ones",
    "everybody",
    "write",
    "code",
    "okay",
    "one",
    "way",
    "directly",
    "assign",
    "df",
    "df",
    "gender",
    "right",
    "way",
    "also",
    "ways",
    "whichever",
    "way",
    "feel",
    "want",
    "ways",
    "work",
    "ranking",
    "guys",
    "zeros",
    "ones",
    "ranking",
    "one",
    "two",
    "three",
    "four",
    "five",
    "six",
    "basically",
    "ranking",
    "uh",
    "zahida",
    "sen",
    "says",
    "apply",
    "feature",
    "engineering",
    "training",
    "set",
    "touch",
    "data",
    "apply",
    "show",
    "apply",
    "okay",
    "perfect",
    "everybody",
    "done",
    "right",
    "respect",
    "handling",
    "categorical",
    "feature",
    "handling",
    "categorical",
    "feature",
    "age",
    "sorry",
    "gender",
    "done",
    "let",
    "go",
    "next",
    "step",
    "next",
    "step",
    "actually",
    "going",
    "gender",
    "done",
    "also",
    "need",
    "handle",
    "age",
    "handle",
    "categorical",
    "feature",
    "age",
    "specifically",
    "saying",
    "age",
    "go",
    "see",
    "age",
    "age",
    "also",
    "categorical",
    "feature",
    "see",
    "0",
    "17",
    "0",
    "17",
    "55",
    "plus",
    "first",
    "thing",
    "try",
    "execute",
    "something",
    "like",
    "write",
    "df",
    "h",
    "dot",
    "uni",
    "basically",
    "give",
    "many",
    "unique",
    "values",
    "age",
    "like",
    "0",
    "17",
    "55",
    "plus",
    "26",
    "35",
    "46",
    "50",
    "51",
    "55",
    "36",
    "45",
    "18",
    "25",
    "particular",
    "unique",
    "way",
    "tell",
    "convert",
    "categorical",
    "feature",
    "numerical",
    "features",
    "also",
    "actually",
    "encoding",
    "type",
    "encoding",
    "probably",
    "many",
    "people",
    "get",
    "confused",
    "like",
    "tell",
    "also",
    "going",
    "use",
    "assign",
    "df",
    "age",
    "right",
    "two",
    "things",
    "definitely",
    "one",
    "directly",
    "get",
    "dummies",
    "directly",
    "see",
    "write",
    "pd",
    "dot",
    "get",
    "underscore",
    "dummies",
    "right",
    "give",
    "df",
    "age",
    "able",
    "get",
    "like",
    "right",
    "drop",
    "drop",
    "first",
    "equal",
    "true",
    "able",
    "get",
    "like",
    "save",
    "column",
    "name",
    "put",
    "inside",
    "data",
    "frame",
    "okay",
    "imagine",
    "something",
    "guys",
    "domain",
    "knowledge",
    "definitely",
    "come",
    "one",
    "important",
    "thing",
    "think",
    "like",
    "shopping",
    "0",
    "17",
    "years",
    "less",
    "right",
    "website",
    "less",
    "right",
    "whereas",
    "say",
    "26",
    "35",
    "may",
    "say",
    "18",
    "25",
    "may",
    "15",
    "55",
    "may",
    "55",
    "plus",
    "may",
    "less",
    "right",
    "46",
    "50",
    "may",
    "also",
    "less",
    "try",
    "convert",
    "dummies",
    "let",
    "ordinal",
    "encoding",
    "let",
    "let",
    "give",
    "rank",
    "okay",
    "let",
    "let",
    "give",
    "directly",
    "values",
    "like",
    "0",
    "1",
    "2",
    "3",
    "4",
    "5",
    "saying",
    "give",
    "0",
    "1",
    "2",
    "3",
    "4",
    "5",
    "training",
    "model",
    "model",
    "maths",
    "definitely",
    "able",
    "understand",
    "right",
    "model",
    "maths",
    "definitely",
    "able",
    "understand",
    "respect",
    "values",
    "given",
    "like",
    "zero",
    "one",
    "two",
    "three",
    "four",
    "five",
    "whatever",
    "values",
    "actually",
    "given",
    "respect",
    "features",
    "model",
    "definitely",
    "able",
    "understand",
    "also",
    "called",
    "target",
    "guiding",
    "something",
    "like",
    "okay",
    "definitely",
    "work",
    "good",
    "practice",
    "also",
    "going",
    "comment",
    "definitely",
    "work",
    "instead",
    "actually",
    "give",
    "say",
    "uh",
    "let",
    "apply",
    "map",
    "function",
    "applied",
    "going",
    "basically",
    "give",
    "way",
    "map",
    "function",
    "going",
    "basically",
    "put",
    "inside",
    "definitely",
    "say",
    "age",
    "h",
    "mapping",
    "0",
    "17",
    "first",
    "let",
    "say",
    "0",
    "17",
    "actually",
    "giving",
    "numbers",
    "let",
    "say",
    "giving",
    "1",
    "least",
    "value",
    "18",
    "25",
    "sorted",
    "order",
    "try",
    "give",
    "18",
    "25",
    "second",
    "one",
    "give",
    "h2",
    "third",
    "one",
    "sorted",
    "order",
    "26",
    "35",
    "give",
    "see",
    "model",
    "training",
    "model",
    "able",
    "understand",
    "called",
    "target",
    "guiding",
    "target",
    "ordinal",
    "encoding",
    "36",
    "45",
    "hope",
    "right",
    "colon",
    "actually",
    "going",
    "give",
    "36",
    "45",
    "46",
    "50",
    "46",
    "50",
    "5",
    "writing",
    "51",
    "55",
    "say",
    "6",
    "55",
    "say",
    "seven",
    "label",
    "encoding",
    "also",
    "done",
    "label",
    "encoding",
    "also",
    "work",
    "perfect",
    "label",
    "encoding",
    "also",
    "work",
    "understand",
    "label",
    "encoding",
    "import",
    "library",
    "perform",
    "also",
    "way",
    "become",
    "good",
    "maths",
    "put",
    "zero",
    "guys",
    "see",
    "said",
    "saying",
    "right",
    "mathematical",
    "equations",
    "happening",
    "want",
    "label",
    "encoding",
    "label",
    "encoding",
    "python",
    "let",
    "see",
    "articles",
    "uh",
    "article",
    "geeksforgreek",
    "music",
    "let",
    "see",
    "basically",
    "upload",
    "entire",
    "thing",
    "right",
    "entire",
    "code",
    "see",
    "entire",
    "code",
    "using",
    "label",
    "encoder",
    "want",
    "get",
    "new",
    "data",
    "set",
    "also",
    "able",
    "apply",
    "things",
    "right",
    "copy",
    "sklearn",
    "see",
    "right",
    "basically",
    "respect",
    "df",
    "dot",
    "age",
    "execute",
    "automatically",
    "work",
    "hesitate",
    "google",
    "right",
    "also",
    "way",
    "second",
    "technique",
    "already",
    "done",
    "probably",
    "go",
    "see",
    "df",
    "dot",
    "head",
    "able",
    "see",
    "age",
    "also",
    "okay",
    "executed",
    "data",
    "executed",
    "go",
    "see",
    "able",
    "see",
    "one",
    "two",
    "three",
    "four",
    "like",
    "able",
    "see",
    "see",
    "hundred",
    "ways",
    "label",
    "encoder",
    "fit",
    "transform",
    "test",
    "data",
    "transform",
    "actually",
    "combined",
    "good",
    "practice",
    "case",
    "suppose",
    "trained",
    "data",
    "touch",
    "data",
    "transform",
    "need",
    "give",
    "weightage",
    "guys",
    "arvinds",
    "see",
    "machine",
    "learning",
    "model",
    "automatically",
    "understand",
    "one",
    "category",
    "actually",
    "actually",
    "seen",
    "something",
    "called",
    "city",
    "categories",
    "see",
    "oh",
    "yes",
    "city",
    "category",
    "also",
    "use",
    "pd",
    "dot",
    "get",
    "dummies",
    "want",
    "pd",
    "dot",
    "get",
    "dummies",
    "basically",
    "combine",
    "order",
    "also",
    "basically",
    "say",
    "pd",
    "dot",
    "get",
    "dummies",
    "basically",
    "going",
    "give",
    "df",
    "city",
    "name",
    "city",
    "category",
    "fixing",
    "categorical",
    "categorical",
    "city",
    "underscore",
    "category",
    "dot",
    "get",
    "dummies",
    "df",
    "city",
    "category",
    "going",
    "basically",
    "say",
    "drop",
    "first",
    "equal",
    "true",
    "values",
    "going",
    "save",
    "one",
    "variable",
    "going",
    "say",
    "df",
    "underscore",
    "city",
    "let",
    "say",
    "df",
    "underscore",
    "city",
    "one",
    "dot",
    "head",
    "combine",
    "entire",
    "cities",
    "df",
    "okay",
    "actually",
    "shown",
    "hope",
    "everybody",
    "done",
    "till",
    "two",
    "features",
    "get",
    "compiled",
    "data",
    "set",
    "order",
    "get",
    "combined",
    "particular",
    "data",
    "set",
    "write",
    "say",
    "basically",
    "going",
    "give",
    "df",
    "df",
    "underscore",
    "city",
    "concatenation",
    "also",
    "give",
    "axis",
    "value",
    "1",
    "save",
    "df",
    "basically",
    "go",
    "probably",
    "last",
    "year",
    "able",
    "see",
    "b",
    "c",
    "require",
    "city",
    "category",
    "drop",
    "city",
    "category",
    "hope",
    "everybody",
    "able",
    "understand",
    "drop",
    "underscore",
    "first",
    "equal",
    "true",
    "always",
    "understand",
    "three",
    "categories",
    "two",
    "categories",
    "sufficient",
    "represent",
    "three",
    "categories",
    "let",
    "go",
    "next",
    "step",
    "let",
    "quickly",
    "drop",
    "drop",
    "going",
    "write",
    "drop",
    "city",
    "category",
    "require",
    "feature",
    "right",
    "require",
    "feature",
    "city",
    "category",
    "right",
    "going",
    "going",
    "basically",
    "say",
    "uh",
    "category",
    "name",
    "city",
    "category",
    "understand",
    "access",
    "one",
    "error",
    "found",
    "access",
    "okay",
    "city",
    "underscore",
    "category",
    "guys",
    "understand",
    "new",
    "data",
    "come",
    "follow",
    "entire",
    "thing",
    "okay",
    "entire",
    "steps",
    "follow",
    "whatever",
    "things",
    "actually",
    "done",
    "encoding",
    "everything",
    "done",
    "see",
    "df",
    "dot",
    "drop",
    "city",
    "category",
    "axis",
    "equal",
    "1",
    "particular",
    "feature",
    "gone",
    "actually",
    "going",
    "make",
    "operation",
    "permanently",
    "going",
    "use",
    "place",
    "equal",
    "true",
    "go",
    "probably",
    "check",
    "entirely",
    "bc",
    "fixed",
    "things",
    "still",
    "done",
    "better",
    "work",
    "till",
    "let",
    "go",
    "check",
    "missing",
    "values",
    "missing",
    "values",
    "city",
    "category",
    "category",
    "feature",
    "uh",
    "pt",
    "category",
    "one",
    "another",
    "age",
    "one",
    "uh",
    "gender",
    "three",
    "categories",
    "fixed",
    "axis",
    "equal",
    "one",
    "basically",
    "means",
    "column",
    "wise",
    "adding",
    "appending",
    "specific",
    "data",
    "frame",
    "axis",
    "equal",
    "one",
    "basically",
    "means",
    "deleting",
    "column",
    "guys",
    "told",
    "eda",
    "basics",
    "prerequisite",
    "need",
    "know",
    "python",
    "need",
    "know",
    "basic",
    "things",
    "knowing",
    "difficult",
    "respect",
    "diff",
    "uh",
    "df",
    "dot",
    "null",
    "missing",
    "values",
    "actually",
    "going",
    "going",
    "sum",
    "df",
    "dot",
    "null",
    "dot",
    "sum",
    "also",
    "function",
    "see",
    "product",
    "category",
    "many",
    "null",
    "values",
    "purchase",
    "also",
    "many",
    "null",
    "values",
    "product",
    "category",
    "2",
    "many",
    "null",
    "values",
    "product",
    "category",
    "3",
    "many",
    "null",
    "values",
    "purchase",
    "many",
    "null",
    "values",
    "amazing",
    "whenever",
    "null",
    "values",
    "people",
    "get",
    "shocked",
    "everybody",
    "get",
    "shocked",
    "okay",
    "categories",
    "replace",
    "categories",
    "something",
    "tell",
    "purchase",
    "null",
    "test",
    "data",
    "null",
    "values",
    "present",
    "test",
    "data",
    "null",
    "two",
    "definitely",
    "fix",
    "right",
    "two",
    "definitely",
    "fix",
    "actually",
    "going",
    "focus",
    "focus",
    "replacing",
    "missing",
    "values",
    "focus",
    "replacing",
    "missing",
    "values",
    "focus",
    "replacing",
    "missing",
    "values",
    "going",
    "going",
    "basically",
    "replace",
    "missing",
    "values",
    "two",
    "feature",
    "kind",
    "data",
    "exploration",
    "two",
    "features",
    "actually",
    "going",
    "going",
    "basically",
    "write",
    "df",
    "dot",
    "product",
    "category",
    "tell",
    "guys",
    "write",
    "dot",
    "unique",
    "tell",
    "kind",
    "feature",
    "becomes",
    "kind",
    "features",
    "becomes",
    "write",
    "dot",
    "underscore",
    "door",
    "kind",
    "features",
    "become",
    "become",
    "discrete",
    "feature",
    "discrete",
    "categorical",
    "discrete",
    "continuous",
    "feature",
    "whether",
    "become",
    "continuous",
    "feature",
    "become",
    "discrete",
    "feature",
    "guys",
    "see",
    "discrete",
    "getting",
    "repeated",
    "get",
    "repeated",
    "people",
    "attended",
    "start",
    "session",
    "definitely",
    "know",
    "right",
    "definitely",
    "focusing",
    "knowing",
    "entire",
    "thing",
    "okay",
    "specifically",
    "see",
    "discrete",
    "feature",
    "okay",
    "entirely",
    "discrete",
    "feature",
    "discrete",
    "feature",
    "nand",
    "value",
    "best",
    "way",
    "replace",
    "missing",
    "values",
    "tell",
    "quickly",
    "lot",
    "discussions",
    "needs",
    "done",
    "tell",
    "better",
    "way",
    "replace",
    "missing",
    "values",
    "also",
    "make",
    "work",
    "little",
    "bit",
    "easy",
    "also",
    "write",
    "product",
    "category",
    "2",
    "say",
    "value",
    "counts",
    "value",
    "counts",
    "basically",
    "give",
    "values",
    "present",
    "respect",
    "okay",
    "value",
    "underscore",
    "counts",
    "see",
    "eight",
    "basically",
    "many",
    "values",
    "four",
    "basically",
    "many",
    "records",
    "six",
    "many",
    "records",
    "think",
    "want",
    "replace",
    "nand",
    "values",
    "best",
    "way",
    "replace",
    "feature",
    "respect",
    "categorical",
    "features",
    "discrete",
    "feature",
    "best",
    "way",
    "replace",
    "missing",
    "value",
    "missing",
    "value",
    "mode",
    "order",
    "replace",
    "missing",
    "value",
    "mode",
    "okay",
    "mean",
    "use",
    "mean",
    "guys",
    "mean",
    "create",
    "new",
    "category",
    "altogether",
    "order",
    "replace",
    "mode",
    "much",
    "simple",
    "let",
    "know",
    "replace",
    "mode",
    "tell",
    "guys",
    "first",
    "write",
    "simple",
    "code",
    "say",
    "df",
    "product",
    "product",
    "product",
    "category",
    "two",
    "okay",
    "please",
    "think",
    "try",
    "write",
    "code",
    "guys",
    "okay",
    "definitely",
    "use",
    "something",
    "called",
    "fill",
    "name",
    "fill",
    "function",
    "already",
    "also",
    "mentioned",
    "explained",
    "lot",
    "lectures",
    "say",
    "dot",
    "fill",
    "n",
    "basically",
    "going",
    "say",
    "df",
    "product",
    "category",
    "dot",
    "mode",
    "right",
    "see",
    "basically",
    "copy",
    "entire",
    "thing",
    "okay",
    "write",
    "df",
    "product",
    "category",
    "dot",
    "mode",
    "output",
    "get",
    "get",
    "2",
    "output",
    "want",
    "find",
    "mode",
    "basically",
    "write",
    "something",
    "like",
    "right",
    "getting",
    "two",
    "values",
    "one",
    "zero",
    "one",
    "eight",
    "point",
    "zero",
    "becomes",
    "series",
    "order",
    "pick",
    "value",
    "basically",
    "use",
    "indexing",
    "use",
    "getting",
    "okay",
    "going",
    "going",
    "basically",
    "copy",
    "entire",
    "thing",
    "dot",
    "mode",
    "get",
    "reflected",
    "probably",
    "write",
    "df",
    "product",
    "category",
    "2",
    "dot",
    "null",
    "dot",
    "sum",
    "see",
    "values",
    "0",
    "basically",
    "means",
    "replacement",
    "happened",
    "clear",
    "interesting",
    "problem",
    "data",
    "set",
    "also",
    "quite",
    "huge",
    "similarly",
    "product",
    "category",
    "3",
    "54",
    "000",
    "okay",
    "also",
    "product",
    "category",
    "okay",
    "product",
    "product",
    "category",
    "3",
    "category",
    "3",
    "replace",
    "missing",
    "values",
    "going",
    "paste",
    "going",
    "write",
    "dot",
    "three",
    "underscore",
    "three",
    "dot",
    "unique",
    "also",
    "see",
    "1417",
    "want",
    "also",
    "want",
    "see",
    "value",
    "counts",
    "basically",
    "write",
    "dot",
    "value",
    "counts",
    "dot",
    "value",
    "counts",
    "values",
    "respect",
    "particular",
    "value",
    "counts",
    "okay",
    "let",
    "go",
    "ahead",
    "replace",
    "replace",
    "missing",
    "values",
    "modes",
    "going",
    "going",
    "copy",
    "please",
    "playing",
    "missing",
    "value",
    "okay",
    "going",
    "use",
    "product",
    "category",
    "3",
    "execute",
    "go",
    "probably",
    "see",
    "okay",
    "everything",
    "product",
    "categories",
    "three",
    "fixed",
    "remove",
    "product",
    "categories",
    "reason",
    "go",
    "see",
    "df",
    "dot",
    "shape",
    "around",
    "7",
    "lakh",
    "83",
    "000",
    "records",
    "around",
    "5",
    "lakhs",
    "records",
    "basically",
    "missing",
    "see",
    "five",
    "lakhs",
    "two",
    "lakhs",
    "drop",
    "okay",
    "probably",
    "may",
    "important",
    "information",
    "said",
    "purchase",
    "column",
    "missing",
    "values",
    "fine",
    "test",
    "data",
    "train",
    "test",
    "split",
    "random",
    "titration",
    "random",
    "cross",
    "validation",
    "let",
    "go",
    "next",
    "step",
    "anything",
    "left",
    "one",
    "category",
    "one",
    "right",
    "stay",
    "current",
    "years",
    "think",
    "say",
    "hashtag",
    "stay",
    "current",
    "years",
    "right",
    "stay",
    "current",
    "city",
    "years",
    "write",
    "df",
    "state",
    "current",
    "city",
    "yes",
    "write",
    "dot",
    "unique",
    "2",
    "4",
    "plus",
    "3",
    "1",
    "0",
    "okay",
    "actually",
    "also",
    "consider",
    "4",
    "right",
    "anyhow",
    "4",
    "plus",
    "also",
    "treated",
    "4",
    "treated",
    "4",
    "value",
    "also",
    "increasing",
    "fine",
    "right",
    "replace",
    "4",
    "plus",
    "tell",
    "write",
    "tf",
    "stay",
    "current",
    "years",
    "dot",
    "htr",
    "dot",
    "replace",
    "actually",
    "going",
    "replace",
    "plus",
    "blank",
    "right",
    "probably",
    "able",
    "find",
    "things",
    "right",
    "entirely",
    "save",
    "inside",
    "df",
    "dot",
    "stay",
    "current",
    "execute",
    "done",
    "warning",
    "okay",
    "see",
    "four",
    "plus",
    "fixed",
    "another",
    "category",
    "categories",
    "today",
    "focusing",
    "solving",
    "categories",
    "let",
    "one",
    "thing",
    "okay",
    "even",
    "though",
    "basically",
    "checking",
    "categories",
    "basically",
    "checking",
    "things",
    "right",
    "probably",
    "go",
    "write",
    "seeing",
    "product",
    "id",
    "object",
    "fine",
    "gender",
    "integer",
    "fine",
    "age",
    "integer",
    "occupation",
    "integer",
    "stay",
    "current",
    "city",
    "years",
    "also",
    "object",
    "see",
    "values",
    "like",
    "2",
    "2",
    "4",
    "4",
    "need",
    "convert",
    "object",
    "integers",
    "major",
    "step",
    "actually",
    "actually",
    "going",
    "convert",
    "object",
    "integers",
    "convert",
    "kind",
    "task",
    "also",
    "may",
    "getting",
    "convert",
    "object",
    "integers",
    "quick",
    "anybody",
    "tell",
    "simple",
    "going",
    "write",
    "df",
    "stay",
    "current",
    "city",
    "years",
    "equal",
    "df",
    "stay",
    "current",
    "city",
    "years",
    "dot",
    "type",
    "type",
    "integer",
    "done",
    "write",
    "df",
    "dot",
    "head",
    "df",
    "dot",
    "info",
    "able",
    "see",
    "see",
    "stain",
    "current",
    "basically",
    "assigned",
    "32",
    "also",
    "assign",
    "64",
    "providing",
    "64",
    "directly",
    "okay",
    "two",
    "columns",
    "b",
    "c",
    "u",
    "u",
    "int",
    "8",
    "q",
    "intake",
    "u",
    "intent",
    "u",
    "int",
    "8",
    "8",
    "bit",
    "assigned",
    "integer",
    "ranging",
    "0",
    "255",
    "decimals",
    "okay",
    "also",
    "convert",
    "type",
    "want",
    "convert",
    "type",
    "use",
    "two",
    "quotes",
    "say",
    "b",
    "c",
    "right",
    "df",
    "b",
    "equal",
    "df",
    "b",
    "dot",
    "type",
    "int",
    "thing",
    "copy",
    "paste",
    "dfr",
    "c",
    "hello",
    "execute",
    "go",
    "probably",
    "see",
    "able",
    "see",
    "done",
    "best",
    "visualization",
    "feel",
    "visualization",
    "present",
    "cbot",
    "called",
    "sns",
    "dot",
    "pair",
    "plot",
    "give",
    "pair",
    "plot",
    "give",
    "df",
    "see",
    "amazing",
    "diagram",
    "take",
    "lot",
    "time",
    "many",
    "data",
    "points",
    "along",
    "many",
    "data",
    "sets",
    "okay",
    "giving",
    "error",
    "let",
    "say",
    "error",
    "reindex",
    "duplicate",
    "access",
    "df",
    "dot",
    "duplicate",
    "points",
    "error",
    "come",
    "okay",
    "see",
    "something",
    "like",
    "product",
    "type",
    "right",
    "actually",
    "get",
    "removed",
    "pair",
    "plot",
    "reason",
    "use",
    "give",
    "error",
    "look",
    "okay",
    "worry",
    "till",
    "let",
    "see",
    "visualization",
    "diagrams",
    "okay",
    "till",
    "let",
    "see",
    "visualization",
    "diagrams",
    "look",
    "probably",
    "coming",
    "definitely",
    "use",
    "another",
    "plot",
    "like",
    "bar",
    "plot",
    "let",
    "say",
    "using",
    "bar",
    "plot",
    "want",
    "basically",
    "compare",
    "age",
    "respect",
    "purchase",
    "actually",
    "help",
    "find",
    "purchased",
    "purchased",
    "less",
    "gender",
    "going",
    "use",
    "hui",
    "gender",
    "okay",
    "done",
    "observation",
    "data",
    "equal",
    "df",
    "okay",
    "let",
    "execute",
    "diagram",
    "getting",
    "age",
    "one",
    "two",
    "three",
    "four",
    "five",
    "basically",
    "map",
    "definitely",
    "see",
    "even",
    "55",
    "plus",
    "respect",
    "genders",
    "observation",
    "gender",
    "zero",
    "zero",
    "replaced",
    "male",
    "right",
    "gender",
    "uh",
    "zero",
    "replaced",
    "female",
    "male",
    "gender",
    "gender",
    "think",
    "male",
    "female",
    "made",
    "zero",
    "yeah",
    "definitely",
    "come",
    "conclusion",
    "whether",
    "female",
    "bought",
    "male",
    "bought",
    "respect",
    "purchases",
    "maximum",
    "amount",
    "purchases",
    "see",
    "uh",
    "mail",
    "huge",
    "purchase",
    "respect",
    "orders",
    "also",
    "try",
    "see",
    "respect",
    "different",
    "different",
    "orders",
    "nothing",
    "visualization",
    "age",
    "versus",
    "purchase",
    "please",
    "write",
    "observations",
    "feel",
    "respect",
    "kind",
    "things",
    "purchasing",
    "goods",
    "range",
    "age",
    "almost",
    "equal",
    "conclude",
    "definitely",
    "purchasing",
    "percentage",
    "purchasing",
    "goods",
    "men",
    "women",
    "high",
    "right",
    "possible",
    "laughter",
    "purchasing",
    "men",
    "men",
    "high",
    "women",
    "observation",
    "done",
    "possible",
    "right",
    "data",
    "lie",
    "right",
    "definitely",
    "purchases",
    "respect",
    "ages",
    "uniform",
    "purchasing",
    "men",
    "higher",
    "women",
    "yeah",
    "nice",
    "like",
    "first",
    "observation",
    "let",
    "say",
    "respect",
    "purchase",
    "try",
    "visualize",
    "occupation",
    "okay",
    "visualization",
    "purchase",
    "occupation",
    "going",
    "copy",
    "thing",
    "going",
    "paste",
    "going",
    "say",
    "occupation",
    "ah",
    "let",
    "see",
    "diagram",
    "quite",
    "huge",
    "stuffed",
    "right",
    "occupations",
    "many",
    "right",
    "occupations",
    "money",
    "go",
    "check",
    "occupations",
    "20",
    "different",
    "occupations",
    "data",
    "set",
    "able",
    "find",
    "initial",
    "data",
    "set",
    "make",
    "observations",
    "let",
    "see",
    "occupation",
    "occupation",
    "categories",
    "mapped",
    "okay",
    "respect",
    "suggest",
    "also",
    "uniform",
    "wo",
    "affect",
    "lot",
    "let",
    "compare",
    "whether",
    "product",
    "category",
    "1",
    "product",
    "category",
    "one",
    "versus",
    "persist",
    "like",
    "many",
    "people",
    "bought",
    "product",
    "category",
    "one",
    "go",
    "see",
    "data",
    "set",
    "able",
    "see",
    "going",
    "copy",
    "bar",
    "plot",
    "going",
    "write",
    "going",
    "basically",
    "write",
    "product",
    "category",
    "one",
    "product",
    "let",
    "see",
    "product",
    "category",
    "one",
    "many",
    "people",
    "bought",
    "respect",
    "purchases",
    "amount",
    "shown",
    "see",
    "graph",
    "respect",
    "product",
    "category",
    "similarly",
    "let",
    "see",
    "respect",
    "product",
    "category",
    "2",
    "know",
    "whether",
    "able",
    "see",
    "thing",
    "see",
    "two",
    "graphs",
    "two",
    "graphs",
    "able",
    "see",
    "guess",
    "coming",
    "one",
    "coming",
    "okay",
    "remove",
    "think",
    "replace",
    "order",
    "okay",
    "execute",
    "product",
    "category",
    "one",
    "product",
    "category",
    "two",
    "next",
    "one",
    "product",
    "category",
    "3",
    "observe",
    "come",
    "conclusion",
    "guys",
    "see",
    "respect",
    "12",
    "000",
    "till",
    "14",
    "16",
    "000",
    "product",
    "category",
    "2",
    "sold",
    "whereas",
    "product",
    "category",
    "1",
    "bought",
    "right",
    "still",
    "20",
    "000",
    "right",
    "definitely",
    "information",
    "take",
    "particular",
    "graph",
    "graphs",
    "want",
    "propose",
    "definitely",
    "use",
    "tell",
    "guys",
    "mo",
    "data",
    "set",
    "good",
    "model",
    "type",
    "database",
    "processing",
    "done",
    "think",
    "good",
    "right",
    "good",
    "also",
    "drop",
    "product",
    "id",
    "also",
    "drop",
    "product",
    "id",
    "let",
    "probably",
    "one",
    "last",
    "thing",
    "okay",
    "feature",
    "scaling",
    "okay",
    "feature",
    "scaling",
    "become",
    "df",
    "underscore",
    "test",
    "remove",
    "df",
    "dot",
    "purchase",
    "dot",
    "null",
    "see",
    "wherever",
    "purchase",
    "purchase",
    "column",
    "null",
    "right",
    "belongs",
    "test",
    "data",
    "trying",
    "find",
    "apart",
    "null",
    "find",
    "null",
    "use",
    "like",
    "able",
    "see",
    "basically",
    "write",
    "df",
    "run",
    "train",
    "df",
    "draw",
    "train",
    "df",
    "underscore",
    "test",
    "df",
    "underscore",
    "train",
    "test",
    "let",
    "go",
    "feature",
    "scaling",
    "future",
    "scaling",
    "basically",
    "apply",
    "standard",
    "scalar",
    "feature",
    "scaling",
    "much",
    "simple",
    "sklearn",
    "dot",
    "going",
    "import",
    "standard",
    "scalar",
    "going",
    "write",
    "sc",
    "equal",
    "standard",
    "scalar",
    "trained",
    "data",
    "set",
    "always",
    "remember",
    "df",
    "underscore",
    "test",
    "okay",
    "want",
    "train",
    "test",
    "split",
    "definitely",
    "go",
    "ahead",
    "problem",
    "definitely",
    "write",
    "df",
    "underscore",
    "train",
    "x",
    "train",
    "x",
    "test",
    "train",
    "test",
    "okay",
    "uh",
    "let",
    "write",
    "one",
    "code",
    "train",
    "test",
    "plate",
    "training",
    "data",
    "going",
    "scale",
    "train",
    "test",
    "split",
    "okay",
    "always",
    "good",
    "google",
    "copy",
    "paste",
    "instead",
    "writing",
    "okay",
    "going",
    "copy",
    "paste",
    "also",
    "thing",
    "tell",
    "krish",
    "bring",
    "queries",
    "answers",
    "going",
    "change",
    "let",
    "write",
    "sk",
    "learn",
    "dot",
    "model",
    "selection",
    "import",
    "trend",
    "test",
    "split",
    "okay",
    "basically",
    "df",
    "underscore",
    "test",
    "x",
    "x",
    "basically",
    "df",
    "underscore",
    "train",
    "colon",
    "minus",
    "1",
    "hope",
    "works",
    "x",
    "dot",
    "head",
    "make",
    "x",
    "axis",
    "get",
    "independent",
    "dependent",
    "feature",
    "x",
    "similarly",
    "also",
    "create",
    "write",
    "f",
    "colon",
    "minus",
    "one",
    "basically",
    "give",
    "okay",
    "minus",
    "one",
    "okay",
    "colon",
    "minus",
    "one",
    "colon",
    "colon",
    "get",
    "last",
    "column",
    "df",
    "colon",
    "minus",
    "one",
    "give",
    "entire",
    "thing",
    "double",
    "colon",
    "minus",
    "one",
    "basically",
    "give",
    "last",
    "value",
    "giving",
    "double",
    "colon",
    "second",
    "basically",
    "say",
    "df",
    "purchase",
    "right",
    "value",
    "colon",
    "comma",
    "minus",
    "1",
    "also",
    "work",
    "colon",
    "comma",
    "minus",
    "1",
    "also",
    "work",
    "give",
    "second",
    "guys",
    "yeah",
    "x",
    "going",
    "give",
    "x",
    "get",
    "error",
    "input",
    "variable",
    "inconsistent",
    "number",
    "samples",
    "comma",
    "36",
    "made",
    "mistake",
    "x",
    "dot",
    "shape",
    "let",
    "see",
    "basically",
    "12",
    "rows",
    "fine",
    "dot",
    "shape",
    "hey",
    "come",
    "difference",
    "mistake",
    "df",
    "underscore",
    "train",
    "mistake",
    "made",
    "fine",
    "work",
    "got",
    "answer",
    "basically",
    "go",
    "execute",
    "extra",
    "next",
    "test",
    "x",
    "comma",
    "f",
    "underscore",
    "train",
    "written",
    "still",
    "getting",
    "error",
    "scalar",
    "node",
    "model",
    "import",
    "train",
    "test",
    "split",
    "x",
    "comma",
    "also",
    "dot",
    "shape",
    "also",
    "might",
    "able",
    "get",
    "oh",
    "one",
    "extra",
    "record",
    "hook",
    "one",
    "extra",
    "record",
    "come",
    "purchase",
    "last",
    "column",
    "screen",
    "visible",
    "properly",
    "looking",
    "hazy",
    "please",
    "reload",
    "okay",
    "oh",
    "purchase",
    "last",
    "column",
    "problem",
    "made",
    "one",
    "mistake",
    "basically",
    "say",
    "df",
    "dot",
    "train",
    "dot",
    "drop",
    "purchase",
    "axis",
    "equal",
    "1",
    "definitely",
    "work",
    "done",
    "features",
    "x",
    "dot",
    "shape",
    "11",
    "columns",
    "df",
    "underscore",
    "train",
    "perfect",
    "perfect",
    "perfectness",
    "happens",
    "google",
    "happens",
    "fixed",
    "see",
    "df",
    "underscore",
    "train",
    "instead",
    "writing",
    "like",
    "going",
    "fit",
    "fit",
    "transform",
    "xtrain",
    "finally",
    "write",
    "fit",
    "underscore",
    "transform",
    "basically",
    "going",
    "write",
    "x",
    "underscore",
    "train",
    "basically",
    "give",
    "x",
    "underscore",
    "train",
    "equal",
    "one",
    "x",
    "underscore",
    "test",
    "equal",
    "sc",
    "dot",
    "transform",
    "x",
    "underscore",
    "transform",
    "think",
    "let",
    "execute",
    "gives",
    "error",
    "could",
    "okay",
    "let",
    "drop",
    "one",
    "last",
    "thing",
    "think",
    "could",
    "dropped",
    "drop",
    "assignment",
    "going",
    "drop",
    "product",
    "id",
    "place",
    "equal",
    "true",
    "want",
    "get",
    "killed",
    "right",
    "x",
    "underscore",
    "test",
    "product",
    "id",
    "done",
    "finished",
    "92",
    "lines",
    "code",
    "100",
    "lines",
    "code",
    "written",
    "front",
    "complete",
    "analysis",
    "data",
    "set",
    "go",
    "train",
    "model",
    "next",
    "step",
    "basically",
    "train",
    "model",
    "want",
    "see",
    "correlation",
    "okay",
    "name",
    "file",
    "black",
    "friday",
    "feature",
    "engineering",
    "everything",
    "giving",
    "uploading",
    "github",
    "able",
    "find",
    "second",
    "uploading",
    "okay",
    "guys",
    "uh",
    "reload",
    "page",
    "uh",
    "yes",
    "able",
    "see",
    "file",
    "description",
    "tomorrow",
    "also",
    "going",
    "take",
    "different",
    "data",
    "set",
    "trying",
    "see",
    "things",
    "going",
    "reload",
    "data",
    "set",
    "tomorrow",
    "continue",
    "session",
    "uh",
    "thank",
    "everyone",
    "joining",
    "yes",
    "hope",
    "liked",
    "thank",
    "great",
    "day",
    "bye",
    "bye",
    "guys",
    "keep",
    "rocking",
    "see",
    "tomorrow",
    "hello",
    "guys",
    "hope",
    "everybody",
    "able",
    "hear",
    "today",
    "basically",
    "going",
    "solve",
    "flight",
    "price",
    "prediction",
    "basically",
    "going",
    "eda",
    "eda",
    "plus",
    "feature",
    "engineering",
    "data",
    "set",
    "actually",
    "giving",
    "data",
    "set",
    "go",
    "see",
    "data",
    "set",
    "data",
    "set",
    "looks",
    "something",
    "like",
    "data",
    "train",
    "test",
    "set",
    "okay",
    "two",
    "xls",
    "file",
    "download",
    "two",
    "files",
    "want",
    "download",
    "make",
    "sure",
    "go",
    "download",
    "right",
    "zip",
    "file",
    "inside",
    "flight",
    "prediction",
    "specific",
    "data",
    "set",
    "two",
    "data",
    "set",
    "going",
    "take",
    "data",
    "train",
    "test",
    "underscore",
    "set",
    "problem",
    "statement",
    "given",
    "flat",
    "price",
    "prediction",
    "problem",
    "statement",
    "given",
    "hackathon",
    "going",
    "basically",
    "solve",
    "let",
    "start",
    "initially",
    "start",
    "importing",
    "basic",
    "libraries",
    "importing",
    "basic",
    "libraries",
    "quickly",
    "libraries",
    "require",
    "already",
    "done",
    "study",
    "session",
    "write",
    "import",
    "pandas",
    "pd",
    "import",
    "numpy",
    "np",
    "import",
    "matplotlib",
    "matplotlib",
    "dot",
    "pi",
    "plot",
    "plt",
    "import",
    "c",
    "bond",
    "sns",
    "import",
    "cbon",
    "sns",
    "probably",
    "also",
    "importing",
    "write",
    "matpotlib",
    "inline",
    "guys",
    "many",
    "people",
    "usually",
    "ask",
    "used",
    "matplotlib",
    "inline",
    "see",
    "suppose",
    "want",
    "probably",
    "show",
    "diagram",
    "within",
    "without",
    "writing",
    "plot",
    "dot",
    "show",
    "basically",
    "go",
    "respect",
    "one",
    "matplotlib",
    "inline",
    "soon",
    "plot",
    "anything",
    "write",
    "plot",
    "dot",
    "show",
    "automatically",
    "get",
    "shown",
    "uh",
    "specifically",
    "taken",
    "data",
    "set",
    "go",
    "see",
    "data",
    "set",
    "something",
    "amazing",
    "data",
    "set",
    "also",
    "date",
    "time",
    "information",
    "okay",
    "date",
    "time",
    "information",
    "really",
    "careful",
    "whenever",
    "working",
    "reason",
    "specifically",
    "taken",
    "uh",
    "wanted",
    "show",
    "different",
    "different",
    "domain",
    "problem",
    "statements",
    "kind",
    "data",
    "able",
    "see",
    "okay",
    "challenges",
    "may",
    "probably",
    "face",
    "usual",
    "actually",
    "going",
    "first",
    "uh",
    "going",
    "import",
    "training",
    "data",
    "set",
    "write",
    "underscore",
    "csv",
    "read",
    "underscore",
    "excel",
    "let",
    "execute",
    "one",
    "first",
    "read",
    "data",
    "set",
    "like",
    "basically",
    "going",
    "give",
    "go",
    "probably",
    "see",
    "train",
    "underscore",
    "able",
    "see",
    "specific",
    "data",
    "set",
    "airline",
    "date",
    "journey",
    "source",
    "destination",
    "route",
    "given",
    "like",
    "bangalore",
    "delhi",
    "departure",
    "time",
    "arrival",
    "time",
    "duration",
    "total",
    "stops",
    "additional",
    "info",
    "price",
    "probably",
    "thing",
    "test",
    "data",
    "set",
    "going",
    "basically",
    "test",
    "data",
    "set",
    "test",
    "uh",
    "test",
    "underscore",
    "df",
    "specifically",
    "write",
    "test",
    "xls",
    "file",
    "name",
    "want",
    "display",
    "test",
    "test",
    "data",
    "one",
    "column",
    "last",
    "column",
    "see",
    "price",
    "done",
    "hope",
    "everybody",
    "done",
    "usual",
    "importing",
    "try",
    "training",
    "model",
    "see",
    "getting",
    "model",
    "score",
    "bad",
    "like",
    "12",
    "13",
    "help",
    "linear",
    "regression",
    "algorithms",
    "try",
    "different",
    "algorithms",
    "right",
    "like",
    "algorithms",
    "also",
    "like",
    "decision",
    "tree",
    "regressor",
    "random",
    "forest",
    "regressor",
    "right",
    "xgb",
    "boost",
    "regressor",
    "one",
    "tried",
    "know",
    "saying",
    "12",
    "13",
    "linear",
    "lasso",
    "keeping",
    "quite",
    "problem",
    "know",
    "taught",
    "machine",
    "learning",
    "algorithms",
    "previously",
    "want",
    "try",
    "machine",
    "learning",
    "algorithm",
    "obviously",
    "linear",
    "regression",
    "creates",
    "straight",
    "line",
    "many",
    "features",
    "accuracy",
    "bad",
    "see",
    "get",
    "much",
    "common",
    "sense",
    "point",
    "time",
    "think",
    "trust",
    "cracking",
    "interviews",
    "become",
    "difficult",
    "work",
    "real",
    "world",
    "industry",
    "go",
    "use",
    "different",
    "different",
    "algorithms",
    "always",
    "tell",
    "hyper",
    "parameter",
    "tuning",
    "top",
    "linear",
    "regression",
    "sir",
    "rich",
    "sir",
    "got",
    "12",
    "percent",
    "tell",
    "want",
    "anything",
    "like",
    "learn",
    "tomorrow",
    "given",
    "problem",
    "statement",
    "time",
    "krishnak",
    "come",
    "right",
    "let",
    "one",
    "thing",
    "first",
    "going",
    "combine",
    "train",
    "df",
    "test",
    "df",
    "another",
    "variable",
    "called",
    "final",
    "df",
    "going",
    "order",
    "combine",
    "write",
    "trend",
    "df",
    "dot",
    "append",
    "write",
    "test",
    "df",
    "comma",
    "ndf",
    "dot",
    "append",
    "test",
    "df",
    "test",
    "df",
    "data",
    "set",
    "train",
    "df",
    "data",
    "set",
    "go",
    "finally",
    "write",
    "final",
    "underscore",
    "combining",
    "train",
    "test",
    "remember",
    "go",
    "see",
    "tail",
    "path",
    "go",
    "see",
    "tail",
    "part",
    "able",
    "see",
    "nan",
    "values",
    "prices",
    "test",
    "data",
    "set",
    "okay",
    "much",
    "think",
    "able",
    "appending",
    "data",
    "set",
    "getting",
    "converted",
    "one",
    "see",
    "features",
    "looks",
    "quite",
    "complex",
    "feature",
    "like",
    "airlines",
    "date",
    "journey",
    "source",
    "destination",
    "route",
    "departure",
    "time",
    "arrival",
    "time",
    "know",
    "arrival",
    "time",
    "duration",
    "total",
    "stops",
    "additional",
    "info",
    "different",
    "different",
    "types",
    "columns",
    "lot",
    "feature",
    "engineering",
    "basically",
    "required",
    "going",
    "focus",
    "feature",
    "engineering",
    "done",
    "extensive",
    "eda",
    "let",
    "go",
    "ahead",
    "try",
    "feature",
    "engineering",
    "every",
    "field",
    "okay",
    "first",
    "field",
    "may",
    "probably",
    "see",
    "something",
    "called",
    "date",
    "journey",
    "date",
    "journey",
    "obviously",
    "day",
    "months",
    "year",
    "probably",
    "let",
    "write",
    "final",
    "underscore",
    "basically",
    "see",
    "date",
    "journey",
    "also",
    "object",
    "date",
    "journey",
    "object",
    "basically",
    "means",
    "string",
    "format",
    "convert",
    "date",
    "time",
    "format",
    "converting",
    "probably",
    "date",
    "time",
    "format",
    "need",
    "pick",
    "specific",
    "information",
    "like",
    "day",
    "basically",
    "month",
    "may",
    "probably",
    "year",
    "technique",
    "particular",
    "field",
    "create",
    "three",
    "fields",
    "specify",
    "day",
    "month",
    "year",
    "say",
    "trying",
    "create",
    "derived",
    "feature",
    "tell",
    "guys",
    "date",
    "journey",
    "create",
    "three",
    "fields",
    "anyone",
    "actually",
    "try",
    "basically",
    "let",
    "know",
    "try",
    "say",
    "code",
    "go",
    "ahead",
    "basically",
    "starting",
    "future",
    "engineering",
    "process",
    "told",
    "first",
    "try",
    "take",
    "derive",
    "features",
    "like",
    "definitely",
    "able",
    "take",
    "day",
    "month",
    "year",
    "actually",
    "going",
    "simple",
    "way",
    "basically",
    "going",
    "say",
    "final",
    "underscore",
    "df",
    "try",
    "create",
    "three",
    "features",
    "said",
    "one",
    "feature",
    "basically",
    "month",
    "date",
    "first",
    "start",
    "date",
    "one",
    "feature",
    "next",
    "feature",
    "actually",
    "going",
    "create",
    "respect",
    "month",
    "third",
    "feature",
    "probably",
    "going",
    "create",
    "respect",
    "ear",
    "three",
    "feature",
    "need",
    "derive",
    "need",
    "create",
    "already",
    "know",
    "feature",
    "called",
    "date",
    "journey",
    "right",
    "date",
    "journey",
    "basically",
    "split",
    "okay",
    "split",
    "using",
    "character",
    "split",
    "using",
    "specific",
    "character",
    "forward",
    "slash",
    "probably",
    "split",
    "basically",
    "able",
    "get",
    "three",
    "important",
    "information",
    "one",
    "six",
    "zero",
    "six",
    "2019",
    "case",
    "date",
    "need",
    "focus",
    "first",
    "index",
    "zeroth",
    "index",
    "case",
    "month",
    "need",
    "focus",
    "first",
    "index",
    "case",
    "2019",
    "need",
    "focus",
    "second",
    "index",
    "actually",
    "going",
    "basically",
    "going",
    "write",
    "dot",
    "str",
    "dot",
    "split",
    "convert",
    "str",
    "need",
    "basically",
    "split",
    "split",
    "copy",
    "run",
    "code",
    "let",
    "see",
    "happen",
    "able",
    "see",
    "write",
    "0",
    "basically",
    "means",
    "able",
    "get",
    "entire",
    "information",
    "okay",
    "see",
    "write",
    "string",
    "sorry",
    "written",
    "0",
    "also",
    "getting",
    "specific",
    "information",
    "also",
    "use",
    "one",
    "keyword",
    "called",
    "dot",
    "htr",
    "zero",
    "see",
    "able",
    "get",
    "dates",
    "okay",
    "dates",
    "actually",
    "able",
    "get",
    "order",
    "get",
    "dates",
    "going",
    "use",
    "forward",
    "going",
    "write",
    "dot",
    "htr",
    "0",
    "process",
    "basically",
    "use",
    "take",
    "date",
    "need",
    "convert",
    "date",
    "time",
    "also",
    "get",
    "convert",
    "integer",
    "forecasting",
    "kind",
    "task",
    "point",
    "time",
    "may",
    "use",
    "month",
    "need",
    "change",
    "index",
    "1",
    "need",
    "change",
    "index",
    "able",
    "get",
    "date",
    "month",
    "year",
    "execute",
    "able",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "head",
    "see",
    "top",
    "two",
    "records",
    "somewhere",
    "end",
    "able",
    "see",
    "date",
    "month",
    "year",
    "created",
    "also",
    "works",
    "well",
    "apply",
    "lambda",
    "function",
    "good",
    "going",
    "ping",
    "copy",
    "paste",
    "code",
    "also",
    "good",
    "technique",
    "definitely",
    "also",
    "using",
    "given",
    "specific",
    "technique",
    "specifically",
    "used",
    "lambda",
    "function",
    "also",
    "definitely",
    "work",
    "hope",
    "everybody",
    "able",
    "understand",
    "till",
    "okay",
    "either",
    "code",
    "basically",
    "use",
    "actually",
    "go",
    "ahead",
    "good",
    "technique",
    "applying",
    "lambda",
    "function",
    "nice",
    "means",
    "efficient",
    "coding",
    "okay",
    "googling",
    "trying",
    "find",
    "better",
    "way",
    "definitely",
    "work",
    "okay",
    "let",
    "see",
    "next",
    "step",
    "simple",
    "basically",
    "also",
    "make",
    "sure",
    "convert",
    "integer",
    "right",
    "integer",
    "also",
    "need",
    "convert",
    "date",
    "month",
    "date",
    "month",
    "year",
    "order",
    "uh",
    "simple",
    "write",
    "final",
    "underscore",
    "df",
    "equal",
    "final",
    "underscore",
    "df",
    "date",
    "actually",
    "going",
    "convert",
    "type",
    "end",
    "okay",
    "copy",
    "probably",
    "paste",
    "paste",
    "month",
    "one",
    "mistake",
    "definitely",
    "making",
    "apply",
    "feature",
    "right",
    "going",
    "copy",
    "make",
    "month",
    "make",
    "execute",
    "got",
    "executed",
    "write",
    "final",
    "underscore",
    "dot",
    "see",
    "see",
    "date",
    "month",
    "year",
    "32",
    "32",
    "price",
    "already",
    "float",
    "64",
    "starting",
    "focus",
    "different",
    "different",
    "features",
    "uh",
    "done",
    "uh",
    "let",
    "go",
    "next",
    "feature",
    "one",
    "want",
    "catch",
    "hold",
    "next",
    "feature",
    "since",
    "done",
    "one",
    "step",
    "try",
    "drop",
    "particular",
    "feature",
    "require",
    "date",
    "journey",
    "right",
    "actually",
    "going",
    "write",
    "final",
    "underscore",
    "df",
    "dot",
    "drop",
    "basically",
    "going",
    "give",
    "feature",
    "name",
    "date",
    "copy",
    "date",
    "journey",
    "access",
    "equal",
    "1",
    "uh",
    "place",
    "equal",
    "true",
    "already",
    "seen",
    "yesterday",
    "go",
    "probably",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "one",
    "see",
    "month",
    "year",
    "date",
    "also",
    "date",
    "journey",
    "let",
    "go",
    "next",
    "feature",
    "next",
    "feature",
    "see",
    "catch",
    "one",
    "feature",
    "time",
    "probably",
    "need",
    "necessary",
    "changes",
    "okay",
    "next",
    "feature",
    "basically",
    "uh",
    "go",
    "respect",
    "route",
    "let",
    "say",
    "route",
    "also",
    "try",
    "understand",
    "okay",
    "arrival",
    "time",
    "route",
    "okay",
    "route",
    "uh",
    "let",
    "wait",
    "time",
    "route",
    "let",
    "focus",
    "arrival",
    "time",
    "departure",
    "time",
    "okay",
    "let",
    "one",
    "thing",
    "let",
    "focus",
    "arrival",
    "departure",
    "time",
    "first",
    "focus",
    "something",
    "similar",
    "type",
    "fields",
    "always",
    "remember",
    "probably",
    "feature",
    "engineering",
    "try",
    "catch",
    "similar",
    "types",
    "field",
    "basically",
    "let",
    "go",
    "ahead",
    "take",
    "arrival",
    "time",
    "arrival",
    "time",
    "obviously",
    "require",
    "information",
    "like",
    "22",
    "march",
    "probably",
    "go",
    "see",
    "around",
    "10",
    "records",
    "able",
    "see",
    "wherever",
    "gap",
    "space",
    "split",
    "let",
    "see",
    "using",
    "space",
    "definitely",
    "get",
    "something",
    "okay",
    "uh",
    "using",
    "space",
    "probably",
    "trying",
    "split",
    "probably",
    "able",
    "get",
    "arrival",
    "time",
    "arrival",
    "time",
    "way",
    "able",
    "get",
    "first",
    "four",
    "important",
    "information",
    "think",
    "require",
    "10",
    "june",
    "date",
    "require",
    "need",
    "focus",
    "first",
    "four",
    "values",
    "write",
    "final",
    "underscore",
    "df",
    "arrival",
    "time",
    "dot",
    "str",
    "dot",
    "split",
    "split",
    "help",
    "empty",
    "braces",
    "write",
    "dot",
    "htr",
    "execute",
    "able",
    "see",
    "like",
    "right",
    "things",
    "need",
    "pick",
    "first",
    "value",
    "see",
    "first",
    "value",
    "able",
    "get",
    "important",
    "information",
    "okay",
    "like",
    "4",
    "25",
    "7",
    "15",
    "first",
    "one",
    "need",
    "focus",
    "get",
    "first",
    "one",
    "use",
    "indexing",
    "htr",
    "0",
    "execute",
    "able",
    "get",
    "particular",
    "value",
    "thing",
    "also",
    "one",
    "amazing",
    "code",
    "done",
    "using",
    "lambda",
    "function",
    "see",
    "dot",
    "apply",
    "lambda",
    "okay",
    "execute",
    "sorry",
    "final",
    "underscore",
    "df",
    "execute",
    "also",
    "see",
    "getting",
    "information",
    "actually",
    "going",
    "going",
    "use",
    "particular",
    "code",
    "make",
    "changes",
    "final",
    "underscore",
    "df",
    "arrival",
    "time",
    "one",
    "code",
    "basically",
    "use",
    "new",
    "new",
    "things",
    "basically",
    "get",
    "order",
    "one",
    "thing",
    "forgot",
    "check",
    "whether",
    "null",
    "value",
    "price",
    "basically",
    "null",
    "values",
    "okay",
    "test",
    "data",
    "route",
    "one",
    "null",
    "value",
    "total",
    "stops",
    "one",
    "null",
    "value",
    "route",
    "basically",
    "means",
    "route",
    "specific",
    "may",
    "row",
    "may",
    "row",
    "total",
    "stops",
    "one",
    "null",
    "value",
    "one",
    "null",
    "value",
    "everybody",
    "clear",
    "arrival",
    "time",
    "still",
    "take",
    "hour",
    "still",
    "take",
    "need",
    "take",
    "arrival",
    "time",
    "guys",
    "hour",
    "minutes",
    "right",
    "specific",
    "thing",
    "next",
    "step",
    "actually",
    "going",
    "write",
    "final",
    "underscore",
    "df",
    "lambda",
    "function",
    "easy",
    "way",
    "basically",
    "split",
    "actually",
    "create",
    "two",
    "features",
    "arrival",
    "underscore",
    "hour",
    "equal",
    "final",
    "underscore",
    "df",
    "arrival",
    "underscore",
    "time",
    "use",
    "dot",
    "apply",
    "lambda",
    "also",
    "dot",
    "htr",
    "dot",
    "split",
    "split",
    "happen",
    "colon",
    "right",
    "within",
    "hours",
    "one",
    "colon",
    "going",
    "split",
    "help",
    "colon",
    "right",
    "split",
    "help",
    "colon",
    "dot",
    "htr",
    "dot",
    "split",
    "dot",
    "htr",
    "0",
    "write",
    "like",
    "become",
    "hour",
    "similarly",
    "want",
    "know",
    "arrival",
    "minutes",
    "basically",
    "write",
    "like",
    "write",
    "htr",
    "one",
    "done",
    "go",
    "probably",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "one",
    "able",
    "see",
    "one",
    "arrival",
    "hour",
    "minute",
    "remember",
    "still",
    "object",
    "type",
    "also",
    "need",
    "convert",
    "integer",
    "type",
    "thing",
    "go",
    "written",
    "specific",
    "code",
    "copy",
    "one",
    "like",
    "okay",
    "copy",
    "code",
    "keep",
    "going",
    "basically",
    "write",
    "arrival",
    "hour",
    "convert",
    "type",
    "arrival",
    "minute",
    "convert",
    "type",
    "two",
    "steps",
    "one",
    "converting",
    "n",
    "type",
    "also",
    "done",
    "along",
    "execute",
    "able",
    "see",
    "write",
    "final",
    "underscore",
    "df",
    "dot",
    "info",
    "able",
    "see",
    "integer",
    "values",
    "added",
    "arrival",
    "hour",
    "arrival",
    "mean",
    "minutes",
    "code",
    "actually",
    "written",
    "drop",
    "arrival",
    "time",
    "write",
    "final",
    "underscore",
    "arrival",
    "time",
    "arrival",
    "underscore",
    "time",
    "comma",
    "axis",
    "equal",
    "1",
    "place",
    "equal",
    "true",
    "step",
    "step",
    "nice",
    "way",
    "hope",
    "everybody",
    "able",
    "think",
    "probably",
    "go",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "one",
    "record",
    "able",
    "see",
    "things",
    "also",
    "okay",
    "uh",
    "departure",
    "time",
    "hope",
    "everybody",
    "able",
    "thing",
    "departure",
    "time",
    "departure",
    "also",
    "format",
    "going",
    "copy",
    "code",
    "paste",
    "paste",
    "also",
    "paste",
    "line",
    "also",
    "finally",
    "paste",
    "also",
    "keep",
    "respect",
    "arrival",
    "time",
    "like",
    "departure",
    "time",
    "right",
    "going",
    "write",
    "departure",
    "time",
    "right",
    "depth",
    "time",
    "going",
    "copy",
    "everywhere",
    "paste",
    "paste",
    "paste",
    "going",
    "basically",
    "write",
    "pt",
    "hour",
    "pept",
    "minutes",
    "require",
    "dept",
    "hour",
    "dept",
    "minute",
    "think",
    "everybody",
    "able",
    "understand",
    "going",
    "change",
    "yes",
    "also",
    "work",
    "herod",
    "done",
    "oh",
    "error",
    "coming",
    "let",
    "see",
    "base",
    "10",
    "20",
    "10",
    "music",
    "oops",
    "department",
    "hour",
    "department",
    "maine",
    "execute",
    "remove",
    "paste",
    "away",
    "well",
    "done",
    "final",
    "underscore",
    "df",
    "dot",
    "info",
    "able",
    "see",
    "two",
    "features",
    "getting",
    "added",
    "department",
    "one",
    "perfect",
    "done",
    "take",
    "care",
    "things",
    "right",
    "airline",
    "actually",
    "departure",
    "done",
    "let",
    "catch",
    "route",
    "inside",
    "able",
    "see",
    "route",
    "basically",
    "information",
    "like",
    "bangalore",
    "delhi",
    "bangalore",
    "delhi",
    "okay",
    "see",
    "anyhow",
    "able",
    "see",
    "uh",
    "even",
    "though",
    "basically",
    "find",
    "like",
    "route",
    "like",
    "route",
    "one",
    "two",
    "three",
    "four",
    "maximum",
    "maximum",
    "see",
    "two",
    "places",
    "like",
    "bangalore",
    "origin",
    "delhi",
    "destination",
    "four",
    "different",
    "different",
    "places",
    "basically",
    "means",
    "first",
    "going",
    "kolkata",
    "ixr",
    "ixr",
    "bbi",
    "bbi",
    "bangalore",
    "total",
    "number",
    "stops",
    "two",
    "particular",
    "case",
    "one",
    "stop",
    "try",
    "capture",
    "route",
    "one",
    "route",
    "places",
    "away",
    "source",
    "destination",
    "two",
    "values",
    "right",
    "number",
    "stops",
    "one",
    "like",
    "right",
    "better",
    "get",
    "specific",
    "information",
    "much",
    "clearly",
    "actually",
    "able",
    "see",
    "route",
    "1",
    "route",
    "2",
    "route",
    "3",
    "route",
    "4",
    "like",
    "right",
    "one",
    "thing",
    "need",
    "know",
    "may",
    "definitely",
    "get",
    "null",
    "values",
    "may",
    "definitely",
    "get",
    "null",
    "values",
    "lot",
    "null",
    "values",
    "may",
    "getting",
    "understand",
    "null",
    "values",
    "like",
    "want",
    "capture",
    "route",
    "4",
    "definitely",
    "null",
    "values",
    "okay",
    "instead",
    "also",
    "also",
    "delete",
    "focus",
    "total",
    "number",
    "stops",
    "right",
    "total",
    "stops",
    "like",
    "total",
    "underscore",
    "stops",
    "also",
    "focus",
    "particular",
    "values",
    "also",
    "think",
    "delete",
    "specific",
    "feature",
    "directly",
    "focus",
    "source",
    "destination",
    "obviously",
    "number",
    "stops",
    "think",
    "like",
    "person",
    "right",
    "really",
    "need",
    "focus",
    "two",
    "things",
    "okay",
    "first",
    "probably",
    "going",
    "kolkata",
    "bangalore",
    "two",
    "places",
    "going",
    "price",
    "might",
    "increase",
    "drastically",
    "okay",
    "based",
    "top",
    "number",
    "stops",
    "particular",
    "case",
    "see",
    "delhi",
    "cok",
    "right",
    "lucknow",
    "bombay",
    "lucknow",
    "bombay",
    "feel",
    "probably",
    "price",
    "taken",
    "place",
    "see",
    "need",
    "definitely",
    "drop",
    "route",
    "focus",
    "total",
    "stops",
    "focusing",
    "total",
    "stops",
    "actually",
    "going",
    "write",
    "going",
    "basically",
    "say",
    "final",
    "underscore",
    "total",
    "total",
    "stops",
    "dot",
    "unique",
    "write",
    "unique",
    "let",
    "see",
    "many",
    "total",
    "stops",
    "basically",
    "means",
    "probably",
    "uh",
    "like",
    "single",
    "stop",
    "see",
    "basically",
    "replace",
    "0",
    "replace",
    "2",
    "replace",
    "1",
    "3",
    "nand",
    "value",
    "try",
    "see",
    "one",
    "null",
    "value",
    "guess",
    "null",
    "dot",
    "sum",
    "see",
    "one",
    "nand",
    "value",
    "replace",
    "uh",
    "one",
    "required",
    "respect",
    "okay",
    "everybody",
    "focus",
    "try",
    "convert",
    "map",
    "values",
    "0",
    "1",
    "2",
    "3",
    "4",
    "5",
    "like",
    "tell",
    "someone",
    "tell",
    "code",
    "amazing",
    "rishi",
    "already",
    "written",
    "code",
    "rishi",
    "basically",
    "said",
    "something",
    "like",
    "using",
    "map",
    "final",
    "underscore",
    "df",
    "final",
    "underscore",
    "df",
    "final",
    "disco",
    "df",
    "total",
    "stops",
    "total",
    "stops",
    "dot",
    "map",
    "equal",
    "zero",
    "one",
    "stop",
    "equal",
    "1",
    "2",
    "stops",
    "equal",
    "2",
    "3",
    "nan",
    "also",
    "want",
    "place",
    "place",
    "one",
    "nand",
    "value",
    "nan",
    "also",
    "make",
    "sure",
    "directly",
    "see",
    "right",
    "specific",
    "record",
    "wait",
    "definitely",
    "see",
    "specific",
    "record",
    "nan",
    "second",
    "df",
    "total",
    "sorry",
    "final",
    "underscore",
    "df",
    "total",
    "stops",
    "dot",
    "um",
    "dot",
    "null",
    "dot",
    "null",
    "basically",
    "write",
    "final",
    "underscore",
    "df",
    "try",
    "take",
    "specific",
    "values",
    "see",
    "route",
    "nan",
    "total",
    "number",
    "stops",
    "also",
    "nan",
    "total",
    "number",
    "stops",
    "also",
    "nan",
    "route",
    "also",
    "nan",
    "see",
    "delhi",
    "cochin",
    "okay",
    "delhi",
    "coaching",
    "think",
    "direct",
    "flight",
    "value",
    "want",
    "replace",
    "since",
    "single",
    "record",
    "think",
    "wo",
    "matter",
    "much",
    "let",
    "one",
    "thing",
    "let",
    "replace",
    "one",
    "stop",
    "common",
    "sense",
    "think",
    "coaching",
    "bangalore",
    "coaching",
    "least",
    "one",
    "stop",
    "required",
    "like",
    "try",
    "change",
    "delete",
    "coaching",
    "sorry",
    "got",
    "executed",
    "okay",
    "go",
    "probably",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "able",
    "see",
    "specific",
    "values",
    "see",
    "total",
    "stops",
    "converted",
    "integer",
    "floating",
    "value",
    "drop",
    "route",
    "column",
    "final",
    "underscore",
    "df",
    "drop",
    "route",
    "going",
    "drop",
    "route",
    "axis",
    "equal",
    "1",
    "place",
    "equal",
    "true",
    "definitely",
    "require",
    "2",
    "2",
    "information",
    "right",
    "finally",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "values",
    "amazing",
    "next",
    "thing",
    "probably",
    "want",
    "guys",
    "deleted",
    "everything",
    "right",
    "department",
    "department",
    "departure",
    "hour",
    "also",
    "dropped",
    "total",
    "stops",
    "also",
    "let",
    "catch",
    "one",
    "want",
    "additional",
    "info",
    "normal",
    "uh",
    "feature",
    "engineering",
    "like",
    "transformation",
    "encoding",
    "special",
    "character",
    "somewhere",
    "probably",
    "catch",
    "hold",
    "write",
    "final",
    "underscore",
    "df",
    "go",
    "ahead",
    "additional",
    "info",
    "additional",
    "info",
    "dot",
    "unique",
    "many",
    "unique",
    "values",
    "see",
    "many",
    "unique",
    "values",
    "converted",
    "uh",
    "one",
    "hot",
    "encoded",
    "format",
    "less",
    "number",
    "records",
    "let",
    "check",
    "anything",
    "data",
    "set",
    "anyone",
    "wants",
    "things",
    "wants",
    "play",
    "data",
    "set",
    "wants",
    "tear",
    "apart",
    "specific",
    "data",
    "set",
    "let",
    "see",
    "df",
    "dot",
    "final",
    "underscore",
    "df",
    "dot",
    "info",
    "able",
    "see",
    "additional",
    "information",
    "object",
    "fine",
    "duration",
    "still",
    "okay",
    "something",
    "like",
    "convert",
    "duration",
    "something",
    "else",
    "nah",
    "duration",
    "minutes",
    "basically",
    "need",
    "convert",
    "duration",
    "minutes",
    "right",
    "basically",
    "apply",
    "mathematical",
    "formula",
    "um",
    "take",
    "let",
    "say",
    "come",
    "try",
    "guys",
    "try",
    "basically",
    "going",
    "write",
    "duration",
    "oh",
    "way",
    "2",
    "hours",
    "50",
    "minutes",
    "mentioned",
    "also",
    "good",
    "way",
    "um",
    "convert",
    "duration",
    "minutes",
    "would",
    "actually",
    "amazing",
    "okay",
    "basically",
    "going",
    "say",
    "duration",
    "okay",
    "split",
    "zero",
    "basically",
    "means",
    "getting",
    "answer",
    "uh",
    "htr",
    "zero",
    "split",
    "use",
    "blank",
    "space",
    "getting",
    "two",
    "hours",
    "okay",
    "two",
    "hours",
    "two",
    "hours",
    "probably",
    "split",
    "split",
    "h",
    "okay",
    "h",
    "becoming",
    "series",
    "right",
    "dot",
    "split",
    "respect",
    "h",
    "okay",
    "series",
    "split",
    "perfect",
    "like",
    "duration",
    "two",
    "minutes",
    "sir",
    "run",
    "split",
    "h",
    "start",
    "replace",
    "dot",
    "replace",
    "work",
    "see",
    "becomes",
    "series",
    "right",
    "okay",
    "execute",
    "actually",
    "getting",
    "something",
    "like",
    "okay",
    "write",
    "htr",
    "zero",
    "comma",
    "zero",
    "also",
    "work",
    "zero",
    "zero",
    "zero",
    "zero",
    "come",
    "anybody",
    "spring",
    "dot",
    "replace",
    "um",
    "series",
    "okay",
    "series",
    "series",
    "guys",
    "understand",
    "string",
    "dot",
    "something",
    "like",
    "see",
    "go",
    "probably",
    "see",
    "type",
    "definitely",
    "become",
    "series",
    "see",
    "series",
    "search",
    "google",
    "okay",
    "search",
    "google",
    "series",
    "split",
    "pandas",
    "series",
    "pandas",
    "provide",
    "method",
    "split",
    "uh",
    "series",
    "series",
    "hdr",
    "dot",
    "split",
    "dot",
    "htr",
    "dot",
    "split",
    "okay",
    "going",
    "basically",
    "write",
    "htr",
    "dot",
    "split",
    "going",
    "basically",
    "use",
    "h",
    "see",
    "getting",
    "right",
    "basically",
    "write",
    "htr",
    "0",
    "actually",
    "getting",
    "values",
    "multiplied",
    "converted",
    "integer",
    "actually",
    "okay",
    "actually",
    "able",
    "get",
    "information",
    "okay",
    "basically",
    "give",
    "hours",
    "want",
    "convert",
    "minutes",
    "okay",
    "want",
    "basically",
    "convert",
    "minutes",
    "entirely",
    "series",
    "want",
    "convert",
    "minutes",
    "type",
    "yeah",
    "type",
    "work",
    "dot",
    "ask",
    "type",
    "error",
    "coming",
    "probably",
    "work",
    "htr",
    "0",
    "work",
    "let",
    "consider",
    "converting",
    "df",
    "duration",
    "underscore",
    "hour",
    "equal",
    "one",
    "duration",
    "hour",
    "final",
    "underscore",
    "df",
    "execute",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "duration",
    "hour",
    "actually",
    "got",
    "help",
    "duration",
    "hour",
    "able",
    "okay",
    "also",
    "get",
    "minutes",
    "minutes",
    "also",
    "important",
    "actually",
    "going",
    "basically",
    "going",
    "write",
    "final",
    "df",
    "dot",
    "info",
    "want",
    "check",
    "whether",
    "still",
    "object",
    "right",
    "actually",
    "going",
    "basically",
    "going",
    "convert",
    "type",
    "okay",
    "final",
    "underscore",
    "df",
    "hey",
    "guys",
    "also",
    "thing",
    "also",
    "facing",
    "difficulty",
    "face",
    "right",
    "need",
    "think",
    "approach",
    "able",
    "think",
    "approach",
    "obviously",
    "get",
    "solved",
    "uh",
    "error",
    "end",
    "5m",
    "somewhere",
    "somewhere",
    "5m",
    "hope",
    "done",
    "syntax",
    "correct",
    "definitely",
    "5",
    "somewhere",
    "5",
    "ohm",
    "value",
    "final",
    "final",
    "underscore",
    "df",
    "duration",
    "w",
    "equal",
    "5m",
    "final",
    "underscore",
    "df",
    "okay",
    "five",
    "minutes",
    "okay",
    "duration",
    "also",
    "five",
    "minutes",
    "okay",
    "problem",
    "come",
    "five",
    "minutes",
    "mumbai",
    "hyderabad",
    "take",
    "five",
    "minutes",
    "possible",
    "better",
    "drop",
    "drop",
    "features",
    "right",
    "use",
    "equal",
    "one",
    "possible",
    "right",
    "possible",
    "tell",
    "want",
    "remove",
    "alt",
    "halt",
    "duration",
    "okay",
    "duration",
    "total",
    "duration",
    "right",
    "yeah",
    "probably",
    "drop",
    "records",
    "right",
    "okay",
    "tell",
    "drop",
    "records",
    "drop",
    "row",
    "axis",
    "zero",
    "okay",
    "perfect",
    "write",
    "final",
    "underscore",
    "df",
    "dot",
    "drop",
    "basically",
    "going",
    "give",
    "index",
    "number",
    "uh",
    "use",
    "lock",
    "drop",
    "ask",
    "labels",
    "suppose",
    "give",
    "six",
    "four",
    "five",
    "seven",
    "four",
    "comma",
    "axis",
    "equal",
    "zero",
    "able",
    "see",
    "get",
    "executed",
    "right",
    "getting",
    "executed",
    "let",
    "say",
    "n",
    "place",
    "equal",
    "one",
    "thing",
    "probably",
    "two",
    "six",
    "six",
    "zero",
    "two",
    "six",
    "six",
    "zero",
    "plane",
    "receive",
    "type",
    "input",
    "argument",
    "place",
    "expected",
    "type",
    "boolean",
    "oh",
    "place",
    "equal",
    "true",
    "executed",
    "working",
    "fine",
    "go",
    "see",
    "one",
    "actually",
    "getting",
    "empty",
    "okay",
    "actually",
    "fixed",
    "convert",
    "type",
    "done",
    "multiply",
    "multiply",
    "60",
    "see",
    "actually",
    "able",
    "get",
    "form",
    "minutes",
    "let",
    "hour",
    "problem",
    "want",
    "also",
    "fine",
    "least",
    "hours",
    "increase",
    "considering",
    "minute",
    "part",
    "also",
    "try",
    "use",
    "okay",
    "try",
    "convert",
    "given",
    "assignment",
    "please",
    "try",
    "minutes",
    "also",
    "try",
    "get",
    "specific",
    "data",
    "done",
    "minutes",
    "okay",
    "everybody",
    "basically",
    "okay",
    "say",
    "chris",
    "class",
    "going",
    "integer",
    "integer",
    "integer",
    "integer",
    "price",
    "float",
    "additional",
    "info",
    "object",
    "duration",
    "drop",
    "duration",
    "final",
    "underscore",
    "df",
    "dot",
    "drop",
    "okay",
    "duration",
    "axis",
    "equal",
    "1",
    "okay",
    "place",
    "equal",
    "2",
    "done",
    "capital",
    "capital",
    "capital",
    "okay",
    "duration",
    "done",
    "finally",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "one",
    "see",
    "things",
    "remaining",
    "converted",
    "remaining",
    "category",
    "features",
    "order",
    "category",
    "features",
    "one",
    "need",
    "simple",
    "try",
    "first",
    "see",
    "respect",
    "airlines",
    "uh",
    "airline",
    "dot",
    "unique",
    "try",
    "see",
    "many",
    "specific",
    "airline",
    "final",
    "underscore",
    "df",
    "final",
    "underscore",
    "df",
    "see",
    "many",
    "airlines",
    "try",
    "label",
    "encoding",
    "order",
    "label",
    "encoding",
    "write",
    "sk",
    "learn",
    "dot",
    "dot",
    "import",
    "label",
    "encoder",
    "many",
    "people",
    "saying",
    "right",
    "krish",
    "get",
    "dummies",
    "get",
    "dummies",
    "also",
    "done",
    "since",
    "try",
    "work",
    "train",
    "test",
    "data",
    "better",
    "use",
    "transform",
    "techniques",
    "right",
    "going",
    "basically",
    "use",
    "label",
    "encoder",
    "equal",
    "label",
    "encoder",
    "okay",
    "label",
    "encoder",
    "finally",
    "every",
    "data",
    "set",
    "want",
    "like",
    "airline",
    "source",
    "destination",
    "additional",
    "info",
    "four",
    "features",
    "final",
    "underscore",
    "df",
    "basically",
    "write",
    "airline",
    "airline",
    "okay",
    "label",
    "encoder",
    "dot",
    "fit",
    "underscore",
    "transform",
    "basically",
    "going",
    "give",
    "feature",
    "final",
    "underscore",
    "dm",
    "airline",
    "right",
    "like",
    "written",
    "feature",
    "also",
    "like",
    "way",
    "many",
    "features",
    "right",
    "source",
    "source",
    "put",
    "destination",
    "finally",
    "additional",
    "info",
    "done",
    "final",
    "underscore",
    "df",
    "dot",
    "shape",
    "try",
    "see",
    "14",
    "columns",
    "good",
    "enough",
    "want",
    "probably",
    "see",
    "final",
    "disco",
    "day",
    "dot",
    "head",
    "first",
    "two",
    "records",
    "see",
    "things",
    "perfect",
    "okay",
    "done",
    "done",
    "label",
    "encoding",
    "also",
    "type",
    "encoding",
    "one",
    "hot",
    "encoding",
    "okay",
    "guys",
    "done",
    "label",
    "encoding",
    "one",
    "step",
    "one",
    "hot",
    "encoding",
    "sk",
    "learn",
    "dot",
    "import",
    "one",
    "hot",
    "encoder",
    "kevin",
    "uh",
    "get",
    "dummies",
    "see",
    "whenever",
    "test",
    "data",
    "need",
    "transform",
    "test",
    "data",
    "right",
    "save",
    "encoder",
    "form",
    "pickle",
    "file",
    "right",
    "one",
    "hot",
    "encoder",
    "h",
    "e",
    "write",
    "one",
    "hot",
    "encoder",
    "thing",
    "specifically",
    "saying",
    "okay",
    "airline",
    "ohe",
    "dot",
    "fit",
    "transform",
    "okay",
    "necessary",
    "information",
    "done",
    "okay",
    "okay",
    "getting",
    "error",
    "error",
    "expected",
    "2d",
    "array",
    "expected",
    "2d",
    "array",
    "reshape",
    "data",
    "okay",
    "understood",
    "problem",
    "problem",
    "understood",
    "music",
    "give",
    "wait",
    "execute",
    "front",
    "till",
    "see",
    "error",
    "getting",
    "understood",
    "error",
    "transform",
    "c",
    "execute",
    "getting",
    "expected",
    "2d",
    "array",
    "dot",
    "okay",
    "series",
    "dot",
    "dot",
    "dot",
    "dot",
    "dot",
    "dot",
    "dot",
    "h",
    "e",
    "transform",
    "n",
    "p",
    "dot",
    "treble",
    "yeah",
    "np",
    "dot",
    "rival",
    "okay",
    "think",
    "work",
    "error",
    "expected",
    "2d",
    "array",
    "instead",
    "getting",
    "one",
    "understand",
    "give",
    "form",
    "series",
    "okay",
    "problem",
    "definitely",
    "give",
    "form",
    "series",
    "write",
    "final",
    "underscore",
    "df",
    "airline",
    "see",
    "getting",
    "form",
    "series",
    "form",
    "series",
    "use",
    "two",
    "brackets",
    "like",
    "using",
    "oh",
    "becomes",
    "something",
    "else",
    "double",
    "cases",
    "getting",
    "compressed",
    "sparse",
    "row",
    "format",
    "p",
    "dot",
    "array",
    "df",
    "airline",
    "okay",
    "one",
    "way",
    "basically",
    "like",
    "np",
    "dot",
    "array",
    "final",
    "object",
    "dot",
    "reshape",
    "minus",
    "1",
    "comma",
    "1",
    "thing",
    "getting",
    "let",
    "try",
    "airlines",
    "doors",
    "source",
    "destination",
    "uh",
    "additional",
    "info",
    "hope",
    "able",
    "understand",
    "first",
    "one",
    "ambiguous",
    "using",
    "get",
    "shape",
    "zero",
    "ah",
    "one",
    "hot",
    "encoding",
    "already",
    "encoding",
    "done",
    "wait",
    "wait",
    "wait",
    "wait",
    "let",
    "see",
    "final",
    "underscore",
    "df",
    "dot",
    "head",
    "one",
    "hot",
    "encoding",
    "probably",
    "search",
    "one",
    "hot",
    "encoding",
    "sql",
    "let",
    "see",
    "documentation",
    "encoding",
    "many",
    "times",
    "encode",
    "many",
    "times",
    "encoded",
    "one",
    "time",
    "right",
    "encoding",
    "value",
    "get",
    "got",
    "converted",
    "right",
    "go",
    "see",
    "final",
    "underscore",
    "df",
    "final",
    "underscore",
    "df",
    "dot",
    "info",
    "able",
    "see",
    "converted",
    "integer",
    "types",
    "okay",
    "know",
    "done",
    "encoding",
    "separately",
    "like",
    "fit",
    "transform",
    "instead",
    "could",
    "focused",
    "one",
    "hot",
    "encoder",
    "would",
    "done",
    "completely",
    "okay",
    "let",
    "one",
    "thing",
    "simple",
    "working",
    "going",
    "simple",
    "thing",
    "basically",
    "going",
    "final",
    "underscore",
    "df",
    "airline",
    "dot",
    "get",
    "underscore",
    "dummies",
    "get",
    "dummies",
    "okay",
    "pd",
    "dot",
    "get",
    "dummies",
    "right",
    "sometimes",
    "syntax",
    "difficult",
    "remember",
    "syntax",
    "df",
    "airline",
    "final",
    "df",
    "let",
    "go",
    "ahead",
    "able",
    "get",
    "try",
    "create",
    "different",
    "data",
    "frame",
    "let",
    "say",
    "df1",
    "create",
    "another",
    "data",
    "frame",
    "df2",
    "say",
    "underscore",
    "dummies",
    "basically",
    "write",
    "column",
    "final",
    "underscore",
    "df",
    "next",
    "column",
    "wanted",
    "one",
    "column",
    "working",
    "source",
    "destination",
    "additional",
    "info",
    "combine",
    "data",
    "frame",
    "train",
    "data",
    "also",
    "nice",
    "work",
    "like",
    "also",
    "good",
    "way",
    "see",
    "one",
    "single",
    "line",
    "written",
    "final",
    "underscore",
    "df",
    "columns",
    "airline",
    "source",
    "destination",
    "additional",
    "info",
    "sources",
    "additional",
    "info",
    "also",
    "probably",
    "definitely",
    "work",
    "things",
    "done",
    "written",
    "pd",
    "dot",
    "get",
    "dummies",
    "final",
    "underscore",
    "df",
    "columns",
    "name",
    "drop",
    "first",
    "equal",
    "true",
    "execute",
    "values",
    "able",
    "get",
    "thank",
    "great",
    "day",
    "ahead"
  ],
  "keywords": [
    "guys",
    "going",
    "lot",
    "amazing",
    "things",
    "respect",
    "data",
    "set",
    "right",
    "start",
    "please",
    "make",
    "inside",
    "many",
    "show",
    "like",
    "country",
    "code",
    "dot",
    "csv",
    "file",
    "three",
    "use",
    "uh",
    "particular",
    "put",
    "entire",
    "also",
    "let",
    "go",
    "first",
    "import",
    "basic",
    "matplotlib",
    "plot",
    "one",
    "something",
    "called",
    "c",
    "finally",
    "using",
    "understand",
    "thing",
    "whenever",
    "need",
    "think",
    "basically",
    "important",
    "specific",
    "much",
    "information",
    "definitely",
    "able",
    "till",
    "actually",
    "ahead",
    "see",
    "given",
    "format",
    "okay",
    "converted",
    "already",
    "write",
    "convert",
    "try",
    "combine",
    "df",
    "pd",
    "read",
    "underscore",
    "execute",
    "getting",
    "0",
    "4",
    "get",
    "kind",
    "error",
    "always",
    "encoding",
    "probably",
    "somewhere",
    "search",
    "four",
    "different",
    "values",
    "directly",
    "used",
    "check",
    "say",
    "number",
    "columns",
    "features",
    "done",
    "next",
    "step",
    "id",
    "name",
    "city",
    "average",
    "two",
    "currency",
    "white",
    "way",
    "whether",
    "column",
    "null",
    "type",
    "integer",
    "variables",
    "frame",
    "object",
    "means",
    "categorical",
    "variable",
    "may",
    "text",
    "find",
    "coming",
    "come",
    "function",
    "help",
    "feature",
    "count",
    "numerical",
    "give",
    "missing",
    "second",
    "know",
    "categories",
    "order",
    "saying",
    "value",
    "zero",
    "want",
    "work",
    "another",
    "simple",
    "tell",
    "1",
    "instead",
    "map",
    "labels",
    "x",
    "label",
    "bar",
    "take",
    "obviously",
    "records",
    "total",
    "five",
    "head",
    "giving",
    "engineering",
    "equal",
    "copy",
    "focus",
    "additional",
    "last",
    "save",
    "final",
    "everything",
    "types",
    "observations",
    "countries",
    "india",
    "united",
    "observation",
    "maximum",
    "hope",
    "everybody",
    "index",
    "pie",
    "chart",
    "sorry",
    "create",
    "axis",
    "online",
    "top",
    "looks",
    "percentage",
    "colon",
    "3",
    "good",
    "remove",
    "diagram",
    "written",
    "rating",
    "color",
    "group",
    "aggregate",
    "writing",
    "test",
    "red",
    "ratings",
    "colors",
    "reset",
    "people",
    "problem",
    "wait",
    "comma",
    "h",
    "perfect",
    "fine",
    "paste",
    "time",
    "question",
    "true",
    "model",
    "train",
    "statement",
    "purchase",
    "month",
    "age",
    "gender",
    "stay",
    "current",
    "product",
    "category",
    "append",
    "male",
    "plus",
    "unique",
    "drop",
    "place",
    "dummies",
    "apply",
    "2",
    "encoder",
    "transform",
    "year",
    "require",
    "replace",
    "series",
    "split",
    "htr",
    "info",
    "date",
    "airline",
    "journey",
    "source",
    "destination",
    "route",
    "departure",
    "arrival",
    "duration",
    "stops",
    "hour",
    "minutes",
    "hot"
  ]
}