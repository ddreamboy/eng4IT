{
  "text": "hi there I am inside of a Jupiter\nnotebook and I'm once again going to be\nusing my trusty little widget to draw me\na data set that I will use what I'm\ndrawing here is a classification data\nset but there's going to be a Twist what\nyou see here are two circles one inside\nthe other and the goal is to separate\nthe orange dots from the blue ones and\nwhen you look at this your initial\nthinking might be well that's relatively\neasy and you wouldn't be wrong many\nalgorithms inside a s could learn would\ntotally be able to handle something like\nthis but what I'm going to do now is I'm\ngoing to make a small change to this\nclassification problem that suddenly\nwill make it a whole lot harder for a\nwhole lot of algorithms including the\ngradient boosting algorithms the point\nof this video is partially to emphasize\nthat even though gradient boosting\nalgorithms are great they can't be\nshoehorned into every problem out there\nbut there are also many other subm\nmodules of psyched learn that could also\nbe worth exploring that can deal with a\nsituation that I'm about to create for\nthis data set and here's the change that\nI'll be making what you're looking at\nhere is exactly the same data set that I\njust drew we've got the outside Circle\nand we've got the inside Circle and the\noutside Circle has blue points and the\ninside Circle has orange ones the big\ndifference now though is that I'm taking\na very small subset so only a few blue\ndots and only a few orange ones are\ngoing to be in here with this change you\ncould Wonder well how well can we expect\nour class classification approaches to\nstill work it's an interesting thought\nexperiment and feel free to pause the\nvideo to think about that because the\nanswer might surprise you\ninitially so let's start by giving the\nhistogram gradient boosted classifier a\nspin I using this algorithm in the Cell\nBlock below here to fit me a good data\nset and when I scroll down you can see\nthe predictive results when this is the\ninput to the algorithm then this is the\nprediction that the histogram boost of\nclass classifier will make and you'll\nimmediately notice everything is blue\nand that'll be the case even if I were\nto rerun this no matter how often it\nalways seems that only one color comes\nout over here and you might start to\nwonder why that is we can introduce a\nsmall change by maybe sampling some more\npoints but still it seems that the\ndefault settings of the boosted\nalgorithm doesn't really do what we want\nit to and the reason for this is pretty\nsubtle but you can get a small Hint by\njust inspecting the settings notice that\nthere is this Min samples Leaf setting\nover here uh let's copy that and let's\nturn that down maybe to something like\nfive when we do this then we do see that\nsomething indeed is happening now the\nreason why this makes such a difference\nis because the default setting of the\ngradient boosted classifier actually\nassumes that a big data set is going in\nnot some somewhat artificially small\ndata set like what I've got down below\nhere here and if there's a setting like\nthis around with the default of 20 where\nwe're saying well don't make another\nLeaf unless there are more data points\nthan 20 well then it shouldn't be that\nmuch of a surprise that we only get one\nclass out it is just going to take the\nmajority class now alternatively if I\nset the number of samples back to 10 I\ncould also choose to go for another\nalgorithm maybe the K neighbors\nclassifier could do some good here and\njust from eyeballing it does certainly\nseem like it is uh doing something\nbetter just from the get-go but also\nhere we have to mind the some of the\nsettings right now it's looking at the\nnearest five neighbors and for this data\nset you could maybe Wonder maybe two is\nbetter I could even tune it down to\none but all in all also for this use\ncase the results just don't look great\nnow one logical response here would be\nto say well this is really not a whole\nlot of data and most of the\nclassification algorithms may just need\na lot more because in the end\nthey do assume there's a big data set to\nlearn from and especially in this case\none thing that you really see happen\nhere is that we are just overfitting on\nthe nearest neighbor and we're not\nreally paying any attention to the\nstructure of the underlying data simply\nbecause that's not what the algorithm is\nmeant to do but there are algorithms\nthat actually do precisely this the main\nidea here is to rethink the problem by\nsaying that this is perhaps not a\nsupervised machine learning problem but\nmaybe this is a semi super vised machine\nlearning problem and maybe something\nlike label propagation would work a lot\nbetter here in a moment I will show what\nlabel propagation would do to this data\nset but I figured it wouldn't hurt to\nmaybe explain some of the intuition\nbehind it first let's pretend that we\njust have a data set with these six\npoints then one thing I could do is I\ncould consider that maybe the structure\nof the data set even when there's no\nlabels could be approximated by\nconsidering nearest Neighbors\nso the data point to the center over\nhere these would be the closest\nneighbors as far as that one entry point\nis\nconcerned I could do that for this one\npoint but I could also do it for some of\nthe other points so let's also do it for\nthis\none and let's also do it for this\none and I could keep drawing and drawing\nand drawing but hopefully one thing that\nyou recognize here is that I will be\nconstructing a graph of sorts one that's\nkind of directional if I'm at a point\nthere are three places that I can jump\nto and if you've taken a course in\nprobability Theory this may sound like a\nmark of chain of sorts if I were to\ndescribe this mathematically and if I\nwere to give a name to every single\npoint over here then one way of looking\nat it is to say that we've got some sort\nof a transition Matrix where if I have\nall of these points listed over here\nthen I can start filling in some\nprobabilities if I start over at Point a\nthat would be this point\nthen there's a third chance that I might\njump to point D or to point B or to\npoint C I could do the same thing for\npoint B etc etc etc and what I'm going\nto do now is I'm going to give this big\nMatrix a name t t for transition so to\nsay so let's now consider a larger data\nset and again for this large data set\nI'm able to construct some sort of graph\nwith\nneighbors and this would again result in\nsome sort of a transition Matrix T but\nthe interesting thing about this uh\ntransition Matrix is that you can at\nsome point get chunks that are separate\nsuppose that I were a frog and I was\njumping around randomly and I would\nstart over here only jumping over the\nedges that exist then there would simply\nbe no way for me to get over here\nbecause there's no Arc going from one\nset to another one and hopefully you can\nalso see how that might encode something\nabout the data when the data has very\nclear clusters so let's now consider\nwhat might happen if there's also labels\naround so let's pretend that I've got a\ngreen label just for this one point over\nhere and let's say I've got a red label\njust for this point over here well then\none thing I could do is I could come up\nwith some sort of input array X that\nindicates where the green points are\nthere would be a bunch of zeros but\nlet's say that there's a one which\nindicates where this Green Dot with the\nlabel is\nwell then what I could do is I could\nmultiply that with my big Matrix T and\nout of this would come a new array where\nthere would be a third at a few\nplaces and a bunch of zeros elsewhere\nwhich again kind of represent a jump to\nuh the neighbors so to say but you could\nWonder well why stop there I could also\nmultiply by this transition Matrix let's\nsay n times then I would get a different\narray coming out this array would be a\nlot more flat if n is big enough we\nshould at some point mimic some sort of\nlongterm probability assuming that this\nwas like a jumping frog but then this\narray will represent the probability\nwhere the Frog will be anywhere on this\ngraph and where would that be well there\nwill be a uniform Distribution on this\nOuter Circle over here and hopefully you\nrecognize that the same argument would\nalso hold for this red Point by\nresembling this point as an array by\nmultiplying it with this transition\nMatrix T we end up with a probability\ndistribution of sorts that will\nrepresent uniform distribution over all\nthe points within this one cluster over\nhere I suppose I could also put this in\nmore layman's terms you could also just\nlook at this as a graph where all the\nstuff that's close to the original Green\nLabel will just start turning green as\nwell and from there on it just kind of\nstarts to\nspread same thing with this red\npoint it's just that from a a math\nperspective there are also very\nconvenient properties about being able\nto translate this into a matrix that\nbehaves like a marov chain there are\nalso all sorts of details that I could\ngo into with this algorithm but the main\nthing that I hope that you appreciate is\nthat the way that we're going about\nspreading the labels is related to the\nstructure of the graph the points are in\ninitially and that is also why this kind\nof approach is usually called\nsemisupervised a lot of the learning\nhappens in an unsupervised Way With No\nLabel whatsoever but from that we gain\nsome knowledge and that allows us to\njust be able to apply our label\nhopefully more effectively and\nespecially in uh low label kinds of\nscenarios stuff like this can really be\ninformative so given that intuition of\nhow label propagation Works let's now\nmake a comparison this is the result\nusing K nearest neighbors and if I were\nto scroll down now then you see the\nresults using label propagation and you\ncan see in this case it is a near\nperfect classification entirely as what\nyou might expect and again the reason\nwhy this works is because we have these\ntwo sets of data points that will never\nhave an arc going between them when you\nonly have a few nearest Neighbors when\nyou are really just looking at the\nnearest three or five neighbors let's\nsay the odds of there ever being an arc\nthat jumps from the inner circle to the\nOuter Circle is pretty much zero in this\ndata set the label propagation call that\nI'm using here uses K nearest neighbors\nunder the hood to construct the graph\nthat I mentioned earlier but I suppose\none final demo that will be good to show\nis to also show what might happen if I\nchange this data set just\nslightly so I'm just going to draw some\nextra parts like so kind of turn this\ninto a steering wheel of sorts and let's\nsee what happens when this is the new\ndata set that I'm interested in and now\nyou can see that the results are\nactually fairly different and the simple\nreason is we now no longer have two\ncircles that don't touch because the\ncircles now touch each other there's\nalso more doubt in the entire system\nsampling a blue dot over here close to\nthe inner orange circle might actually\ncause the label propagation to believe\nthat there's a lot of blue that should\nbe here so even though label propagation\nas an idea is definitely pretty neat it\nshould also not be seen as a silver\nbullet it can be helpful in situations\nwhere you've got not a whole lot of\nlabel data but a lot of data that does\nhave internal structure but once you are\ndealing with data where there might be\nclusters internally but they do touch a\nlot then you are just going to have to\naccept that you'll need more labels and\nonce you've got more labels then maybe\nlabel propagation isn't what you need\nanymore given a lot of labels then the\nclassical machine learning approaches\nlike the classification algorithms would\nalso be a bunch better\n",
  "words": [
    "hi",
    "inside",
    "jupiter",
    "notebook",
    "going",
    "using",
    "trusty",
    "little",
    "widget",
    "draw",
    "data",
    "set",
    "use",
    "drawing",
    "classification",
    "data",
    "set",
    "going",
    "twist",
    "see",
    "two",
    "circles",
    "one",
    "inside",
    "goal",
    "separate",
    "orange",
    "dots",
    "blue",
    "ones",
    "look",
    "initial",
    "thinking",
    "might",
    "well",
    "relatively",
    "easy",
    "would",
    "wrong",
    "many",
    "algorithms",
    "inside",
    "could",
    "learn",
    "would",
    "totally",
    "able",
    "handle",
    "something",
    "like",
    "going",
    "going",
    "make",
    "small",
    "change",
    "classification",
    "problem",
    "suddenly",
    "make",
    "whole",
    "lot",
    "harder",
    "whole",
    "lot",
    "algorithms",
    "including",
    "gradient",
    "boosting",
    "algorithms",
    "point",
    "video",
    "partially",
    "emphasize",
    "even",
    "though",
    "gradient",
    "boosting",
    "algorithms",
    "great",
    "ca",
    "shoehorned",
    "every",
    "problem",
    "also",
    "many",
    "subm",
    "modules",
    "psyched",
    "learn",
    "could",
    "also",
    "worth",
    "exploring",
    "deal",
    "situation",
    "create",
    "data",
    "set",
    "change",
    "making",
    "looking",
    "exactly",
    "data",
    "set",
    "drew",
    "got",
    "outside",
    "circle",
    "got",
    "inside",
    "circle",
    "outside",
    "circle",
    "blue",
    "points",
    "inside",
    "circle",
    "orange",
    "ones",
    "big",
    "difference",
    "though",
    "taking",
    "small",
    "subset",
    "blue",
    "dots",
    "orange",
    "ones",
    "going",
    "change",
    "could",
    "wonder",
    "well",
    "well",
    "expect",
    "class",
    "classification",
    "approaches",
    "still",
    "work",
    "interesting",
    "thought",
    "experiment",
    "feel",
    "free",
    "pause",
    "video",
    "think",
    "answer",
    "might",
    "surprise",
    "initially",
    "let",
    "start",
    "giving",
    "histogram",
    "gradient",
    "boosted",
    "classifier",
    "spin",
    "using",
    "algorithm",
    "cell",
    "block",
    "fit",
    "good",
    "data",
    "set",
    "scroll",
    "see",
    "predictive",
    "results",
    "input",
    "algorithm",
    "prediction",
    "histogram",
    "boost",
    "class",
    "classifier",
    "make",
    "immediately",
    "notice",
    "everything",
    "blue",
    "case",
    "even",
    "rerun",
    "matter",
    "often",
    "always",
    "seems",
    "one",
    "color",
    "comes",
    "might",
    "start",
    "wonder",
    "introduce",
    "small",
    "change",
    "maybe",
    "sampling",
    "points",
    "still",
    "seems",
    "default",
    "settings",
    "boosted",
    "algorithm",
    "really",
    "want",
    "reason",
    "pretty",
    "subtle",
    "get",
    "small",
    "hint",
    "inspecting",
    "settings",
    "notice",
    "min",
    "samples",
    "leaf",
    "setting",
    "uh",
    "let",
    "copy",
    "let",
    "turn",
    "maybe",
    "something",
    "like",
    "five",
    "see",
    "something",
    "indeed",
    "happening",
    "reason",
    "makes",
    "difference",
    "default",
    "setting",
    "gradient",
    "boosted",
    "classifier",
    "actually",
    "assumes",
    "big",
    "data",
    "set",
    "going",
    "somewhat",
    "artificially",
    "small",
    "data",
    "set",
    "like",
    "got",
    "setting",
    "like",
    "around",
    "default",
    "20",
    "saying",
    "well",
    "make",
    "another",
    "leaf",
    "unless",
    "data",
    "points",
    "20",
    "well",
    "much",
    "surprise",
    "get",
    "one",
    "class",
    "going",
    "take",
    "majority",
    "class",
    "alternatively",
    "set",
    "number",
    "samples",
    "back",
    "10",
    "could",
    "also",
    "choose",
    "go",
    "another",
    "algorithm",
    "maybe",
    "k",
    "neighbors",
    "classifier",
    "could",
    "good",
    "eyeballing",
    "certainly",
    "seem",
    "like",
    "uh",
    "something",
    "better",
    "also",
    "mind",
    "settings",
    "right",
    "looking",
    "nearest",
    "five",
    "neighbors",
    "data",
    "set",
    "could",
    "maybe",
    "wonder",
    "maybe",
    "two",
    "better",
    "could",
    "even",
    "tune",
    "one",
    "also",
    "use",
    "case",
    "results",
    "look",
    "great",
    "one",
    "logical",
    "response",
    "would",
    "say",
    "well",
    "really",
    "whole",
    "lot",
    "data",
    "classification",
    "algorithms",
    "may",
    "need",
    "lot",
    "end",
    "assume",
    "big",
    "data",
    "set",
    "learn",
    "especially",
    "case",
    "one",
    "thing",
    "really",
    "see",
    "happen",
    "overfitting",
    "nearest",
    "neighbor",
    "really",
    "paying",
    "attention",
    "structure",
    "underlying",
    "data",
    "simply",
    "algorithm",
    "meant",
    "algorithms",
    "actually",
    "precisely",
    "main",
    "idea",
    "rethink",
    "problem",
    "saying",
    "perhaps",
    "supervised",
    "machine",
    "learning",
    "problem",
    "maybe",
    "semi",
    "super",
    "vised",
    "machine",
    "learning",
    "problem",
    "maybe",
    "something",
    "like",
    "label",
    "propagation",
    "would",
    "work",
    "lot",
    "better",
    "moment",
    "show",
    "label",
    "propagation",
    "would",
    "data",
    "set",
    "figured",
    "would",
    "hurt",
    "maybe",
    "explain",
    "intuition",
    "behind",
    "first",
    "let",
    "pretend",
    "data",
    "set",
    "six",
    "points",
    "one",
    "thing",
    "could",
    "could",
    "consider",
    "maybe",
    "structure",
    "data",
    "set",
    "even",
    "labels",
    "could",
    "approximated",
    "considering",
    "nearest",
    "neighbors",
    "data",
    "point",
    "center",
    "would",
    "closest",
    "neighbors",
    "far",
    "one",
    "entry",
    "point",
    "concerned",
    "could",
    "one",
    "point",
    "could",
    "also",
    "points",
    "let",
    "also",
    "one",
    "let",
    "also",
    "one",
    "could",
    "keep",
    "drawing",
    "drawing",
    "drawing",
    "hopefully",
    "one",
    "thing",
    "recognize",
    "constructing",
    "graph",
    "sorts",
    "one",
    "kind",
    "directional",
    "point",
    "three",
    "places",
    "jump",
    "taken",
    "course",
    "probability",
    "theory",
    "may",
    "sound",
    "like",
    "mark",
    "chain",
    "sorts",
    "describe",
    "mathematically",
    "give",
    "name",
    "every",
    "single",
    "point",
    "one",
    "way",
    "looking",
    "say",
    "got",
    "sort",
    "transition",
    "matrix",
    "points",
    "listed",
    "start",
    "filling",
    "probabilities",
    "start",
    "point",
    "would",
    "point",
    "third",
    "chance",
    "might",
    "jump",
    "point",
    "point",
    "b",
    "point",
    "c",
    "could",
    "thing",
    "point",
    "b",
    "etc",
    "etc",
    "etc",
    "going",
    "going",
    "give",
    "big",
    "matrix",
    "name",
    "transition",
    "say",
    "let",
    "consider",
    "larger",
    "data",
    "set",
    "large",
    "data",
    "set",
    "able",
    "construct",
    "sort",
    "graph",
    "neighbors",
    "would",
    "result",
    "sort",
    "transition",
    "matrix",
    "interesting",
    "thing",
    "uh",
    "transition",
    "matrix",
    "point",
    "get",
    "chunks",
    "separate",
    "suppose",
    "frog",
    "jumping",
    "around",
    "randomly",
    "would",
    "start",
    "jumping",
    "edges",
    "exist",
    "would",
    "simply",
    "way",
    "get",
    "arc",
    "going",
    "one",
    "set",
    "another",
    "one",
    "hopefully",
    "also",
    "see",
    "might",
    "encode",
    "something",
    "data",
    "data",
    "clear",
    "clusters",
    "let",
    "consider",
    "might",
    "happen",
    "also",
    "labels",
    "around",
    "let",
    "pretend",
    "got",
    "green",
    "label",
    "one",
    "point",
    "let",
    "say",
    "got",
    "red",
    "label",
    "point",
    "well",
    "one",
    "thing",
    "could",
    "could",
    "come",
    "sort",
    "input",
    "array",
    "x",
    "indicates",
    "green",
    "points",
    "would",
    "bunch",
    "zeros",
    "let",
    "say",
    "one",
    "indicates",
    "green",
    "dot",
    "label",
    "well",
    "could",
    "could",
    "multiply",
    "big",
    "matrix",
    "would",
    "come",
    "new",
    "array",
    "would",
    "third",
    "places",
    "bunch",
    "zeros",
    "elsewhere",
    "kind",
    "represent",
    "jump",
    "uh",
    "neighbors",
    "say",
    "could",
    "wonder",
    "well",
    "stop",
    "could",
    "also",
    "multiply",
    "transition",
    "matrix",
    "let",
    "say",
    "n",
    "times",
    "would",
    "get",
    "different",
    "array",
    "coming",
    "array",
    "would",
    "lot",
    "flat",
    "n",
    "big",
    "enough",
    "point",
    "mimic",
    "sort",
    "longterm",
    "probability",
    "assuming",
    "like",
    "jumping",
    "frog",
    "array",
    "represent",
    "probability",
    "frog",
    "anywhere",
    "graph",
    "would",
    "well",
    "uniform",
    "distribution",
    "outer",
    "circle",
    "hopefully",
    "recognize",
    "argument",
    "would",
    "also",
    "hold",
    "red",
    "point",
    "resembling",
    "point",
    "array",
    "multiplying",
    "transition",
    "matrix",
    "end",
    "probability",
    "distribution",
    "sorts",
    "represent",
    "uniform",
    "distribution",
    "points",
    "within",
    "one",
    "cluster",
    "suppose",
    "could",
    "also",
    "put",
    "layman",
    "terms",
    "could",
    "also",
    "look",
    "graph",
    "stuff",
    "close",
    "original",
    "green",
    "label",
    "start",
    "turning",
    "green",
    "well",
    "kind",
    "starts",
    "spread",
    "thing",
    "red",
    "point",
    "math",
    "perspective",
    "also",
    "convenient",
    "properties",
    "able",
    "translate",
    "matrix",
    "behaves",
    "like",
    "marov",
    "chain",
    "also",
    "sorts",
    "details",
    "could",
    "go",
    "algorithm",
    "main",
    "thing",
    "hope",
    "appreciate",
    "way",
    "going",
    "spreading",
    "labels",
    "related",
    "structure",
    "graph",
    "points",
    "initially",
    "also",
    "kind",
    "approach",
    "usually",
    "called",
    "semisupervised",
    "lot",
    "learning",
    "happens",
    "unsupervised",
    "way",
    "label",
    "whatsoever",
    "gain",
    "knowledge",
    "allows",
    "us",
    "able",
    "apply",
    "label",
    "hopefully",
    "effectively",
    "especially",
    "uh",
    "low",
    "label",
    "kinds",
    "scenarios",
    "stuff",
    "like",
    "really",
    "informative",
    "given",
    "intuition",
    "label",
    "propagation",
    "works",
    "let",
    "make",
    "comparison",
    "result",
    "using",
    "k",
    "nearest",
    "neighbors",
    "scroll",
    "see",
    "results",
    "using",
    "label",
    "propagation",
    "see",
    "case",
    "near",
    "perfect",
    "classification",
    "entirely",
    "might",
    "expect",
    "reason",
    "works",
    "two",
    "sets",
    "data",
    "points",
    "never",
    "arc",
    "going",
    "nearest",
    "neighbors",
    "really",
    "looking",
    "nearest",
    "three",
    "five",
    "neighbors",
    "let",
    "say",
    "odds",
    "ever",
    "arc",
    "jumps",
    "inner",
    "circle",
    "outer",
    "circle",
    "pretty",
    "much",
    "zero",
    "data",
    "set",
    "label",
    "propagation",
    "call",
    "using",
    "uses",
    "k",
    "nearest",
    "neighbors",
    "hood",
    "construct",
    "graph",
    "mentioned",
    "earlier",
    "suppose",
    "one",
    "final",
    "demo",
    "good",
    "show",
    "also",
    "show",
    "might",
    "happen",
    "change",
    "data",
    "set",
    "slightly",
    "going",
    "draw",
    "extra",
    "parts",
    "like",
    "kind",
    "turn",
    "steering",
    "wheel",
    "sorts",
    "let",
    "see",
    "happens",
    "new",
    "data",
    "set",
    "interested",
    "see",
    "results",
    "actually",
    "fairly",
    "different",
    "simple",
    "reason",
    "longer",
    "two",
    "circles",
    "touch",
    "circles",
    "touch",
    "also",
    "doubt",
    "entire",
    "system",
    "sampling",
    "blue",
    "dot",
    "close",
    "inner",
    "orange",
    "circle",
    "might",
    "actually",
    "cause",
    "label",
    "propagation",
    "believe",
    "lot",
    "blue",
    "even",
    "though",
    "label",
    "propagation",
    "idea",
    "definitely",
    "pretty",
    "neat",
    "also",
    "seen",
    "silver",
    "bullet",
    "helpful",
    "situations",
    "got",
    "whole",
    "lot",
    "label",
    "data",
    "lot",
    "data",
    "internal",
    "structure",
    "dealing",
    "data",
    "might",
    "clusters",
    "internally",
    "touch",
    "lot",
    "going",
    "accept",
    "need",
    "labels",
    "got",
    "labels",
    "maybe",
    "label",
    "propagation",
    "need",
    "anymore",
    "given",
    "lot",
    "labels",
    "classical",
    "machine",
    "learning",
    "approaches",
    "like",
    "classification",
    "algorithms",
    "would",
    "also",
    "bunch",
    "better"
  ],
  "keywords": [
    "inside",
    "going",
    "using",
    "data",
    "set",
    "drawing",
    "classification",
    "see",
    "two",
    "circles",
    "one",
    "orange",
    "blue",
    "ones",
    "look",
    "might",
    "well",
    "would",
    "algorithms",
    "could",
    "learn",
    "able",
    "something",
    "like",
    "make",
    "small",
    "change",
    "problem",
    "whole",
    "lot",
    "gradient",
    "point",
    "even",
    "though",
    "also",
    "looking",
    "got",
    "circle",
    "points",
    "big",
    "wonder",
    "class",
    "let",
    "start",
    "boosted",
    "classifier",
    "algorithm",
    "good",
    "results",
    "case",
    "maybe",
    "default",
    "settings",
    "really",
    "reason",
    "pretty",
    "get",
    "setting",
    "uh",
    "five",
    "actually",
    "around",
    "another",
    "k",
    "neighbors",
    "better",
    "nearest",
    "say",
    "need",
    "thing",
    "happen",
    "structure",
    "machine",
    "learning",
    "label",
    "propagation",
    "show",
    "consider",
    "labels",
    "hopefully",
    "graph",
    "sorts",
    "kind",
    "jump",
    "probability",
    "way",
    "sort",
    "transition",
    "matrix",
    "etc",
    "suppose",
    "frog",
    "jumping",
    "arc",
    "green",
    "red",
    "array",
    "bunch",
    "represent",
    "distribution",
    "touch"
  ]
}