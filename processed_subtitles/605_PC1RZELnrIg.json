{
  "text": "Welcome back!\nRemember that the goal for\ndimensionality reduction is to find a lower dimensional subspace that you can use to capture much of the structure of your original data.\nSo to understand how this can work, we need to understand how you can represent data in multiple different coordinate systems.\nIn fact there are many ways to represent multivariate data.\nWe can define a basis as a set of N vectors that you can use to construct any point in an N-dimensional vector space.\nWe're used to using a specific choice of basis called the standard basis in which\nyour first basis vector is one unit in the direction of the\nactivity for neuron one and the second basis vector is one unit in the direction of neuron two.\nSo when we say that this point here is equal to\n3,2 what that really means is that we can represent it as a combination of\n3 times the vector u plus 2 times the vector w.\nBut this is not the only basis that we can imagine for this data. So you could rotate\nthese basis vectors and therefore represent this point v as a completely different set of coefficients.\nSo in this case your view would be 3.5 times the vector u minus 1.2 times the vector w.\nThese are both examples of orthogonal basis.\nSo in both this standard basis and this rotated basis, all of the basis vectors are orthogonal to each other.\nYou can also have a basis where the vectors are not orthogonal so here's an example of that. But you can still represent\neach point in the two-dimensional plane as a combination of these two vectors.\nYou can also rescale your basis. So in this case, I'm rescaling the standard basis by increasing u and w.\nSo that v is now equal to 1,1 instead of 3,2.\nThis is an example where the basis vectors are orthogonal but it's not an orthonormal basis.\nBy orthonormal, we mean that the basis is orthogonal and all basis vectors have a length of 1,\nand we can measure the length as the square root of the sum of the squared values of the entries.\nIt's worth noting that if you already have an orthogonal basis, then you can very easily normalize it by\ndividing each basis vector by its magnitude.\nSo now the question is how do you tell if your two basis vectors are orthogonal to each other.\nSo you can test this using the dot product which is a scalar quantity.\nSo it's just a number and it's a function of two vectors, so u dot w is defined\nas the magnitude of u times the magnitude of w times the cosine of the angle between them.\nAnd what happens if It is at a right angle?\nSo if they're perpendicular or orthogonal then the cosine is equal to zero,\nso that means that the dot product is zero. And in fact two vectors are defined as orthogonal\nexactly when the dot product is equal to zero.\nBut does this mean that we need to always look for the angle between any two vectors to find out if they're orthogonal?\nThankfully there is another formulation of the dot product.\nSo this is the algebraic definition and it turns out that these are actually equivalent definitions if you use some trigonometric\nidentities to prove it. So u dot w can also be written as the sum of ui times wi.\nThat's much easier to calculate especially in a vector format.\nSo if u and w are both column vectors then u dot w is u transpose times w.\nSo this is a much easier way to test if two vectors are orthogonal is by taking u transpose times w.\n",
  "words": [
    "welcome",
    "back",
    "remember",
    "goal",
    "dimensionality",
    "reduction",
    "find",
    "lower",
    "dimensional",
    "subspace",
    "use",
    "capture",
    "much",
    "structure",
    "original",
    "data",
    "understand",
    "work",
    "need",
    "understand",
    "represent",
    "data",
    "multiple",
    "different",
    "coordinate",
    "systems",
    "fact",
    "many",
    "ways",
    "represent",
    "multivariate",
    "data",
    "define",
    "basis",
    "set",
    "n",
    "vectors",
    "use",
    "construct",
    "point",
    "vector",
    "space",
    "used",
    "using",
    "specific",
    "choice",
    "basis",
    "called",
    "standard",
    "basis",
    "first",
    "basis",
    "vector",
    "one",
    "unit",
    "direction",
    "activity",
    "neuron",
    "one",
    "second",
    "basis",
    "vector",
    "one",
    "unit",
    "direction",
    "neuron",
    "two",
    "say",
    "point",
    "equal",
    "really",
    "means",
    "represent",
    "combination",
    "3",
    "times",
    "vector",
    "u",
    "plus",
    "2",
    "times",
    "vector",
    "basis",
    "imagine",
    "data",
    "could",
    "rotate",
    "basis",
    "vectors",
    "therefore",
    "represent",
    "point",
    "v",
    "completely",
    "different",
    "set",
    "coefficients",
    "case",
    "view",
    "would",
    "times",
    "vector",
    "u",
    "minus",
    "times",
    "vector",
    "examples",
    "orthogonal",
    "basis",
    "standard",
    "basis",
    "rotated",
    "basis",
    "basis",
    "vectors",
    "orthogonal",
    "also",
    "basis",
    "vectors",
    "orthogonal",
    "example",
    "still",
    "represent",
    "point",
    "plane",
    "combination",
    "two",
    "vectors",
    "also",
    "rescale",
    "basis",
    "case",
    "rescaling",
    "standard",
    "basis",
    "increasing",
    "u",
    "v",
    "equal",
    "instead",
    "example",
    "basis",
    "vectors",
    "orthogonal",
    "orthonormal",
    "basis",
    "orthonormal",
    "mean",
    "basis",
    "orthogonal",
    "basis",
    "vectors",
    "length",
    "1",
    "measure",
    "length",
    "square",
    "root",
    "sum",
    "squared",
    "values",
    "entries",
    "worth",
    "noting",
    "already",
    "orthogonal",
    "basis",
    "easily",
    "normalize",
    "dividing",
    "basis",
    "vector",
    "magnitude",
    "question",
    "tell",
    "two",
    "basis",
    "vectors",
    "orthogonal",
    "test",
    "using",
    "dot",
    "product",
    "scalar",
    "quantity",
    "number",
    "function",
    "two",
    "vectors",
    "u",
    "dot",
    "w",
    "defined",
    "magnitude",
    "u",
    "times",
    "magnitude",
    "w",
    "times",
    "cosine",
    "angle",
    "happens",
    "right",
    "angle",
    "perpendicular",
    "orthogonal",
    "cosine",
    "equal",
    "zero",
    "means",
    "dot",
    "product",
    "zero",
    "fact",
    "two",
    "vectors",
    "defined",
    "orthogonal",
    "exactly",
    "dot",
    "product",
    "equal",
    "zero",
    "mean",
    "need",
    "always",
    "look",
    "angle",
    "two",
    "vectors",
    "find",
    "orthogonal",
    "thankfully",
    "another",
    "formulation",
    "dot",
    "product",
    "algebraic",
    "definition",
    "turns",
    "actually",
    "equivalent",
    "definitions",
    "use",
    "trigonometric",
    "identities",
    "prove",
    "u",
    "dot",
    "w",
    "also",
    "written",
    "sum",
    "ui",
    "times",
    "wi",
    "much",
    "easier",
    "calculate",
    "especially",
    "vector",
    "format",
    "u",
    "w",
    "column",
    "vectors",
    "u",
    "dot",
    "w",
    "u",
    "transpose",
    "times",
    "much",
    "easier",
    "way",
    "test",
    "two",
    "vectors",
    "orthogonal",
    "taking",
    "u",
    "transpose",
    "times",
    "w"
  ],
  "keywords": [
    "find",
    "use",
    "much",
    "data",
    "understand",
    "need",
    "represent",
    "different",
    "fact",
    "basis",
    "set",
    "vectors",
    "point",
    "vector",
    "using",
    "standard",
    "one",
    "unit",
    "direction",
    "neuron",
    "two",
    "equal",
    "means",
    "combination",
    "times",
    "u",
    "v",
    "case",
    "orthogonal",
    "also",
    "example",
    "orthonormal",
    "mean",
    "length",
    "sum",
    "magnitude",
    "test",
    "dot",
    "product",
    "w",
    "defined",
    "cosine",
    "angle",
    "zero",
    "easier",
    "transpose"
  ]
}