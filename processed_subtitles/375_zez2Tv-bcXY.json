{
  "text": "hello everyone this is sort of from area\nRekha and in today's session will focus\non Big Data\nI have rational I will also be sharing\nour knowledge about big data with us\nwelcome Reshma hi sorrow and hello\neveryone I hope you'll all find this\nsession interesting and informative even\nI hope so\nso let's move forward and have a look at\nthe agenda so this is what we'll be\ndiscussing today we'll begin by\nunderstanding how data evolved that is\nhow big data came into existence then\nwe'll see what exactly is big data we'll\nunderstand what sort of data can be\nconsidered as big data after that we'll\nsee how big data can be an opportunity\nnow obviously big data is an opportunity\nbut we know that there are no free\nlunches in life so we'll focus on the\nvarious problems associated in encasing\nthis opportunity and it won't be fair if\nI tell you only about the problems and\nnot the solution therefore we'll see how\nHadoop solve this problems and we'll dig\na bit deep and understand about few\ncomponents of this Hadoop framework and\nfinally we'll tell you about the big\ndata and hadoop training provided by Ed\nEureka we'll also see the various\nprojects that will be a part of this\ncourse now I feel sort of it's the best\ntime to tell the story about how data\nevolved and how big data came fine\nracemaster will move forward so sort of\nwhat can you notice you wish my see how\ntechnology has evolved earlier we had\nlandline phones but now we have\nsmartphones we have Android we have iOS\nthat are making a life smarter as other\nphone smarter\napart from that we were also using bulky\ndesktops for processing MB of data now\nif you can remember we were using\nfloppies and you know how much data it\ncan store right then came hard disk for\nstoring TVs of data and now we can store\ndata on cloud as well and similarly\nnowadays even self-driving cars have\ncome up I know you must be thinking why\nare we telling that now if you notice\ndue to this enhancement of technology\nwe're generating a lot of data so let's\ntake the example of your phones have you\never noticed how much data is generated\ndue to your fancy smart phones your\nevery action even one video that is sent\nthrough whatsapp or any other messenger\napp that generates data\nnow this is just an example you have no\nidea how much data you're generating\nbecause of every action you do melody\nlist this data is not in a format that\nour relational database can handle and\napart from that even the volume of data\nhas also increased exponentially now I\nwas talking about self-driving cars so\nbasically this cars have sensors that\nrecords every my new details like the\nsize of the obstacle the distance from\nthe obstacle and many more and then it\ndecides how to react now you can imagine\nhow much data is generated for each\nkilometer that you drive on that car\nI completely agree with Eurasia so let's\nmove forward and focus on various other\nfactors behind the evolution of data I\nthink you guys must have heard about IOT\nif you can recall the previous slide we\nwere discussing about self-driving cars\nit is nothing but an example of IOT let\nme tell you what exactly it is IOT\nconnect your physical device with\nInternet and makes the device smarter so\nnowadays you have noticed we have smart\nACS TVs etc so we'll take the example of\nsmart air conditioners so this device\nactually monitors your body temperature\nand the outside temperature and\naccordingly decides what should be the\ntemperature of the room now in order to\ndo this it has to first accumulate the\ndata from where it can accumulate data\nfrom Internet through sensors that are\nmonitoring your body temperature and the\nsurroundings so basically from various\nsources that you might not even know\nabout it is actually fetching that data\nand accordingly it decides what should\nbe the temperature of your room now we\ncan actually see that because of IOT we\nare generating a huge amount of data now\nthere is one start also that is there in\nfront of your screen so you can notice\nby 2020 we will have 50 billion IOT\ndevices so I don't thinks I need to\nexplain much that how IOT is generating\nhuge amount of data so we'll move\nforward and focus on one more factor\nthat is social media now when we talk\nabout social media I think race might\ncan explain this better right Reshma\nyes aura but I'm pretty sure that even\nyou use it so let me tell you that\nsocial media is actually one of the most\nimportant factor in the evolution of big\ndata so nowadays everyone is using\nFacebook Instagram YouTube and a lot of\nother social media websites\nso this social media sites have so much\ndata for example it will have your\npersonal details like your name age and\napart from that even each picture that\nyou like or react to also generates data\nand even the Facebook pages that you go\naround liking that is also generating\ndata and nowadays you can see that most\npeople are sharing videos on Facebook so\nthat is also generating a huge amount of\ndata and the most challenging part here\nis that the data is not present in a\nstructured manner and at the same time\nit is huge in size\nisn't that right sort of Karnik remove\nthe point you made about the form of\ndata is actually one of the biggest\nfactor for the evolution of big data so\ndo you do all these reasons that we have\ndiscussed i have not only increased the\namount of data but it has also shown us\nthat data is actually getting generated\nin various format for example data is\ngenerated with videos that is actually\nunstructured same goes for images as\nwell so there are numerous or you can\nsay millions of ways in which data is\nthat getting generated nowadays\nabsolutely and these are just few\nexamples that we have given you there\nare many other driving factors for the\nevolution of data so these are a few\nmore examples because of which data is\nevolving and converting to Big Data when\ndiscuss about the detailed part I'm\npretty sure that all of you must have\nvisited websites like Amazon Flipkart\netc and reshma I know you visited a lot\nof times yeah I do\nI suppose Rachel wants to buy shoes so\nshe won't just directly go buy shoes\nshe's so it's for a lot of shoes so\nsomewhere her search history will be\nstored and I know for sure that this\nwon't be the first time that she's\nbuying something so there'll be her\npurchase history as well along with her\npersonal details so there are numerous\nways in which she might not even know\nthat she's generating data and obviously\nAmazon was not present earlier so at\nthat time there is no way that such user\nmodel data was invaded similarly the\ndata has evolved due to other reasons as\nwell like banking and finance media and\nentertainment etc etc so now the deal is\nwhat exactly is Big Data\nhow do we consider a data as big data so\nlet's move forward and understand what\nexactly it is okay now let us look at\nthe proper definition of Big Data even\nthough we've put forward\nour own definitions already so far\navoiding to take us through it yes a\nSmasher so Big Data is a term for\ncollection of data set so large and\ncomplex that it becomes difficult to\nprocess using on-hand database system\ntools or traditional data processing\napplications okay so what I understand\nfrom this is that our traditional\nsystems are a problem because they're\ntoo old-fashioned to process this data\nor something\nno Reshma the real problem is there is\ntoo much data to process when the\ntraditional systems were invented in the\nbeginning we never anticipated that we\nwould have to deal with such enormous\nmodel of the data it's like a disease\ninfected on you you don't change your\nbody orientation when you get infected\nwith a disease right ratio you cure it\nwith medicines Curtin agree more sort of\nnow the question is how do we consider\nsome data as big data how do we classify\nsome data as big data how do we know\nwhich kind of data is going to be hard\nfor us a process well sort of we have\nthe five V's to tell us that so let's\ntake a closer look at what are those so\nstarting with the first V it's the\nvolume of data it's tremendously large\nso if you look at the stats here you can\nsee the volume of data is rising\nexponentially so now we are dealing with\njust 4.4 zettabytes of data and by 2020\njust in three years is expected that the\ndata will rise up to 44 zettabytes which\nis like equal to 44 trillion gigabytes\nso that's really really huge it is\nbecause all these humongous all this\namongest data is coming from multiple\nsources and that is the second way which\nis nothing but variety we deal with so\nmany different kinds of files at all\nonce there are mp3 files videos days on\nCSV TSV and many more now these are all\nstructured unstructured and\nsemi-structured all together now let me\nexplain you this with a diagram that is\nthere on your screen so over here we\nhave audio we have video files we have\nPNG files we have JSON log files emails\nvarious formats of data now this data is\nclassified into three forms one is\nstructured format now in structured\nformat you have a proper schema for your\ndata so you know what all\nwe'll be there and basically you know\nthe scheme about your data set is\nstructured it is in a structured format\nor we can say in a tabular format now\nwhen we talk about semi structured files\nthese are nothing but JSON XML and CSV\nfiles where schema is not defined\nproperly now when I go to unstructured\nformat we have blob files they're audio\nfiles videos and images so these are all\nconsidered as unstructured files and\nsorry\nit is also because of the speed of\naccumulation of all this variety of data\naltogether which brings us to our third\nV which is velocity so if you look here\nearlier we were using mainframe systems\nhuge computers but less data because\nthere are less people working with\ncomputers at that time but as computers\nevolved and we came to the client-server\nmodel the time came for the web\napplications and the internet boom and\nas it grew among the masses the web\napplications got increased over the\ninternet and everyone started using all\nthis applications not only from their\ncomputers and also from mobile devices\nso more users more appliances more apps\nand hence a lot of data and then you\ntalk about people generating data our\ninternet base not the one kind of\napplication that strikes first in a -\nsocial media so you tell me how much\ndata you submit alone with your\nInstagram posts and stories it will be\nquite a boast if I only talk about\nmyself here so let's talk including\nevery social media user so if you see\nthe stats in front of your screen you\ncan see that for every 60 seconds there\nare 100,000 tweets actually more than\n100,000 tweets generated in Twitter\nevery minute similarly there are six\nhundred ninety five thousand status\nupdates on Facebook we talk about\nmessaging there are 11 million messages\ngenerated every minute and similarly\nthere are six hundred and ninety eight\nthousand four hundred forty-five Google\nsearches 168 million emails and that\nequals to almost 1820 terabytes of data\nand obviously the number of mobile users\nare also increasing every minute and\nthere are 217 plus new mobile users\nevery 60 seconds geez that's a lot of\ndata I\nyou want to go ahead and calculate the\ntotal it would actually scare me yeah\nthat's a lot now the bigger problem is\nhow to extract the useful data from here\nand that's when we come to a next we\nthat is value so over here what happens\nfirst you need to mind the useful\ncontent from your data basically you\nneed to make sure that you have only\nuseful peas in your data set\nafter that you perform certain analytics\nor you say you perform certain analysis\non that data that you have cleaned and\nyou need to make sure that whatever\nanalysis you have done it is of some\nvalue that is it will help you in your\nbusiness to grow it can basically find\nout certain insights which were not\npossible earlier so you need to make\nsure that whatever big data that has\nbeen generated or whatever data that has\nbeen generated it makes sense it will\nactually help your business to grow and\nit has some value to it now getting the\nvalue of this data is one big challenge\nlet me tell you why and that brings us\nto our next we which is velocity now\nthis big data has a lot of\ninconsistencies obviously when you're\ndumping such huge amount of data some\ndata packets are bound to lose in the\nprocess now what we need to do we need\nto fill up these missing data and then\nstart mining again and then process it\nand then come up with a good insight if\npossible so if you can notice there's a\ndiagram in front of your screen so over\nhere we have this field which is not\ndefined similarly this field and if you\ncan notice here when we talk about this\nminimum value you see the other minimum\nvalues and when you talk about this it\nis it is very more than the other fields\npresent in this particular column\nsimilarly goes for this particular\nelement as well okay so obviously\nprocessing data like this is one\nproblematic thing and now I get it why\nbig data is a problem statement well we\nhave only five is now but maybe later on\nwe'll have more so there are good\nchances that big data might be even more\nbig okay so there are a lot of problems\nin dealing with big data but there are\nalways different ways to look at\nsomething so let us get some positivity\nin the environment now and let us\nunderstand how can we use big data as an\nopportunity yes a Sh'ma and I would say\nthe situation is similar to the proverb\nor when life throws you lemons may\nlemonade yeah so let us go through the\nfields where we can use big data as a\nboon and there are certain unknown\nproblem solved only cuz we started\ndealing with big data and the boon that\nyou're talking about Reshma is big data\nanalytics first thing with big data we\nfigured out how to store our data\ncost-effectively we were spending too\nmuch money on storage before until big\ndata came into the picture we never\nthought of using commodity hardware to\nstore and manage the data which is both\nreliable and feasible as compared to the\ncostly servers now let me give you a few\nexamples in order to show you how\nimportant big data analytics is nowadays\nso when you go to a website like Amazon\nor YouTube or Pandora Netflix any other\nwebsite so they'll actually provide you\ncertain fees in which they'll recommend\nsome products or some videos or some\nmovies or some songs for you right so\nhow do you think they do that so\nbasically whatever data that you are\ngenerating on these kind of websites\nthey make sure that they analyze it\nproperly and let me tell you guys that\ndata is not small it is actually big\ndata now they analyze that big data and\nthey make sure that whatever you like or\nwhatever your preferences are\naccordingly they generate\nrecommendations for you and when I go to\nyoutube I don't know if you guys must\nhave noticed it but I'm pretty sure you\nmust have done that so when I go to\nYouTube YouTube knows what song or what\nvideo that I want to watch next\nsimilarly Netflix knows what kind of\nmovies are like and when I go to Amazon\nit actually shows me what all products\nthat I would prefer to buy right so how\ndo you think it happens it happens only\nbecause of big data analytics okay so\nthere is one more example that just\npopped into my mind I'll share with you\nguys so there's this time when the\nhurricane sandy was about to hit on New\nJersey in the United States so what\nhappened then the Walmart used big data\nanalytics to profit from it now I'll\ntell you how they did it so what Walmart\ndid is that they studied the purchase\npatterns of different customers when a\nhurricane is about to strike or any kind\nof natural calamity is about to strike\non a particular area and when they made\nan analysis of it so they found out that\npeople tend to buy emergency stuff like\nflashlight lifejackets\na little bit of other stuff and\ninterestingly people also buy a lot of\nstrawberry pop-tarts strawberry tarts\nare you serious yeah and now I didn't do\nthat analysis I Walmart did that and\napparently it is true so what they did\nis they stuffed all their stores with a\nlot of strawberry pop-tarts and\nemergency stuff and obviously it was\nsold out and they earned a lot of money\nduring that time but my question here is\n- people want to die eating strawberry\npop-tarts like what was the idea behind\nstrawberry pop-tarts I'm pretty unsure\nabout it but yeah since you have given\nus a very interesting example and\nWalmart did that analysis we didn't do\nit so yeah so it is a very good example\nin order to understand how big data\nanalytics can help your business to grow\nand find better insights from the data\nthat you have yeah and also if you want\nto know why strawberry pop-tarts maybe\nlater on we can start making an analysis\nby gathering some more data also yeah\nthat can be possible ok so now let's\nmove ahead and take a look at a case\nstudy by IBM how they have used big data\nanalytics to profit their company so if\nyou have noticed that earlier the data\nthat was collected from the meters that\nyou have in your home that measures the\nelectricity consumed it is actually\nsending data after one month but\nnowadays what IBM did they came up with\nthis thing called smart meter and that\nsmart meter used to collect data after\nevery 15 minutes so whatever energy that\nyou have consumed after every 50 minutes\nit will send that data and because of it\nbig data was generated so we have some\nstarts here it says that we have 96\nmillion reads per day for every million\nmeters which is pretty huge this data\nthe amount of data that is generated is\npretty huge\nnow IBM actually realized the data that\nthey're generating it is very important\nfor them to gain something from that\ndata so for that what they needed for\nthat what they need to do they need to\nmake sure that they analyze this data so\nthey realize that big data analytics can\nsolve a lot of problems and they can get\nbetter business insight through that so\nlet us move forward and see what type of\nanalysis they did on that data so before\nanalyzing that data they came to know\nthat energy utilization and billing was\nonly increasing\nnow after analyzing big data they came\nto know that during peak load the users\nrequire more energy and during off-peak\ntimes that users require less energy so\nwhat advantage they must have got from\nthis analysis one thing that I can think\nof right now is they can tell the\nindustries to use their machinery only\nduring the off-peak times so that the\nload will be pretty much balanced and\nyou can even say that time-of-use\npricing encourages cost severe e-tail\nlike industrial heavy machines to be\nused off-peak type so yeah take it save\nmoney as well because off-peak times\npricing will be less than the peak time\nprices right so this is just one\nanalysis now let us move forward and see\nthe IBM suite that they developed so\nover here what happens you first dump\nall your data that you get in this data\nwarehouse after that it is very\nimportant to make sure that your user\ndata is secure then what happens you\nneed to clean that data as I've told you\nearlier as well there might be many fees\nthat you don't require so you need to\nmake sure that you have only useful\nmaterial or useful data in your data set\nand then you perform certain analysis\nand in order to use this suite that IBM\noffered you efficiently you have to take\ncare of a few things the first thing is\nthat you have to be able to manage the\nsmart meter data now there is a lot of\ndata coming from all these million smart\nmeters so you have to be able to manage\nthat large volume of data and also be\nable to retain it because maybe in later\non you might need it for some kind of\nregulatory requirements or something and\nnext thing you should keep in mind is to\nmonitor the distribution grid so that\nyou can improve and optimize the overall\ngrid reliability so that it can identify\nthe abnormal conditions which are\ncausing any kind of problem and then you\nalso have to take care of optimizing the\nunit commitment so by optimizing the\nunit commitment the companies can\nsatisfy their customers even more they\ncan reduce the power outages that is\nthey can reduce the power outages so\nthat their customers don't get angry\nmore identify problems and then reduce\nit obviously and then you have also to\noptimize the energy trading so it means\nthat you can advise your customers when\nthey should use their appliances in\norder to maintain that balance\nin the power load and then you also have\nto forecast and schedule loads so\ncompanies must be able to predict when\nthey can profitably sell the excess\npower and when they need to hedge the\nsupply and continuing from this now\nlet's talk about how encore have made\nuse of the i-beam solution so encore is\nan electric delivery company and it is\nthe largest electrical distribution and\ntransmission company in Texas and it is\none of the six largest in the United\nStates they have more than three million\ncustomers and their service area covers\nalmost 117 thousand square miles and\nthey begin the advanced feeder program\nin 2008 and they have deployed almost\nthree point two five million meters\nserving customers of North and Central\nTexas so when they were implementing it\nthey kept three things in mind the first\nthing was that it should be instrumented\nso this solution utilizes the smart\nelectricity meters so that they can\naccurately measure the electricity usage\nof a household in every 15 minutes\nbecause like we discussed that the smart\nmeters were sending out data every 15\nminutes and it provided data inputs that\nis essential for consumption insights\nnext thing is that it should be\ninterconnected so now the customers have\naccess to the detail information about\nthe electricity they are consuming and\nit creates a very enterprise-wide view\nof all the meter assets and it helped\nthem to improve the service delivery the\nnext thing is to make your customers\nintelligent now since it is getting\nmonitored already about how each of the\nhousehold or each customer is consuming\nthe power so now they are able to advise\nthe customers about maybe to tell them\nto wash their clothes at night because\nthey're using a lot of appliances during\nthe data and so maybe they could divide\nit up so that they can use some\nappliances at off-peak hours so that\nthey can even save more money and this\nis beneficial for both of them for both\nthe customers and the company as well\nand they have gained a lot of benefits\nby using the IBM solution so what are\nthe benefits they got is that it enabled\non\nor to identifying six outages before the\ncustomers get inconvenience that means\nthey were able to identify the problem\nbefore it even occurred and it also\nimproved the emergency response on\nevents of severe weather events and\nviews of outages and it also provides\nthe customers the data needed to become\nof active participant in the power\nconsumption management and it enables\nevery individual household to reduce\ntheir electrical consumption by almost\nfive to ten percent and this is how\nencore use the IBM solution and made\nhuge benefits out of it just by using\nbig data analytics that IBM performed\nbut let me just interrupt right now so\nsince ray Smart told us in the beginning\nas well that there are no free lunches\nin life right so this is an opportunity\nbut there are many problems to encase\nthis opportunity right so let us focus\non those problems one by one so the\nfirst problem is storing colossal amount\nof data so let us discuss these stars\nthat are there in front of your screen\nso data is a riddle in past two years is\nmore than the previous history in total\nso guys what are we doing stop\ngenerating so much amount of data I said\nthat by 2020 total digital data will\ngrow to 44 zettabytes approximately and\nthis one will start that amazes me is\nabout 1.7 MB of new information will be\ncreated every second for every person by\n2020 so storing this huge data in\ntraditional system is not possible the\nreason is obvious the storage will be\nlimited for one system for example you\nhave a server with a storage limit of 10\nterabytes but your company is growing\nreally fast and data is exponentially\nincreasing now what do you do now at one\npoint you exhaust all the storage so\ninvesting in youth servers is definitely\nnot a cost-effective solution so ratio\nwhat do you think what can be the\nsolution to this problem according to me\na distributed file system will be a\nbetter way to store this huge data\nbecause with this we'll be saving a lot\nof money let me tell you how because due\nto this distributed system you can\nactually store your data in commodity\nhardware instead of spending money on\nhigh-end servers\ndon't you agree Thoreau completely now\nVito storing is a problem but let me\ntell you guys it is just one part of the\nproblem\nlet's see few more okay so since we saw\nthat the data is not only huge but it is\npresent in various formats as well like\nunstructured semi-structured and\nstructured so you not only need to store\nthis huge data but you also need to make\nsure that a system is present to store\nthis varieties of data generated from\nvarious sources and now let's focus on\nthe next problem now let's focus on the\ndiagram so over here you can notice that\nthe hard disk capacity is increasing but\nthe distance of performance or speed is\nnot increasing at that rate let me\nexplain you this with an example if you\nhave only 100 Mbps input-output channel\nand you're processing say one terabyte\nof data now how much time will it take\nmaybe calculate it'll be somewhere\naround two point nine one hours right so\nwill be somewhere around two point nine\nMenards and I have taken an example of\none terabytes what if you're processing\nsome zettabyte of data so you can\nimagine how much time will it take now\nwhat if you have a four input output\nchannels for the same amount of data\nthen it will take approximately 0.72\nhours or convert into minutes so it'll\nbe around 43 minutes approximately right\nand now imagine instead of 1tb you have\ndata bytes of data for me modern storage\naccessing and processing speed for huge\ndata is a bigger problem\nokay so Reshma has a very good example\nto discuss yeah so since you are talking\nabout accessing the data and you told us\nalready about how Amazon at different\nwebsites and YouTube they make those\nrecommendations so if there was no\nsolution for it it would take so much\ntime to access the data the\nrecommendation system won't work at all\nand they make a lot of money just for a\nrecommendation system because a lot of\npeople go there and click over there and\nbuy that product right so let's consider\nthat that it is taking like hours or\nmaybe years of time in order to process\nmy that big amount of data so let's say\nthat at one time I purchased an iPhone\n5s from\nand after two years I'm again browsing\nonto Amazon and since it took so much\ntime to access the data and I've already\nswitched over to a new iPhone and they\nare recommending me the old iPhone case\nfor 5s obviously that won't work I\nwouldn't go there and click it because\nI've already changed my phone right so\nthat will be a huge problem for Amazon\nthe recommendation system wouldn't work\nanymore and I know that very smart\nchanges respond every year so if she has\nbought a phone and people are\nrecommending LCS Bora for now and\nsomeone's recommending the case so that\nphone after 2 years doesn't make sense\nto me at all\nyeah only it'll work if I have both the\ntwo phones at the same time but yeah I\ndon't want to waste money on purchasing\nnew iPhone case for my older phone so\nbasically it won't be fair if we don't\ndiscuss the solution to these problems\nRachel we can't leave our viewers with\njust a problem so it won't be fair what\nis the solution\nHadoop Hadoop is a solution so let's\nintroduce Hadoop now ok so now what is\nHadoop so Hadoop is a framework that\nallows you to first store big data in a\ndistributed environment so that it can\nprocess it parallely there are basically\ntwo parts one is HDFS that is Hadoop\ndistributed file system for storage it\nallows you to store data of various\nformats across a cluster and the second\npart is MapReduce now it is nothing but\na processing unit of Hadoop it allows\nparallel processing of data that is\nstored across the HDFS now let us dig\ndeep in HDFS and understand it better\nyeah so HDFS creates an abstraction of\nresources let me simplify it for you so\nsimilar to virtualization you can see\nHDFS logically as a single unit for\nstoring big data but actually restoring\nyour data across multiple systems or you\ncan say in a distributed fashion so here\nyou have a master/slave architecture in\nwhich the name node is a master node and\nthe data nodes are slaves and the name\nnode contains the metadata about the\ndata that is stored in the data\nlike which data block is stored in which\ndata node where are the replications of\nthe data block captain etc etc so the\nactual data is stored in the data nodes\nand I also want to add that we actually\nreplicate the data blocks that is\npresent in the data nodes and by default\nthe replication factor is 3 so it means\nthat there are 3 copies of each file so\nso I'm going to tell us why do we need\nthat replication shell reshma since we\nare using commodity Hardware right and\nwe know failure rate of these hardware's\nare pretty high so if one of the data\nloads fail I won't have that data block\nand that's the reason we need to\nreplicate the data block now this\nreplication factor depends on your\nrequirements right now let us understand\nhow actually Hadoop provided the\nsolution to the big data problems that\nwe have discussed so race my can you\nremember what was the first problem yeah\nit was storing the big data\nso how HDFS solved it let's discuss it\nso HDFS provides a distributed way to\nstore big data we've already told you\nthat so your data is stored in blocks in\ndata nodes and you then specify the size\nof each block so basically if you have a\n512 MB of data and you've configured\nHDFS such that it will create 128\nmegabytes of data blocks so HDFS will so\nHDFS will divide the data in four blocks\nbecause 512 divided by 128 is 4 and it\nrestored across different data nodes and\nit will also replicate the data blocks\non the different data nodes so now we\nare using commodity Hardware and storing\nis not a challenge so what are your\nthoughts on it sorted I will also add\none thing Reshma it also solves the\nscaling problem it focuses on horizontal\nscaling instead of vertical now you can\nalways add some extra data nodes to your\nHDFS cluster as and when required\ninstead of scaling the resources of your\ndata nodes so you're not actually\nincreasing the resources of your data\nnodes you're just adding few more data\nnodes when you require\nlet me summarize it for you so basically\nfor storing 1 TB of data I don't need a\n1 TB system I can instead do it on\nmultiple 128 GB systems or even less\nnow Reshma one of the second challenge\nwith big data so the next problem was\nstoring variety of data and that problem\nwas also addressed by HDFS\nso with HDFS you can store all kinds of\ndata whether it's structured\nsemi-structured or unstructured it is\nbecause in HDFS there is no pre dumping\nschema validation so you can just dump\nall the kinds of data that you have in\none place and it also follows a right\nones and read many model and due to this\nyou can just write the data once and you\ncan read it multiple times for finding\nout insights and if you can recall the\nthird challenge was accessing the data\nfaster and this is one of the major\nchallenge with big data and in order to\nsolve it we're moving processing to data\nand not data to processing so what it\nmeans sort of just go ahead and explain\nit yes a survival so over here let me\nexplain you what do you mean by actually\nmoving process to data so consider this\nas a master and these are our slaves so\nthe data is stored in these slaves so\nwhat happens one way of processing this\ndata is what I can do is I can send this\ndata to my master node and I can process\nit over here but what will happen if all\nof my slaves will send the data to my\nmaster node it will cause network\ncongestion plus input output channel\ncongestion and at the same time my\nmaster node will take a lot of time in\norder to process this user monitored so\nwhat I can do I can send this process to\ndata that means I can send the logic to\nall these slaves which actually contain\nthe data and perform processing in the\nmaze itself so after that what will\nhappen the small chunks of the result\nthat will come out will be sent to our\nname node so in that way there won't be\nany network congestion or input-output\ncongestion and it will take\ncomparatively very less time so this is\nwhat actually means sending process to\ndata so I hope you all not clear with\nthis I hope you even raise my square and\nclear all right good to hear that so\nlet's move forward and focus on few\ncomponents of Hadoop so we look at the\nHadoop ecosystem so you can see that\nthis is the entire Hadoop eco\nsystem so there are a lot of tools that\nwe use so there you can see that we have\nflume and scoop and they are used to\ningest data into HDFS now we have\nalready seen what HDFS is so there is\none more component which is known as\nyarn and you can consider yarn as the\nbrain of your Hadoop ecosystem it\nperforms all your processing activities\nand it allocates resources and schedules\ndifferent tasks now apart from these\ncomponents there are many other\ncomponents as well so I'll just give you\na brief introduction about these\ncomponents we have pig and I which are\nnothing but the analytics tool hive is\nintroduced by Facebook and pig was\nintroduced by Yahoo now the language\nthat is user is called Pig Latin and\nover here we use high quality language\nwhich is very similar to sequel the\nstory behind hive is very very\ninteresting I want to share this so\nbasically Facebook wanted some tool in\norder to perform queries on the huge\nchunks of data so what they did they\nintroduced height so with the help of\nhive they can actually use the same\nemployees which no sequel and they can\nperform analytics on a huge set of data\nthat is big data apart from that we have\nSparky's will which is used for near\nreal-time processing and in order to\nperform machine learning we have a\ncomponent in spark itself that is called\nml lip and even ma hood now when we talk\nabout MapReduce we all know what exactly\nMapReduce is it is basically Java\nprograms only that are used to process\nyour big data now when I talk about\nApache HBase now HDFS is a file system\nand what is HBase HBase is nothing but a\nno sequel database on top of HDFS now\nlet's move forward and focus on few\nimportant components among these now\nHadoop we all know what exactly Hadoop\nis what is hive a box a hive is nothing\nbut a data warehousing tool that allows\nyou to perform big data analytics using\nhigh square E and this language is very\nsimilar to sequel and I've told you the\nstory also behind it by Facebook\nactually implemented now when we talk\nabout a power chip Pig it is again an\nanalytics tool which is used to analyze\nlarge set of data representing them as\ndata flows spark is nothing but\nin-memory data processing engine that\nallows us to efficiently execute\nstreaming machine learning sequel\nworkloads and requires pass\ncreative access to data set so basically\nstreaming and all those things in which\nyou require near real-time processing\nyou can integrate spark with Hadoop what\nis a space it is nothing but a no sequel\ndatabase present on top of your HDFS\nPyne system so this is all about Hadoop\nand Big Data now the point is how ad\nRaigarh can help you become a big data\nand hadoop expert now let's move forward\nand understand the big data and hadoop\ntraining provided by Ed Eureka big data\nHadoop certification training so Eddy\nRica provides a structured program in\norder to make you a certified Hadoop\ndeveloper now before I explain you the\nstructure of the program let me tell you\nguys that Eddy rekha provides 24/7\nsupport team so if you have any\nquestions doubts at any point of time\nyou can contact them apart from that\nwherever you pay for the course you get\naccess to elements now what is elements\nLMS is nothing but learning management\nsystem so all of your class recordings\nyour PDS your presentations will be\nthere in your LMS and you get the access\nto LMS for life style let me tell you\nyou get it for lifetime so once you're\neven done with the course and you want\nto take it again you can do that as well\nso you come back after ten years also if\nyou want to learn Hadoop we will put you\nin a live patch so basically you get\neverything for lifetime so let's focus\non the structure of the program so it\nstarts with basics and it covers all the\nadvanced portion of Big Data Hadoop as\nwell so the first module you'll be\nlearning about what exactly Big Data and\nHadoop is and various concepts just the\nintroductory module then comes the\nconcepts of hdf and MapReduce this how\ndoes the architecture looks like in all\nthose things and then in the third\nmodule you'll understand how to actually\nset up a Ducasse cluster and how this\narchitecture looks like in the fourth\nmodule you'll be dealing with MapReduce\nprogram then the fifth module to learn\ndata loading techniques then comes the\nsixth module now in six modules you will\nbe introduced to analytics tools like\nPig and height and I told you earlier as\nwell why we use Pig in height then comes\nHBase which is nothing but a no sequel\ndatabase on top of HDFS after that we\nhave hoozy then we'll look at various\nbest practices for hadoop developing now\ncomes\nspark now let me tell you we won't\ndiscuss tumor\nabout spark in this course Eddie Vega\nhas a separate course in spot but still\nwe have included the introduction of\nspark in in Big Data Hadoop Isabel\nyou'll also learn how to work in r DD in\nspa and finally you'll be working on\nreal-life project on big data analytics\nso once you're done with this project on\nthe basis of how you have done it you\nwill be getting grades in your\ncertificate so you'll get a certificate\nonly when you are done with the project\nand we have multiple projects so it's\nnot like once you were done with one\nproject you cannot take up the other\nproject you can do that as well you can\ntake multiple projects you can just\nrequest for multiple projects and\ndefinitely they'll give it to you but at\nleast one project you need to finish in\norder to get the certification so we'll\nmove forward and Rachel will give you an\nintroduction of what all projects are\npart of this course yeah so these are\nsome of the projects that you can choose\nto work on so the first one you can see\nthat it is to analyze social bookmarking\nsites now I'll tell you a little bit\nabout that so here you have to work with\nthe social media data so the data here\nwas comprised of the information\ngathered from sites like Reddit comm\nStumbleUpon com etc so these are\nbookmarking sites and they allow you to\nbookmark review rate and search various\nlinks on any kind of topic so the data\nis an XML format and it contains various\nkind of links post URLs and different\ncategories defining it and the ratings\nare linked with it so what you have to\ndo is that you have to analyze the data\nin the Hadoop ecosystem so that you can\nfetch data into the HDFS and analyze it\nwith the help of MapReduce Pig and hives\nto find out the top-rated links based on\nuser comments likes etc so this is the\nproblem statement so you have to analyze\nthe entire data they also post in this\nkind of sites and you have to find the\ntop post according to the likes and\ncomments so this is what you have to do\nsimilarly we have other projects like\nthe customer complaint analysis so this\nis related to the retail industry\nsimilarly you have tourism data analysis\nwhich is related to some tourism data\nfacts and you have airline data analysis\nthe loan data set which is related to\nbanking and finance movie ratings which\nis the media data\nthat so even choose any of the projects\nfrom it so you can give it a try and\ncome up with a solution for all these\nproblems and if any time you get stumble\nupon something and you're stuck with\nsomething we have our support team which\nis 24/7 available you could call us\nanytime and they will help you with that\nso Reshma I was thinking how about we\ngive a brief summary report of things we\nhave discussed and now yes our that\nwould be great so we should just go\nahead and provide a summary so we\nstarted with how data evolved and how\nBig Data came into existence we saw\nvarious factors that actually led to Big\nData then we focus on five B's so\nbasically in order to consider any data\nas big data we need to consider these\nfive B's and one of those five is reshma\nfirst we saw the volume of data than we\nsaw variety velocity value and finally\nveracity all right fine then we focused\non big data as an opportunity we\ndiscussed quite a lot of examples and\nI'm still unclear why people are buying\nstrawberry pop-tarts during hurricanes\nbut that's not the point\nbut don't worry sorry we'll find out\nthat answer for you all right so after\nthose examples we saw a case study of\nIBM then we shifted our focus towards\nthe problems that are associated with\nbig data now obviously it is an\nopportunity but in order in case that\nopportunity you need to come up with a\nsolution to all these problems and what\nwas the solution raised well\nthe solution was Hadoop and we have seen\nhow to use HDFS and MapReduce in order\nto solve those problems and we finally\nwe discussed about the curriculum the\nHadoop curriculum in ed Eureka the kind\nof projects that you can choose and what\nall you'll be learning in this course\nall right fine so by this we come to the\nend of today's session\nthank you race MA for joining us it was\npleasure having you in today's\ndiscussion\nthank you sorrow I enjoyed it a lot as\nwell alright fine guys so this video\nwill be uploaded into your LMS so you\ncan go through it if you have any\nquestions about you can ask our 24/7\nsupport team or you can bring your\ndoubts in the next session as well and\nlet me tell you guys this was just an\nintroductory video to Big Data and\nHadoop the real course will start from\nthe next session thank you and have a\ngreat day\nI hope you enjoyed listening to this\nvideo please be kind enough to like it\nand\ncan comment any of your doubts and\nqueries and we will reply to them at the\nearliest to look out for more videos in\nour playlist and subscribe to our at\nRica channel to learn more happy\nlearning\n",
  "words": [
    "hello",
    "everyone",
    "sort",
    "area",
    "rekha",
    "today",
    "session",
    "focus",
    "big",
    "data",
    "rational",
    "also",
    "sharing",
    "knowledge",
    "big",
    "data",
    "us",
    "welcome",
    "reshma",
    "hi",
    "sorrow",
    "hello",
    "everyone",
    "hope",
    "find",
    "session",
    "interesting",
    "informative",
    "even",
    "hope",
    "let",
    "move",
    "forward",
    "look",
    "agenda",
    "discussing",
    "today",
    "begin",
    "understanding",
    "data",
    "evolved",
    "big",
    "data",
    "came",
    "existence",
    "see",
    "exactly",
    "big",
    "data",
    "understand",
    "sort",
    "data",
    "considered",
    "big",
    "data",
    "see",
    "big",
    "data",
    "opportunity",
    "obviously",
    "big",
    "data",
    "opportunity",
    "know",
    "free",
    "lunches",
    "life",
    "focus",
    "various",
    "problems",
    "associated",
    "encasing",
    "opportunity",
    "wo",
    "fair",
    "tell",
    "problems",
    "solution",
    "therefore",
    "see",
    "hadoop",
    "solve",
    "problems",
    "dig",
    "bit",
    "deep",
    "understand",
    "components",
    "hadoop",
    "framework",
    "finally",
    "tell",
    "big",
    "data",
    "hadoop",
    "training",
    "provided",
    "ed",
    "eureka",
    "also",
    "see",
    "various",
    "projects",
    "part",
    "course",
    "feel",
    "sort",
    "best",
    "time",
    "tell",
    "story",
    "data",
    "evolved",
    "big",
    "data",
    "came",
    "fine",
    "racemaster",
    "move",
    "forward",
    "sort",
    "notice",
    "wish",
    "see",
    "technology",
    "evolved",
    "earlier",
    "landline",
    "phones",
    "smartphones",
    "android",
    "ios",
    "making",
    "life",
    "smarter",
    "phone",
    "smarter",
    "apart",
    "also",
    "using",
    "bulky",
    "desktops",
    "processing",
    "mb",
    "data",
    "remember",
    "using",
    "floppies",
    "know",
    "much",
    "data",
    "store",
    "right",
    "came",
    "hard",
    "disk",
    "storing",
    "tvs",
    "data",
    "store",
    "data",
    "cloud",
    "well",
    "similarly",
    "nowadays",
    "even",
    "cars",
    "come",
    "know",
    "must",
    "thinking",
    "telling",
    "notice",
    "due",
    "enhancement",
    "technology",
    "generating",
    "lot",
    "data",
    "let",
    "take",
    "example",
    "phones",
    "ever",
    "noticed",
    "much",
    "data",
    "generated",
    "due",
    "fancy",
    "smart",
    "phones",
    "every",
    "action",
    "even",
    "one",
    "video",
    "sent",
    "whatsapp",
    "messenger",
    "app",
    "generates",
    "data",
    "example",
    "idea",
    "much",
    "data",
    "generating",
    "every",
    "action",
    "melody",
    "list",
    "data",
    "format",
    "relational",
    "database",
    "handle",
    "apart",
    "even",
    "volume",
    "data",
    "also",
    "increased",
    "exponentially",
    "talking",
    "cars",
    "basically",
    "cars",
    "sensors",
    "records",
    "every",
    "new",
    "details",
    "like",
    "size",
    "obstacle",
    "distance",
    "obstacle",
    "many",
    "decides",
    "react",
    "imagine",
    "much",
    "data",
    "generated",
    "kilometer",
    "drive",
    "car",
    "completely",
    "agree",
    "eurasia",
    "let",
    "move",
    "forward",
    "focus",
    "various",
    "factors",
    "behind",
    "evolution",
    "data",
    "think",
    "guys",
    "must",
    "heard",
    "iot",
    "recall",
    "previous",
    "slide",
    "discussing",
    "cars",
    "nothing",
    "example",
    "iot",
    "let",
    "tell",
    "exactly",
    "iot",
    "connect",
    "physical",
    "device",
    "internet",
    "makes",
    "device",
    "smarter",
    "nowadays",
    "noticed",
    "smart",
    "acs",
    "tvs",
    "etc",
    "take",
    "example",
    "smart",
    "air",
    "conditioners",
    "device",
    "actually",
    "monitors",
    "body",
    "temperature",
    "outside",
    "temperature",
    "accordingly",
    "decides",
    "temperature",
    "room",
    "order",
    "first",
    "accumulate",
    "data",
    "accumulate",
    "data",
    "internet",
    "sensors",
    "monitoring",
    "body",
    "temperature",
    "surroundings",
    "basically",
    "various",
    "sources",
    "might",
    "even",
    "know",
    "actually",
    "fetching",
    "data",
    "accordingly",
    "decides",
    "temperature",
    "room",
    "actually",
    "see",
    "iot",
    "generating",
    "huge",
    "amount",
    "data",
    "one",
    "start",
    "also",
    "front",
    "screen",
    "notice",
    "2020",
    "50",
    "billion",
    "iot",
    "devices",
    "thinks",
    "need",
    "explain",
    "much",
    "iot",
    "generating",
    "huge",
    "amount",
    "data",
    "move",
    "forward",
    "focus",
    "one",
    "factor",
    "social",
    "media",
    "talk",
    "social",
    "media",
    "think",
    "race",
    "might",
    "explain",
    "better",
    "right",
    "reshma",
    "yes",
    "aura",
    "pretty",
    "sure",
    "even",
    "use",
    "let",
    "tell",
    "social",
    "media",
    "actually",
    "one",
    "important",
    "factor",
    "evolution",
    "big",
    "data",
    "nowadays",
    "everyone",
    "using",
    "facebook",
    "instagram",
    "youtube",
    "lot",
    "social",
    "media",
    "websites",
    "social",
    "media",
    "sites",
    "much",
    "data",
    "example",
    "personal",
    "details",
    "like",
    "name",
    "age",
    "apart",
    "even",
    "picture",
    "like",
    "react",
    "also",
    "generates",
    "data",
    "even",
    "facebook",
    "pages",
    "go",
    "around",
    "liking",
    "also",
    "generating",
    "data",
    "nowadays",
    "see",
    "people",
    "sharing",
    "videos",
    "facebook",
    "also",
    "generating",
    "huge",
    "amount",
    "data",
    "challenging",
    "part",
    "data",
    "present",
    "structured",
    "manner",
    "time",
    "huge",
    "size",
    "right",
    "sort",
    "karnik",
    "remove",
    "point",
    "made",
    "form",
    "data",
    "actually",
    "one",
    "biggest",
    "factor",
    "evolution",
    "big",
    "data",
    "reasons",
    "discussed",
    "increased",
    "amount",
    "data",
    "also",
    "shown",
    "us",
    "data",
    "actually",
    "getting",
    "generated",
    "various",
    "format",
    "example",
    "data",
    "generated",
    "videos",
    "actually",
    "unstructured",
    "goes",
    "images",
    "well",
    "numerous",
    "say",
    "millions",
    "ways",
    "data",
    "getting",
    "generated",
    "nowadays",
    "absolutely",
    "examples",
    "given",
    "many",
    "driving",
    "factors",
    "evolution",
    "data",
    "examples",
    "data",
    "evolving",
    "converting",
    "big",
    "data",
    "discuss",
    "detailed",
    "part",
    "pretty",
    "sure",
    "must",
    "visited",
    "websites",
    "like",
    "amazon",
    "flipkart",
    "etc",
    "reshma",
    "know",
    "visited",
    "lot",
    "times",
    "yeah",
    "suppose",
    "rachel",
    "wants",
    "buy",
    "shoes",
    "wo",
    "directly",
    "go",
    "buy",
    "shoes",
    "lot",
    "shoes",
    "somewhere",
    "search",
    "history",
    "stored",
    "know",
    "sure",
    "wo",
    "first",
    "time",
    "buying",
    "something",
    "purchase",
    "history",
    "well",
    "along",
    "personal",
    "details",
    "numerous",
    "ways",
    "might",
    "even",
    "know",
    "generating",
    "data",
    "obviously",
    "amazon",
    "present",
    "earlier",
    "time",
    "way",
    "user",
    "model",
    "data",
    "invaded",
    "similarly",
    "data",
    "evolved",
    "due",
    "reasons",
    "well",
    "like",
    "banking",
    "finance",
    "media",
    "entertainment",
    "etc",
    "etc",
    "deal",
    "exactly",
    "big",
    "data",
    "consider",
    "data",
    "big",
    "data",
    "let",
    "move",
    "forward",
    "understand",
    "exactly",
    "okay",
    "let",
    "us",
    "look",
    "proper",
    "definition",
    "big",
    "data",
    "even",
    "though",
    "put",
    "forward",
    "definitions",
    "already",
    "far",
    "avoiding",
    "take",
    "us",
    "yes",
    "smasher",
    "big",
    "data",
    "term",
    "collection",
    "data",
    "set",
    "large",
    "complex",
    "becomes",
    "difficult",
    "process",
    "using",
    "database",
    "system",
    "tools",
    "traditional",
    "data",
    "processing",
    "applications",
    "okay",
    "understand",
    "traditional",
    "systems",
    "problem",
    "process",
    "data",
    "something",
    "reshma",
    "real",
    "problem",
    "much",
    "data",
    "process",
    "traditional",
    "systems",
    "invented",
    "beginning",
    "never",
    "anticipated",
    "would",
    "deal",
    "enormous",
    "model",
    "data",
    "like",
    "disease",
    "infected",
    "change",
    "body",
    "orientation",
    "get",
    "infected",
    "disease",
    "right",
    "ratio",
    "cure",
    "medicines",
    "curtin",
    "agree",
    "sort",
    "question",
    "consider",
    "data",
    "big",
    "data",
    "classify",
    "data",
    "big",
    "data",
    "know",
    "kind",
    "data",
    "going",
    "hard",
    "us",
    "process",
    "well",
    "sort",
    "five",
    "v",
    "tell",
    "us",
    "let",
    "take",
    "closer",
    "look",
    "starting",
    "first",
    "v",
    "volume",
    "data",
    "tremendously",
    "large",
    "look",
    "stats",
    "see",
    "volume",
    "data",
    "rising",
    "exponentially",
    "dealing",
    "zettabytes",
    "data",
    "2020",
    "three",
    "years",
    "expected",
    "data",
    "rise",
    "44",
    "zettabytes",
    "like",
    "equal",
    "44",
    "trillion",
    "gigabytes",
    "really",
    "really",
    "huge",
    "humongous",
    "amongest",
    "data",
    "coming",
    "multiple",
    "sources",
    "second",
    "way",
    "nothing",
    "variety",
    "deal",
    "many",
    "different",
    "kinds",
    "files",
    "mp3",
    "files",
    "videos",
    "days",
    "csv",
    "tsv",
    "many",
    "structured",
    "unstructured",
    "together",
    "let",
    "explain",
    "diagram",
    "screen",
    "audio",
    "video",
    "files",
    "png",
    "files",
    "json",
    "log",
    "files",
    "emails",
    "various",
    "formats",
    "data",
    "data",
    "classified",
    "three",
    "forms",
    "one",
    "structured",
    "format",
    "structured",
    "format",
    "proper",
    "schema",
    "data",
    "know",
    "basically",
    "know",
    "scheme",
    "data",
    "set",
    "structured",
    "structured",
    "format",
    "say",
    "tabular",
    "format",
    "talk",
    "semi",
    "structured",
    "files",
    "nothing",
    "json",
    "xml",
    "csv",
    "files",
    "schema",
    "defined",
    "properly",
    "go",
    "unstructured",
    "format",
    "blob",
    "files",
    "audio",
    "files",
    "videos",
    "images",
    "considered",
    "unstructured",
    "files",
    "sorry",
    "also",
    "speed",
    "accumulation",
    "variety",
    "data",
    "altogether",
    "brings",
    "us",
    "third",
    "v",
    "velocity",
    "look",
    "earlier",
    "using",
    "mainframe",
    "systems",
    "huge",
    "computers",
    "less",
    "data",
    "less",
    "people",
    "working",
    "computers",
    "time",
    "computers",
    "evolved",
    "came",
    "model",
    "time",
    "came",
    "web",
    "applications",
    "internet",
    "boom",
    "grew",
    "among",
    "masses",
    "web",
    "applications",
    "got",
    "increased",
    "internet",
    "everyone",
    "started",
    "using",
    "applications",
    "computers",
    "also",
    "mobile",
    "devices",
    "users",
    "appliances",
    "apps",
    "hence",
    "lot",
    "data",
    "talk",
    "people",
    "generating",
    "data",
    "internet",
    "base",
    "one",
    "kind",
    "application",
    "strikes",
    "first",
    "social",
    "media",
    "tell",
    "much",
    "data",
    "submit",
    "alone",
    "instagram",
    "posts",
    "stories",
    "quite",
    "boast",
    "talk",
    "let",
    "talk",
    "including",
    "every",
    "social",
    "media",
    "user",
    "see",
    "stats",
    "front",
    "screen",
    "see",
    "every",
    "60",
    "seconds",
    "tweets",
    "actually",
    "tweets",
    "generated",
    "twitter",
    "every",
    "minute",
    "similarly",
    "six",
    "hundred",
    "ninety",
    "five",
    "thousand",
    "status",
    "updates",
    "facebook",
    "talk",
    "messaging",
    "11",
    "million",
    "messages",
    "generated",
    "every",
    "minute",
    "similarly",
    "six",
    "hundred",
    "ninety",
    "eight",
    "thousand",
    "four",
    "hundred",
    "google",
    "searches",
    "168",
    "million",
    "emails",
    "equals",
    "almost",
    "1820",
    "terabytes",
    "data",
    "obviously",
    "number",
    "mobile",
    "users",
    "also",
    "increasing",
    "every",
    "minute",
    "217",
    "plus",
    "new",
    "mobile",
    "users",
    "every",
    "60",
    "seconds",
    "geez",
    "lot",
    "data",
    "want",
    "go",
    "ahead",
    "calculate",
    "total",
    "would",
    "actually",
    "scare",
    "yeah",
    "lot",
    "bigger",
    "problem",
    "extract",
    "useful",
    "data",
    "come",
    "next",
    "value",
    "happens",
    "first",
    "need",
    "mind",
    "useful",
    "content",
    "data",
    "basically",
    "need",
    "make",
    "sure",
    "useful",
    "peas",
    "data",
    "set",
    "perform",
    "certain",
    "analytics",
    "say",
    "perform",
    "certain",
    "analysis",
    "data",
    "cleaned",
    "need",
    "make",
    "sure",
    "whatever",
    "analysis",
    "done",
    "value",
    "help",
    "business",
    "grow",
    "basically",
    "find",
    "certain",
    "insights",
    "possible",
    "earlier",
    "need",
    "make",
    "sure",
    "whatever",
    "big",
    "data",
    "generated",
    "whatever",
    "data",
    "generated",
    "makes",
    "sense",
    "actually",
    "help",
    "business",
    "grow",
    "value",
    "getting",
    "value",
    "data",
    "one",
    "big",
    "challenge",
    "let",
    "tell",
    "brings",
    "us",
    "next",
    "velocity",
    "big",
    "data",
    "lot",
    "inconsistencies",
    "obviously",
    "dumping",
    "huge",
    "amount",
    "data",
    "data",
    "packets",
    "bound",
    "lose",
    "process",
    "need",
    "need",
    "fill",
    "missing",
    "data",
    "start",
    "mining",
    "process",
    "come",
    "good",
    "insight",
    "possible",
    "notice",
    "diagram",
    "front",
    "screen",
    "field",
    "defined",
    "similarly",
    "field",
    "notice",
    "talk",
    "minimum",
    "value",
    "see",
    "minimum",
    "values",
    "talk",
    "fields",
    "present",
    "particular",
    "column",
    "similarly",
    "goes",
    "particular",
    "element",
    "well",
    "okay",
    "obviously",
    "processing",
    "data",
    "like",
    "one",
    "problematic",
    "thing",
    "get",
    "big",
    "data",
    "problem",
    "statement",
    "well",
    "five",
    "maybe",
    "later",
    "good",
    "chances",
    "big",
    "data",
    "might",
    "even",
    "big",
    "okay",
    "lot",
    "problems",
    "dealing",
    "big",
    "data",
    "always",
    "different",
    "ways",
    "look",
    "something",
    "let",
    "us",
    "get",
    "positivity",
    "environment",
    "let",
    "us",
    "understand",
    "use",
    "big",
    "data",
    "opportunity",
    "yes",
    "would",
    "say",
    "situation",
    "similar",
    "proverb",
    "life",
    "throws",
    "lemons",
    "may",
    "lemonade",
    "yeah",
    "let",
    "us",
    "go",
    "fields",
    "use",
    "big",
    "data",
    "boon",
    "certain",
    "unknown",
    "problem",
    "solved",
    "cuz",
    "started",
    "dealing",
    "big",
    "data",
    "boon",
    "talking",
    "reshma",
    "big",
    "data",
    "analytics",
    "first",
    "thing",
    "big",
    "data",
    "figured",
    "store",
    "data",
    "spending",
    "much",
    "money",
    "storage",
    "big",
    "data",
    "came",
    "picture",
    "never",
    "thought",
    "using",
    "commodity",
    "hardware",
    "store",
    "manage",
    "data",
    "reliable",
    "feasible",
    "compared",
    "costly",
    "servers",
    "let",
    "give",
    "examples",
    "order",
    "show",
    "important",
    "big",
    "data",
    "analytics",
    "nowadays",
    "go",
    "website",
    "like",
    "amazon",
    "youtube",
    "pandora",
    "netflix",
    "website",
    "actually",
    "provide",
    "certain",
    "fees",
    "recommend",
    "products",
    "videos",
    "movies",
    "songs",
    "right",
    "think",
    "basically",
    "whatever",
    "data",
    "generating",
    "kind",
    "websites",
    "make",
    "sure",
    "analyze",
    "properly",
    "let",
    "tell",
    "guys",
    "data",
    "small",
    "actually",
    "big",
    "data",
    "analyze",
    "big",
    "data",
    "make",
    "sure",
    "whatever",
    "like",
    "whatever",
    "preferences",
    "accordingly",
    "generate",
    "recommendations",
    "go",
    "youtube",
    "know",
    "guys",
    "must",
    "noticed",
    "pretty",
    "sure",
    "must",
    "done",
    "go",
    "youtube",
    "youtube",
    "knows",
    "song",
    "video",
    "want",
    "watch",
    "next",
    "similarly",
    "netflix",
    "knows",
    "kind",
    "movies",
    "like",
    "go",
    "amazon",
    "actually",
    "shows",
    "products",
    "would",
    "prefer",
    "buy",
    "right",
    "think",
    "happens",
    "happens",
    "big",
    "data",
    "analytics",
    "okay",
    "one",
    "example",
    "popped",
    "mind",
    "share",
    "guys",
    "time",
    "hurricane",
    "sandy",
    "hit",
    "new",
    "jersey",
    "united",
    "states",
    "happened",
    "walmart",
    "used",
    "big",
    "data",
    "analytics",
    "profit",
    "tell",
    "walmart",
    "studied",
    "purchase",
    "patterns",
    "different",
    "customers",
    "hurricane",
    "strike",
    "kind",
    "natural",
    "calamity",
    "strike",
    "particular",
    "area",
    "made",
    "analysis",
    "found",
    "people",
    "tend",
    "buy",
    "emergency",
    "stuff",
    "like",
    "flashlight",
    "lifejackets",
    "little",
    "bit",
    "stuff",
    "interestingly",
    "people",
    "also",
    "buy",
    "lot",
    "strawberry",
    "strawberry",
    "tarts",
    "serious",
    "yeah",
    "analysis",
    "walmart",
    "apparently",
    "true",
    "stuffed",
    "stores",
    "lot",
    "strawberry",
    "emergency",
    "stuff",
    "obviously",
    "sold",
    "earned",
    "lot",
    "money",
    "time",
    "question",
    "people",
    "want",
    "die",
    "eating",
    "strawberry",
    "like",
    "idea",
    "behind",
    "strawberry",
    "pretty",
    "unsure",
    "yeah",
    "since",
    "given",
    "us",
    "interesting",
    "example",
    "walmart",
    "analysis",
    "yeah",
    "good",
    "example",
    "order",
    "understand",
    "big",
    "data",
    "analytics",
    "help",
    "business",
    "grow",
    "find",
    "better",
    "insights",
    "data",
    "yeah",
    "also",
    "want",
    "know",
    "strawberry",
    "maybe",
    "later",
    "start",
    "making",
    "analysis",
    "gathering",
    "data",
    "also",
    "yeah",
    "possible",
    "ok",
    "let",
    "move",
    "ahead",
    "take",
    "look",
    "case",
    "study",
    "ibm",
    "used",
    "big",
    "data",
    "analytics",
    "profit",
    "company",
    "noticed",
    "earlier",
    "data",
    "collected",
    "meters",
    "home",
    "measures",
    "electricity",
    "consumed",
    "actually",
    "sending",
    "data",
    "one",
    "month",
    "nowadays",
    "ibm",
    "came",
    "thing",
    "called",
    "smart",
    "meter",
    "smart",
    "meter",
    "used",
    "collect",
    "data",
    "every",
    "15",
    "minutes",
    "whatever",
    "energy",
    "consumed",
    "every",
    "50",
    "minutes",
    "send",
    "data",
    "big",
    "data",
    "generated",
    "starts",
    "says",
    "96",
    "million",
    "reads",
    "per",
    "day",
    "every",
    "million",
    "meters",
    "pretty",
    "huge",
    "data",
    "amount",
    "data",
    "generated",
    "pretty",
    "huge",
    "ibm",
    "actually",
    "realized",
    "data",
    "generating",
    "important",
    "gain",
    "something",
    "data",
    "needed",
    "need",
    "need",
    "make",
    "sure",
    "analyze",
    "data",
    "realize",
    "big",
    "data",
    "analytics",
    "solve",
    "lot",
    "problems",
    "get",
    "better",
    "business",
    "insight",
    "let",
    "us",
    "move",
    "forward",
    "see",
    "type",
    "analysis",
    "data",
    "analyzing",
    "data",
    "came",
    "know",
    "energy",
    "utilization",
    "billing",
    "increasing",
    "analyzing",
    "big",
    "data",
    "came",
    "know",
    "peak",
    "load",
    "users",
    "require",
    "energy",
    "times",
    "users",
    "require",
    "less",
    "energy",
    "advantage",
    "must",
    "got",
    "analysis",
    "one",
    "thing",
    "think",
    "right",
    "tell",
    "industries",
    "use",
    "machinery",
    "times",
    "load",
    "pretty",
    "much",
    "balanced",
    "even",
    "say",
    "pricing",
    "encourages",
    "cost",
    "severe",
    "like",
    "industrial",
    "heavy",
    "machines",
    "used",
    "type",
    "yeah",
    "take",
    "save",
    "money",
    "well",
    "times",
    "pricing",
    "less",
    "peak",
    "time",
    "prices",
    "right",
    "one",
    "analysis",
    "let",
    "us",
    "move",
    "forward",
    "see",
    "ibm",
    "suite",
    "developed",
    "happens",
    "first",
    "dump",
    "data",
    "get",
    "data",
    "warehouse",
    "important",
    "make",
    "sure",
    "user",
    "data",
    "secure",
    "happens",
    "need",
    "clean",
    "data",
    "told",
    "earlier",
    "well",
    "might",
    "many",
    "fees",
    "require",
    "need",
    "make",
    "sure",
    "useful",
    "material",
    "useful",
    "data",
    "data",
    "set",
    "perform",
    "certain",
    "analysis",
    "order",
    "use",
    "suite",
    "ibm",
    "offered",
    "efficiently",
    "take",
    "care",
    "things",
    "first",
    "thing",
    "able",
    "manage",
    "smart",
    "meter",
    "data",
    "lot",
    "data",
    "coming",
    "million",
    "smart",
    "meters",
    "able",
    "manage",
    "large",
    "volume",
    "data",
    "also",
    "able",
    "retain",
    "maybe",
    "later",
    "might",
    "need",
    "kind",
    "regulatory",
    "requirements",
    "something",
    "next",
    "thing",
    "keep",
    "mind",
    "monitor",
    "distribution",
    "grid",
    "improve",
    "optimize",
    "overall",
    "grid",
    "reliability",
    "identify",
    "abnormal",
    "conditions",
    "causing",
    "kind",
    "problem",
    "also",
    "take",
    "care",
    "optimizing",
    "unit",
    "commitment",
    "optimizing",
    "unit",
    "commitment",
    "companies",
    "satisfy",
    "customers",
    "even",
    "reduce",
    "power",
    "outages",
    "reduce",
    "power",
    "outages",
    "customers",
    "get",
    "angry",
    "identify",
    "problems",
    "reduce",
    "obviously",
    "also",
    "optimize",
    "energy",
    "trading",
    "means",
    "advise",
    "customers",
    "use",
    "appliances",
    "order",
    "maintain",
    "balance",
    "power",
    "load",
    "also",
    "forecast",
    "schedule",
    "loads",
    "companies",
    "must",
    "able",
    "predict",
    "profitably",
    "sell",
    "excess",
    "power",
    "need",
    "hedge",
    "supply",
    "continuing",
    "let",
    "talk",
    "encore",
    "made",
    "use",
    "solution",
    "encore",
    "electric",
    "delivery",
    "company",
    "largest",
    "electrical",
    "distribution",
    "transmission",
    "company",
    "texas",
    "one",
    "six",
    "largest",
    "united",
    "states",
    "three",
    "million",
    "customers",
    "service",
    "area",
    "covers",
    "almost",
    "117",
    "thousand",
    "square",
    "miles",
    "begin",
    "advanced",
    "feeder",
    "program",
    "2008",
    "deployed",
    "almost",
    "three",
    "point",
    "two",
    "five",
    "million",
    "meters",
    "serving",
    "customers",
    "north",
    "central",
    "texas",
    "implementing",
    "kept",
    "three",
    "things",
    "mind",
    "first",
    "thing",
    "instrumented",
    "solution",
    "utilizes",
    "smart",
    "electricity",
    "meters",
    "accurately",
    "measure",
    "electricity",
    "usage",
    "household",
    "every",
    "15",
    "minutes",
    "like",
    "discussed",
    "smart",
    "meters",
    "sending",
    "data",
    "every",
    "15",
    "minutes",
    "provided",
    "data",
    "inputs",
    "essential",
    "consumption",
    "insights",
    "next",
    "thing",
    "interconnected",
    "customers",
    "access",
    "detail",
    "information",
    "electricity",
    "consuming",
    "creates",
    "view",
    "meter",
    "assets",
    "helped",
    "improve",
    "service",
    "delivery",
    "next",
    "thing",
    "make",
    "customers",
    "intelligent",
    "since",
    "getting",
    "monitored",
    "already",
    "household",
    "customer",
    "consuming",
    "power",
    "able",
    "advise",
    "customers",
    "maybe",
    "tell",
    "wash",
    "clothes",
    "night",
    "using",
    "lot",
    "appliances",
    "data",
    "maybe",
    "could",
    "divide",
    "use",
    "appliances",
    "hours",
    "even",
    "save",
    "money",
    "beneficial",
    "customers",
    "company",
    "well",
    "gained",
    "lot",
    "benefits",
    "using",
    "ibm",
    "solution",
    "benefits",
    "got",
    "enabled",
    "identifying",
    "six",
    "outages",
    "customers",
    "get",
    "inconvenience",
    "means",
    "able",
    "identify",
    "problem",
    "even",
    "occurred",
    "also",
    "improved",
    "emergency",
    "response",
    "events",
    "severe",
    "weather",
    "events",
    "views",
    "outages",
    "also",
    "provides",
    "customers",
    "data",
    "needed",
    "become",
    "active",
    "participant",
    "power",
    "consumption",
    "management",
    "enables",
    "every",
    "individual",
    "household",
    "reduce",
    "electrical",
    "consumption",
    "almost",
    "five",
    "ten",
    "percent",
    "encore",
    "use",
    "ibm",
    "solution",
    "made",
    "huge",
    "benefits",
    "using",
    "big",
    "data",
    "analytics",
    "ibm",
    "performed",
    "let",
    "interrupt",
    "right",
    "since",
    "ray",
    "smart",
    "told",
    "us",
    "beginning",
    "well",
    "free",
    "lunches",
    "life",
    "right",
    "opportunity",
    "many",
    "problems",
    "encase",
    "opportunity",
    "right",
    "let",
    "us",
    "focus",
    "problems",
    "one",
    "one",
    "first",
    "problem",
    "storing",
    "colossal",
    "amount",
    "data",
    "let",
    "us",
    "discuss",
    "stars",
    "front",
    "screen",
    "data",
    "riddle",
    "past",
    "two",
    "years",
    "previous",
    "history",
    "total",
    "guys",
    "stop",
    "generating",
    "much",
    "amount",
    "data",
    "said",
    "2020",
    "total",
    "digital",
    "data",
    "grow",
    "44",
    "zettabytes",
    "approximately",
    "one",
    "start",
    "amazes",
    "mb",
    "new",
    "information",
    "created",
    "every",
    "second",
    "every",
    "person",
    "2020",
    "storing",
    "huge",
    "data",
    "traditional",
    "system",
    "possible",
    "reason",
    "obvious",
    "storage",
    "limited",
    "one",
    "system",
    "example",
    "server",
    "storage",
    "limit",
    "10",
    "terabytes",
    "company",
    "growing",
    "really",
    "fast",
    "data",
    "exponentially",
    "increasing",
    "one",
    "point",
    "exhaust",
    "storage",
    "investing",
    "youth",
    "servers",
    "definitely",
    "solution",
    "ratio",
    "think",
    "solution",
    "problem",
    "according",
    "distributed",
    "file",
    "system",
    "better",
    "way",
    "store",
    "huge",
    "data",
    "saving",
    "lot",
    "money",
    "let",
    "tell",
    "due",
    "distributed",
    "system",
    "actually",
    "store",
    "data",
    "commodity",
    "hardware",
    "instead",
    "spending",
    "money",
    "servers",
    "agree",
    "thoreau",
    "completely",
    "vito",
    "storing",
    "problem",
    "let",
    "tell",
    "guys",
    "one",
    "part",
    "problem",
    "let",
    "see",
    "okay",
    "since",
    "saw",
    "data",
    "huge",
    "present",
    "various",
    "formats",
    "well",
    "like",
    "unstructured",
    "structured",
    "need",
    "store",
    "huge",
    "data",
    "also",
    "need",
    "make",
    "sure",
    "system",
    "present",
    "store",
    "varieties",
    "data",
    "generated",
    "various",
    "sources",
    "let",
    "focus",
    "next",
    "problem",
    "let",
    "focus",
    "diagram",
    "notice",
    "hard",
    "disk",
    "capacity",
    "increasing",
    "distance",
    "performance",
    "speed",
    "increasing",
    "rate",
    "let",
    "explain",
    "example",
    "100",
    "mbps",
    "channel",
    "processing",
    "say",
    "one",
    "terabyte",
    "data",
    "much",
    "time",
    "take",
    "maybe",
    "calculate",
    "somewhere",
    "around",
    "two",
    "point",
    "nine",
    "one",
    "hours",
    "right",
    "somewhere",
    "around",
    "two",
    "point",
    "nine",
    "menards",
    "taken",
    "example",
    "one",
    "terabytes",
    "processing",
    "zettabyte",
    "data",
    "imagine",
    "much",
    "time",
    "take",
    "four",
    "input",
    "output",
    "channels",
    "amount",
    "data",
    "take",
    "approximately",
    "hours",
    "convert",
    "minutes",
    "around",
    "43",
    "minutes",
    "approximately",
    "right",
    "imagine",
    "instead",
    "1tb",
    "data",
    "bytes",
    "data",
    "modern",
    "storage",
    "accessing",
    "processing",
    "speed",
    "huge",
    "data",
    "bigger",
    "problem",
    "okay",
    "reshma",
    "good",
    "example",
    "discuss",
    "yeah",
    "since",
    "talking",
    "accessing",
    "data",
    "told",
    "us",
    "already",
    "amazon",
    "different",
    "websites",
    "youtube",
    "make",
    "recommendations",
    "solution",
    "would",
    "take",
    "much",
    "time",
    "access",
    "data",
    "recommendation",
    "system",
    "wo",
    "work",
    "make",
    "lot",
    "money",
    "recommendation",
    "system",
    "lot",
    "people",
    "go",
    "click",
    "buy",
    "product",
    "right",
    "let",
    "consider",
    "taking",
    "like",
    "hours",
    "maybe",
    "years",
    "time",
    "order",
    "process",
    "big",
    "amount",
    "data",
    "let",
    "say",
    "one",
    "time",
    "purchased",
    "iphone",
    "5s",
    "two",
    "years",
    "browsing",
    "onto",
    "amazon",
    "since",
    "took",
    "much",
    "time",
    "access",
    "data",
    "already",
    "switched",
    "new",
    "iphone",
    "recommending",
    "old",
    "iphone",
    "case",
    "5s",
    "obviously",
    "wo",
    "work",
    "would",
    "go",
    "click",
    "already",
    "changed",
    "phone",
    "right",
    "huge",
    "problem",
    "amazon",
    "recommendation",
    "system",
    "would",
    "work",
    "anymore",
    "know",
    "smart",
    "changes",
    "respond",
    "every",
    "year",
    "bought",
    "phone",
    "people",
    "recommending",
    "lcs",
    "bora",
    "someone",
    "recommending",
    "case",
    "phone",
    "2",
    "years",
    "make",
    "sense",
    "yeah",
    "work",
    "two",
    "phones",
    "time",
    "yeah",
    "want",
    "waste",
    "money",
    "purchasing",
    "new",
    "iphone",
    "case",
    "older",
    "phone",
    "basically",
    "wo",
    "fair",
    "discuss",
    "solution",
    "problems",
    "rachel",
    "ca",
    "leave",
    "viewers",
    "problem",
    "wo",
    "fair",
    "solution",
    "hadoop",
    "hadoop",
    "solution",
    "let",
    "introduce",
    "hadoop",
    "ok",
    "hadoop",
    "hadoop",
    "framework",
    "allows",
    "first",
    "store",
    "big",
    "data",
    "distributed",
    "environment",
    "process",
    "parallely",
    "basically",
    "two",
    "parts",
    "one",
    "hdfs",
    "hadoop",
    "distributed",
    "file",
    "system",
    "storage",
    "allows",
    "store",
    "data",
    "various",
    "formats",
    "across",
    "cluster",
    "second",
    "part",
    "mapreduce",
    "nothing",
    "processing",
    "unit",
    "hadoop",
    "allows",
    "parallel",
    "processing",
    "data",
    "stored",
    "across",
    "hdfs",
    "let",
    "us",
    "dig",
    "deep",
    "hdfs",
    "understand",
    "better",
    "yeah",
    "hdfs",
    "creates",
    "abstraction",
    "resources",
    "let",
    "simplify",
    "similar",
    "virtualization",
    "see",
    "hdfs",
    "logically",
    "single",
    "unit",
    "storing",
    "big",
    "data",
    "actually",
    "restoring",
    "data",
    "across",
    "multiple",
    "systems",
    "say",
    "distributed",
    "fashion",
    "architecture",
    "name",
    "node",
    "master",
    "node",
    "data",
    "nodes",
    "slaves",
    "name",
    "node",
    "contains",
    "metadata",
    "data",
    "stored",
    "data",
    "like",
    "data",
    "block",
    "stored",
    "data",
    "node",
    "replications",
    "data",
    "block",
    "captain",
    "etc",
    "etc",
    "actual",
    "data",
    "stored",
    "data",
    "nodes",
    "also",
    "want",
    "add",
    "actually",
    "replicate",
    "data",
    "blocks",
    "present",
    "data",
    "nodes",
    "default",
    "replication",
    "factor",
    "3",
    "means",
    "3",
    "copies",
    "file",
    "going",
    "tell",
    "us",
    "need",
    "replication",
    "shell",
    "reshma",
    "since",
    "using",
    "commodity",
    "hardware",
    "right",
    "know",
    "failure",
    "rate",
    "hardware",
    "pretty",
    "high",
    "one",
    "data",
    "loads",
    "fail",
    "wo",
    "data",
    "block",
    "reason",
    "need",
    "replicate",
    "data",
    "block",
    "replication",
    "factor",
    "depends",
    "requirements",
    "right",
    "let",
    "us",
    "understand",
    "actually",
    "hadoop",
    "provided",
    "solution",
    "big",
    "data",
    "problems",
    "discussed",
    "race",
    "remember",
    "first",
    "problem",
    "yeah",
    "storing",
    "big",
    "data",
    "hdfs",
    "solved",
    "let",
    "discuss",
    "hdfs",
    "provides",
    "distributed",
    "way",
    "store",
    "big",
    "data",
    "already",
    "told",
    "data",
    "stored",
    "blocks",
    "data",
    "nodes",
    "specify",
    "size",
    "block",
    "basically",
    "512",
    "mb",
    "data",
    "configured",
    "hdfs",
    "create",
    "128",
    "megabytes",
    "data",
    "blocks",
    "hdfs",
    "hdfs",
    "divide",
    "data",
    "four",
    "blocks",
    "512",
    "divided",
    "128",
    "4",
    "restored",
    "across",
    "different",
    "data",
    "nodes",
    "also",
    "replicate",
    "data",
    "blocks",
    "different",
    "data",
    "nodes",
    "using",
    "commodity",
    "hardware",
    "storing",
    "challenge",
    "thoughts",
    "sorted",
    "also",
    "add",
    "one",
    "thing",
    "reshma",
    "also",
    "solves",
    "scaling",
    "problem",
    "focuses",
    "horizontal",
    "scaling",
    "instead",
    "vertical",
    "always",
    "add",
    "extra",
    "data",
    "nodes",
    "hdfs",
    "cluster",
    "required",
    "instead",
    "scaling",
    "resources",
    "data",
    "nodes",
    "actually",
    "increasing",
    "resources",
    "data",
    "nodes",
    "adding",
    "data",
    "nodes",
    "require",
    "let",
    "summarize",
    "basically",
    "storing",
    "1",
    "tb",
    "data",
    "need",
    "1",
    "tb",
    "system",
    "instead",
    "multiple",
    "128",
    "gb",
    "systems",
    "even",
    "less",
    "reshma",
    "one",
    "second",
    "challenge",
    "big",
    "data",
    "next",
    "problem",
    "storing",
    "variety",
    "data",
    "problem",
    "also",
    "addressed",
    "hdfs",
    "hdfs",
    "store",
    "kinds",
    "data",
    "whether",
    "structured",
    "unstructured",
    "hdfs",
    "pre",
    "dumping",
    "schema",
    "validation",
    "dump",
    "kinds",
    "data",
    "one",
    "place",
    "also",
    "follows",
    "right",
    "ones",
    "read",
    "many",
    "model",
    "due",
    "write",
    "data",
    "read",
    "multiple",
    "times",
    "finding",
    "insights",
    "recall",
    "third",
    "challenge",
    "accessing",
    "data",
    "faster",
    "one",
    "major",
    "challenge",
    "big",
    "data",
    "order",
    "solve",
    "moving",
    "processing",
    "data",
    "data",
    "processing",
    "means",
    "sort",
    "go",
    "ahead",
    "explain",
    "yes",
    "survival",
    "let",
    "explain",
    "mean",
    "actually",
    "moving",
    "process",
    "data",
    "consider",
    "master",
    "slaves",
    "data",
    "stored",
    "slaves",
    "happens",
    "one",
    "way",
    "processing",
    "data",
    "send",
    "data",
    "master",
    "node",
    "process",
    "happen",
    "slaves",
    "send",
    "data",
    "master",
    "node",
    "cause",
    "network",
    "congestion",
    "plus",
    "input",
    "output",
    "channel",
    "congestion",
    "time",
    "master",
    "node",
    "take",
    "lot",
    "time",
    "order",
    "process",
    "user",
    "monitored",
    "send",
    "process",
    "data",
    "means",
    "send",
    "logic",
    "slaves",
    "actually",
    "contain",
    "data",
    "perform",
    "processing",
    "maze",
    "happen",
    "small",
    "chunks",
    "result",
    "come",
    "sent",
    "name",
    "node",
    "way",
    "wo",
    "network",
    "congestion",
    "congestion",
    "take",
    "comparatively",
    "less",
    "time",
    "actually",
    "means",
    "sending",
    "process",
    "data",
    "hope",
    "clear",
    "hope",
    "even",
    "raise",
    "square",
    "clear",
    "right",
    "good",
    "hear",
    "let",
    "move",
    "forward",
    "focus",
    "components",
    "hadoop",
    "look",
    "hadoop",
    "ecosystem",
    "see",
    "entire",
    "hadoop",
    "eco",
    "system",
    "lot",
    "tools",
    "use",
    "see",
    "flume",
    "scoop",
    "used",
    "ingest",
    "data",
    "hdfs",
    "already",
    "seen",
    "hdfs",
    "one",
    "component",
    "known",
    "yarn",
    "consider",
    "yarn",
    "brain",
    "hadoop",
    "ecosystem",
    "performs",
    "processing",
    "activities",
    "allocates",
    "resources",
    "schedules",
    "different",
    "tasks",
    "apart",
    "components",
    "many",
    "components",
    "well",
    "give",
    "brief",
    "introduction",
    "components",
    "pig",
    "nothing",
    "analytics",
    "tool",
    "hive",
    "introduced",
    "facebook",
    "pig",
    "introduced",
    "yahoo",
    "language",
    "user",
    "called",
    "pig",
    "latin",
    "use",
    "high",
    "quality",
    "language",
    "similar",
    "sequel",
    "story",
    "behind",
    "hive",
    "interesting",
    "want",
    "share",
    "basically",
    "facebook",
    "wanted",
    "tool",
    "order",
    "perform",
    "queries",
    "huge",
    "chunks",
    "data",
    "introduced",
    "height",
    "help",
    "hive",
    "actually",
    "use",
    "employees",
    "sequel",
    "perform",
    "analytics",
    "huge",
    "set",
    "data",
    "big",
    "data",
    "apart",
    "sparky",
    "used",
    "near",
    "processing",
    "order",
    "perform",
    "machine",
    "learning",
    "component",
    "spark",
    "called",
    "ml",
    "lip",
    "even",
    "hood",
    "talk",
    "mapreduce",
    "know",
    "exactly",
    "mapreduce",
    "basically",
    "java",
    "programs",
    "used",
    "process",
    "big",
    "data",
    "talk",
    "apache",
    "hbase",
    "hdfs",
    "file",
    "system",
    "hbase",
    "hbase",
    "nothing",
    "sequel",
    "database",
    "top",
    "hdfs",
    "let",
    "move",
    "forward",
    "focus",
    "important",
    "components",
    "among",
    "hadoop",
    "know",
    "exactly",
    "hadoop",
    "hive",
    "box",
    "hive",
    "nothing",
    "data",
    "warehousing",
    "tool",
    "allows",
    "perform",
    "big",
    "data",
    "analytics",
    "using",
    "high",
    "square",
    "e",
    "language",
    "similar",
    "sequel",
    "told",
    "story",
    "also",
    "behind",
    "facebook",
    "actually",
    "implemented",
    "talk",
    "power",
    "chip",
    "pig",
    "analytics",
    "tool",
    "used",
    "analyze",
    "large",
    "set",
    "data",
    "representing",
    "data",
    "flows",
    "spark",
    "nothing",
    "data",
    "processing",
    "engine",
    "allows",
    "us",
    "efficiently",
    "execute",
    "streaming",
    "machine",
    "learning",
    "sequel",
    "workloads",
    "requires",
    "pass",
    "creative",
    "access",
    "data",
    "set",
    "basically",
    "streaming",
    "things",
    "require",
    "near",
    "processing",
    "integrate",
    "spark",
    "hadoop",
    "space",
    "nothing",
    "sequel",
    "database",
    "present",
    "top",
    "hdfs",
    "pyne",
    "system",
    "hadoop",
    "big",
    "data",
    "point",
    "ad",
    "raigarh",
    "help",
    "become",
    "big",
    "data",
    "hadoop",
    "expert",
    "let",
    "move",
    "forward",
    "understand",
    "big",
    "data",
    "hadoop",
    "training",
    "provided",
    "ed",
    "eureka",
    "big",
    "data",
    "hadoop",
    "certification",
    "training",
    "eddy",
    "rica",
    "provides",
    "structured",
    "program",
    "order",
    "make",
    "certified",
    "hadoop",
    "developer",
    "explain",
    "structure",
    "program",
    "let",
    "tell",
    "guys",
    "eddy",
    "rekha",
    "provides",
    "support",
    "team",
    "questions",
    "doubts",
    "point",
    "time",
    "contact",
    "apart",
    "wherever",
    "pay",
    "course",
    "get",
    "access",
    "elements",
    "elements",
    "lms",
    "nothing",
    "learning",
    "management",
    "system",
    "class",
    "recordings",
    "pds",
    "presentations",
    "lms",
    "get",
    "access",
    "lms",
    "life",
    "style",
    "let",
    "tell",
    "get",
    "lifetime",
    "even",
    "done",
    "course",
    "want",
    "take",
    "well",
    "come",
    "back",
    "ten",
    "years",
    "also",
    "want",
    "learn",
    "hadoop",
    "put",
    "live",
    "patch",
    "basically",
    "get",
    "everything",
    "lifetime",
    "let",
    "focus",
    "structure",
    "program",
    "starts",
    "basics",
    "covers",
    "advanced",
    "portion",
    "big",
    "data",
    "hadoop",
    "well",
    "first",
    "module",
    "learning",
    "exactly",
    "big",
    "data",
    "hadoop",
    "various",
    "concepts",
    "introductory",
    "module",
    "comes",
    "concepts",
    "hdf",
    "mapreduce",
    "architecture",
    "looks",
    "like",
    "things",
    "third",
    "module",
    "understand",
    "actually",
    "set",
    "ducasse",
    "cluster",
    "architecture",
    "looks",
    "like",
    "fourth",
    "module",
    "dealing",
    "mapreduce",
    "program",
    "fifth",
    "module",
    "learn",
    "data",
    "loading",
    "techniques",
    "comes",
    "sixth",
    "module",
    "six",
    "modules",
    "introduced",
    "analytics",
    "tools",
    "like",
    "pig",
    "height",
    "told",
    "earlier",
    "well",
    "use",
    "pig",
    "height",
    "comes",
    "hbase",
    "nothing",
    "sequel",
    "database",
    "top",
    "hdfs",
    "hoozy",
    "look",
    "various",
    "best",
    "practices",
    "hadoop",
    "developing",
    "comes",
    "spark",
    "let",
    "tell",
    "wo",
    "discuss",
    "tumor",
    "spark",
    "course",
    "eddie",
    "vega",
    "separate",
    "course",
    "spot",
    "still",
    "included",
    "introduction",
    "spark",
    "big",
    "data",
    "hadoop",
    "isabel",
    "also",
    "learn",
    "work",
    "r",
    "dd",
    "spa",
    "finally",
    "working",
    "project",
    "big",
    "data",
    "analytics",
    "done",
    "project",
    "basis",
    "done",
    "getting",
    "grades",
    "certificate",
    "get",
    "certificate",
    "done",
    "project",
    "multiple",
    "projects",
    "like",
    "done",
    "one",
    "project",
    "take",
    "project",
    "well",
    "take",
    "multiple",
    "projects",
    "request",
    "multiple",
    "projects",
    "definitely",
    "give",
    "least",
    "one",
    "project",
    "need",
    "finish",
    "order",
    "get",
    "certification",
    "move",
    "forward",
    "rachel",
    "give",
    "introduction",
    "projects",
    "part",
    "course",
    "yeah",
    "projects",
    "choose",
    "work",
    "first",
    "one",
    "see",
    "analyze",
    "social",
    "bookmarking",
    "sites",
    "tell",
    "little",
    "bit",
    "work",
    "social",
    "media",
    "data",
    "data",
    "comprised",
    "information",
    "gathered",
    "sites",
    "like",
    "reddit",
    "comm",
    "stumbleupon",
    "com",
    "etc",
    "bookmarking",
    "sites",
    "allow",
    "bookmark",
    "review",
    "rate",
    "search",
    "various",
    "links",
    "kind",
    "topic",
    "data",
    "xml",
    "format",
    "contains",
    "various",
    "kind",
    "links",
    "post",
    "urls",
    "different",
    "categories",
    "defining",
    "ratings",
    "linked",
    "analyze",
    "data",
    "hadoop",
    "ecosystem",
    "fetch",
    "data",
    "hdfs",
    "analyze",
    "help",
    "mapreduce",
    "pig",
    "hives",
    "find",
    "links",
    "based",
    "user",
    "comments",
    "likes",
    "etc",
    "problem",
    "statement",
    "analyze",
    "entire",
    "data",
    "also",
    "post",
    "kind",
    "sites",
    "find",
    "top",
    "post",
    "according",
    "likes",
    "comments",
    "similarly",
    "projects",
    "like",
    "customer",
    "complaint",
    "analysis",
    "related",
    "retail",
    "industry",
    "similarly",
    "tourism",
    "data",
    "analysis",
    "related",
    "tourism",
    "data",
    "facts",
    "airline",
    "data",
    "analysis",
    "loan",
    "data",
    "set",
    "related",
    "banking",
    "finance",
    "movie",
    "ratings",
    "media",
    "data",
    "even",
    "choose",
    "projects",
    "give",
    "try",
    "come",
    "solution",
    "problems",
    "time",
    "get",
    "stumble",
    "upon",
    "something",
    "stuck",
    "something",
    "support",
    "team",
    "available",
    "could",
    "call",
    "us",
    "anytime",
    "help",
    "reshma",
    "thinking",
    "give",
    "brief",
    "summary",
    "report",
    "things",
    "discussed",
    "yes",
    "would",
    "great",
    "go",
    "ahead",
    "provide",
    "summary",
    "started",
    "data",
    "evolved",
    "big",
    "data",
    "came",
    "existence",
    "saw",
    "various",
    "factors",
    "actually",
    "led",
    "big",
    "data",
    "focus",
    "five",
    "b",
    "basically",
    "order",
    "consider",
    "data",
    "big",
    "data",
    "need",
    "consider",
    "five",
    "b",
    "one",
    "five",
    "reshma",
    "first",
    "saw",
    "volume",
    "data",
    "saw",
    "variety",
    "velocity",
    "value",
    "finally",
    "veracity",
    "right",
    "fine",
    "focused",
    "big",
    "data",
    "opportunity",
    "discussed",
    "quite",
    "lot",
    "examples",
    "still",
    "unclear",
    "people",
    "buying",
    "strawberry",
    "hurricanes",
    "point",
    "worry",
    "sorry",
    "find",
    "answer",
    "right",
    "examples",
    "saw",
    "case",
    "study",
    "ibm",
    "shifted",
    "focus",
    "towards",
    "problems",
    "associated",
    "big",
    "data",
    "obviously",
    "opportunity",
    "order",
    "case",
    "opportunity",
    "need",
    "come",
    "solution",
    "problems",
    "solution",
    "raised",
    "well",
    "solution",
    "hadoop",
    "seen",
    "use",
    "hdfs",
    "mapreduce",
    "order",
    "solve",
    "problems",
    "finally",
    "discussed",
    "curriculum",
    "hadoop",
    "curriculum",
    "ed",
    "eureka",
    "kind",
    "projects",
    "choose",
    "learning",
    "course",
    "right",
    "fine",
    "come",
    "end",
    "today",
    "session",
    "thank",
    "race",
    "joining",
    "us",
    "pleasure",
    "today",
    "discussion",
    "thank",
    "sorrow",
    "enjoyed",
    "lot",
    "well",
    "alright",
    "fine",
    "guys",
    "video",
    "uploaded",
    "lms",
    "go",
    "questions",
    "ask",
    "support",
    "team",
    "bring",
    "doubts",
    "next",
    "session",
    "well",
    "let",
    "tell",
    "guys",
    "introductory",
    "video",
    "big",
    "data",
    "hadoop",
    "real",
    "course",
    "start",
    "next",
    "session",
    "thank",
    "great",
    "day",
    "hope",
    "enjoyed",
    "listening",
    "video",
    "please",
    "kind",
    "enough",
    "like",
    "comment",
    "doubts",
    "queries",
    "reply",
    "earliest",
    "look",
    "videos",
    "playlist",
    "subscribe",
    "rica",
    "channel",
    "learn",
    "happy",
    "learning"
  ],
  "keywords": [
    "everyone",
    "sort",
    "today",
    "session",
    "focus",
    "big",
    "data",
    "also",
    "us",
    "reshma",
    "hope",
    "find",
    "even",
    "let",
    "move",
    "forward",
    "look",
    "evolved",
    "came",
    "see",
    "exactly",
    "understand",
    "opportunity",
    "obviously",
    "know",
    "life",
    "various",
    "problems",
    "wo",
    "tell",
    "solution",
    "hadoop",
    "solve",
    "components",
    "finally",
    "provided",
    "projects",
    "part",
    "course",
    "time",
    "fine",
    "notice",
    "earlier",
    "phones",
    "phone",
    "apart",
    "using",
    "processing",
    "much",
    "store",
    "right",
    "storing",
    "well",
    "similarly",
    "nowadays",
    "cars",
    "come",
    "must",
    "due",
    "generating",
    "lot",
    "take",
    "example",
    "noticed",
    "generated",
    "smart",
    "every",
    "one",
    "video",
    "format",
    "database",
    "volume",
    "basically",
    "new",
    "like",
    "many",
    "behind",
    "evolution",
    "think",
    "guys",
    "iot",
    "nothing",
    "internet",
    "etc",
    "actually",
    "temperature",
    "order",
    "first",
    "might",
    "huge",
    "amount",
    "start",
    "front",
    "screen",
    "2020",
    "need",
    "explain",
    "factor",
    "social",
    "media",
    "talk",
    "better",
    "yes",
    "pretty",
    "sure",
    "use",
    "important",
    "facebook",
    "youtube",
    "websites",
    "sites",
    "name",
    "go",
    "around",
    "people",
    "videos",
    "present",
    "structured",
    "point",
    "made",
    "discussed",
    "getting",
    "unstructured",
    "say",
    "examples",
    "discuss",
    "amazon",
    "times",
    "yeah",
    "buy",
    "stored",
    "something",
    "way",
    "user",
    "model",
    "consider",
    "okay",
    "already",
    "set",
    "large",
    "process",
    "system",
    "traditional",
    "applications",
    "systems",
    "problem",
    "would",
    "get",
    "kind",
    "five",
    "dealing",
    "three",
    "years",
    "multiple",
    "second",
    "variety",
    "different",
    "files",
    "computers",
    "less",
    "users",
    "appliances",
    "six",
    "million",
    "almost",
    "increasing",
    "want",
    "ahead",
    "useful",
    "next",
    "value",
    "happens",
    "mind",
    "make",
    "perform",
    "certain",
    "analytics",
    "analysis",
    "whatever",
    "done",
    "help",
    "business",
    "grow",
    "insights",
    "possible",
    "challenge",
    "good",
    "thing",
    "maybe",
    "similar",
    "money",
    "storage",
    "commodity",
    "hardware",
    "give",
    "analyze",
    "walmart",
    "used",
    "customers",
    "strawberry",
    "since",
    "case",
    "ibm",
    "company",
    "meters",
    "electricity",
    "meter",
    "minutes",
    "energy",
    "send",
    "require",
    "told",
    "things",
    "able",
    "unit",
    "reduce",
    "power",
    "outages",
    "means",
    "program",
    "two",
    "access",
    "hours",
    "provides",
    "distributed",
    "file",
    "instead",
    "saw",
    "work",
    "iphone",
    "allows",
    "hdfs",
    "across",
    "mapreduce",
    "resources",
    "node",
    "master",
    "nodes",
    "slaves",
    "block",
    "blocks",
    "congestion",
    "pig",
    "tool",
    "hive",
    "introduced",
    "sequel",
    "learning",
    "spark",
    "hbase",
    "top",
    "lms",
    "learn",
    "module",
    "comes",
    "project"
  ]
}