{
  "text": "hey there I'm happy to welcome you to\nanother video series in which we will\nexplore four different dimensionality\nreduction techniques chances are a lot\nof you have come across these methods in\nresearch papers or even applied them in\ncyc learn but have you ever wondered\nwhat's happening behind the scenes if so\ngreat that you are here we will learn\nall of that in the next videos based on\nyour voting we will Deep dive into each\nof the techniques and also have a bit of\nhands-on experience the goal is really\nto get a proper understanding that\nallows you to select the right method\nfor your problem so let's get started in\nthis first video we will talk about the\nbasics of dimensionality reduction and\ndiscuss some of the terminologies such\nas manifold learning or the curse of\ndimensionality from image data like\namness to word embeddings and language\nmodels to the molecular space there are\nmany situations where we have\nhigh-dimensional data which we try to\nbetter understand and visualize human\nperception is limited to the thre\ndimension dimensional space and\ntherefore multivariat or\nmulti-dimensional data somehow needs to\nbe converted to a lower dimensional\nspace that is depictable and\ncomprehensible pixels for example have\nthousands of Dimensions but the plot on\nthe top left does a pretty good job at\nclustering the amness data set therefore\nthese techniques are absolutely Central\nfor data analysis in this series I'm\nmostly interested in using these\ntechniques for the sake of visualizing\ndata usually embeddings it is however\nalso common to reduce the number of\nDimensions to improve machine learning\nalgorithms to create these low\ndimensional representations we can\nchoose from a variety of techniques\nwhich can be categorized in various ways\nhere we will just distinguish between\nlinear methods and nonlinear methods\nnonlinear approaches belong to the field\nof manifold learning which can be\nfurther divided into local and Global\ntechniques which means if they just look\nat the neighborhood or if they consider\nthe entire data set a classical example\nof a linear method we will talk about is\nthe principal component analysis most of\nyou are probably familiar with it then\nwe will also talk about the linear\nvariant of multi-dimensional scaling\ncalled metric MDS a global technique\nconsidered in the series is the\nnonlinear variant of MDS called\nnon-metric MDS as a local manifold\nlearning approach we will look at the\npopular tne and lastly we will discuss\numap a method that can be considered to\nfall somewhere between local and Global\napproaches besides the one mentioned\nhere there are of course plenty of\nothers which would however extend the\nscope of this series this also includes\nneuron network based techniques like\nAuto\nencoders again this is just one way of\ngrouping the techniques and hopefully\nthis provides a rough overview now let's\nquickly revisit the overall concept of\ndimensionality reduction there's a way\nto mathematically formulate this idea we\nall start with a set of high dimensional\ndata for example n samples with a\ndimensionality of M dimensionality here\nsimply refers to the number of\ncoordinates needed to describe a data\npoint in this example it equals to 10\nthis is the original data space let's\nassume there exists a metric that allows\nus to Define how similar data points are\nin this space we will call this metric\nDM our goal is to transform these data\npoints into a low dimensional\nrepresentation which allows us to for\nexample visual them in this example we\nchoose a dimensionality of two and call\nthe samples Y and in this\ntwo-dimensional space we also have a\nmetric which allows us to quantify data\nsimilarity the idea of most\ndimensionality reduction approaches is\nto optimize a mapping function that\ntransform the high dimensional data into\na lower Dimension while and this is the\nimportant piece preserving the ratio of\nthe distance Matrix and therefore\napproxim imate the original data space\nof course it's impossible to squeeze all\nof the information of 10 Dimensions into\ntwo because there are simply less\ndegrees of freedom therefore this\nmapping will have an inherent error most\nof the time the actual information\ncontained in the data is less relevant\nand instead we care about the\ntopological structure of the data which\nmeans the relationship between points\nand how they are arranged in space but\nthere is a difficulty because all of\nthis is based on distance metrics there\nare some pretty interesting studies for\nexample the paper on the surprising\nbehavior of distance Matrix in high\ndimensional space that highlight that\ndistance Matrix become less meaningful\nin higher Dimensions the so-called curse\nof dimensionality was coined by Bellman\nin\n1961 and exactly describes What's\nHappening Here I assume that many of you\nare familiar with it basically the\nhigher the number of dimensions\nthe more uniform the distance becomes\nthis is especially the case for the\nukian metric this phenomenon of distance\nconcentration is also a reason why many\nmachine learning algorithms struggle to\nseparate data when the data points have\ntoo many dimensions having more features\nis therefore not always better what you\ncan also see here is that absolute\nvalues of the distances become larger\nwhich means the more Dimensions the\nfurther away the points are from each\nother visually this reflects the\nwell-known fact that most of the data\nspreads out to the shell and edges of\nthe data space rather than lying inside\nof the volume these visuals are from a\ngreat tutorial on the curse of\ndimensionality from vision.com the link\nis in the video description okay so this\nmight have been a refresher for most of\nyou but it's crucial for understanding\nsome of the following concepts before we\nmove on and discuss how to solve the\nissue with the curse of dimensionality\nlet's take a moment to look at the\nsponsor of this video which is\nbrilliant.org\nbrilliant is a free and easy way to\nlearn math data science and computer\nscience\ninteractively there are thousands of\nlessons from basic to Advanced topics\nincluding neuron networks probability\nTheory programming large language models\nand many more what I personally like\nabout this learning platform is that you\ncan use it on every device like mobile\nphone computer or tablet\nand therefore can learn stuff wherever\nyou are nowadays people spend a lot of\ntime in the internet and Brilliant is a\ngreat way to spend your time\nmeaningfully by learning new things\nevery day all of the learning is\npossible in a fun and gamified way as\nyou can see here and in a future video\nof this series we will also dive a bit\ndeeper into some of the courses to get a\nfeeling for what it's like to learn with\nbrilliant if you want to try this you\ncan use the link in the video\ndescription and the first 200 will get\n20% off also there's a free 30 days\ntrial for\neveryone back to dimensionality\nreduction let's remind ourselves of the\ndifficulties when dealing with many\ndimensions we realize that it's getting\nmore difficult for distance metrics as\nwell as machine learning models to\noperate on high dimensional data but\nthere is hope the data might in reality\nhave a lower intrinsic dimensionality\nthan the original data space this\nopposite effect to the curse of\ndimensionality is the so-called blessing\nof\nnon-uniformity which means that the data\nis typically not uniformly distributed\nin the original space and therefore can\nbe reduced into a lower dimensional\nspace there is a pretty intuitive\nexample for this namely faces images of\nfaces consist of thousands of pixels\nwhich span a high-dimensional space the\nblessing of non-uniformity tells us that\nmost real world data sets don't spread\nout\nuniformly for the face images this means\nthat we observe a specific concentration\nin the pixel space this gets even more\nobvious when we realize that we are able\nto describe faces with only very few\nattributes such as the hair\ncharacteristics shape of the lips and so\non this means faces have an\nintrinsically low Dimension and\ntherefore the actually relevant\ninformation lays on the lower\ndimensional space there's also pretty\ncool paper on finding the intrinsic\ndimension of image representations which\nis linked in the video description\nso-called manifolds are a useful\nframework to understand all of this from\na mathematical point of view the data\nlike the face images we've just seen is\nembedded in a multi-dimensional space\nthis is also called the ambient space\nthe data itself however might actually\nlie on a Surface which can be found in a\nsmaller dimensional space such a\ntopological space is called manifolds a\nterm originating from the mathematician\nremman who used it to refer to the\nvariety of topological spaces which can\nfold in unique ways mathematically\nspeaking a manifold is a description of\na flat geometric surface that locally\nbehaves like the ukian space what this\nmeans is that moving through the\nmanifold is easily possible as the\nneighborhood is always well behaved\nthere are different types of manifolds\nand also manifolds with specific names\nin fact you can find a large collection\nof different types but I won't go into\nfurther details in this video this is\njust to give you some ideas\none-dimensional manifolds are lines and\ncircles two-dimensional manifolds are\nspheres or the plane and of course the\nprobably most prominent manifolds to\nplanet Earth the Swiss roll data set\nwhich you can see here is a benchmark\nfor evaluating dimensionality reduction\ntechniques it's called like that because\nit looks like the tasty Swiss cake which\ncomes in many different\nflavors M anyways on the left the data\nis embedded in three dimensions and\nforms a curved manifold we also say that\nthe data lies on this manifold a\nsuccessful manifold learning algorithm\nis able to unroll the data into to the\nshape on the right which is a lower\ndimensional 2D plane manifold and in\nmany cases data can be separated more\neffectively on specific manifolds which\nimproves the performance of machine\nlearning algorithms now what I've just\ndescribed is also known as the manifold\nhypothesis which posits that many high\ndimensional data sets actually lie on\nlow-dimensional latent manifolds and\nlatent is the keyword here because\nusually we don't know how they look look\nlike that's why some of the techniques\ncaptured in this series belong to the\nclass of manifold learning approaches\nbecause they approximate the underlying\nlow dimensional manifolds for the last\nminutes let's have a look at some\nrandomly selected real world\napplications of dimensionality reduction\na variety of methods are used in\ncomputational biology for example on\ngene expression data sets this paper\nuses umap to analyze genetic\ninteractions clustering of genes I think\nthat's a very nice way to make sense of\nthe data dimensionality reduction is not\nonly applied in the supervised setting\nbut sometimes all of the data is\nprojected into a smaller Dimension and\nclustering is applied afterwards here's\nan example for unsupervised anomaly\ndetection in heating systems performed\non time series data and one last example\nthat demonstrates that dimensionality\nreduction can be applied on pretty much\nany data set in analysis of the Dow\nJones index using different\ndimensionality reduction algorithms the\ndifferent clusters indicate data points\nwith certain characteristics regarding\nthe dynamical behavior of markets for\nexample stock market crashes or\npandemics overall a great example for\npreserving topological information on a\nlower dimensional manifold finally here\nare three takeaways from this short\nintroduction first there are linear and\nnonlinear as well as Global and local\ntechniques to perform dimensionality\nreduction secondly dimensionality\nreduction tries to transform\nhigh-dimensional data into a low\ndimensional space while preserving the\ndata\nstructure and finally data might lie on\nlow dimensional manifolds we can try to\nlearn them and that's it for this\nintroduction in the next video we will\nhave a look at principal component anal\nis the probably most popular\ndimensionality reduction technique\nthanks for watching and see you\nsoon\n",
  "words": [
    "hey",
    "happy",
    "welcome",
    "another",
    "video",
    "series",
    "explore",
    "four",
    "different",
    "dimensionality",
    "reduction",
    "techniques",
    "chances",
    "lot",
    "come",
    "across",
    "methods",
    "research",
    "papers",
    "even",
    "applied",
    "cyc",
    "learn",
    "ever",
    "wondered",
    "happening",
    "behind",
    "scenes",
    "great",
    "learn",
    "next",
    "videos",
    "based",
    "voting",
    "deep",
    "dive",
    "techniques",
    "also",
    "bit",
    "experience",
    "goal",
    "really",
    "get",
    "proper",
    "understanding",
    "allows",
    "select",
    "right",
    "method",
    "problem",
    "let",
    "get",
    "started",
    "first",
    "video",
    "talk",
    "basics",
    "dimensionality",
    "reduction",
    "discuss",
    "terminologies",
    "manifold",
    "learning",
    "curse",
    "dimensionality",
    "image",
    "data",
    "like",
    "amness",
    "word",
    "embeddings",
    "language",
    "models",
    "molecular",
    "space",
    "many",
    "situations",
    "data",
    "try",
    "better",
    "understand",
    "visualize",
    "human",
    "perception",
    "limited",
    "thre",
    "dimension",
    "dimensional",
    "space",
    "therefore",
    "multivariat",
    "data",
    "somehow",
    "needs",
    "converted",
    "lower",
    "dimensional",
    "space",
    "depictable",
    "comprehensible",
    "pixels",
    "example",
    "thousands",
    "dimensions",
    "plot",
    "top",
    "left",
    "pretty",
    "good",
    "job",
    "clustering",
    "amness",
    "data",
    "set",
    "therefore",
    "techniques",
    "absolutely",
    "central",
    "data",
    "analysis",
    "series",
    "mostly",
    "interested",
    "using",
    "techniques",
    "sake",
    "visualizing",
    "data",
    "usually",
    "embeddings",
    "however",
    "also",
    "common",
    "reduce",
    "number",
    "dimensions",
    "improve",
    "machine",
    "learning",
    "algorithms",
    "create",
    "low",
    "dimensional",
    "representations",
    "choose",
    "variety",
    "techniques",
    "categorized",
    "various",
    "ways",
    "distinguish",
    "linear",
    "methods",
    "nonlinear",
    "methods",
    "nonlinear",
    "approaches",
    "belong",
    "field",
    "manifold",
    "learning",
    "divided",
    "local",
    "global",
    "techniques",
    "means",
    "look",
    "neighborhood",
    "consider",
    "entire",
    "data",
    "set",
    "classical",
    "example",
    "linear",
    "method",
    "talk",
    "principal",
    "component",
    "analysis",
    "probably",
    "familiar",
    "also",
    "talk",
    "linear",
    "variant",
    "scaling",
    "called",
    "metric",
    "mds",
    "global",
    "technique",
    "considered",
    "series",
    "nonlinear",
    "variant",
    "mds",
    "called",
    "mds",
    "local",
    "manifold",
    "learning",
    "approach",
    "look",
    "popular",
    "tne",
    "lastly",
    "discuss",
    "umap",
    "method",
    "considered",
    "fall",
    "somewhere",
    "local",
    "global",
    "approaches",
    "besides",
    "one",
    "mentioned",
    "course",
    "plenty",
    "others",
    "would",
    "however",
    "extend",
    "scope",
    "series",
    "also",
    "includes",
    "neuron",
    "network",
    "based",
    "techniques",
    "like",
    "auto",
    "encoders",
    "one",
    "way",
    "grouping",
    "techniques",
    "hopefully",
    "provides",
    "rough",
    "overview",
    "let",
    "quickly",
    "revisit",
    "overall",
    "concept",
    "dimensionality",
    "reduction",
    "way",
    "mathematically",
    "formulate",
    "idea",
    "start",
    "set",
    "high",
    "dimensional",
    "data",
    "example",
    "n",
    "samples",
    "dimensionality",
    "dimensionality",
    "simply",
    "refers",
    "number",
    "coordinates",
    "needed",
    "describe",
    "data",
    "point",
    "example",
    "equals",
    "10",
    "original",
    "data",
    "space",
    "let",
    "assume",
    "exists",
    "metric",
    "allows",
    "us",
    "define",
    "similar",
    "data",
    "points",
    "space",
    "call",
    "metric",
    "dm",
    "goal",
    "transform",
    "data",
    "points",
    "low",
    "dimensional",
    "representation",
    "allows",
    "us",
    "example",
    "visual",
    "example",
    "choose",
    "dimensionality",
    "two",
    "call",
    "samples",
    "space",
    "also",
    "metric",
    "allows",
    "us",
    "quantify",
    "data",
    "similarity",
    "idea",
    "dimensionality",
    "reduction",
    "approaches",
    "optimize",
    "mapping",
    "function",
    "transform",
    "high",
    "dimensional",
    "data",
    "lower",
    "dimension",
    "important",
    "piece",
    "preserving",
    "ratio",
    "distance",
    "matrix",
    "therefore",
    "approxim",
    "imate",
    "original",
    "data",
    "space",
    "course",
    "impossible",
    "squeeze",
    "information",
    "10",
    "dimensions",
    "two",
    "simply",
    "less",
    "degrees",
    "freedom",
    "therefore",
    "mapping",
    "inherent",
    "error",
    "time",
    "actual",
    "information",
    "contained",
    "data",
    "less",
    "relevant",
    "instead",
    "care",
    "topological",
    "structure",
    "data",
    "means",
    "relationship",
    "points",
    "arranged",
    "space",
    "difficulty",
    "based",
    "distance",
    "metrics",
    "pretty",
    "interesting",
    "studies",
    "example",
    "paper",
    "surprising",
    "behavior",
    "distance",
    "matrix",
    "high",
    "dimensional",
    "space",
    "highlight",
    "distance",
    "matrix",
    "become",
    "less",
    "meaningful",
    "higher",
    "dimensions",
    "curse",
    "dimensionality",
    "coined",
    "bellman",
    "1961",
    "exactly",
    "describes",
    "happening",
    "assume",
    "many",
    "familiar",
    "basically",
    "higher",
    "number",
    "dimensions",
    "uniform",
    "distance",
    "becomes",
    "especially",
    "case",
    "ukian",
    "metric",
    "phenomenon",
    "distance",
    "concentration",
    "also",
    "reason",
    "many",
    "machine",
    "learning",
    "algorithms",
    "struggle",
    "separate",
    "data",
    "data",
    "points",
    "many",
    "dimensions",
    "features",
    "therefore",
    "always",
    "better",
    "also",
    "see",
    "absolute",
    "values",
    "distances",
    "become",
    "larger",
    "means",
    "dimensions",
    "away",
    "points",
    "visually",
    "reflects",
    "fact",
    "data",
    "spreads",
    "shell",
    "edges",
    "data",
    "space",
    "rather",
    "lying",
    "inside",
    "volume",
    "visuals",
    "great",
    "tutorial",
    "curse",
    "dimensionality",
    "link",
    "video",
    "description",
    "okay",
    "might",
    "refresher",
    "crucial",
    "understanding",
    "following",
    "concepts",
    "move",
    "discuss",
    "solve",
    "issue",
    "curse",
    "dimensionality",
    "let",
    "take",
    "moment",
    "look",
    "sponsor",
    "video",
    "brilliant",
    "free",
    "easy",
    "way",
    "learn",
    "math",
    "data",
    "science",
    "computer",
    "science",
    "interactively",
    "thousands",
    "lessons",
    "basic",
    "advanced",
    "topics",
    "including",
    "neuron",
    "networks",
    "probability",
    "theory",
    "programming",
    "large",
    "language",
    "models",
    "many",
    "personally",
    "like",
    "learning",
    "platform",
    "use",
    "every",
    "device",
    "like",
    "mobile",
    "phone",
    "computer",
    "tablet",
    "therefore",
    "learn",
    "stuff",
    "wherever",
    "nowadays",
    "people",
    "spend",
    "lot",
    "time",
    "internet",
    "brilliant",
    "great",
    "way",
    "spend",
    "time",
    "meaningfully",
    "learning",
    "new",
    "things",
    "every",
    "day",
    "learning",
    "possible",
    "fun",
    "gamified",
    "way",
    "see",
    "future",
    "video",
    "series",
    "also",
    "dive",
    "bit",
    "deeper",
    "courses",
    "get",
    "feeling",
    "like",
    "learn",
    "brilliant",
    "want",
    "try",
    "use",
    "link",
    "video",
    "description",
    "first",
    "200",
    "get",
    "20",
    "also",
    "free",
    "30",
    "days",
    "trial",
    "everyone",
    "back",
    "dimensionality",
    "reduction",
    "let",
    "remind",
    "difficulties",
    "dealing",
    "many",
    "dimensions",
    "realize",
    "getting",
    "difficult",
    "distance",
    "metrics",
    "well",
    "machine",
    "learning",
    "models",
    "operate",
    "high",
    "dimensional",
    "data",
    "hope",
    "data",
    "might",
    "reality",
    "lower",
    "intrinsic",
    "dimensionality",
    "original",
    "data",
    "space",
    "opposite",
    "effect",
    "curse",
    "dimensionality",
    "blessing",
    "means",
    "data",
    "typically",
    "uniformly",
    "distributed",
    "original",
    "space",
    "therefore",
    "reduced",
    "lower",
    "dimensional",
    "space",
    "pretty",
    "intuitive",
    "example",
    "namely",
    "faces",
    "images",
    "faces",
    "consist",
    "thousands",
    "pixels",
    "span",
    "space",
    "blessing",
    "tells",
    "us",
    "real",
    "world",
    "data",
    "sets",
    "spread",
    "uniformly",
    "face",
    "images",
    "means",
    "observe",
    "specific",
    "concentration",
    "pixel",
    "space",
    "gets",
    "even",
    "obvious",
    "realize",
    "able",
    "describe",
    "faces",
    "attributes",
    "hair",
    "characteristics",
    "shape",
    "lips",
    "means",
    "faces",
    "intrinsically",
    "low",
    "dimension",
    "therefore",
    "actually",
    "relevant",
    "information",
    "lays",
    "lower",
    "dimensional",
    "space",
    "also",
    "pretty",
    "cool",
    "paper",
    "finding",
    "intrinsic",
    "dimension",
    "image",
    "representations",
    "linked",
    "video",
    "description",
    "manifolds",
    "useful",
    "framework",
    "understand",
    "mathematical",
    "point",
    "view",
    "data",
    "like",
    "face",
    "images",
    "seen",
    "embedded",
    "space",
    "also",
    "called",
    "ambient",
    "space",
    "data",
    "however",
    "might",
    "actually",
    "lie",
    "surface",
    "found",
    "smaller",
    "dimensional",
    "space",
    "topological",
    "space",
    "called",
    "manifolds",
    "term",
    "originating",
    "mathematician",
    "remman",
    "used",
    "refer",
    "variety",
    "topological",
    "spaces",
    "fold",
    "unique",
    "ways",
    "mathematically",
    "speaking",
    "manifold",
    "description",
    "flat",
    "geometric",
    "surface",
    "locally",
    "behaves",
    "like",
    "ukian",
    "space",
    "means",
    "moving",
    "manifold",
    "easily",
    "possible",
    "neighborhood",
    "always",
    "well",
    "behaved",
    "different",
    "types",
    "manifolds",
    "also",
    "manifolds",
    "specific",
    "names",
    "fact",
    "find",
    "large",
    "collection",
    "different",
    "types",
    "wo",
    "go",
    "details",
    "video",
    "give",
    "ideas",
    "manifolds",
    "lines",
    "circles",
    "manifolds",
    "spheres",
    "plane",
    "course",
    "probably",
    "prominent",
    "manifolds",
    "planet",
    "earth",
    "swiss",
    "roll",
    "data",
    "set",
    "see",
    "benchmark",
    "evaluating",
    "dimensionality",
    "reduction",
    "techniques",
    "called",
    "like",
    "looks",
    "like",
    "tasty",
    "swiss",
    "cake",
    "comes",
    "many",
    "different",
    "flavors",
    "anyways",
    "left",
    "data",
    "embedded",
    "three",
    "dimensions",
    "forms",
    "curved",
    "manifold",
    "also",
    "say",
    "data",
    "lies",
    "manifold",
    "successful",
    "manifold",
    "learning",
    "algorithm",
    "able",
    "unroll",
    "data",
    "shape",
    "right",
    "lower",
    "dimensional",
    "2d",
    "plane",
    "manifold",
    "many",
    "cases",
    "data",
    "separated",
    "effectively",
    "specific",
    "manifolds",
    "improves",
    "performance",
    "machine",
    "learning",
    "algorithms",
    "described",
    "also",
    "known",
    "manifold",
    "hypothesis",
    "posits",
    "many",
    "high",
    "dimensional",
    "data",
    "sets",
    "actually",
    "lie",
    "latent",
    "manifolds",
    "latent",
    "keyword",
    "usually",
    "know",
    "look",
    "look",
    "like",
    "techniques",
    "captured",
    "series",
    "belong",
    "class",
    "manifold",
    "learning",
    "approaches",
    "approximate",
    "underlying",
    "low",
    "dimensional",
    "manifolds",
    "last",
    "minutes",
    "let",
    "look",
    "randomly",
    "selected",
    "real",
    "world",
    "applications",
    "dimensionality",
    "reduction",
    "variety",
    "methods",
    "used",
    "computational",
    "biology",
    "example",
    "gene",
    "expression",
    "data",
    "sets",
    "paper",
    "uses",
    "umap",
    "analyze",
    "genetic",
    "interactions",
    "clustering",
    "genes",
    "think",
    "nice",
    "way",
    "make",
    "sense",
    "data",
    "dimensionality",
    "reduction",
    "applied",
    "supervised",
    "setting",
    "sometimes",
    "data",
    "projected",
    "smaller",
    "dimension",
    "clustering",
    "applied",
    "afterwards",
    "example",
    "unsupervised",
    "anomaly",
    "detection",
    "heating",
    "systems",
    "performed",
    "time",
    "series",
    "data",
    "one",
    "last",
    "example",
    "demonstrates",
    "dimensionality",
    "reduction",
    "applied",
    "pretty",
    "much",
    "data",
    "set",
    "analysis",
    "dow",
    "jones",
    "index",
    "using",
    "different",
    "dimensionality",
    "reduction",
    "algorithms",
    "different",
    "clusters",
    "indicate",
    "data",
    "points",
    "certain",
    "characteristics",
    "regarding",
    "dynamical",
    "behavior",
    "markets",
    "example",
    "stock",
    "market",
    "crashes",
    "pandemics",
    "overall",
    "great",
    "example",
    "preserving",
    "topological",
    "information",
    "lower",
    "dimensional",
    "manifold",
    "finally",
    "three",
    "takeaways",
    "short",
    "introduction",
    "first",
    "linear",
    "nonlinear",
    "well",
    "global",
    "local",
    "techniques",
    "perform",
    "dimensionality",
    "reduction",
    "secondly",
    "dimensionality",
    "reduction",
    "tries",
    "transform",
    "data",
    "low",
    "dimensional",
    "space",
    "preserving",
    "data",
    "structure",
    "finally",
    "data",
    "might",
    "lie",
    "low",
    "dimensional",
    "manifolds",
    "try",
    "learn",
    "introduction",
    "next",
    "video",
    "look",
    "principal",
    "component",
    "anal",
    "probably",
    "popular",
    "dimensionality",
    "reduction",
    "technique",
    "thanks",
    "watching",
    "see",
    "soon"
  ],
  "keywords": [
    "video",
    "series",
    "different",
    "dimensionality",
    "reduction",
    "techniques",
    "lot",
    "methods",
    "even",
    "applied",
    "learn",
    "happening",
    "great",
    "next",
    "based",
    "dive",
    "also",
    "bit",
    "goal",
    "get",
    "understanding",
    "allows",
    "right",
    "method",
    "let",
    "first",
    "talk",
    "discuss",
    "manifold",
    "learning",
    "curse",
    "image",
    "data",
    "like",
    "amness",
    "embeddings",
    "language",
    "models",
    "space",
    "many",
    "try",
    "better",
    "understand",
    "dimension",
    "dimensional",
    "therefore",
    "lower",
    "pixels",
    "example",
    "thousands",
    "dimensions",
    "left",
    "pretty",
    "clustering",
    "set",
    "analysis",
    "using",
    "usually",
    "however",
    "number",
    "machine",
    "algorithms",
    "low",
    "representations",
    "choose",
    "variety",
    "ways",
    "linear",
    "nonlinear",
    "approaches",
    "belong",
    "local",
    "global",
    "means",
    "look",
    "neighborhood",
    "principal",
    "component",
    "probably",
    "familiar",
    "variant",
    "called",
    "metric",
    "mds",
    "technique",
    "considered",
    "popular",
    "umap",
    "one",
    "course",
    "neuron",
    "way",
    "overall",
    "mathematically",
    "idea",
    "high",
    "samples",
    "simply",
    "describe",
    "point",
    "10",
    "original",
    "assume",
    "us",
    "points",
    "call",
    "transform",
    "two",
    "mapping",
    "preserving",
    "distance",
    "matrix",
    "information",
    "less",
    "time",
    "relevant",
    "topological",
    "structure",
    "metrics",
    "paper",
    "behavior",
    "become",
    "higher",
    "ukian",
    "concentration",
    "always",
    "see",
    "fact",
    "link",
    "description",
    "might",
    "brilliant",
    "free",
    "science",
    "computer",
    "large",
    "use",
    "every",
    "spend",
    "possible",
    "realize",
    "well",
    "intrinsic",
    "blessing",
    "uniformly",
    "faces",
    "images",
    "real",
    "world",
    "sets",
    "face",
    "specific",
    "able",
    "characteristics",
    "shape",
    "actually",
    "manifolds",
    "embedded",
    "lie",
    "surface",
    "smaller",
    "used",
    "types",
    "plane",
    "swiss",
    "three",
    "latent",
    "last",
    "finally",
    "introduction"
  ]
}