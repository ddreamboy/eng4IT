{
  "text": "hello and welcome to the tutorial on\ndata science in this tutorial we are\ngoing to see what is data science and\nwho is a data scientist what are the\nskills of a data scientist and what does\nthe data scientist do a day in the life\nof a data scientist what is the\nmethodology used for data science like\ndata acquisition preparation\nmining and model building and testing\nand then maintenance and then towards\nthe end we will also see an example\nprogram as well i'll take you through a\nquick code where we have done some data\nscience activity and then we will\nconclude so let's get started so what is\ndata science as the name suggests it is\nnothing but study of using data and\ntrying to find out some insights or\nextracting some insights or knowledge\nusing all the data that is at your\ndisposal so that's pretty much what data\nscience is all about so you take the\ndata and apply certain methodologies\ncertain algorithms and\nyour business domain knowledge as well\nand of course a certain amount of\ncreativity to extract some insights very\noften they are also known as actionable\ninsights because once you have the\ninsights you should be in a position to\ntake some action to let's say solve a\nproblem or improve a situation there are\na lot of areas where data science can be\nused one of the very common one is fraud\ndetection or fraud prevention there are\na lot of fraudulent activities or\ntransactions primarily on the internet\nit's very easy to commit fraud and\ntherefore we can use data science to\neither prevent or detect fraud there are\ncertain algorithms machine learning\nalgorithms that can be used like for\nexample some outlier techniques\nclustering techniques that can be used\nto detect fraud and prevent fraud as\nwell so who is a data scientist rather\nit is actually a very generic role that\ndefines somebody who is working with\ndata is known as a data scientist but\nthere can be very specific activities\nand the roles can be actually much more\nspecific what exactly a person does\nwithin the area of data science can be\nmuch more specific but broadly anybody\nworking in the area of data science is\nknown as a data scientist so what does a\ndata scientist do these are some of the\nactivities data acquisition data\npreparation data mining data modeling\nand then model maintenance we will talk\nabout each of these in a great detail\nbut at a very high level the first step\nobviously is to get the raw data which\nis known as data acquisition it can be\nin all kinds of format and it could be\nmultiple sources but obviously that raw\ndata cannot be used as it is for\nperforming data mining activities or\ndata modeling activities so the data has\nto be claimed and prepared for using in\nthe data models or in the data mining\nactivity so that is the data preparation\nthen we actually do the data mining\nwhich can also include some exploratory\nactivities and then if we have to do\nstuff like machine learning then you\nneed to build a machine learning model\nand test the model get insights out of\nit and then if\nthe model is fine you deploy it and then\nyou need to maintain the model because\nover a period of time it is possible\nthat you need to tweak the model because\nof change in the process or changing the\ndata and so on so that all comes under\nthe model maintenance so let's take\ndeeper look at each of these activities\nlet's start with data acquisition so the\nstage of data acquisition basically the\ndata scientist will collect raw data\nfrom all possible sources so this could\nbe typically an rdbms which is a\nrelational database or it can also be a\nnon-rdbms or it could be flat files or\nunstructured data and so on so we need\nto bring all that data from different\nsources if required we need to do some\nkind of homogeneous formatting so that\nit all fits into a in a looks at least\nformat from a format perspective it\nlooks homogeneous so that may be\nrequiring some kind of transformation\nvery often this is loaded into what is\nknown as data warehouse so this can also\nbe sometimes referred to as etl or\nextract transform and load so a data\nwarehouse is like a common place where\ndata from different sources is brought\ntogether so that people can perform data\nscience activities like reporting or\ndata mining or statistical analysis and\nso on so data from various sources is\nput in a centralized place which is\nknown as a data warehouse so that is\nalso known as etl and in order to do\nthis there can be a data scientist can\ntake help of some etl tools there are\nsome existing tools that a data\nscientist can take help of like for\nexample data stage or talent or\ninformatica these are pretty good tools\nfor performing these etl activities and\ngetting the data the next stage now that\nyou have the raw data into a data\nwarehouse you still probably are not in\na position to straight away use this\ndata for performing the data mining\nactivities so that is where data\npreparation comes into play and there\nare multiple reasons for that one of\nthem could be the data is dirty there\nare some missing values and so on and so\nforth so a lot of time is actually spent\nin this particular stage so a data\nscientist spends a lot of time almost 60\nto 70 percent of the time in\nthis part of the project or the process\nwhich is data preparation so there are\nagain within this there can be multiple\nsub activities starting from let's say\ndata cleaning you will probably have\nmissing values the data there is some\ncolumns the values are missing or the\nvalues are incorrect there are null\nvalues and so on and so forth so that is\nbasically the data cleaning part of it\nthen you need to perform certain\ntransformations like for example\nnormalizing the data and so on right so\nyou could probably have to modify a\ncategorical values into numerical values\nand so on and so forth so these are\ntransformational activities then we may\nhave to handle outliers so the data\ncould be such that there are a few\nvalues which are way beyond the normal\nbehavior of the data for whatever reason\neither people have keyed in wrong values\nor for some reason some of the values\nare completely out of range so those are\nknown as outliers so there are certain\nways of handling these outliers and\ndetecting and handling these outliers so\nthis is a part of what is known as\nexploratory analysis so you quickly\nexplore the data to find out other so\nand you can use visual tools like plots\nand identify what are the outliers and\nsee how we can get rid of the outliers\nand so on then the next part could be\ndata integrity data integrity is to\nvalidate for example if there are some\nprimary keys that all the primary keys\nare populated there are some foreign\nkeys then at least most of the foreign\nkeys should be populated and otherwise\nwhen we are trying to query the data you\nmay get wrong values and so on so that\nis the data integrity part of it and\nthen we have what is known as data\nreduction sometimes we may have\nduplicate values we may have columns\nthat may be\nduplicated because they are coming from\ndifferent sources the same values are\nthere and so on so a lot of this can be\ndone using what is known as data\nreduction and thereby you can reduce the\nsize of the data drastically because\nvery often this could be written in data\nwhich can be removed and so on so let's\ntake a look at what are the various\ntechniques that are used for data\ncleaning so we need to ensure that the\ndata is valid and it is consistent and\nuniform and accurate so these are the\nvarious parameters that we need to\nensure as a part of the data cleaning\nprocess now what are the techniques that\nthat are used for data cleaning or so we\nwill see what each of these are in this\nparticular case and so what is the data\nset that we have we have data about a\nbank and its customer details so let's\ntake an example and see how we go about\ncleaning the data and in this particular\nexample we are assuming we are using\npython so let's assume we loaded this\ndata which is the raw file.csv this is\nhow the customer data looks like and\nwe will see for example we take a closer\nlook at the geography column we will see\nthat there are quite a few blank spaces\nso how do we go about when we have some\nblank spaces or if it is a string value\nthen we put an empty string here or we\njust use a space or empty string if\nthere are numerical values then we need\nto come up with a strategy\nfor example\nwe put the mean value so wherever it is\nmissing we find the mean for that\nparticular column so in this case let's\nassume we have credit score and we see\nthat quite a few of these values are\nmissing so what do we do here we find\nthe mean for this column for all the\nexisting values and we found that the\nmean is equal to\n638.6 so we kind of write a piece of\ncode to replace wherever there are blank\nvalues nan is basically like null and\nwe just go ahead and say fill it with\nthe mean value so this is the piece of\ncode we are writing to fill it so all\nthe blanks or all the null values get\nreplaced with the mean value now one of\nthe reasons for doing this is that very\noften if you have some such situation\nmany of your statistical functions may\nnot even work so that's the reason you\nneed to fill up these values or either\nget rid of these records or fill up\nthese values with something meaningful\nso this is one mechanism which is\nbasically using a mean there are few\nothers as we move forward we can see\nwhat are the other ways for example we\ncan also say that any missing value in a\nparticular row if even one column the\nvalue is missing you just drop that\nparticular row or delete all rows where\neven a single column has missing values\nso that is one way of dealing now the\nproblem here can be that if a lot of\ndata has let's say one or two columns\nmissing and\nwe dropped many such rows then overall\nyou may lose out on let's say 60 of the\ndata has some value or the other missing\n60 of the rows then it may not be a good\nidea to delete all the rows like in that\nmanner because then you're losing pretty\nmuch 60 of your data therefore your\nanalysis won't be accurate but if it is\nonly 5 or 10 percent then this will work\nanother way is only to drop values where\nor rather dropped rows where all the\ncolumns are empty which makes sense\nbecause that means that record is of\nreally no use because it has no\ninformation in it so there can be some\nsituations like that so we can provide a\ncondition saying that drop the records\nwhere all the columns are blank or not\napplicable we can also specify some kind\nof a threshold let's say you have 10 or\n20 columns in a row you can specify that\nmaybe five columns are blank or null\nthen you drop that record so again we\nneed to take care that such a condition\nsuch a situation the amount of data that\nhas been removed or excluded is not\nlarge if it is like maybe five percent\nmaximum ten percent then it's okay but\nby doing this if you're losing out on a\nlarge chunk of data then it may not be a\ngood idea you need to come up with\nsomething better what else we need to do\nnext is so the data preparation part is\ndone so now we get into the data mining\npart so what exactly we do in data\nmining primarily we come up with ways to\ntake meaningful decisions so data mining\nwill give us insights into the data what\nis existing there and then we can do\nadditional stuff like maybe machine\nlearning and so on to get perform\nadvanced analytics and so on so one of\nthe first steps we do is what is known\nas data discovery and\nwhich is basically like exploratory\nanalysis so we can use tools like\ntableau for doing some of this so let's\njust take a quick look at how we go\nabout that so tableau is excellent data\nmining or actually more of a reporting\nor a bi tool\nand you can download a trial version of\ntableau at tableau.com or there is also\ntableau public which is free and you can\nactually use and play around however if\nyou want to use it for enterprise\npurpose then it is a commercial software\nso you need to purchase license and you\ncan then run some of the data mining\nactivities say your data source your\ndata is in some excel sheet so you can\nselect the source as microsoft excel or\nany other format and the data will be\nbrought into the tableau environment and\nthen it will show you what is known as\ndimensions and measures so dimensions\nare all the descriptive columns so and\ntableau is intelligent enough to\nactually identify these dimensions and\nmeasure so measures are the numerical\nvalues so as you can see here customer\nid gender geography these are all\ndimensions non-numerical values whereas\nage balance credit score and so on are\nnumeric values so they come under\nmeasures so you've got your data into\ntableau and then you want to let's say\nbuild a small model and you want to\nlet's say solve a particular problem so\nwhat is the problem statement all right\nlet's say we want to analyze why\ncustomers are\nleaving the bank which is known as exit\nand we want to analyze and see what are\nsome of the factors for exiting the bank\nand we want to let's assume consider\nthese three of them like let's say\ngender credit card and geography these\nas a criteria and analyze if these are\nin any way impacting or have some\nbearing on the customer exiting or the\ncustomer exit behavior okay so let's um\nuse tableau and very quickly we will be\nable to find out how these parameters\nare affecting all right so let's see so\nthis is our customer data so from our\nexcel sheet we have data set about let's\nsay 10 000 rows and we want to find out\nwhat is the criteria let's start with\ngender let's say we want to first use\ngender as a criteria so tableau really\noffers an easy drag and drop kind of a\nmechanism so that makes it really really\neasy to perform this kind of analysis so\nwhat we need to do is exited says\nwhether the customer has exited or not\nso it has a value of 0 and 1 and then of\ncourse you have gender and so on so we\nwill take these two and simply drag and\ndrop okay so exit it and then we will\nput gender and if we drag and drop into\nthe analysis side of tableau all right\nso here what we are doing is we are\nshowing male female as two different\ncolumns here and zero for people who did\nnot exist and one for people who exited\nand that is color coded so the blue\ncolor means people who did not exist and\nthis yellow color means people who\ndetects it all right so now if we pull\nthe data here create like bar graphs\nthis is how it would look so what is\nyellow let's go back so yellow is uh who\nexited and\nfor the male only\n16.45 percent have exited and we can\nalso draw a reference line that will\nhelp us or even provide aliases so these\nare a lot of fancy stuff that is\nprovided by tableau you can create\naliases and so that it looks good rather\nthan basic labels and you can also add a\nreference line so you add a reference\nline something like this from here we\ncan make out that on an average female\ncustomers exit more than the male\ncustomers right so that is what we are\nseeing here on an average so we have\nanalyzed based on gender we do see that\nthere is some difference in the male and\nfemale behavior now let's take the next\ncriteria which is the credit card so\nlet's see if having a credit card has\nany impact on the customer exit behavior\nso just like before we drag and drop the\ncredit card has credit card a column if\nwe drag and drop here and then we will\nsee that there is pretty much no\ndifference between people having credit\ncard and not having credit card\n20.81 percent of people who have no\ncredit card have exited and similarly\n20.18 of people who have credit card\nhave also exited so the credit card is\nnot having\nmuch of an impact that's what this piece\nof analysis shows last we will basically\ngo and check how the geography is\nimpacting so once again we can drag and\ndrop geography column onto this side and\nif we see here there are geographies\nlike i think there are about three\ngeographies like france germany and\nspain and\nwe see that there is some kind of\nimpact with the geography as well okay\nso what we derive from this is that the\ncredit card is really we can ignore the\ncredit card variable or feature from our\nanalysis because that doesn't have any\nimpact but gender and geography we can\nkeep and do further analysis okay all\nright so what are some of the advantages\nof data mining bit more detailed\nanalysis can help us in predicting the\nfuture trends and it also helps in\nidentifying customer behavior patterns\nokay so you can take informed decisions\nbecause the data is telling you or\nproviding you with some insights and\nthen you take a decision based on that\nif there is any fraudulent activity data\nmining will help in quickly identifying\nsuch a fraud as well and of course it\nwill also help us in identifying the\nright algorithm for performing more\nadvanced data mining activities like\nmachine learning and so on all right so\nthe next activity now that we have the\ndata we have prepared the data and\nperformed some data mining activity the\nnext step is model building let's take a\nlook at model building so what is model\nbuilding if we want to perform a more\ndetailed data mining activity like maybe\nperform some machine learning then\nyou need to build a model and how do you\nbuild a model first thing is you need to\nselect which algorithm you want to use\nto solve the problem on hand and also\nwhat kind of data that is available and\nso on and so forth so you need to make a\nchoice of the algorithm and based on\nthat you go ahead and create a model\ntrain the model and so on now machine\nlearning is kind of at a very high level\nclassified into supervised and\nunsupervised so if we want to predict a\ncontinuous value could be a price or a\ntemperature or a height or a length or\nthings like that so those are continuous\nvalues and if you want to find some of\nthose then you use techniques like\nregression linear regression simple\nlinear regression multiple linear\nregression and so on so these are the\nalgorithms on the other hand there will\nbe situations or there may be situations\nwhere you need to perform unsupervised\nlearning case of unsupervised learning\nyou don't have any historical\nlabeled data so to learn from so that is\nwhen you use unsupervised learning and\nsome of the algorithms in unsupervised\nlearning are clustering k means\nclustering is the most common algorithm\nused in unsupervised learning and\nsimilarly in supervised learning if you\nwant to perform some activity on\ncategorical values like for example it\nis not measured but it is counted like\nyou want to classify whether this image\nis a cat or a dog whether you want to\nclassify whether this customer will buy\nthe product or not or you want to\nclassify whether this email is spam or\nnot spam so these are examples of\ncategorical values and\nthese are examples of classification\nthen you have algorithms like logistic\nregression k nearest neighbor or k nn\nand support vector machine so these are\nsome of the algorithms that are used in\nthis case and similarly in case of\nunsupervised learning if you need to\nperform on categorical values you have\nsome algorithms like association\nanalysis and hidden markov model okay so\nin order to understand this better let's\ntake an example and\ntake you through the whole process and\nthen we will also see how the code can\nbe written to perform this now let's\ntake our example here where we want to\nperform supervised learning which is\nbasically we want to do a multi-linear\nregression which means there are\nmultiple independent variables and then\nyou want to perform a linear regression\nto predict certain value so in this\nparticular example we have world\nhappiness data so this is the data about\nthe happiness quotient of people from\nvarious countries and we are trying to\npredict and see whether or how our model\nwill perform so what is the question\nthat we need to ask first of all how to\ndescribe the data and then can we make a\npredictive model to calculate the\nhappiness score right so based on this\nwe can then decide on what algorithm to\nuse and what model to use and so on so\nvariables that are available or used in\nthis model this is a list of variables\nthat are available there is a happiness\nrank i'll load the data and i'll show\nyou the data in a little bit so it\nbecomes clear what are these so there is\nwhat is known as the happiness rank\nhappiness score which is happiness score\nis more uh like absolute value whereas\nrank is what is the ranking and then\nwhich country we are talking about and\nwithin that country which region and\nwhat kind of economy and whether the\nfamily which family and health details\nand freedom trust generosity and so on\nand so forth so there are multiple\nvariables that are available to us and\nthe specific details probably are not\nrequired and there can be\nin another example the variables can be\ncompletely different so we don't have to\ngo into the details of what exactly\nthese variables are but just enough to\nunderstand that we have a bunch of these\nvariables and now we need to use either\nall or some of these variables and then\nwhich we also sometimes refer to as\nfeatures and then we need to build our\nmodel and train our model all right so\nlet's assume we will use python in order\nto perform this analysis or perform this\nmachine learning activity and i will\nactually show you in our lab in in a\nlittle bit this whole thing we will run\nthe live code but quickly i will run you\nthrough the slides and then we will go\ninto the lab so what are we doing here\nfirst thing we need to do is import a\nbunch of libraries in python which are\nrequired to perform our analysis most of\nthese are for manipulating the data\npreparing the data and then scikit-learn\nor sk learn is the library which you\nwill use actually for this particular\nmachine learning activity which is\nlinear regression so we have numpy we\nhave pandas and so on and so forth so\nall these libraries are imported and\nthen we load our data and the data is in\nthe form of a csv file and there are\ndifferent files for each year so we have\ndata for 2015 16 and 17. and so we will\nload this data and then combine them\nconcatenate them to prepare a single\ndata frame and here we are making an\nassumption that you are familiar with\npython so it becomes easier if you are\nfamiliar with python programming\nlanguage or at least some programming\nlanguage so that you can at least\nunderstand by looking at the code so we\nare reading the file each of these files\nfor each year and this is basically we\nare creating a list of all the names of\nthe columns we will be using later on\nyou will see in the code so we have\nloaded 2015 then 2016\nand then also 2017. so we have created\nthree data frames and then we\nconcatenate all these three data frames\nthis is what we are doing here then we\nidentify which of these columns are\nrequired which for example some of the\ncategorical values do we really need we\nprobably don't then we drop those\ncolumns so that we don't unnecessarily\nuse all the columns and make the\ncomputation complicated we can then\ncreate some plots using plotly library\nand it has some powerful features\nincluding creation or creation of maps\nand so on just to understand the pattern\nthe happiness quotient or how the\nhappiness is across all the countries so\nit's a nice visualization we can see\neach of these countries how they are in\nterms of their happiness score this is\nthe legend here so the lighter colored\ncountries have lower ranking and so\nthese are the lower ranking ones and\nthese are higher ranking which means\nthat the ones with these dark colors are\nthe happiest ones so as you can see here\naustralia and maybe this side us and so\non are the happiest ones\nokay the other thing that we need to do\nis the correlation between the happiness\nscore and happiness rank we can find a\ncorrelation using a scatter plot and we\nfind that yes they are kind of inversely\nproportioned which is obvious so if the\nscore is high happiness score is high\nthen they are ranked number one for\nexample highest is scored as number one\nso that's the idea behind this so the\nhappiness score given here and the\nhappiness rank is actually given here so\nthey are inversely proportional because\nthe higher the score then the absolute\nvalue of the rank will be lower right so\nnumber one has the highest value of the\nscore and so on so they are inversely\ncorrelated but there is a strong what\nthis graph shows is that there is a\nstrong correlation between happiness\nrank and happiness score and then we do\nsome more plots to visualize this we\ndetermine that probably rank and score\nare pretty much conveying the same\nmessage so we don't need both of them so\nwe will kind of drop one of them and\nthat is what we are doing here so we\ndrop the happiness rank and similarly so\nthis is one example of how we can remove\nsome columns which are not adding value\nso we will see in the code as well how\nthat works moving on this is a\ncorrelation between pretty much each of\nthe columns with the other columns so\nthis is a correlation you can plot using\nplot function and we will see here that\nfor example happiness score and\nhappiness score are correlated strongest\ncorrelation right because every variable\nwill be highly correlated to itself so\nthat's the reason so the darker the\ncolor is the higher the correlation and\nas so the and correlation in numerical\nterms goes from zero to one so one is\nthe highest value and it can only be\nbetween zero and one correlation between\ntwo variables can be only have a value\nbetween zero and one so the numerical\nvalue can go from zero to one and one\nhere is dark color and\nzero is uh kind of dark but it is blue\ncolor from red it goes down the dark\nblue color indicates pretty much no\ncorrelation so from this heat map we see\nthat happiness and economy and family\nare probably also health probably are\nthe most correlated and then it keeps\ndecreasing after freedom kind of keeps\ndecreasing and coming to pretty much\nzero all right so that is a correlation\ngraph and then we can probably use this\nto find out which are the columns that\nneed to be dropped which do not have\nvery high correlation and\nwe take only those columns that we will\nneed so this is the code for dropping\nsome of the columns once we have\nprepared the data when we have the\nrequired columns then we use scikit\nlearn to actually split the data first\nof all this is a normal machine learning\nprocess you need to split the data into\ntraining and test data set in this case\nwe are splitting into 80 20 so 80 is the\ntraining data set and 20 is the test\ndata set so that's what we are doing\nhere so we use train test split method\nor function so you have all your\ntraining data\nin x underscore train the labels in y\nunderscore train similarly x underscore\ntest has the test data the inputs\nwhereas the labels are in y underscore\ntest so that's how and this value\nwhether it is 80 20 or 50 50 that is all\nindividual preference so in our case we\nare using 80 20. all right and then the\nnext is to create a linear regression\ninstance so this is what we are doing we\nare creating an instance of linear\nregression and then we train the model\nusing the fit function and we are\npassing x and y which is the x value and\nthe label data regular input and the\nlabel data label information then we do\nthe test we run the or we perform the\nevaluation on the test data set so this\nis what we are doing with the test data\nset and then we will evaluate how\naccurate the model is and using the\nscikit-learn functionality itself we can\nalso see what are the various parameters\nand what are the various coefficients\nbecause in linear regression you will\nget like a equation of like a straight\nline y is equal to beta 0 plus beta 1 x\n1 plus beta 2 x 2 so those beta 1 beta 2\nbeta 3 are known as the coefficients and\nbeta0 is the intercept after the\ntraining you can actually get these\ninformation of the model what is the\nintercept value what are the\ncoefficients and so on by using these\nfunctions so let's take quickly go into\nthe lab and take a look at our code okay\nso this is\nmy\nlab this is my jupiter notebook where\nthe code i have the actual code and i\nwill take you through this code to run\nthis linear regression on the world\nhappiness data so we will import a bunch\nof libraries numpy pandas plot plotly\nand so on also yeah scikit learn that's\nalso very important\nso\nthat's the first step then i will import\nmy data and the data is in three parts\nthere are three files one for each year\n2015 2016 and 2017 and it is a csv file\nso i've imported my data let's take a\nlook at the data quickly glance at data\nso this is how it looks we have the\ncountry region happiness rank and then\nhappiness score there are some standard\nerrors and then what is the per capita\nfamily and so on so then we will keep\ngoing we will create a list of all these\ncolumn names we will be using later so\nfor now just i will run this code no\nneed of major explanation at this point\nwe know that some of these columns\nprobably are not required so you can use\nthis drop functionality to remove some\nof the columns which we don't need like\nfor example region and standard error\nwill not be contributing to our model so\nwe will basically drop those values out\nhere so we use the drop and then we\ncreated a vector with these names column\nnames that's what we are passing here\ninstead of giving the names of the\ncolumns here we can pass a vector so\nthat's what we are doing so this will\ndrop from our data frame it will remove\nregion and standard error these two\ncolumns then the next step we will read\nthe data for 2016 and also 2017\nand then we will concatenate this data\nso let's do that so we have now data\nframe called happiness which is a\nconcatenation of both all the three\nfiles let's take a quick look at the\ndata now so most of the unwanted columns\nhave been removed and you have all the\ndata in one place for all the three\nyears and this is how the data looks and\nif you want to take a\nlook at the summary\nof the columns you can say describe and\nyou will get this information for\nexample for each of the columns what is\nthe count what what is the mean value\nstandard deviation especially the\nnumeric values okay not the categorical\nvalues so this is a quick way to see how\nthe data is and\ninitial little bit of exploratory\nanalysis can be done here so what is the\nmaximum value what's the minimum value\nand so on for each of the columns all\nright so then we go ahead and create\nsome visualizations using plotly so let\nus go and\nbuild a plot so if we see here now this\nis the relation correlation between\nhappiness rank and happiness score this\nis what we have seen in the slides as\nwell we can see that there is a tight\ncorrelation between them only thing is\nit is inverse correlation but otherwise\nthey are very tightly correlated which\nalso says that they both probably\nprovide the same information so there is\nno not much of value add so we will go\nahead and drop the happiness rank as\nwell from our columns so that's what\nwe're doing here and now we can\ndo the creation of the correlation heat\nmap let us plot the correlation heat map\nto see how each of these columns is\ncorrelated to the others and we as we\nhave seen in the slides this is how it\nlooks so happiness score is very highly\ncorrelated so this is the legend we have\nseen in the slide as well so blue color\nindicates pretty much zero or very low\ncorrelation deep red color indicates\nvery high correlation and the value\ncorrelation is a numeric value and the\nvalue goes from zero to one if the two\nitems or two features or columns are\nhighly correlated then there will be as\nclose to one as possible and two columns\nthat are not at all correlated will be\nas close to zero as possible so that's\nhow it is for example here happiness\nscore and happiness score every column\nor every feature will be highly\ncorrelated to itself so it is like\nbetween them there will be correlation\nvalue will be one so that's why we see\ndeep red color but then others are for\nexample with higher values are economy\nand then health and then maybe family\nand freedom so these are generosity and\ntrust are not very highly correlated to\nhappiness score so that is\none quick exploratory analysis we can do\nand therefore we can drop the country\nand happiness rank because they also\nagain don't have any major impact on the\nanalysis on our analysis so now we have\nprepared our data there was no need to\nclean the data because the data was\nclean but if there were some missing\nvalues and so on as we have discussed in\nthe slides we would have had to perform\nsome of the data cleaning activities as\nwell but in this case the data was clean\nall we needed to do was just the\npreparation part so we removed some\nunwanted columns and we did some\nexploratory data analysis now we are\nready to perform the machine learning\nactivity so we use scikit-learn for\ndoing the machine learning circuit learn\nis python library that is available for\nperforming our machine learning once\nagain we will import some of these\nlibraries like pandas and numpy and\nalso psychic learn first step we will do\nis split the data in 2080 format so you\nhave all the test data which is 20 of\nthe data is test data and 80 percent is\nyour training data so this test size\nindicates how much of it is the what is\nthe size of the test data the remaining\nwhich is a point here we are saying\npoint two therefore that means training\nis point eight so training data is\neighty percent all right so we have\nexecuted that split the data and now we\ncreate an instance of the linear\nregression model so lm is our linear\nregression model and we pass x and y the\ntraining data set and call the function\nfit so that the model gets trained so\nnow once that is done training is done\ntraining is completed and now what we\nhave to do is we need to predict the\nvalues for the test data so the next\nstep is using so you see your fit will\nbasically run the training method\npredict will actually predict the values\nso we are passing the input values which\nis the independent variables and we are\nasking for the values of the dependent\nvariable which is which we are capturing\nin y underscore track and we use the\npredict method here lm.predict so this\nwill give us all the predicted y values\nand remember we already have y\nunderscore test has the actual values\nwhich are the labels so that we can use\nthese two to compare and find out how\nmuch of it is error so that's what we\nare doing here we are trying to find the\ndifference between the predicted value\nand the actual value why underscore test\nis the actual value for the test data\nand why underscore predict is the\npredicted value we just found out the\npredictive line so we will run that and\nwe can do a quick check as to how the\ndata looks how is the difference so in\nsome cases it is positive some cases it\nis negative but in most of the cases i\nthink the difference is very small this\nis exponential to the power of 0 minus\n04 and so on so looks like our model has\nperformed reasonably well we can now\ncheck some of the parameters of our\nmodel like the intercept and the\ncoefficients so that's what we are doing\nhere so these are the coefficients of\nthe various parameters that we are the\ncoefficients of the various independent\nvariables okay so these are the values\nthen we can quickly go ahead and list\nthem down as well against the\ncorresponding independent variables so\nthe coefficients against the\ncorresponding independent variable so\n1.0051 is the coefficient for economy\n0.99983 is for family coefficient for\nfamily and health and so on and so forth\nright so that's what this is showing now\nwe can use the functionality readily\navailable functionality of scikit-learn\nand then plot that to find some of the\nparameters which determine the accuracy\nof this model like for example what is\nthe mean square error and so on so\nthat's what we are doing here so let's\njust go ahead and run this so you can\nsee here that the root mean square error\nis pretty low which is a good sign and\nwhich is one of the measures of\nhow well our model is performing we can\ndo one more quick plot to just see how\nthe actual values and the predicted\nvalues are looking and once again you\ncan see that as we have seen from the\nroot mean square error root mean square\nerror is very very low that means that\nthe actual values and the predicted\nvalues are pretty much matching up\nalmost matching up and this plot also\nshows the same so this line is going\nthrough the predicted values and the\nactual values and the differences very\nvery low so again this is actual data\nthis is one example where the accuracy\nis high and the predicted values are\npretty much matching with the actual\nvalues but in real life you may find\nthat these values are slightly more\nscattered and you may get the error\nvalue can be relatively on the higher\nside the root mean squared okay so this\nwas a good\nquick example of the code to perform\ndata science activity or a machine\nlearning or data mining activity in this\ncase we did what is known as linear\nregression so let's go back to our\nslides and see what else is there so we\nsaw this these are the coefficients of\neach of the features in our code and\nwe have seen the root mean square error\nas well and we can take a few hundred\ncountries\ncertain values and actually predict to\nsee if how the model is performing and i\nthink we have done this as well and in\nthis case as we have seen pretty much\nthe predicted values and the actual\nvalues are pretty much matching which\nmeans our model is almost hundred\npercent accurate as i mentioned in real\nlife it may not be the case but in this\nparticular case we have got a pretty\ngood model which is very good also\nsubsequently we can assume that this is\nhow the equation in linear regression\nthe model is nothing but an equation\nlike y is equal to beta 0 plus beta 1 x\n1 plus beta 2 x 2 plus beta 3 x 3 and so\non so this is what we are showing here\nso this is our intercept which is beta0\nand then we have beta1 into economy\nvalue beta2 into the family value beta3\ninto health value and so on so that is\nwhat is shown here okay so i think the\nnext step once we have the results from\nthe data mining or machine learning\nactivity the next step is to communicate\nthese results to the appropriate\nstakeholders so that is what we will see\nhere now so how do we communicate\nusually you take these results and then\neither prepare a presentation or put it\nin a document and then show them these\nactionable results or reasonable\ninsights and you need to find out who\nare your target audience and put all the\nresults in context and maybe if there\nwas a problem statement you need to put\nthis results in the context of the\nproblem statement what was our initial\ngoal that we wanted to achieve so that\nwe need to communicate here based on you\nremember we started off with what is the\nquestion and what is the data and so on\nand then what is the answer so we we\nneed to put the results and then what is\nthe methodology that we have used all\nthat has to be put and clearly\ncommunicated in business terms so that\nthe people understand very well from a\nbusiness perspective so once the model\nbuilding is done once the results are\npublished and communicated the last part\nis maintenance of this model now very\noften what can happen is the model may\nhave to be subsequently updated or\nmodified because of multiple reasons\neither the the data has changed the way\nthe data comes has changed or the\nprocess has changed or for whatever\nreason the accuracy may keep changing\nonce you have a trained model the for\nexample we got a very high accuracy but\nthen over a period of time there can be\nvarious factors which can cause that so\nfrom time to time we need to check\nwhether the model is performing well or\nnot the accuracy needs to be tested once\nin a while and if required you may have\nto rebuild or retrain the model so you\ndo the assessment you you see if it\nneeds any tweaks or changes and then if\nit is required you need to probably\nretrain the model with the latest data\nthat you have and then you deploy it to\nyou build the model train it and then\nyou deploy it so that is like the\nmaintenance cycle that you may have to\ntake the model through all right so we\nare pretty much at the end of our\ntutorial so what did we learn in this\ntutorial we talked about what is data\nscience and\nwho is a data scientist then we talked\nabout what a data scientist performs or\ndoes a day in the life of a data\nscientist some of the activities or the\nmethodologies like the processes rather\ndata acquisition data preparation\nmining and model building and so on and\nthen last but not least the model\nmaintenance and in the process we have\nalso taken a look at the python code\nthat was used for performing a linear\nregression model creating a linear\nregression model training it and testing\nit and checking the various parameters\nof that model with that we come to the\nend of this tutorial i hope you enjoyed\nit if you have any questions or comments\nput it below the video in the comment\nsection we will be more than happy to\nrespond especially if you leave your\nemail address i would like to thank you\nonce again and have a great day thank\nyou and bye\nhi there if you like this video\nsubscribe to the simply learn youtube\nchannel and click here to watch similar\nvideos turn it up and get certified\nclick here\n",
  "words": [
    "hello",
    "welcome",
    "tutorial",
    "data",
    "science",
    "tutorial",
    "going",
    "see",
    "data",
    "science",
    "data",
    "scientist",
    "skills",
    "data",
    "scientist",
    "data",
    "scientist",
    "day",
    "life",
    "data",
    "scientist",
    "methodology",
    "used",
    "data",
    "science",
    "like",
    "data",
    "acquisition",
    "preparation",
    "mining",
    "model",
    "building",
    "testing",
    "maintenance",
    "towards",
    "end",
    "also",
    "see",
    "example",
    "program",
    "well",
    "take",
    "quick",
    "code",
    "done",
    "data",
    "science",
    "activity",
    "conclude",
    "let",
    "get",
    "started",
    "data",
    "science",
    "name",
    "suggests",
    "nothing",
    "study",
    "using",
    "data",
    "trying",
    "find",
    "insights",
    "extracting",
    "insights",
    "knowledge",
    "using",
    "data",
    "disposal",
    "pretty",
    "much",
    "data",
    "science",
    "take",
    "data",
    "apply",
    "certain",
    "methodologies",
    "certain",
    "algorithms",
    "business",
    "domain",
    "knowledge",
    "well",
    "course",
    "certain",
    "amount",
    "creativity",
    "extract",
    "insights",
    "often",
    "also",
    "known",
    "actionable",
    "insights",
    "insights",
    "position",
    "take",
    "action",
    "let",
    "say",
    "solve",
    "problem",
    "improve",
    "situation",
    "lot",
    "areas",
    "data",
    "science",
    "used",
    "one",
    "common",
    "one",
    "fraud",
    "detection",
    "fraud",
    "prevention",
    "lot",
    "fraudulent",
    "activities",
    "transactions",
    "primarily",
    "internet",
    "easy",
    "commit",
    "fraud",
    "therefore",
    "use",
    "data",
    "science",
    "either",
    "prevent",
    "detect",
    "fraud",
    "certain",
    "algorithms",
    "machine",
    "learning",
    "algorithms",
    "used",
    "like",
    "example",
    "outlier",
    "techniques",
    "clustering",
    "techniques",
    "used",
    "detect",
    "fraud",
    "prevent",
    "fraud",
    "well",
    "data",
    "scientist",
    "rather",
    "actually",
    "generic",
    "role",
    "defines",
    "somebody",
    "working",
    "data",
    "known",
    "data",
    "scientist",
    "specific",
    "activities",
    "roles",
    "actually",
    "much",
    "specific",
    "exactly",
    "person",
    "within",
    "area",
    "data",
    "science",
    "much",
    "specific",
    "broadly",
    "anybody",
    "working",
    "area",
    "data",
    "science",
    "known",
    "data",
    "scientist",
    "data",
    "scientist",
    "activities",
    "data",
    "acquisition",
    "data",
    "preparation",
    "data",
    "mining",
    "data",
    "modeling",
    "model",
    "maintenance",
    "talk",
    "great",
    "detail",
    "high",
    "level",
    "first",
    "step",
    "obviously",
    "get",
    "raw",
    "data",
    "known",
    "data",
    "acquisition",
    "kinds",
    "format",
    "could",
    "multiple",
    "sources",
    "obviously",
    "raw",
    "data",
    "used",
    "performing",
    "data",
    "mining",
    "activities",
    "data",
    "modeling",
    "activities",
    "data",
    "claimed",
    "prepared",
    "using",
    "data",
    "models",
    "data",
    "mining",
    "activity",
    "data",
    "preparation",
    "actually",
    "data",
    "mining",
    "also",
    "include",
    "exploratory",
    "activities",
    "stuff",
    "like",
    "machine",
    "learning",
    "need",
    "build",
    "machine",
    "learning",
    "model",
    "test",
    "model",
    "get",
    "insights",
    "model",
    "fine",
    "deploy",
    "need",
    "maintain",
    "model",
    "period",
    "time",
    "possible",
    "need",
    "tweak",
    "model",
    "change",
    "process",
    "changing",
    "data",
    "comes",
    "model",
    "maintenance",
    "let",
    "take",
    "deeper",
    "look",
    "activities",
    "let",
    "start",
    "data",
    "acquisition",
    "stage",
    "data",
    "acquisition",
    "basically",
    "data",
    "scientist",
    "collect",
    "raw",
    "data",
    "possible",
    "sources",
    "could",
    "typically",
    "rdbms",
    "relational",
    "database",
    "also",
    "could",
    "flat",
    "files",
    "unstructured",
    "data",
    "need",
    "bring",
    "data",
    "different",
    "sources",
    "required",
    "need",
    "kind",
    "homogeneous",
    "formatting",
    "fits",
    "looks",
    "least",
    "format",
    "format",
    "perspective",
    "looks",
    "homogeneous",
    "may",
    "requiring",
    "kind",
    "transformation",
    "often",
    "loaded",
    "known",
    "data",
    "warehouse",
    "also",
    "sometimes",
    "referred",
    "etl",
    "extract",
    "transform",
    "load",
    "data",
    "warehouse",
    "like",
    "common",
    "place",
    "data",
    "different",
    "sources",
    "brought",
    "together",
    "people",
    "perform",
    "data",
    "science",
    "activities",
    "like",
    "reporting",
    "data",
    "mining",
    "statistical",
    "analysis",
    "data",
    "various",
    "sources",
    "put",
    "centralized",
    "place",
    "known",
    "data",
    "warehouse",
    "also",
    "known",
    "etl",
    "order",
    "data",
    "scientist",
    "take",
    "help",
    "etl",
    "tools",
    "existing",
    "tools",
    "data",
    "scientist",
    "take",
    "help",
    "like",
    "example",
    "data",
    "stage",
    "talent",
    "informatica",
    "pretty",
    "good",
    "tools",
    "performing",
    "etl",
    "activities",
    "getting",
    "data",
    "next",
    "stage",
    "raw",
    "data",
    "data",
    "warehouse",
    "still",
    "probably",
    "position",
    "straight",
    "away",
    "use",
    "data",
    "performing",
    "data",
    "mining",
    "activities",
    "data",
    "preparation",
    "comes",
    "play",
    "multiple",
    "reasons",
    "one",
    "could",
    "data",
    "dirty",
    "missing",
    "values",
    "forth",
    "lot",
    "time",
    "actually",
    "spent",
    "particular",
    "stage",
    "data",
    "scientist",
    "spends",
    "lot",
    "time",
    "almost",
    "60",
    "70",
    "percent",
    "time",
    "part",
    "project",
    "process",
    "data",
    "preparation",
    "within",
    "multiple",
    "sub",
    "activities",
    "starting",
    "let",
    "say",
    "data",
    "cleaning",
    "probably",
    "missing",
    "values",
    "data",
    "columns",
    "values",
    "missing",
    "values",
    "incorrect",
    "null",
    "values",
    "forth",
    "basically",
    "data",
    "cleaning",
    "part",
    "need",
    "perform",
    "certain",
    "transformations",
    "like",
    "example",
    "normalizing",
    "data",
    "right",
    "could",
    "probably",
    "modify",
    "categorical",
    "values",
    "numerical",
    "values",
    "forth",
    "transformational",
    "activities",
    "may",
    "handle",
    "outliers",
    "data",
    "could",
    "values",
    "way",
    "beyond",
    "normal",
    "behavior",
    "data",
    "whatever",
    "reason",
    "either",
    "people",
    "keyed",
    "wrong",
    "values",
    "reason",
    "values",
    "completely",
    "range",
    "known",
    "outliers",
    "certain",
    "ways",
    "handling",
    "outliers",
    "detecting",
    "handling",
    "outliers",
    "part",
    "known",
    "exploratory",
    "analysis",
    "quickly",
    "explore",
    "data",
    "find",
    "use",
    "visual",
    "tools",
    "like",
    "plots",
    "identify",
    "outliers",
    "see",
    "get",
    "rid",
    "outliers",
    "next",
    "part",
    "could",
    "data",
    "integrity",
    "data",
    "integrity",
    "validate",
    "example",
    "primary",
    "keys",
    "primary",
    "keys",
    "populated",
    "foreign",
    "keys",
    "least",
    "foreign",
    "keys",
    "populated",
    "otherwise",
    "trying",
    "query",
    "data",
    "may",
    "get",
    "wrong",
    "values",
    "data",
    "integrity",
    "part",
    "known",
    "data",
    "reduction",
    "sometimes",
    "may",
    "duplicate",
    "values",
    "may",
    "columns",
    "may",
    "duplicated",
    "coming",
    "different",
    "sources",
    "values",
    "lot",
    "done",
    "using",
    "known",
    "data",
    "reduction",
    "thereby",
    "reduce",
    "size",
    "data",
    "drastically",
    "often",
    "could",
    "written",
    "data",
    "removed",
    "let",
    "take",
    "look",
    "various",
    "techniques",
    "used",
    "data",
    "cleaning",
    "need",
    "ensure",
    "data",
    "valid",
    "consistent",
    "uniform",
    "accurate",
    "various",
    "parameters",
    "need",
    "ensure",
    "part",
    "data",
    "cleaning",
    "process",
    "techniques",
    "used",
    "data",
    "cleaning",
    "see",
    "particular",
    "case",
    "data",
    "set",
    "data",
    "bank",
    "customer",
    "details",
    "let",
    "take",
    "example",
    "see",
    "go",
    "cleaning",
    "data",
    "particular",
    "example",
    "assuming",
    "using",
    "python",
    "let",
    "assume",
    "loaded",
    "data",
    "raw",
    "customer",
    "data",
    "looks",
    "like",
    "see",
    "example",
    "take",
    "closer",
    "look",
    "geography",
    "column",
    "see",
    "quite",
    "blank",
    "spaces",
    "go",
    "blank",
    "spaces",
    "string",
    "value",
    "put",
    "empty",
    "string",
    "use",
    "space",
    "empty",
    "string",
    "numerical",
    "values",
    "need",
    "come",
    "strategy",
    "example",
    "put",
    "mean",
    "value",
    "wherever",
    "missing",
    "find",
    "mean",
    "particular",
    "column",
    "case",
    "let",
    "assume",
    "credit",
    "score",
    "see",
    "quite",
    "values",
    "missing",
    "find",
    "mean",
    "column",
    "existing",
    "values",
    "found",
    "mean",
    "equal",
    "kind",
    "write",
    "piece",
    "code",
    "replace",
    "wherever",
    "blank",
    "values",
    "nan",
    "basically",
    "like",
    "null",
    "go",
    "ahead",
    "say",
    "fill",
    "mean",
    "value",
    "piece",
    "code",
    "writing",
    "fill",
    "blanks",
    "null",
    "values",
    "get",
    "replaced",
    "mean",
    "value",
    "one",
    "reasons",
    "often",
    "situation",
    "many",
    "statistical",
    "functions",
    "may",
    "even",
    "work",
    "reason",
    "need",
    "fill",
    "values",
    "either",
    "get",
    "rid",
    "records",
    "fill",
    "values",
    "something",
    "meaningful",
    "one",
    "mechanism",
    "basically",
    "using",
    "mean",
    "others",
    "move",
    "forward",
    "see",
    "ways",
    "example",
    "also",
    "say",
    "missing",
    "value",
    "particular",
    "row",
    "even",
    "one",
    "column",
    "value",
    "missing",
    "drop",
    "particular",
    "row",
    "delete",
    "rows",
    "even",
    "single",
    "column",
    "missing",
    "values",
    "one",
    "way",
    "dealing",
    "problem",
    "lot",
    "data",
    "let",
    "say",
    "one",
    "two",
    "columns",
    "missing",
    "dropped",
    "many",
    "rows",
    "overall",
    "may",
    "lose",
    "let",
    "say",
    "60",
    "data",
    "value",
    "missing",
    "60",
    "rows",
    "may",
    "good",
    "idea",
    "delete",
    "rows",
    "like",
    "manner",
    "losing",
    "pretty",
    "much",
    "60",
    "data",
    "therefore",
    "analysis",
    "wo",
    "accurate",
    "5",
    "10",
    "percent",
    "work",
    "another",
    "way",
    "drop",
    "values",
    "rather",
    "dropped",
    "rows",
    "columns",
    "empty",
    "makes",
    "sense",
    "means",
    "record",
    "really",
    "use",
    "information",
    "situations",
    "like",
    "provide",
    "condition",
    "saying",
    "drop",
    "records",
    "columns",
    "blank",
    "applicable",
    "also",
    "specify",
    "kind",
    "threshold",
    "let",
    "say",
    "10",
    "20",
    "columns",
    "row",
    "specify",
    "maybe",
    "five",
    "columns",
    "blank",
    "null",
    "drop",
    "record",
    "need",
    "take",
    "care",
    "condition",
    "situation",
    "amount",
    "data",
    "removed",
    "excluded",
    "large",
    "like",
    "maybe",
    "five",
    "percent",
    "maximum",
    "ten",
    "percent",
    "okay",
    "losing",
    "large",
    "chunk",
    "data",
    "may",
    "good",
    "idea",
    "need",
    "come",
    "something",
    "better",
    "else",
    "need",
    "next",
    "data",
    "preparation",
    "part",
    "done",
    "get",
    "data",
    "mining",
    "part",
    "exactly",
    "data",
    "mining",
    "primarily",
    "come",
    "ways",
    "take",
    "meaningful",
    "decisions",
    "data",
    "mining",
    "give",
    "us",
    "insights",
    "data",
    "existing",
    "additional",
    "stuff",
    "like",
    "maybe",
    "machine",
    "learning",
    "get",
    "perform",
    "advanced",
    "analytics",
    "one",
    "first",
    "steps",
    "known",
    "data",
    "discovery",
    "basically",
    "like",
    "exploratory",
    "analysis",
    "use",
    "tools",
    "like",
    "tableau",
    "let",
    "take",
    "quick",
    "look",
    "go",
    "tableau",
    "excellent",
    "data",
    "mining",
    "actually",
    "reporting",
    "bi",
    "tool",
    "download",
    "trial",
    "version",
    "tableau",
    "also",
    "tableau",
    "public",
    "free",
    "actually",
    "use",
    "play",
    "around",
    "however",
    "want",
    "use",
    "enterprise",
    "purpose",
    "commercial",
    "software",
    "need",
    "purchase",
    "license",
    "run",
    "data",
    "mining",
    "activities",
    "say",
    "data",
    "source",
    "data",
    "excel",
    "sheet",
    "select",
    "source",
    "microsoft",
    "excel",
    "format",
    "data",
    "brought",
    "tableau",
    "environment",
    "show",
    "known",
    "dimensions",
    "measures",
    "dimensions",
    "descriptive",
    "columns",
    "tableau",
    "intelligent",
    "enough",
    "actually",
    "identify",
    "dimensions",
    "measure",
    "measures",
    "numerical",
    "values",
    "see",
    "customer",
    "id",
    "gender",
    "geography",
    "dimensions",
    "values",
    "whereas",
    "age",
    "balance",
    "credit",
    "score",
    "numeric",
    "values",
    "come",
    "measures",
    "got",
    "data",
    "tableau",
    "want",
    "let",
    "say",
    "build",
    "small",
    "model",
    "want",
    "let",
    "say",
    "solve",
    "particular",
    "problem",
    "problem",
    "statement",
    "right",
    "let",
    "say",
    "want",
    "analyze",
    "customers",
    "leaving",
    "bank",
    "known",
    "exit",
    "want",
    "analyze",
    "see",
    "factors",
    "exiting",
    "bank",
    "want",
    "let",
    "assume",
    "consider",
    "three",
    "like",
    "let",
    "say",
    "gender",
    "credit",
    "card",
    "geography",
    "criteria",
    "analyze",
    "way",
    "impacting",
    "bearing",
    "customer",
    "exiting",
    "customer",
    "exit",
    "behavior",
    "okay",
    "let",
    "um",
    "use",
    "tableau",
    "quickly",
    "able",
    "find",
    "parameters",
    "affecting",
    "right",
    "let",
    "see",
    "customer",
    "data",
    "excel",
    "sheet",
    "data",
    "set",
    "let",
    "say",
    "10",
    "000",
    "rows",
    "want",
    "find",
    "criteria",
    "let",
    "start",
    "gender",
    "let",
    "say",
    "want",
    "first",
    "use",
    "gender",
    "criteria",
    "tableau",
    "really",
    "offers",
    "easy",
    "drag",
    "drop",
    "kind",
    "mechanism",
    "makes",
    "really",
    "really",
    "easy",
    "perform",
    "kind",
    "analysis",
    "need",
    "exited",
    "says",
    "whether",
    "customer",
    "exited",
    "value",
    "0",
    "1",
    "course",
    "gender",
    "take",
    "two",
    "simply",
    "drag",
    "drop",
    "okay",
    "exit",
    "put",
    "gender",
    "drag",
    "drop",
    "analysis",
    "side",
    "tableau",
    "right",
    "showing",
    "male",
    "female",
    "two",
    "different",
    "columns",
    "zero",
    "people",
    "exist",
    "one",
    "people",
    "exited",
    "color",
    "coded",
    "blue",
    "color",
    "means",
    "people",
    "exist",
    "yellow",
    "color",
    "means",
    "people",
    "detects",
    "right",
    "pull",
    "data",
    "create",
    "like",
    "bar",
    "graphs",
    "would",
    "look",
    "yellow",
    "let",
    "go",
    "back",
    "yellow",
    "uh",
    "exited",
    "male",
    "percent",
    "exited",
    "also",
    "draw",
    "reference",
    "line",
    "help",
    "us",
    "even",
    "provide",
    "aliases",
    "lot",
    "fancy",
    "stuff",
    "provided",
    "tableau",
    "create",
    "aliases",
    "looks",
    "good",
    "rather",
    "basic",
    "labels",
    "also",
    "add",
    "reference",
    "line",
    "add",
    "reference",
    "line",
    "something",
    "like",
    "make",
    "average",
    "female",
    "customers",
    "exit",
    "male",
    "customers",
    "right",
    "seeing",
    "average",
    "analyzed",
    "based",
    "gender",
    "see",
    "difference",
    "male",
    "female",
    "behavior",
    "let",
    "take",
    "next",
    "criteria",
    "credit",
    "card",
    "let",
    "see",
    "credit",
    "card",
    "impact",
    "customer",
    "exit",
    "behavior",
    "like",
    "drag",
    "drop",
    "credit",
    "card",
    "credit",
    "card",
    "column",
    "drag",
    "drop",
    "see",
    "pretty",
    "much",
    "difference",
    "people",
    "credit",
    "card",
    "credit",
    "card",
    "percent",
    "people",
    "credit",
    "card",
    "exited",
    "similarly",
    "people",
    "credit",
    "card",
    "also",
    "exited",
    "credit",
    "card",
    "much",
    "impact",
    "piece",
    "analysis",
    "shows",
    "last",
    "basically",
    "go",
    "check",
    "geography",
    "impacting",
    "drag",
    "drop",
    "geography",
    "column",
    "onto",
    "side",
    "see",
    "geographies",
    "like",
    "think",
    "three",
    "geographies",
    "like",
    "france",
    "germany",
    "spain",
    "see",
    "kind",
    "impact",
    "geography",
    "well",
    "okay",
    "derive",
    "credit",
    "card",
    "really",
    "ignore",
    "credit",
    "card",
    "variable",
    "feature",
    "analysis",
    "impact",
    "gender",
    "geography",
    "keep",
    "analysis",
    "okay",
    "right",
    "advantages",
    "data",
    "mining",
    "bit",
    "detailed",
    "analysis",
    "help",
    "us",
    "predicting",
    "future",
    "trends",
    "also",
    "helps",
    "identifying",
    "customer",
    "behavior",
    "patterns",
    "okay",
    "take",
    "informed",
    "decisions",
    "data",
    "telling",
    "providing",
    "insights",
    "take",
    "decision",
    "based",
    "fraudulent",
    "activity",
    "data",
    "mining",
    "help",
    "quickly",
    "identifying",
    "fraud",
    "well",
    "course",
    "also",
    "help",
    "us",
    "identifying",
    "right",
    "algorithm",
    "performing",
    "advanced",
    "data",
    "mining",
    "activities",
    "like",
    "machine",
    "learning",
    "right",
    "next",
    "activity",
    "data",
    "prepared",
    "data",
    "performed",
    "data",
    "mining",
    "activity",
    "next",
    "step",
    "model",
    "building",
    "let",
    "take",
    "look",
    "model",
    "building",
    "model",
    "building",
    "want",
    "perform",
    "detailed",
    "data",
    "mining",
    "activity",
    "like",
    "maybe",
    "perform",
    "machine",
    "learning",
    "need",
    "build",
    "model",
    "build",
    "model",
    "first",
    "thing",
    "need",
    "select",
    "algorithm",
    "want",
    "use",
    "solve",
    "problem",
    "hand",
    "also",
    "kind",
    "data",
    "available",
    "forth",
    "need",
    "make",
    "choice",
    "algorithm",
    "based",
    "go",
    "ahead",
    "create",
    "model",
    "train",
    "model",
    "machine",
    "learning",
    "kind",
    "high",
    "level",
    "classified",
    "supervised",
    "unsupervised",
    "want",
    "predict",
    "continuous",
    "value",
    "could",
    "price",
    "temperature",
    "height",
    "length",
    "things",
    "like",
    "continuous",
    "values",
    "want",
    "find",
    "use",
    "techniques",
    "like",
    "regression",
    "linear",
    "regression",
    "simple",
    "linear",
    "regression",
    "multiple",
    "linear",
    "regression",
    "algorithms",
    "hand",
    "situations",
    "may",
    "situations",
    "need",
    "perform",
    "unsupervised",
    "learning",
    "case",
    "unsupervised",
    "learning",
    "historical",
    "labeled",
    "data",
    "learn",
    "use",
    "unsupervised",
    "learning",
    "algorithms",
    "unsupervised",
    "learning",
    "clustering",
    "k",
    "means",
    "clustering",
    "common",
    "algorithm",
    "used",
    "unsupervised",
    "learning",
    "similarly",
    "supervised",
    "learning",
    "want",
    "perform",
    "activity",
    "categorical",
    "values",
    "like",
    "example",
    "measured",
    "counted",
    "like",
    "want",
    "classify",
    "whether",
    "image",
    "cat",
    "dog",
    "whether",
    "want",
    "classify",
    "whether",
    "customer",
    "buy",
    "product",
    "want",
    "classify",
    "whether",
    "email",
    "spam",
    "spam",
    "examples",
    "categorical",
    "values",
    "examples",
    "classification",
    "algorithms",
    "like",
    "logistic",
    "regression",
    "k",
    "nearest",
    "neighbor",
    "k",
    "nn",
    "support",
    "vector",
    "machine",
    "algorithms",
    "used",
    "case",
    "similarly",
    "case",
    "unsupervised",
    "learning",
    "need",
    "perform",
    "categorical",
    "values",
    "algorithms",
    "like",
    "association",
    "analysis",
    "hidden",
    "markov",
    "model",
    "okay",
    "order",
    "understand",
    "better",
    "let",
    "take",
    "example",
    "take",
    "whole",
    "process",
    "also",
    "see",
    "code",
    "written",
    "perform",
    "let",
    "take",
    "example",
    "want",
    "perform",
    "supervised",
    "learning",
    "basically",
    "want",
    "regression",
    "means",
    "multiple",
    "independent",
    "variables",
    "want",
    "perform",
    "linear",
    "regression",
    "predict",
    "certain",
    "value",
    "particular",
    "example",
    "world",
    "happiness",
    "data",
    "data",
    "happiness",
    "quotient",
    "people",
    "various",
    "countries",
    "trying",
    "predict",
    "see",
    "whether",
    "model",
    "perform",
    "question",
    "need",
    "ask",
    "first",
    "describe",
    "data",
    "make",
    "predictive",
    "model",
    "calculate",
    "happiness",
    "score",
    "right",
    "based",
    "decide",
    "algorithm",
    "use",
    "model",
    "use",
    "variables",
    "available",
    "used",
    "model",
    "list",
    "variables",
    "available",
    "happiness",
    "rank",
    "load",
    "data",
    "show",
    "data",
    "little",
    "bit",
    "becomes",
    "clear",
    "known",
    "happiness",
    "rank",
    "happiness",
    "score",
    "happiness",
    "score",
    "uh",
    "like",
    "absolute",
    "value",
    "whereas",
    "rank",
    "ranking",
    "country",
    "talking",
    "within",
    "country",
    "region",
    "kind",
    "economy",
    "whether",
    "family",
    "family",
    "health",
    "details",
    "freedom",
    "trust",
    "generosity",
    "forth",
    "multiple",
    "variables",
    "available",
    "us",
    "specific",
    "details",
    "probably",
    "required",
    "another",
    "example",
    "variables",
    "completely",
    "different",
    "go",
    "details",
    "exactly",
    "variables",
    "enough",
    "understand",
    "bunch",
    "variables",
    "need",
    "use",
    "either",
    "variables",
    "also",
    "sometimes",
    "refer",
    "features",
    "need",
    "build",
    "model",
    "train",
    "model",
    "right",
    "let",
    "assume",
    "use",
    "python",
    "order",
    "perform",
    "analysis",
    "perform",
    "machine",
    "learning",
    "activity",
    "actually",
    "show",
    "lab",
    "little",
    "bit",
    "whole",
    "thing",
    "run",
    "live",
    "code",
    "quickly",
    "run",
    "slides",
    "go",
    "lab",
    "first",
    "thing",
    "need",
    "import",
    "bunch",
    "libraries",
    "python",
    "required",
    "perform",
    "analysis",
    "manipulating",
    "data",
    "preparing",
    "data",
    "sk",
    "learn",
    "library",
    "use",
    "actually",
    "particular",
    "machine",
    "learning",
    "activity",
    "linear",
    "regression",
    "numpy",
    "pandas",
    "forth",
    "libraries",
    "imported",
    "load",
    "data",
    "data",
    "form",
    "csv",
    "file",
    "different",
    "files",
    "year",
    "data",
    "2015",
    "16",
    "load",
    "data",
    "combine",
    "concatenate",
    "prepare",
    "single",
    "data",
    "frame",
    "making",
    "assumption",
    "familiar",
    "python",
    "becomes",
    "easier",
    "familiar",
    "python",
    "programming",
    "language",
    "least",
    "programming",
    "language",
    "least",
    "understand",
    "looking",
    "code",
    "reading",
    "file",
    "files",
    "year",
    "basically",
    "creating",
    "list",
    "names",
    "columns",
    "using",
    "later",
    "see",
    "code",
    "loaded",
    "2015",
    "2016",
    "also",
    "created",
    "three",
    "data",
    "frames",
    "concatenate",
    "three",
    "data",
    "frames",
    "identify",
    "columns",
    "required",
    "example",
    "categorical",
    "values",
    "really",
    "need",
    "probably",
    "drop",
    "columns",
    "unnecessarily",
    "use",
    "columns",
    "make",
    "computation",
    "complicated",
    "create",
    "plots",
    "using",
    "plotly",
    "library",
    "powerful",
    "features",
    "including",
    "creation",
    "creation",
    "maps",
    "understand",
    "pattern",
    "happiness",
    "quotient",
    "happiness",
    "across",
    "countries",
    "nice",
    "visualization",
    "see",
    "countries",
    "terms",
    "happiness",
    "score",
    "legend",
    "lighter",
    "colored",
    "countries",
    "lower",
    "ranking",
    "lower",
    "ranking",
    "ones",
    "higher",
    "ranking",
    "means",
    "ones",
    "dark",
    "colors",
    "happiest",
    "ones",
    "see",
    "australia",
    "maybe",
    "side",
    "us",
    "happiest",
    "ones",
    "okay",
    "thing",
    "need",
    "correlation",
    "happiness",
    "score",
    "happiness",
    "rank",
    "find",
    "correlation",
    "using",
    "scatter",
    "plot",
    "find",
    "yes",
    "kind",
    "inversely",
    "proportioned",
    "obvious",
    "score",
    "high",
    "happiness",
    "score",
    "high",
    "ranked",
    "number",
    "one",
    "example",
    "highest",
    "scored",
    "number",
    "one",
    "idea",
    "behind",
    "happiness",
    "score",
    "given",
    "happiness",
    "rank",
    "actually",
    "given",
    "inversely",
    "proportional",
    "higher",
    "score",
    "absolute",
    "value",
    "rank",
    "lower",
    "right",
    "number",
    "one",
    "highest",
    "value",
    "score",
    "inversely",
    "correlated",
    "strong",
    "graph",
    "shows",
    "strong",
    "correlation",
    "happiness",
    "rank",
    "happiness",
    "score",
    "plots",
    "visualize",
    "determine",
    "probably",
    "rank",
    "score",
    "pretty",
    "much",
    "conveying",
    "message",
    "need",
    "kind",
    "drop",
    "one",
    "drop",
    "happiness",
    "rank",
    "similarly",
    "one",
    "example",
    "remove",
    "columns",
    "adding",
    "value",
    "see",
    "code",
    "well",
    "works",
    "moving",
    "correlation",
    "pretty",
    "much",
    "columns",
    "columns",
    "correlation",
    "plot",
    "using",
    "plot",
    "function",
    "see",
    "example",
    "happiness",
    "score",
    "happiness",
    "score",
    "correlated",
    "strongest",
    "correlation",
    "right",
    "every",
    "variable",
    "highly",
    "correlated",
    "reason",
    "darker",
    "color",
    "higher",
    "correlation",
    "correlation",
    "numerical",
    "terms",
    "goes",
    "zero",
    "one",
    "one",
    "highest",
    "value",
    "zero",
    "one",
    "correlation",
    "two",
    "variables",
    "value",
    "zero",
    "one",
    "numerical",
    "value",
    "go",
    "zero",
    "one",
    "one",
    "dark",
    "color",
    "zero",
    "uh",
    "kind",
    "dark",
    "blue",
    "color",
    "red",
    "goes",
    "dark",
    "blue",
    "color",
    "indicates",
    "pretty",
    "much",
    "correlation",
    "heat",
    "map",
    "see",
    "happiness",
    "economy",
    "family",
    "probably",
    "also",
    "health",
    "probably",
    "correlated",
    "keeps",
    "decreasing",
    "freedom",
    "kind",
    "keeps",
    "decreasing",
    "coming",
    "pretty",
    "much",
    "zero",
    "right",
    "correlation",
    "graph",
    "probably",
    "use",
    "find",
    "columns",
    "need",
    "dropped",
    "high",
    "correlation",
    "take",
    "columns",
    "need",
    "code",
    "dropping",
    "columns",
    "prepared",
    "data",
    "required",
    "columns",
    "use",
    "scikit",
    "learn",
    "actually",
    "split",
    "data",
    "first",
    "normal",
    "machine",
    "learning",
    "process",
    "need",
    "split",
    "data",
    "training",
    "test",
    "data",
    "set",
    "case",
    "splitting",
    "80",
    "20",
    "80",
    "training",
    "data",
    "set",
    "20",
    "test",
    "data",
    "set",
    "use",
    "train",
    "test",
    "split",
    "method",
    "function",
    "training",
    "data",
    "x",
    "underscore",
    "train",
    "labels",
    "underscore",
    "train",
    "similarly",
    "x",
    "underscore",
    "test",
    "test",
    "data",
    "inputs",
    "whereas",
    "labels",
    "underscore",
    "test",
    "value",
    "whether",
    "80",
    "20",
    "50",
    "50",
    "individual",
    "preference",
    "case",
    "using",
    "80",
    "right",
    "next",
    "create",
    "linear",
    "regression",
    "instance",
    "creating",
    "instance",
    "linear",
    "regression",
    "train",
    "model",
    "using",
    "fit",
    "function",
    "passing",
    "x",
    "x",
    "value",
    "label",
    "data",
    "regular",
    "input",
    "label",
    "data",
    "label",
    "information",
    "test",
    "run",
    "perform",
    "evaluation",
    "test",
    "data",
    "set",
    "test",
    "data",
    "set",
    "evaluate",
    "accurate",
    "model",
    "using",
    "functionality",
    "also",
    "see",
    "various",
    "parameters",
    "various",
    "coefficients",
    "linear",
    "regression",
    "get",
    "like",
    "equation",
    "like",
    "straight",
    "line",
    "equal",
    "beta",
    "0",
    "plus",
    "beta",
    "1",
    "x",
    "1",
    "plus",
    "beta",
    "2",
    "x",
    "2",
    "beta",
    "1",
    "beta",
    "2",
    "beta",
    "3",
    "known",
    "coefficients",
    "beta0",
    "intercept",
    "training",
    "actually",
    "get",
    "information",
    "model",
    "intercept",
    "value",
    "coefficients",
    "using",
    "functions",
    "let",
    "take",
    "quickly",
    "go",
    "lab",
    "take",
    "look",
    "code",
    "okay",
    "lab",
    "jupiter",
    "notebook",
    "code",
    "actual",
    "code",
    "take",
    "code",
    "run",
    "linear",
    "regression",
    "world",
    "happiness",
    "data",
    "import",
    "bunch",
    "libraries",
    "numpy",
    "pandas",
    "plot",
    "plotly",
    "also",
    "yeah",
    "scikit",
    "learn",
    "also",
    "important",
    "first",
    "step",
    "import",
    "data",
    "data",
    "three",
    "parts",
    "three",
    "files",
    "one",
    "year",
    "2015",
    "2016",
    "2017",
    "csv",
    "file",
    "imported",
    "data",
    "let",
    "take",
    "look",
    "data",
    "quickly",
    "glance",
    "data",
    "looks",
    "country",
    "region",
    "happiness",
    "rank",
    "happiness",
    "score",
    "standard",
    "errors",
    "per",
    "capita",
    "family",
    "keep",
    "going",
    "create",
    "list",
    "column",
    "names",
    "using",
    "later",
    "run",
    "code",
    "need",
    "major",
    "explanation",
    "point",
    "know",
    "columns",
    "probably",
    "required",
    "use",
    "drop",
    "functionality",
    "remove",
    "columns",
    "need",
    "like",
    "example",
    "region",
    "standard",
    "error",
    "contributing",
    "model",
    "basically",
    "drop",
    "values",
    "use",
    "drop",
    "created",
    "vector",
    "names",
    "column",
    "names",
    "passing",
    "instead",
    "giving",
    "names",
    "columns",
    "pass",
    "vector",
    "drop",
    "data",
    "frame",
    "remove",
    "region",
    "standard",
    "error",
    "two",
    "columns",
    "next",
    "step",
    "read",
    "data",
    "2016",
    "also",
    "2017",
    "concatenate",
    "data",
    "let",
    "data",
    "frame",
    "called",
    "happiness",
    "concatenation",
    "three",
    "files",
    "let",
    "take",
    "quick",
    "look",
    "data",
    "unwanted",
    "columns",
    "removed",
    "data",
    "one",
    "place",
    "three",
    "years",
    "data",
    "looks",
    "want",
    "take",
    "look",
    "summary",
    "columns",
    "say",
    "describe",
    "get",
    "information",
    "example",
    "columns",
    "count",
    "mean",
    "value",
    "standard",
    "deviation",
    "especially",
    "numeric",
    "values",
    "okay",
    "categorical",
    "values",
    "quick",
    "way",
    "see",
    "data",
    "initial",
    "little",
    "bit",
    "exploratory",
    "analysis",
    "done",
    "maximum",
    "value",
    "minimum",
    "value",
    "columns",
    "right",
    "go",
    "ahead",
    "create",
    "visualizations",
    "using",
    "plotly",
    "let",
    "us",
    "go",
    "build",
    "plot",
    "see",
    "relation",
    "correlation",
    "happiness",
    "rank",
    "happiness",
    "score",
    "seen",
    "slides",
    "well",
    "see",
    "tight",
    "correlation",
    "thing",
    "inverse",
    "correlation",
    "otherwise",
    "tightly",
    "correlated",
    "also",
    "says",
    "probably",
    "provide",
    "information",
    "much",
    "value",
    "add",
    "go",
    "ahead",
    "drop",
    "happiness",
    "rank",
    "well",
    "columns",
    "creation",
    "correlation",
    "heat",
    "map",
    "let",
    "us",
    "plot",
    "correlation",
    "heat",
    "map",
    "see",
    "columns",
    "correlated",
    "others",
    "seen",
    "slides",
    "looks",
    "happiness",
    "score",
    "highly",
    "correlated",
    "legend",
    "seen",
    "slide",
    "well",
    "blue",
    "color",
    "indicates",
    "pretty",
    "much",
    "zero",
    "low",
    "correlation",
    "deep",
    "red",
    "color",
    "indicates",
    "high",
    "correlation",
    "value",
    "correlation",
    "numeric",
    "value",
    "value",
    "goes",
    "zero",
    "one",
    "two",
    "items",
    "two",
    "features",
    "columns",
    "highly",
    "correlated",
    "close",
    "one",
    "possible",
    "two",
    "columns",
    "correlated",
    "close",
    "zero",
    "possible",
    "example",
    "happiness",
    "score",
    "happiness",
    "score",
    "every",
    "column",
    "every",
    "feature",
    "highly",
    "correlated",
    "like",
    "correlation",
    "value",
    "one",
    "see",
    "deep",
    "red",
    "color",
    "others",
    "example",
    "higher",
    "values",
    "economy",
    "health",
    "maybe",
    "family",
    "freedom",
    "generosity",
    "trust",
    "highly",
    "correlated",
    "happiness",
    "score",
    "one",
    "quick",
    "exploratory",
    "analysis",
    "therefore",
    "drop",
    "country",
    "happiness",
    "rank",
    "also",
    "major",
    "impact",
    "analysis",
    "analysis",
    "prepared",
    "data",
    "need",
    "clean",
    "data",
    "data",
    "clean",
    "missing",
    "values",
    "discussed",
    "slides",
    "would",
    "perform",
    "data",
    "cleaning",
    "activities",
    "well",
    "case",
    "data",
    "clean",
    "needed",
    "preparation",
    "part",
    "removed",
    "unwanted",
    "columns",
    "exploratory",
    "data",
    "analysis",
    "ready",
    "perform",
    "machine",
    "learning",
    "activity",
    "use",
    "machine",
    "learning",
    "circuit",
    "learn",
    "python",
    "library",
    "available",
    "performing",
    "machine",
    "learning",
    "import",
    "libraries",
    "like",
    "pandas",
    "numpy",
    "also",
    "psychic",
    "learn",
    "first",
    "step",
    "split",
    "data",
    "2080",
    "format",
    "test",
    "data",
    "20",
    "data",
    "test",
    "data",
    "80",
    "percent",
    "training",
    "data",
    "test",
    "size",
    "indicates",
    "much",
    "size",
    "test",
    "data",
    "remaining",
    "point",
    "saying",
    "point",
    "two",
    "therefore",
    "means",
    "training",
    "point",
    "eight",
    "training",
    "data",
    "eighty",
    "percent",
    "right",
    "executed",
    "split",
    "data",
    "create",
    "instance",
    "linear",
    "regression",
    "model",
    "lm",
    "linear",
    "regression",
    "model",
    "pass",
    "x",
    "training",
    "data",
    "set",
    "call",
    "function",
    "fit",
    "model",
    "gets",
    "trained",
    "done",
    "training",
    "done",
    "training",
    "completed",
    "need",
    "predict",
    "values",
    "test",
    "data",
    "next",
    "step",
    "using",
    "see",
    "fit",
    "basically",
    "run",
    "training",
    "method",
    "predict",
    "actually",
    "predict",
    "values",
    "passing",
    "input",
    "values",
    "independent",
    "variables",
    "asking",
    "values",
    "dependent",
    "variable",
    "capturing",
    "underscore",
    "track",
    "use",
    "predict",
    "method",
    "give",
    "us",
    "predicted",
    "values",
    "remember",
    "already",
    "underscore",
    "test",
    "actual",
    "values",
    "labels",
    "use",
    "two",
    "compare",
    "find",
    "much",
    "error",
    "trying",
    "find",
    "difference",
    "predicted",
    "value",
    "actual",
    "value",
    "underscore",
    "test",
    "actual",
    "value",
    "test",
    "data",
    "underscore",
    "predict",
    "predicted",
    "value",
    "found",
    "predictive",
    "line",
    "run",
    "quick",
    "check",
    "data",
    "looks",
    "difference",
    "cases",
    "positive",
    "cases",
    "negative",
    "cases",
    "think",
    "difference",
    "small",
    "exponential",
    "power",
    "0",
    "minus",
    "04",
    "looks",
    "like",
    "model",
    "performed",
    "reasonably",
    "well",
    "check",
    "parameters",
    "model",
    "like",
    "intercept",
    "coefficients",
    "coefficients",
    "various",
    "parameters",
    "coefficients",
    "various",
    "independent",
    "variables",
    "okay",
    "values",
    "quickly",
    "go",
    "ahead",
    "list",
    "well",
    "corresponding",
    "independent",
    "variables",
    "coefficients",
    "corresponding",
    "independent",
    "variable",
    "coefficient",
    "economy",
    "family",
    "coefficient",
    "family",
    "health",
    "forth",
    "right",
    "showing",
    "use",
    "functionality",
    "readily",
    "available",
    "functionality",
    "plot",
    "find",
    "parameters",
    "determine",
    "accuracy",
    "model",
    "like",
    "example",
    "mean",
    "square",
    "error",
    "let",
    "go",
    "ahead",
    "run",
    "see",
    "root",
    "mean",
    "square",
    "error",
    "pretty",
    "low",
    "good",
    "sign",
    "one",
    "measures",
    "well",
    "model",
    "performing",
    "one",
    "quick",
    "plot",
    "see",
    "actual",
    "values",
    "predicted",
    "values",
    "looking",
    "see",
    "seen",
    "root",
    "mean",
    "square",
    "error",
    "root",
    "mean",
    "square",
    "error",
    "low",
    "means",
    "actual",
    "values",
    "predicted",
    "values",
    "pretty",
    "much",
    "matching",
    "almost",
    "matching",
    "plot",
    "also",
    "shows",
    "line",
    "going",
    "predicted",
    "values",
    "actual",
    "values",
    "differences",
    "low",
    "actual",
    "data",
    "one",
    "example",
    "accuracy",
    "high",
    "predicted",
    "values",
    "pretty",
    "much",
    "matching",
    "actual",
    "values",
    "real",
    "life",
    "may",
    "find",
    "values",
    "slightly",
    "scattered",
    "may",
    "get",
    "error",
    "value",
    "relatively",
    "higher",
    "side",
    "root",
    "mean",
    "squared",
    "okay",
    "good",
    "quick",
    "example",
    "code",
    "perform",
    "data",
    "science",
    "activity",
    "machine",
    "learning",
    "data",
    "mining",
    "activity",
    "case",
    "known",
    "linear",
    "regression",
    "let",
    "go",
    "back",
    "slides",
    "see",
    "else",
    "saw",
    "coefficients",
    "features",
    "code",
    "seen",
    "root",
    "mean",
    "square",
    "error",
    "well",
    "take",
    "hundred",
    "countries",
    "certain",
    "values",
    "actually",
    "predict",
    "see",
    "model",
    "performing",
    "think",
    "done",
    "well",
    "case",
    "seen",
    "pretty",
    "much",
    "predicted",
    "values",
    "actual",
    "values",
    "pretty",
    "much",
    "matching",
    "means",
    "model",
    "almost",
    "hundred",
    "percent",
    "accurate",
    "mentioned",
    "real",
    "life",
    "may",
    "case",
    "particular",
    "case",
    "got",
    "pretty",
    "good",
    "model",
    "good",
    "also",
    "subsequently",
    "assume",
    "equation",
    "linear",
    "regression",
    "model",
    "nothing",
    "equation",
    "like",
    "equal",
    "beta",
    "0",
    "plus",
    "beta",
    "1",
    "x",
    "1",
    "plus",
    "beta",
    "2",
    "x",
    "2",
    "plus",
    "beta",
    "3",
    "x",
    "3",
    "showing",
    "intercept",
    "beta0",
    "beta1",
    "economy",
    "value",
    "beta2",
    "family",
    "value",
    "beta3",
    "health",
    "value",
    "shown",
    "okay",
    "think",
    "next",
    "step",
    "results",
    "data",
    "mining",
    "machine",
    "learning",
    "activity",
    "next",
    "step",
    "communicate",
    "results",
    "appropriate",
    "stakeholders",
    "see",
    "communicate",
    "usually",
    "take",
    "results",
    "either",
    "prepare",
    "presentation",
    "put",
    "document",
    "show",
    "actionable",
    "results",
    "reasonable",
    "insights",
    "need",
    "find",
    "target",
    "audience",
    "put",
    "results",
    "context",
    "maybe",
    "problem",
    "statement",
    "need",
    "put",
    "results",
    "context",
    "problem",
    "statement",
    "initial",
    "goal",
    "wanted",
    "achieve",
    "need",
    "communicate",
    "based",
    "remember",
    "started",
    "question",
    "data",
    "answer",
    "need",
    "put",
    "results",
    "methodology",
    "used",
    "put",
    "clearly",
    "communicated",
    "business",
    "terms",
    "people",
    "understand",
    "well",
    "business",
    "perspective",
    "model",
    "building",
    "done",
    "results",
    "published",
    "communicated",
    "last",
    "part",
    "maintenance",
    "model",
    "often",
    "happen",
    "model",
    "may",
    "subsequently",
    "updated",
    "modified",
    "multiple",
    "reasons",
    "either",
    "data",
    "changed",
    "way",
    "data",
    "comes",
    "changed",
    "process",
    "changed",
    "whatever",
    "reason",
    "accuracy",
    "may",
    "keep",
    "changing",
    "trained",
    "model",
    "example",
    "got",
    "high",
    "accuracy",
    "period",
    "time",
    "various",
    "factors",
    "cause",
    "time",
    "time",
    "need",
    "check",
    "whether",
    "model",
    "performing",
    "well",
    "accuracy",
    "needs",
    "tested",
    "required",
    "may",
    "rebuild",
    "retrain",
    "model",
    "assessment",
    "see",
    "needs",
    "tweaks",
    "changes",
    "required",
    "need",
    "probably",
    "retrain",
    "model",
    "latest",
    "data",
    "deploy",
    "build",
    "model",
    "train",
    "deploy",
    "like",
    "maintenance",
    "cycle",
    "may",
    "take",
    "model",
    "right",
    "pretty",
    "much",
    "end",
    "tutorial",
    "learn",
    "tutorial",
    "talked",
    "data",
    "science",
    "data",
    "scientist",
    "talked",
    "data",
    "scientist",
    "performs",
    "day",
    "life",
    "data",
    "scientist",
    "activities",
    "methodologies",
    "like",
    "processes",
    "rather",
    "data",
    "acquisition",
    "data",
    "preparation",
    "mining",
    "model",
    "building",
    "last",
    "least",
    "model",
    "maintenance",
    "process",
    "also",
    "taken",
    "look",
    "python",
    "code",
    "used",
    "performing",
    "linear",
    "regression",
    "model",
    "creating",
    "linear",
    "regression",
    "model",
    "training",
    "testing",
    "checking",
    "various",
    "parameters",
    "model",
    "come",
    "end",
    "tutorial",
    "hope",
    "enjoyed",
    "questions",
    "comments",
    "put",
    "video",
    "comment",
    "section",
    "happy",
    "respond",
    "especially",
    "leave",
    "email",
    "address",
    "would",
    "like",
    "thank",
    "great",
    "day",
    "thank",
    "bye",
    "hi",
    "like",
    "video",
    "subscribe",
    "simply",
    "learn",
    "youtube",
    "channel",
    "click",
    "watch",
    "similar",
    "videos",
    "turn",
    "get",
    "certified",
    "click"
  ],
  "keywords": [
    "tutorial",
    "data",
    "science",
    "see",
    "scientist",
    "life",
    "used",
    "like",
    "acquisition",
    "preparation",
    "mining",
    "model",
    "building",
    "maintenance",
    "also",
    "example",
    "well",
    "take",
    "quick",
    "code",
    "done",
    "activity",
    "let",
    "get",
    "using",
    "trying",
    "find",
    "insights",
    "pretty",
    "much",
    "certain",
    "algorithms",
    "often",
    "known",
    "say",
    "problem",
    "lot",
    "one",
    "fraud",
    "activities",
    "therefore",
    "use",
    "either",
    "machine",
    "learning",
    "techniques",
    "rather",
    "actually",
    "specific",
    "high",
    "first",
    "step",
    "raw",
    "format",
    "could",
    "multiple",
    "sources",
    "performing",
    "prepared",
    "exploratory",
    "need",
    "build",
    "test",
    "time",
    "possible",
    "process",
    "look",
    "stage",
    "basically",
    "files",
    "different",
    "required",
    "kind",
    "looks",
    "least",
    "may",
    "warehouse",
    "etl",
    "load",
    "people",
    "perform",
    "analysis",
    "various",
    "put",
    "help",
    "tools",
    "good",
    "next",
    "probably",
    "missing",
    "values",
    "forth",
    "particular",
    "60",
    "percent",
    "part",
    "cleaning",
    "columns",
    "null",
    "right",
    "categorical",
    "numerical",
    "outliers",
    "way",
    "behavior",
    "reason",
    "quickly",
    "keys",
    "removed",
    "accurate",
    "parameters",
    "case",
    "set",
    "customer",
    "details",
    "go",
    "python",
    "assume",
    "geography",
    "column",
    "blank",
    "value",
    "come",
    "mean",
    "credit",
    "score",
    "ahead",
    "fill",
    "even",
    "drop",
    "rows",
    "two",
    "means",
    "really",
    "information",
    "20",
    "maybe",
    "okay",
    "us",
    "tableau",
    "want",
    "run",
    "show",
    "dimensions",
    "measures",
    "gender",
    "exit",
    "three",
    "card",
    "criteria",
    "drag",
    "exited",
    "whether",
    "0",
    "1",
    "side",
    "male",
    "zero",
    "color",
    "blue",
    "create",
    "line",
    "labels",
    "make",
    "based",
    "difference",
    "impact",
    "similarly",
    "check",
    "think",
    "variable",
    "bit",
    "algorithm",
    "thing",
    "available",
    "train",
    "unsupervised",
    "predict",
    "regression",
    "linear",
    "learn",
    "understand",
    "independent",
    "variables",
    "happiness",
    "countries",
    "list",
    "rank",
    "ranking",
    "country",
    "region",
    "economy",
    "family",
    "health",
    "features",
    "lab",
    "slides",
    "import",
    "libraries",
    "names",
    "ones",
    "higher",
    "dark",
    "correlation",
    "plot",
    "correlated",
    "function",
    "highly",
    "indicates",
    "split",
    "training",
    "80",
    "x",
    "underscore",
    "functionality",
    "coefficients",
    "beta",
    "plus",
    "2",
    "intercept",
    "actual",
    "standard",
    "point",
    "error",
    "seen",
    "low",
    "predicted",
    "accuracy",
    "square",
    "root",
    "matching",
    "results"
  ]
}