with great power comes great
responsibility
these are the words of stan lee author
of the spider-man comic book series
but where does data power come from and
what are the responsibilities for us
as data scientists first let's talk
about
power in may 2017 the economist ran the
following headline
the world's most valuable resource is no
longer oil but data
in fact the data as the new oil analogy
originates from as early as 2006 when
clive humbey from tesco in the uk
said that data is the new oil it's
valuable but if unrefined
it cannot really be used and that's
where you come in
data is an extremely valuable resource
but it's up to you to extract the value
data is potential and it's up to you to
realize its full potential
being a data scientist is a powerful and
privileged role
you have highly sought after skills
skills that most people do not have the
opportunity
to be educated on this is due to a
variety of reasons
including teaching statistics and
programming is hard
and we don't have enough teachers to do
it getting exposed to and encouraged to
pursue skills in data science is rare
and especially rare in certain groups
like women or rural populations
a master's degree in data science is
expensive and therefore cost prohibitive
for many
and we do not have widespread
statistical literacy
to make the path to becoming a data
scientist easier
learning brand new things is tough power
will be handed to you
in possibly unexpected ways western
society
often values quantitative methods over
observational reports lived experience
or even rigorous qualitative analyses
this has some historical roots in
misogyny and colonialism
where only a small proportion of people
were seen as intelligent enough to
pursue logical subjects like math and
statistics
of course science is still crucial for
society and quantitative methods can
tell us a lot
but they are overvalued even when plenty
of statistical findings are outright
false
remember boyd and crawford's mythology
of big data
so you may be handed respect authority
and power
simply for being the data science person
so here you are a powerful resource and
people looking to you to turn the
numbers into insight
after acknowledging the privileges you
came in with you can also be proud of
yourself for making it this far
you worked hard to learn your data
science skills and you do have lots of
different talents
from programming to visualizing to
communicating you are a very important
part of solving the world's problems
so now let's talk about responsibility
when you think of data science you might
think about business models such as
those that optimize
ad revenue even these seemingly trivial
data science tasks come with a lot
of responsibility as a small mistake
could propagate into a lot of money lost
for your company
data science is used in every field
imaginable from marketing to medicine
from transportation to waste management
and while a data scientist might feel a
bit removed from the real world
implementations of their work
their models and analytics will
eventually affect real lives
the decisions we make because it's
convenient or tidy or because we
aren't entirely sure what the model is
doing yes that will happen to you
can end up with large scale harms
let's work through an example of a not
so obvious mistake in an algorithm that
snowballs into unjustly harming a lot of
people
risk assessment scores for whether or
not someone is likely to commit a crime
this isn't science fiction this is real
life risk assessment scores are used in
the criminal justice system today
because people tend to see numbers and
statistics as more objective
society has introduced predictive
algorithms into our courtrooms and law
enforcement agencies
it's not just one algorithm it's many
ranging from predicting where a crime
will occur
or using someone's social media data to
predict if they are likely to be more
violent
and in this example we will be looking
at an algorithmic risk assessment of
recidivism recidivism the tendency of a
convicted criminal to re-offend
parole or release from prison with some
restrictions
can be granted to prisoners who are
deemed fit to reintegrate into society
an individual may go up for parole where
several factors will be examined by a
judge
including their original crime their
behavior while serving in prison
their demographics and other features
with an overworked system and the desire
to reduce imprisonment numbers
it makes sense to want an automated
system to help determine
who should get parole but hidden in this
desire for efficiency
is the perpetuation of racial bias
biases that have a lot of historical
inertia in these systems
it is well known that our prison system
is particularly harsh on black and brown
members of society
the school to prison pipeline describes
the disproportionate tendency of minors
and young adults
from disadvantaged backgrounds to become
incarcerated
because of increasingly harsh school and
municipal policies
as well as because of educational
inequality in the united states
with black students affected the most
harshly
black men are at the highest risk for
police violence
and overall receive longer prison
sentences than white men
arrested for the same crimes these
racial disparities are present in all
historical crime data used to train
algorithms maybe you're seeing the
problem now
a good way to repeat biases of the past
would be to use them to train an
automated tool to determine the future
when training data contains racial bias
the model will learn that racial bias
and replicate it we are telling a model
this is who got parole in the past
please automatically sort people to fit
what we have done before
but what we have done before is racist
what seems objective and flawless to a
judge or jury
who are unlikely to know what went into
the tool is actually an opaque
replicator of bias
it is our job as data scientists to both
think critically about algorithmic
design
and to communicate how algorithms work
to non-experts
when in doubt ask the stakeholders of
the models to weigh
in we call this situated data science
where the goal is not to design for but
to design with
remember to stay kind stay curious and
stay critical
