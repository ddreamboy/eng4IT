hi everyone my name is B Hamed and
welcome to this video so guys in this
video we'll be learning the data
preprocessing part uh in our previous
video I already discussed about end to
end gener TBI pipeline so there I told
you what is the use of data
pre-processing right because if you want
to use the model that means large
language model the first thing you have
to do the data P processing Because
unless and until you are not processing
the data how your model will try to
understand that one right that is the
idea so here we'll be learning various
kinds of technique uh to clean up about
data so for this what I have done I have
created a beautiful uh collab notebook
so there actually I have uh added all
the examples you can uh use for the data
cleanup operation so guys now let's try
to see how we can do the data
preprocessing part so guys as you can
see this is The Notebook I already
prepared so here you can see I'm using
one data set from Kagel so let me open
the
link um this is the link so the data set
name is IMDb uh data set and it is
having actually 50k uh movie reviews
okay 50k actually movie reviews if you
are already from let's say machine
learning deep learning background I
think you know about this data set right
it's like very common data set and why I
took this particular data set because in
this data set you will see uh there are
so many U actually unnecessary text okay
because it's a movie review so what they
did actually they extracted they scra
this data from the IMDb website if you
don't know this is the IMDB website IMDb
so in this website you will see uh all
the movies reviews and rating and what
they did actually they published this
data set in the Kagel website so that if
anyone is working in the field of let's
say genit tvi or natural language
processing they can use the data set now
here what you just need to do you just
need to download this data okay it's
around uh I think 27 MB just click on
download button it will download okay so
I already downloaded this data set so it
is available inside my download folder
so I'm going to upload in my collab
notebook so here first of all what you
have to do you have to connect this
particular notebook so there is a
connect button just try to connect and
no need to worry I will also share this
notebook Link in the resources section
from there you can open it up so my
notebook is connected so first of all
let's import uh some of the library
first of all I need something called
pandas because if you see the data uh
it's a csb data okay it's a csb data so
let me upload and let me show you so if
you want to upload anything in the
Google Drive just try to right click and
there is a upload button click on upload
and try to upload this data
here now see it's a CSV file okay and if
I want to load any kinds of CSV file
Json file or let's Excel file whatever
file you can use the pandas package for
that so you can see my data set is
upload it now if I want to load the data
set what I have to do I have to assign
the path and see you don't need to
execute deser the code because uh this
code I have added let's say if your data
set is available in your Google Drive
that time what you have to do you have
to Mount Your Google Drive first of all
Mount means you will be connecting with
your Google Drive then we'll be
relocating the folder okay like inside
which folder you kept your data okay
with the the help of CD command CD means
change directory okay then after that
what you will do he will assign the data
path but here I haven't kept my data
inside my Google Drive I kept inside my
collab actually you can see drive this
is the collab di I'm using here you will
get around 74 GB of space so here you
also can keep your data so I don't need
to execute this code what I will do I'll
just go below and if I check my current
working directory that means PWD you'll
see I'm inside content content means
this is the directory right now now here
I'll just simply Define my data path
I'll copy the path copy and let me paste
it here okay that's it now let me
execute now see if I now load the data
pd. csb I'm doing so now see it will
load the data see it has loaded the data
if you want to see the shape of the data
this is the shape okay you have around
50 uh 50k actually movies movies reviews
in this particular csb file and two
columns two columns means is the reviews
column other is like the sentiment
column okay sentiment means whether it's
a positive sentiment whether it's a
negative sentiment this kinds of
sentiment you will get here I hope it is
clear now see here I'm having 50k movie
reviews but here I'm not going to use
all the reviews here I'm going to show
you the demo like how we can perform the
text preprocessing and if I'm taking all
the 50k reviews so it will take like
lots of time um to process those are the
text so what I will do I'll only take
the 100 example okay the first 100
example I I'll be taking and on top of
that I will perform all the text
processing task right so this is the
code you can execute so it will load 100
example now if I show you the shape see
now we are having 100 example and only
two columns fine now if I want to show
you the data see this is the data so I
think you remember in my uh theoretical
class I was discussing about some
pre-processing technique uh here I think
H so here you can perform something
called HTML tag removal Emoji handle art
then spelling correction then in the
basic preprocessing we saw that we can
perform something called tokenization
then we had some optional pre-processing
as well like stop word streaming LZ pun
CH lower case Okay language detection
each and everything so first thing we'll
be learning how we can perform the lower
case operation and why lower case
important I already explained here I
think you remember let's say let's say
if one of the name is containing
uppercase character it will consider
these are actually separate name okay
these are actually separate entity that
is the idea so that's how we have to
bring everything in a lowercase
character so that's why you have to
apply this lower operation and how to
perform lower operation I think you
already know in Python we are having a
function called Lower with the help of
lower also we can do it right now see
here let me show you one example let's
say I'm taking the reviews three so here
I'm taking the three three three number
rows this is the three number rows now
you can see some of the uh character is
uppercase character here so this is
uppercase this is uppercase okay so
that's how actually you will see
different different uppercase character
would be there now if I want to make
them lower case what I have to do first
of all I have to select my column like
in which column you have to apply the
lower function I have to apply on top of
my review column now first of all I'm
converting everything to the string okay
string data type then I'm applying the
lower because lower is a string method
okay lower is a string method I think
you already know that then whatever
changes actually I'm doing I'm saving
inside my column that means I'm just
doing the permanent change okay inside
my column so that's why I have given
review again that is the idea now if I
execute now see if I show you the data
now see guys all the character has
become lower case right now now if I
want to show you the now if I again
execute that review three you'll see
that all the character has converted to
the lowercase character okay that is the
idea now the next thing we'll be
learning how we can handle the HTML tags
that means how we can remove the HTML
tags for this here I have written a
function here I'm using something called
regular expression regx okay so inside
regx you can give a pattern let's say
here you are giving a pattern if you're
are getting this kinds of symbol okay if
you are getting these kinds of symbol
it's a like HTML tag you have to remove
those HTML tags and you have to replace
with empty okay empty string that is the
idea now this is the function we can use
now if I execute now let's say this is a
one text I have prepared you can see in
this text actually we are having lots of
HTML tags now if I pass this particular
text to my function see it will
automatically remove all the tags now
see I'm only getting the text okay
relevant text that is the idea so this
notebook I prepared in such a way so
that you can use it as a template let's
say whenever you need anything any kinds
of functionality you can come here you
can copy those function so please try to
keep this particular notebook with you
because this is is going to help you a
lot okay whenever you'll be developing
the projects this is going to help you a
lot now if you want to apply on top of
the entire data set again just call this
column name let's say review column okay
and there is a function called apply and
inside that just try to pass this
function okay apply function takes
actually uh one function object now here
I'm giving the function object so what
it will do it will try to apply this
particular function on top of the entire
uh rows you are having in your data set
okay now see if I execute and and the
changes actually I'm doing I'm saving
everything permanent okay now let me
execute now if I show you any kinds of
random let's AR row now you'll see all
the uh now let's see if I also show you
um seven okay seven number rows now
let's try to see there is no HTML tags
in this particular text you can pick up
any kinds of let's say index let's say
if I show you the
10 nowhere you will see the HTML tags
here now we'll be learning how we can
remove actually URL let's say if you are
having some URL in the text how we and
remove it for this again I'm using
regular expression and there is a
pattern I have given if you are getting
these kinds of let's say a word HTTP
then slash then ww that means it is a
URL and you have to remove the URL with
the empty string okay this is the
function now let me execute now here I
have just mentioned some of the URL so
this is my YouTube channel URL this is
my LinkedIn URL and google.com and
kaggle.com okay now these are the text I
prepared one by one now let's say if I'm
passing any kinds of text inside my
remove URL function it will remove that
UR URL let me show you see I'm giving
the text to that means my LinkedIn URL
now you can see check out my LinkedIn I
hope it is clear see again I'm telling
you it's not a mandatory things let's
say you need URL in your data at that
time you can keep it let's say you need
actually HTML tags you can keep it but
if you don't need it you can remove it
because I already told you uh nowadays
actually we are having Advanced genv
application it also supports all kinds
of text like emojis HTML okay everything
it supports so if you're are creating
these kinds of advanc let say u i mean
application that time you need these
other data you don't need to remove it
okay but sometimes actually you also
need to remove this data set so that's
why I'm showing you how you can remove
it and if you want to keep it you can
also keep it it's up to you okay you
have to decide based on your project
architecture that time this is the idea
now we'll be learning how we can handle
the punctuation so if you want to see
the punctuation so there is a string
package you can use now if you just
write string. punctuation you will see
all kinds of punctuations are available
now what I have done I just stor these
are the fation in a variable called
exclude now here I have written a
function okay here I've written a
function called remove punctuation and
here I've written a for Loop so I'm just
looping through this punctuation one by
one and user is giving the text and I'm
just checking whether if there is any
punctuation okay I'm just replacing with
the empty string now let me show you how
it will work now let's say this is one
text string with a punctuation you can
see there are so many punctuation I have
assigned now if I pass this particular
text to my punctuation functions it will
remove the punctuation now see there is
no punctuation right now even I'm also
calculating the time like how much time
it is taking to remove the punctuation
because there is another way you can
follow to remove the punctuation I'll
tell you how you can do it see this is
the function guys uh so here you can use
something called text. translate inside
that just try to use this particular
function okay make translate and inside
that just try to mention the punctuation
so what it will do it will uh take your
text and it will remove all the funu so
this is another approach now see if I
calculate the time of this function you
will see that this is the time that
means this function is taking less time
than your this function because here you
are using one for Loop and for Loop has
the linear time complexity I think you
know that if you are familiar with DSA
concept I you know that it is having
linear time time complexity okay so this
particular approach is good let's say if
you are applying this particular Logic
on top of 50k data set just try to think
how much time it will take this full
loop and in other hand if you're using
this particular method it will take very
less time to perform the operation now
if you want to see the time difference
you can also see the time difference now
if I show you
my uh text now see inside this text
actually I'm having lots of punctuation
now what I will do I will use my uh
remove function one that means this
particular function and inside that I'm
going to pass my entire review now see
it will remove the punctuation okay see
all the function has been removed now
you can also pass the entire data like
that you can also pass the entire data
it will remove all the punctuation
inside your entire data now we'll be
learning how we can handle the chat
conversation see sometimes whenever we
from the chatting operation we give uh
like lots of shortcut let's say if I
want to write as far as I know what you
will give you will give AF a ik then
let's say away from keyboard AFK then as
soon as possible ASAP that's how we use
lots of chat keyword okay we use lots of
chat shortcut keyword okay here I have
listed down some of them you can see for
your information FYI so that's how I
have listed all the chat conversation
short uh word now let's say you are
working with actually social media data
set in social media data set you will
see these kinds of data a lot people
will be using short form okay short form
so how we can handle this particular
short form for this first of all try to
create a dictionary like that the entire
dictionary you have to create then after
that here I've written a function so
this is the function chat conversation
handle so inside that I'm just taking
the text okay I'm just taking the text
and I'm checking and inside that with
the help of this full loop I'm checking
if we are having these kinds of word
okay if you're having these kinds of
word what we doing we're just mapping
with the value that means let's say if
anyone having actually this particular
let's say shortcut word let's say FYI
what I will do instead of FYI I will
just return for your information because
this is a dictionary if I if I want to
get the value I want to call the key
okay that's how we are mapping now see
if I execute the program now let's see
here we are giving a short message uh do
this work as up now see it will return
me do this work as soon as possible okay
because here it is coming here and it is
mapping and it is giving me this value
okay this is the idea now let me see how
we can handle the Inc correct text let's
say sometimes what happens whenever you
are using real time data there would be
lots of spelling M mistake right let's
say this is one example certain so
certain spelling is not correct then
condition spelling is not correct that's
how so that's how you'll see different
different word is having the spelling
mistake so how to handle this spelling
mistake for this you have to use one
package called text blob so let me
import this text
blob and now see here I'm having my
incorrect text now if I pass this
incorrect text to my text blob and if I
call this particular function called
correct now see it will uh handle
everything now see certain conditions
during several see all the word has been
corrected so this is one amazing package
you can use if you want to handle the
spelling okay spelling of any word now
the next thing we'll be learning how we
can handle the stop words so inside
English language not only English
language inside all kinds of language
we're having some stop words okay now
here we're working with the English
language so let me show you some English
related stop wordss for this I will be
importing stop wordss from the nltk is a
so nltk is nothing but it's a natural
language toolkit Library so with the
help of NLP also you can perform lots of
NLP related task so here you can see I'm
importing the stop word so here I'm
performing nltk do download it will
download all the stop wordss from the
internet now see now see if I uh click
this sell it will download the stop
wordss now if you want to list down all
the stop wordss you can just write stop
words. wordss and here you can specify
the language so here I working with the
so here I'm working with the English
language so here I've given the English
let's see you are working with Hindi
Bengali you can give that language also
it will give you the stop word related
that language so you can uh see the
documentation of nlk we'll see that how
we can pass the parameter here now see
these are the words we are having inside
English so this is called stop word so
this word doesn't have any kind of
meaning okay in a sentence okay we use
it uh to represent one sentence but
there is no meaning so let me show you
why I'm telling there is no meaning
let's if you want to perform uh
sentiment analysis so let's say there is
one uh review we are having so let me
just write this
movie is
awesome I loved
it now just try to see here you are
having some stop word right like is is
there this is there I is there it is
there right but if I want to get the
sentiment of this particular let's say
reviews I can see movies is required
awesome is required
loved is required now if I'm getting
this kinds of word actually this kinds
of positive word that means it's a
positive sentiment okay it's a positive
sentiment yes or no right so here
actually I don't need these are the stop
word okay I don't need this are the stop
word to understand whether this
particular reviews is a positive or
negative and if you're using these are
the stop word in the sentence what will
happen whenever you will perform the
text vectorization it will make actually
extra Dimension okay it will make the
extra dimension in the data and whenever
it is making the extra Dimension that
means if Dimension is increasing that
time uh your model might get uh
difficulties right because we know that
there is a concept of cards of
dimensionality so we always need to
reduce the dimensionality somehow I
think you have learned in your machine
learning okay machine learning let's say
topic so that is why we don't need these
are the stop WS so we have to remove
this particular stop W sometimes and
sometimes actually we have to also keep
it so these are the stop W guys you saw
now let me show you the length so around
we are having 170
Nine stop wordss present inside English
now here I've written a function so this
function will remove the stop wordss
from a text now let me show you let's
say this is a text I have given so
inside that you can see different
different stop wordss are there now if I
pass to my function so see now see there
is no stop word in this particular text
right now okay that's how you can use
this particular function now again this
is my data and if I want to apply on top
of my entire reviews I can do it I can
use the apply function and I can pass my
uh function object remove stop words
and if you want to uh store permanently
what you can do you can write this code
okay re uh DF reviews is equal to DF
reviews apply stop wordss okay it will
save everything permanent but I don't
want to save it permanent as of now
because I'm showing you as a demo if you
want to do the perment you can do it so
now guys I think it is clear how we can
uh remove the stop words now the next
thing we'll be learning how to handle
the Emoji okay see Emoji is nothing but
it's a unic code actually uh character
okay if I show you if you just write
emoji
uni
codee you will see different different
uni codes of different different emojis
so let me open it up see uh here we are
having different different emojis based
on that we are having the uni code okay
Unicode character okay Unicode character
so that's why I just collected some of
the Unicode character uh like for the
emotions emojis symbols then uh picture
of graphs then we're having transport
map symbol flag okay so these are the
images related uni code I collected here
and I just written a function okay and
again I'm using the regular expression
so here I'm telling if you're getting
these kinds of uni code in a sentence
that means the Emoji so what you have to
do you have to remove this emoji with
the empty space okay now let me show you
so let's say this is one text I'm giving
love the the movie it was flying case
okay now see if I pass this particular
text now see it will remove the Emojis
automatically now this is the next one
now see only LMO is coming now sometimes
actually I told you emojis are required
because let's say I told you in the chat
GPT example so if you pass any kinds of
emoji through the chat GPT it will also
able to understand okay what you are
trying to say let's say if I pass any
kind of emoji here let's say I'll give
this
Emoji hey there what's on your mind
today see it is trying to understand my
feelings right now if I want to handle
these kinds of situations what I have to
do I have to keep the Emoji that time
what I can do I can uh extract the
meaning of the Emoji so for this I can
use one Library called uh Emoji okay now
let me show you first of all you have to
install Sol
it now just import the Emoji and inside
Emoji you are having one method called
demo eyes okay now inside that just try
to pass the text python is fire I'm
giving the fire Emoji now see it will
automatically convert to the word python
is fire okay that means it is trying to
extract the meaning of that particular
Emoji right now I hope you you cleared
so that's how whenever you are passing
any kind of emoji as input to the Chart
GPT it is trying to convert this Emoji
to the word and is trying to understand
what you are trying to say now there is
another example I have given love this
movie it was flying case see see love
this movie it was face blowing a keys
now we'll be understanding the
tokenization I told you we are having
two kinds of tokenization sentence level
tokenization and Word level tokenization
so let's try to see see if you want to
perform the tokenization uh directly you
can use the split function because split
also will give you the individual word
in the list see if I have one sentence
now if I perform the split operation see
I'm giving I'm getting actually
individual part so with the help of
split also you can perform the
tokenization so similar wise you can
also do the sentence level tokenization
this is the word level tokenization now
for this you have to mention this
particular fully stop sign so whenever
it is getting the fly stop that means
this is one sentence okay now see if I
execute so here I'm having three
sentence so I am going to DHI I will
stay there for 3 Days Let's uh hope the
tree to be great okay see three sentence
I'm getting so this is called sentence
level tokenization so again some of the
example with the split
function now with the help of regular
expression you can also do the um
tokenization so this is one example I
give with the regular expression so here
is my sentence and it will give you the
individual word this is the sentence
level tokenization okay and this is the
pattern for the word level this is the
pattern for the sentence level okay this
is the idea now you can also use
something called nltk okay that means
natural language toolkit library for
this tokenization as well inside that we
are having two fun two actually function
mod level tokenizer and sentence level
tokenizer now let me and if you want to
perform the tokenization you have to
download this particular thing called p
n KT okay this particular thing you have
to download okay now see here is my
sentence and I want to perform Word
level tokenization I will pass this so
it will give me the B level tokenization
so automatically this function will
handle now if you want to perform
sentence level tokenization you can use
send tokenizer okay from here and you
are getting the sentence level
tokenization okay so again some of the
example you can try I have given and I
created this notebook in a such a way
you can use it as a template I already
told you I have written like like the
function wise right if you need any
kinds of let's say um I mean cleanup
technique you can copy from here and you
can use it in your code that's that's
the idea now there is another package
you can use called spacy with the help
of spacy also you can perform the
tokenization fine so you can explore
this part now let me go to the steamr
okay I already told you what is steamr
steamr means you are trying to bring the
different different word in a root form
that that means uh let's say you are
having play playing played so what you
will do you will apple and you will just
try to convert it is to the and you just
try to convert to the root word that
means play right because it is meaning
the same okay in the sentence so now let
me show you so inside nltk we are having
this streamr post poster pter streamr
now we are importing portal steamer and
here we have created a function steam
word so whenever you will give any kinds
of let's say uh sentence it will perform
the steaming operation now see here I'm
giving work Works working work now if I
give this particular sentence it will
give me the root form that means walk
walk walk and all okay now see here I
kept one sentence so this is the entire
sentence you can see now I want to
perform streaming operation on top of
the sentence so I'm using my function
inside that I'm passing the sentence now
see uh it will give me the um steaming
word right now now see probably it has
been uh probable okay probable that's
why I told you streaming is not readable
sometimes you will get some kinds of
word it's not readable but your model
will try to understand okay but as a
human it's not read see favorite has
been converted to favorite right now
okay so in case actually what you can do
you can use something called LZ okay LZ
will handle these kinds of situation it
will give you readable word actually now
see this is the LZ code so it is
available inside nltk I'm importing the
LZ initializing the lamati and if you
want to use LZ you have to download
these at the things wet and OMW and now
if I execute this code you will see that
it will give you the LZ for all the word
see
so this is the word this is the LZ this
is the word this is the LZ now see it's
readable okay it's readable then your
steaming one I op it is clear fine so
that's why I just written uh streaming
and LZ are same to retrieve root words
but LZ is worked uh good LZ is slow and
streaming is fast because LZ will give
you the readable output that's why it's
little bit slow than your streaming okay
I hope it is clear so yes these are the
technique you can follow for the text
preprocessing if you're having any kinds
of text you can perform text
preprocessing with the help of these are
the technique you can clean up your text
okay and again I'm tell telling you it's
not required to perform all the text
cleaning uh let's say uh I mean
technique sometimes if you need anything
just try to keep it as it is that is the
idea fine so yes this is all from this
video and what you can do right now you
can download any other data set from the
kagle kaggle.com because kagle is having
different different data set not only
movie data set you will also get
something called Twitter data set I
think Twitter data set is also available
see Twitter data set is also available
just try to download the Twitter
sentiment data set and try to apply
these are the text preprocessing on top
of the Twitter dat data set okay so this
should be one task guys from my side
please try to attempt Because unless and
until you are not practicing things
would be more complicated and whenever
you will be doing the Practical okay by
yourself things would be more clear here
so in the next video we'll be learning
how we can perform the tech data
representation that means text
representation how we can vectorize our
text that means we'll be converting our
text to numbers okay for the model so
yes this is all from this video I hope
you like liked it thank you so much for
watching this video and I will see you
next time
