hey guys welcome to this live session by
Intel apart so in this session we'll be
learning about big data tools and
technologies so I hope in the last
session you would have understood and
you would have learned something from
the hadoop session
how do pico system session so in this
session we'll be looking at the top big
data tools which are available as well
as we learn few things about big data as
well so about big data analytics on the
five V's of big data so after learning
that we'll be looking into the top tools
after that I'll summarize them and once
that is done we will come to the end of
this session so I hope you learned a lot
from this session let's get started so
first the agenda we'll start off with
what is Big Data
then we look into the challenges after
that we'll look at the big data tools
and then I'll summarize them in the most
used big data tools and finally I will
show you how to get started with Big
Data if that is what you want to do in
your career first what is Big Data so
before starting off with something
you'll have to understand what it is
right so like that you'll have to us
understand what is Big Data
so before understanding the buzzword Big
Data what is data first of all so data
is an individual unit of information
that is defined as figures of facts and
stored for later processing so data is
everything so let's say if you want to
call someone you have their name and
adjacent to that you will have their
number so that is Theta you know whom
and what is the number to call them so
you have the precise amount of
information so you can do a task same
thing comes with data if you have
certain information which you can use to
do a certain task so there are three
types of data one a structured on a
semi-structured and one is unstructured
structured are basically relational
databases so they are they have complete
cells and rows with even data so let's
say you have an excel sheet with FiOS
and five columns with data filling up it
all so it's not just FiOS it can be any
number of rows the columns are defined
and also one you get data for everything
so it is structured as a record next a
semi-structured it can be both
structured ants and it can have other
of data as well so if you take Jason it
in Jason it's not required that you
should have a certain set of columns
jason is basically a file in which you
can store any type of data in any order
which you want same goes with CSV and
XML and finally unstructured data
unstructured data is everything it can
be the PDF doc file an image video audio
file a PPT presentation so right now the
PPD I'm presenting you is an
unstructured data the images which I've
used if this is this is collected and
put together in a storage system for
analyzing then again that would be
unstructured data so badly you see and
structure data the most in social media
sites so if you go in there you will get
videos audios image files everything
over that text ok so this is Theta now
as you understood data now let's see
what is big data so big data is a
collection of extremely large data sets
that may be analyzed computationally to
reveal patterns trends and associations
especially relating to human behavior
and interactions so it is basically a
collection of a lot of data so let's
remove these words likes large data sets
it's basically a huge amount of data
which is analyzed to see if there is
something useful inside of that data so
that's why we need big data and then
coming to black box data so it captures
voices of the flight crew for recordings
of microphones and earphones and
performance information of the aircraft
so why do they have this black box in a
flight so whenever the flight is going
to crash or something so to get the
information of what exactly caused that
so let's say a flight has been
malfunction and it has written erosion
so now they'll go and retrieve the black
box to check the information in that so
with that information from black box
they can conclude what exactly happened
in the flight and cost that particular
crash so again this is a example of pick
a table and third one is the you biggest
one right now so everybody will be using
social media sites
you are using a social media site to
watch this live which is YouTube which
is a video streaming platform you have
Facebook whatsapp Instagram Twitter
snapchat and so many others so Google
Plus is already gone so you can exclude
that so there is LinkedIn Pinterest yeah
so that is reddit there is 4chan
actually there are so many social media
sites and every single social media
sites job is to make you communicate
with others so obviously you will add
images videos you'll have text you will
have audio files you'll have every kind
of information so this all will be
gathered together and this will be sent
to
let's take Instagram so you're posting
videos text you are posting audio files
you're posting as well as images so all
of these data will be pushed into
instagrams storage so now they'll have
to segregate it right and so that they
can analyze it so social media data is
also a form of big data so similar
examples power data stock exchange data
search engine data transport data so I
think you can easily relate them by
having these examples social media data
and black box data ok now so this is one
of the important concepts you should
understand while learning big data so I
think you understood understand what
exactly is big data right now so it is
basically large amounts of data in which
you are trying to gather some useful
information from so there may be a lot
of information but not every single line
is useful some lines can be out of value
as well
so you have to find exactly what is the
most useful things and take it out so
that you can use it for your benefit so
also in Big Data the five most important
things are the five beasts to make sense
of the huge amount of data you should
break them down break them down into
five parts the velocity volume value
variety and velocity so let's see what
exactly do these mean first velocity
velocity I think you know what the
velocity is so velocity refers to the
high speed at which data flows in from
multiple sources such as machines
networks social media mobile phones IOT
devices any kind of devices
cetera so there is a massive and
continuous flow of data for example on
Google every day there are three point
billion searches made if there are three
point billion searches made three point
five billion searches made then there
are three point there are so many people
trying to search something so whenever
somebody is trying to search something
some data will be yeah so there will be
some data coming in so obviously
whenever some data is flowing so the
amount of data which is flowing at the
same time is very very high so that is
velocity so let's say you have set up a
big data analytic system in which data
is coming from various sources let's see
so from social media from an IOT device
from a a local machine which you have so
there are so many different inputs for
you so the data flow is continuous so
when data flow is really fast when the
velocity is really high you will have to
have a very highly efficient system so
that you can analyze every single gb of
data which is coming in so next is
volume so volume means the huge amount
of data obviously the highest amount of
data if the velocity is very high the
data size also will be very high because
a lot of data will be coming in to
determine volume the size of the data
plays a crucial role the data may be
very small and a lot of data may be
coming in sometimes the one single file
can be very big and it can be uploaded
just one or two for few minutes so it
depends so and that plays a crucial role
when dealing with big data it is
necessary to consider the volume of it
this is one of the important things you
will always have to consider the size or
the volume of it for example in the year
2016
yeah so the estimated global mobile
traffic so right now every every single
person is having a mobile phone in their
hand so uploading images to social media
sites uploading images to your own cloud
or something so the estimate the total
estimate per month itself is 6.2 billion
gigabytes of data every single month so
now you can understand the amount of
data come coming into the internet
everything
next is variety so we already discussed
this the three types of data structured
semi-structured or unstructured the
thing is it is not that you get only one
type of data either structured or
unstructured or semi structured in some
systems you will get all three types of
data and you'll have to figure out what
kind of data is what and then you have
to segregate them and then analyze them
it also refers to the heterogeneous
sources so that is heterogeneous in the
sense various different sources with
which do not have any connection variety
is basically the arrival of data from
various new sources both inside and
outside of the enterprise so I think you
can understand this point it is so you
can also see that image there is a video
there is an audio file there is a mail
also there is a document so all these
are different varieties of data so every
variety of data will be coming in will
also have to take that into account
before setting up a big data system the
fourth one is you voracity so this
refers to the inconsistencies and
uncertainties in data it is not that
always you get the most perfect data so
every single data set will have an
unnecessary data set so the thing is
there will be unnecessary columns so you
will have to figure out which is messy
which is messy data and remove it so
that you can get a more accurate output
you can get more quality in that so you
can see data can sometimes get messy
hence quality and accuracy of the data
are difficult to control so the thing is
you have to control it so that your
output your trend your information which
you take out of that large amount of
data is actually useful data in bulk can
create confusion whereas less amount of
data can convey half or incomplete
information so a huge amount of data
cannot be easily interpreted but even
though there is a less amount of data
and if it is incomplete you cannot take
anything out of it so the thing is your
data shouldn't be incomplete you should
make sure that your data is complete and
without any inconsistency and finally
and one of the most important thing is
value so you have to figure out whether
the information which you are going to
get out of this data set whether it is
going to give you value or not your
company value or not if this particular
data set is of no value to your
company's growth then the
no use of analyzing it wasting time on
it so you'll have to figure which data
set is needed for you which is not so
the bulk data of having no value is of
no good to the company unless we turn
into something useful
data is of no use are important but it
needs to be converted into something
valuable to extract information that's
what I said if it is not useful then
there is no need to extract information
you have to make sure that it is
important only then you can extract and
it can be used for your company's growth
hence we can state that value is the
most important V of all the files so
even though there is a lot of data
coming in the volume of data is very
high variety of data and there are no
inconsistencies if that particular data
set is of no value to your company then
there is no use of considering all these
other four V's okay so we've seen the
five E's now let's see what is big data
analytics so big data analytics is the
process of examining big data to uncover
trends hidden patterns statistical
information and performing large
calculations using that data so I've
already explained to you multiple times
the same thing because while explaining
Big Data I've also told Big Data is used
to uncover trends and hidden patterns
from a large amount of data so today
almost every major commercial
organization is using big data analytics
because without big data analytics still
not exactly know which is the customer
base they have to target what exactly
they have to do and so there's a lot of
things for marketing as well so let's
say a product is coming into the market
and they want to market that product to
a particular segment let's say teenagers
so they'll have to find out which area
teenagers are mostly using for example
which application the teenagers are
mostly using let's say you know it's all
mostly using Instagram so now this
company will decide to market its
products on Instagram so to get that
information that is whether Instagram
has a lot of teenagers who are using
that particular app so big data
analytics has actually made a direct
impact on the company's profits
company's customer retention targeted
publicity and ads for his advertisements
and then customer satisfaction as well
as the company's understanding of what
exactly the customers want if
only the company use what the customers
want their profits will increase for
that they need big data analytics so the
next is why is it important so big data
analytics is an essential part of
everybody's life right now because as I
told you everything any company does
that so first
personalized customer experience so if
you open Amazon and you just want to
look cameras and gadgets so you are
searching for gadgets a lot but when you
search for gadgets a lot your
recommendations will be filled up with
other gadgets which you may like so
instead of showing gadgets if Amazon
showed you beauty products will you like
it you obviously won't that is basically
the personalized customer experience
next is showing of only in relevant data
so again this comes under that category
so instead of showing you a product
which you will never buy we can show you
a product which you might buy so that
will increase the chances of that
product to be sold third one targeted
advertising so again this will come
under the same first two category but it
is a little different here you pay money
to push your advertisement to that
particular user may buy that product
because he has searched about this
product a lot fourth will search on
technical analysis so research you might
know so let's say if even if it is
scientific research or patent research
you will need big data analytics to
gather the required data to check if
this particular project has been done or
this particular patent has been already
taken so these are some reasons why big
data analytics is important and there
are so many other reasons as well so
we've seen this next yeah so challenges
phased in big data analytics first SQL
so structured query language it is used
to communicate with a database and is
considered to be the standard language
for our DBMS so you provide a query
statement to get the name of all the
customers in a table so your statement
will be directed to the our DBMS server
which has that data then you will get
the output back so this is how basic SQL
works now what are the problems with it
first one hardware failure all those
storage capacities of hard drives
increased massively that is so obviously
you first we had floppy disks then we
had CDs then we got pen drives then we
got smaller SD cards so the devices are
getting smaller the storage space is
getting bigger and that even though that
happens access speech that is the rate
in which the data can be read so for for
names that is easy let's say you want to
read a million names so that will
obviously take a lot of time
so in that case sometimes the hardware
might fail and then the second one is
combining data most analyses require to
combine data in some way to join
multiple tables so data read from one
particular hard drive or disk may be
combined with another disk and it can be
combined with multiple disks and this
particular thing is very dangerous or it
will it is very time consuming if there
are separate disks this is a challenge
for distributed systems now what is the
solution for this
so let's look into that so first for a
solution for hardware failure well we
start using many pieces of hardware the
chance for one to fail is far behind and
this might this is the result data loss
a common way of avoiding data loss is
through replication the replication
basically means having multiple copies
of data in multiple locations or
multiple drives so that even if one even
if data is lost in one particular drive
you can get it from another tribe so in
this event of failure there is another
copy available so this is what exactly
Hadoop does Hadoop has and file system
called HDFS Hadoop distributed file
systems which has multiple copies of
data whenever one drive fails it gets
the data from another distributed system
for combining data we have MapReduce
MapReduce is a programming model so this
is used to map and reduce and it uses
key and value pairs so MapReduce has a
built-in reliability and interface where
the mixing of map and reduce mid videos
occurs so if you have a lot of data
MapReduce can help you to reduce into a
smaller amount of data so that you can
use it to so it will combine the data
into a smaller column or a smaller set
of data which makes it easier for you to
analyze data so I just
to give this information even though
this information will be given in the
hadoop session as well also in other big
data sessions provided by Intel apart
now let's get into it and look into the
big data tools which are really popular
so first for data storage and management
there are multiple tools so Apache
Cassandra is one of the most highly used
tools then MongoDB I'm pretty sure you
would have known either one of these
names
so first Apache Cassandra this is a
database which is widely used to provide
an effective management of large amounts
of data
it supports replication and also offers
a very good fault tolerance and low
latency so basically Apache Cassandra is
not exactly a traditional database type
of system but this this a database which
is basically so let's say you have large
amounts of data then you can go with
Apache Cassandra so it is very effective
to manage it and then comes MongoDB it
isn't no sequel database it's a non
relational database basically so it is
also open source it is cross-platform
compatible it is compatible with so many
different software's and platforms and
frameworks it is ideal for the business
that needs fast and real-time data for
fast decisions as we know MongoDB is
really fast because it is no sequel even
though it is no sequel it has inbuilt
features so that you can easily query
data out of MongoDB tables so that's why
it is really fast and also it is very
very required for real-time data
so basically no sequel databases are
used for real-time data meaning for
example if you go to Amazon you will
have filters to choose a particular
brand or within a particular range of
cost or this type of product so all of
that filtering is done on a no sequel
database so it is ideal for the users
who want data driven experiences so this
is basically for applications which is
completely data driven again it is for
applications like e-commerce
applications Amazon flip card a web so
all of these applications and then
coming to others so there is hey Hadoop
and then my sequel so I'm pretty sure
you know my sequel is an O
source relational database it is mainly
used for a structured data and it uses
basic SQL to query its tables and then
how do Hadoop is the most popular Big
Data - I don't need to tell it to you if
you even just type in Google the most
popular Big Data tool you will get
Hadoop so Apache Hadoop software the
library is a big data framework so HDFS
is used for storing data in that HDFS as
I already told you it is Hadoop
distributed file system and it is mainly
used for storing data in a distributed
platform so that you have replications
of this same data so it also allows
distributed processing of large data
sets across clusters of computers so to
make it simpler let's say you have four
different computers and one master
computer
now you have uploaded a large data set
into the master computer and that match
the computer will split the data set
data set into four different smaller
parts and provided to the four different
client computers so that the task is
completed four times faster than
analyzing it in a single computer so
this is how Hadoop works and then it is
designed to scale up from single server
to thousands of machines so you can also
do it on a single machine you can also
do it on the organs of machines which is
connected under it okay so we've seen
these four tools
next comes data cleansing so as I told
you there might be inconsistencies there
might be uncertain data so to remove
that you need a data cleansing tool so
these two are the top data cleansing
tools which I could find open refine and
try factor Wrangler first in open refine
it is a powerful tool to work with messy
data or under its inconsistent data it
is used for cleaning and transforming it
from one format to another it can also
you can also actually easily explore
large data sets using it and also you
can upload so once you clean your data
you can upload that data into a central
database let's say you can also upload
it to a cloud database and AWS database
or an Azul database or even to wiki
later a central database and then
factor bang Wrangler so this is used to
discover structure clean and rich and
also publish data of all shapes and
sizes so again this is for data
wrangling you can also do data cleansing
so this also supports large data volumes
and also it also supports connecting
with cloud and other deployment that is
on-premise setup finally it is a
connected desktop application so
basically it is a desktop application
which you can connect with other
deployment options and also this is to
transform data for downstream analytics
and visualization so this provides you
the ability to make your data clean so
that that data can be used for
visualization and analytics okay so this
is for data cleansing next for data
analysis we have Apache spark we have
five and we have hadoop mapreduce so we
already seen MapReduce what exactly
happens there so again you will see that
once more facilitates processing by
splitting petabytes of data into smaller
chunks as I told you this is used for
accessing and processing data which is
told in HDFS what it does is it splits
petabytes of data into smaller chunks so
then it can be processed really fast the
logic is executed on this server by the
data already resides so the thing is
using MapReduce you don't need to
download the data first and then process
it you can run MapReduce on the server
where the data is already available so
that it saves a lot of time coming back
to Apache spark this is again an open
source big data to every single Apache
tool is open source this fills the gaps
of Apache Hadoop concerning data
processing so spark can handle both
patched data also real-time data as part
this in-memory data processing it
processes data much faster than
traditional disk processing so in memory
disk processing in the sense it does not
copy the data to the hard disk and then
process it it basically gets the data
stores in the temporary memory processes
it and pushes it it doesn't store
anything that's why it is really faster
than Apache Hadoop and then comes hi-5
again this open source as
told you every single Apache a big data
tool is open-source it's an open-source
software big data tool it allows
programmers to analyze large sets of
data on Hadoop so it is mainly used for
querying and managing large data sets
which is available in Hadoop so these
are some data analysis to spark hive and
MapReduce and finally we look into data
visualization tools so these two are the
most popular in the industry tableau and
power bi so tableau is again a bi
analytics tool it is used mainly for
visualizations and to create bi AR
trends so you can see the main thing
with tableau is you can extract data
from any source you can connect it to a
database you can extract information
from Excel from a PDF file from an
Oracle database from a cloud provided
like Amazon Web Services as you GCP so
it's a tool for visualization in the BI
industry it has really powerful
visualizations which is also interactive
so as well as you can also connect it to
Hadoop so tableau can be connected to
Hadoop so it is a really useful feature
in tableau and then it comes power bi
again this is a business analytics tool
which is a bi tool power bi is provided
by Microsoft and power bi does not
require anything else you just have to
know a little bit of SQL and it is more
than enough to start off with it so
again it provides interactive
visualizations and ba capabilities and
also they have made it so simple that
anyone can start off with power bi again
it can connect with Excel it can connect
to cloud databases it can also connect
to compromise databases and data
warehouses so these are the top two
visualization tools okay now let's just
quickly look into the Hadoop ecosystem
I'm pretty sure this has been taught in
the afternoon session but I'm just going
to roughly I'll tell you why exactly is
Hadoop ecosystem very popular and why it
is free as well so first for Hadoop
ecosystem is open source and you have
every single tool which you need to
create a complete big data analytic
system over here you have
hadoop mapreduce for processing you have
hive for analytics query you have mahute
and spark for machine learning and data
processing you have Kafka and storm for
streaming you have another you have
patches park for in-memory data flow
engine which is basically for in-memory
data processing you have a no sequel
database you can use HBase instead of
MongoDB you can have you can use Susi
for scale scheduling the tasks you can
use solar and Lucene for searching and
in texting and then you can use Pig it
is a scripting language which you can
use in the Hadoop ecosystem you have
zookeeper which is basically used to
manage and coordinate every single other
big data tool in the Hadoop ecosystem
you also have Hadoop yarn and Hadoop
HDFS
yarisis resource management tool it is
again it is used to manage all the other
how do echo system tools HDFS it is the
storage so you can see it is at the
bottom any data coming in unstructured
semi-structured structure it will first
hit how to fetch the office it will
store then it will move the data to
whichever part of how to pick which
system you want to yeah so this is the
Hadoop ecosystem I think the morning
session would have covered this
thoroughly okay now let's just quickly
summarize the most use big data tools so
the first most used big data tool is
Hadoop Hadoop is used everywhere in
every single company which ever uses big
data analytics
Hadoop is really popular it is available
in almost every single cloud platform
and so Hadoop for visualization tableau
is the most popular for a no sequel
database MongoDB is really popular
because it can integrate with any any
back-end tool it can integrate with any
third-party tool and then comes Apache
spark Cassandra ok so there are some
honorable mentions as well I wanted to
say so there is Amazon redshift which is
a data warehouse which is really good
for analytics there is Amazon quick site
which is for visualization again it is
really fast and quick for cloud data
warehouses and then you have data Lake
in Azure that is
really good and then also you have
multiple tools so many different tools
are available you have even an Apache
you have so many different tools in
visualization again you have click sense
you have sigh since you have so many
different tools so you'll have to do a
lot of research before choosing what
exactly you need but I would strongly
suggest these fight tools over here if
you want to start off with big data
Hadoop MongoDB spark Cassandra and
tableau ok guys we've seen this next I
wanted to show you is if you want to
start off a career if you want to have a
career in big data how do you get
started with it ok so first let me
introduce you to something first of all
we in telepods provide you a lot of free
resources first we provide you blocks
and also a YouTube channel with so much
of free content so much of free content
we have complete Big Data courses as
well so coming to in telepods block we
already have so I have already have
opened over here I'll just close this so
you can see here until I become slash
blog so you can come here to the home
page and you can see we have so much
free content
so here it's big data click on it and
you get all the blogs here and you also
get Big Data tutorials so you can see
major Hadoop developer roles you can see
your elevate your career in politics
what is apache Pig and you can see
Amazon glacier scholar certifications
plum certification patches Park waters
but get analytics so let's say if you
want to learn what is big data analytics
just click on it you will get a complete
page with information content you can
check over here and also we have YouTube
videos so currently you're watching this
video in youtube so you can see this so
obviously your you will know we have a
YouTube channel and it is really
informative you can check it out coming
back to these slides recently we've come
up with a new initiative called the
Intel apat Academy to provide you with
free courses so let me open so you can
see here in telecom slash
cata me coming down you can see all the
free courses we provide we provide java
c excel SQL and then a lot of foundation
courses on AWS devops Kazu salesforce
tableau so i think there's a lot of free
courses we provide and if you want for
example if you want to start with java
just click on it you can check out about
the course you can check out why should
you join it you can check out what we'll
be teaching in this session and then if
you want to take up the free course it's
pretty simple click on take this course
join us with google or you can just
register it quickly once you join you
will have a free course and you can
start off with it so you've seen that
both and finally one last thing I want
to introduce is our website in the lipid
comp so I think most of you will like to
start your career and you would need
professional advice and professional
training so we Intel apart
provide professional training recently
we have come up with a PG certification
in big data analytics let me open that
this is in collaboration with E and ICT
a department of IIT Guwahati as well as
it is screen collaboration with IBM so
you will get two certificates coming
down so you'll get these two
certificates one is from Intel apart and
ID go at it and one is from IBM so you
can see here you will also get the
alumni say status of E and ICT Academy
of IIT Guwahati so you can check out
about the whole program over here what
exactly we will be teaching in this so
let me just introduce you to the main
features 400-plus horse of
instructor-led training this is a one
your course you will get a lot of
training we help you with jobs will send
your resumes to our top 500 clients and
we provide you twenty plus projects and
30 plus case studies you can just you
can apply to it immediately and you can
start off with your career so you can
get in touch with us and coming down you
can see what are the projects will be
covering will be covering twitter
sentimental analysis
finding top movies based on movie lens
data using movie data we will be finding
the top movies and then connecting
Pentaho with a dopey ecosystem we'll be
teaching you the complete Hadoop
ecosystem so that you can become the
most complete and one of the top Big
Data professionals in the industry hope
you guys love coming back to these
slides so I've introduced you how to get
started with it you can take up the free
codes and start off if you want to take
a course from us you can go to our
website and it's pretty simple to start
off okay so one more thing
whoare is watching this particular live
video you will get a 30 percent flat
discount on every course if you take up
the course right now using the coupon
code youtube / - so guys what are you
waiting for
so go ahead take up a course and get
started with your career also if you
want to contact with us you can call us
in the number which is available in this
screen or we will provide you the number
in the chat also you feel from any other
country or from us you can call us in
the from the toll free number or you can
put up a mail to sale set in the lipid
comm or start a chat with our course
advisor in the website's bottom right
corner so anything you can do anything
from this and we will contact you
immediately so thank you for attending
this session meet you in another session
I hope this session was really helpful
meet you in another session and one last
thing
at 8:30 we have another session so that
session again will be on Big Data itself
so you please stay and watch that as
well right now after the session you
have two more ours at 8:30 we'll have
one more life you can come again and
watch so we are making three lives
everyday for your sake we want our
customers to be satisfied we want our
viewers to be satisfied so we are doing
so many different videos so please watch
them and also subscribe to our channel
thank you
you
