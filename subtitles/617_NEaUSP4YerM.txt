I'm drawing a graph doesn't it look cool
but I didn't know how until I watched a
quest hello and welcome to stack quest
stack quest is brought to you by the
friendly folks in the genetics
department at the University of North
Carolina at Chapel Hill
today we're going to be talking about T
Snee or tis knee to be honest I don't
actually know how it's pronounced but
it's gonna be clearly explained I know
that bet also this stack quest is by
request a couple of people put it in the
comments below and I got a couple of
emails from other people so I'm doing it
because you guys want it here goes if
you're watching this stack quest chances
are you've seen an example of a tea
sneak graph before what tea Snee does is
it takes a high dimensional data set and
reduces it to a low dimensional graph
that retains a lot of the original
information if you're not familiar with
those terms of taking a high dimensional
data set and reducing it to a low
dimensional graph you might want to
watch the stat quest for pca because i
explain what that means in that video
here's a basic 2d scatter plot let's do
a walk through of how tea stain would
transform this graph into a flat one
dimensional plot on a number line I'm
going to use this super simple example
to explain the concepts behind tea Snee
so that when you see it applied to a
much larger data set a much more complex
data set you'll still know how that
graph was drawn note if we just
projected the data onto one of the axes
we just get a big mess that doesn't
preserve the original clustering if we
project it on to the y axis instead of
two distinct clusters we just see a
mishmash and the same thing happens if
we just project the data onto the x axis
what T Snee does is find a way to
project data into a low dimensional
space in this case the one-dimensional
number line so that the clustering in
the high dimensional space in this case
the 2-dimensional scatterplot is
preserved so let's step through the
basic ideas of how tasty does this we'll
start with the original scatter plot
then we'll put the points on the number
line in a random order from here on out
T sneem moves these points a little bit
at a time until it has clustered them
let's figure out where to move this
first point should it move a little to
the left or a little to the right
because it is part of this cluster in
the two-dimensional scatter plot it
wants to move closer to these points but
at the same time these points are far
away in the scatter plot so they push
back these points attract while these
points repel in this case the attraction
is strongest
so the point moves a little to the right
BAM now let's move this point a little
bit these points attract because they
are close to each other in the
two-dimensional scatter plot and this
point repels a little bit because it is
far from the point in the
two-dimensional scatter plot so it moves
a little closer to the other orange
points
double bam at each step a point on the
line is attracted to points it is near
in the scatterplot and repelled by
points it is far from
triple bail now that we've seen what tea
Snee tries to do let's dive into the
nitty-gritty details of how it does what
it does step 1 determine the similarity
of all the points in the scatter plot
for this example let's focus on
determining the similarities between
this point and all of the other points
first measure the distance between two
points then plot that distance on a
normal curve that is centered on the
point of interest
lastly draw a line from the point to the
curve the length of that line is the
unscaled similarity I made that
terminology up but it'll make sense in
just a bit so hold on
now we calculate the unscaled similarity
for this pair of points now we calculate
the unscaled similarity for this pair of
points and now we calculate the unscaled
similarity for this pair of points etc
etc etc using a normal distribution
means that distant points have very low
similarity values and close points have
high similarity values ultimately we
measure the distances between all of the
points and the point of interest then
plot them on a normal curve and then
measure the distances from the points to
the curve to get the unscaled similarity
scores with respect to the point of
interest the next step is to scale the
unscaled similarities so that they add
up to 1 um why do the similarity scores
need to add up to 1 it has to do with
something I didn't tell you earlier and
to illustrate the concept I need to add
a cluster that is half as dense as the
others the width of the normal curve
depends on the density of data near the
point of interest less dense regions
have wider curves so if these points
have 1/2 the density as these points and
this curve is half as wide as this curve
then scaling the similarity scores will
make them the same for both clusters
here's an example where I've worked out
the math this curve has a standard
deviation equal to 1 these are the
unscaled similarity values this curve
has a standard deviation equal to 2
these points are twice as far from the
middle the unscaled similarity values
are half of the other ones
to scale the similarity scores so that
they sum to one you take a score and you
divided by the sum of all the scores
that equals the scaled score here's how
the math works out when the distribution
has a standard deviation equals to one
we get zero point eight two and zero
point one eight as the scaled similarity
scores and here's the math for when
everything is spread out twice as much
we get zero point eight two and zero
point one eight the similarity scores on
top are equal to the similarity scores
below they are the same
that implies that the scaled similarity
scores for this relatively tight cluster
are the same for this relatively loose
cluster the reality is a little more
complicated but only slightly T Snee has
a perplexity parameter equal to the
expected density around each point and
that comes into play but these clusters
are still more similar than you might
expect now back to the original scatter
plot we've calculated similarity scores
for this point now we do it for this
point and we do it for all the points
one last thing and the scatter plot will
be all set with similarity scores
because the width of the distribution is
based on the density of the surrounding
data points the similarity score for
this node might not be the same as the
similarity to this node so T Snee just
averages the two similarity scores from
the two directions no big deal
ultimately you end up with a matrix of
similarity scores each row and column
represents the similarity scores
calculated from that point of interest
red equals high similarity and white
equals low similarity I've drawn the
similarity from a point of interest to
itself as dark red however it doesn't
really make sense to say that a point is
similar to itself because that doesn't
help the clustering so T's knee actually
defines that similarity as zero hooray
were done calculating similarity scores
for the scatter plot now we randomly
project the data onto the number line
and calculate similarity scores for the
points on the number line just like
before that means picking a point
measuring a distance and lastly drawing
a line from the point to a curve however
this time we're using a t-distribution
a t-distribution is a lot like a normal
distribution except the tea isn't as
tall in the middle and the tails are
taller on the ends the t-distribution is
the tea in tea stay we'll talk about why
the t-distribution is used in a little
bit
so using a t-distribution we calculate
unscaled similarity scores for all the
points and then scale them like before
like before we end up with a matrix of
similarity scores but this matrix is a
mess compared to the original matrix the
goal of moving this point is we want to
make this row look like this row t Snee
moves the points a little bit at a time
edit each step it chooses a direction
that makes the matrix on the left more
like the matrix on the right it uses
small steps because it's a little bit
like a chess game and can't be solved
all at once instead it goes one move at
a time BAM
now to finally tell you why the
t-distribution is used without it the
clusters would all clump up in the
middle and be harder to see triple bam
and now we know how teeny works i've
used a really simple example here but
the concepts are the exact same for more
complicated data sets
hooray we've made it to the end of
another exciting stack quest if you like
this stack quest and want to see more
like it please subscribe and if you have
any ideas for future stack quests just
put them in the comments below until
next time quest on
