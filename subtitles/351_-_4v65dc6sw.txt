yes what's
next on
the the folder structure
reinforc Lear and sampling of the
confidence okay
reinforc okay
reinforcement upper first upper
conference e
screenshot people okay
screen share some please
much e
just
see data set add CTR optim see
okay so this is coming
under which algorithm we have seen I
mean
we so this
is
okay I just wanted to want you to
understand whether you will be able to I
mean make some kind
of uh understanding and then we'll know
we we need to explore the what is UCB
what are the other methods that are in
reinforcement can see
take your time but I mean this is this
is you know you are getting some
practice how you need to understand
a and how you have to approach any
algorithm from a from a common man's
perspective from a machine learning
perspective and
[Music]
how we are breaking up each and every
element how I mean how much time you'll
be taking to understand SE
we are going to
learn let me know you just to teach me
try to teach
me or practice I don't
know okay
right take your time and then like what
what you guys
think
e
e
e
e e
okay any
information add one add two add s and
[Music]
first user second user
[Music]
okay first we'll just try to evaluate
for ourselves okay we have so many
options
is
getting ma math
[Music]
application so on the reward function
each L explain just ask with the prompt
e
e e
sh e
sh
okay
[Music]
the total rewards for each
okay Su of Rewards
[Music]
Max
[Music]
Max
[Music]
okay
okay then
yeah I
Max
okay
go okay fine
um just open the
tab reinforcement
learning in
medium Med reinforcement learning
Mission
learning in medium
okay
understanding
understand inion
where
where Okay so
this
okay confidence
okay
[Music]
um okay first we'll see from the
basics open the next open the other Tab
and search for
UCB of upper uh
B
in reinforcement learning
uh yes yes Lear Med
all
right so let us try to break each and
every point of view and also we need to
break down
anything I want to I want you to make
more
[Music]
present you're going to learn
something and you I mean you won't get
any kind of a chances that you have to
speak or you have to know present you
have to know give out your thought
process learning
don't I'm just
common I wanted to be a
mentor the learning
methodology I just injected
you have to go each and every step of
the
theal try to understand and visualize
first of all
and so and so
okay just know they given an
option I me practic
me this is greatest
time so we will behind the mentors
I want you to be know more independent
okay why I'm saying this this is how we
have to
practice where my experience comes into
you or my experience comes into a play
are useful for
you how toy
okay
[Music]
you never
have you should have a proper planning
place
how you are going to Str
data set how are going
to the macro or
whatever this is
you will be
IND you will given the work scenario
re okay this is how you have to learn
and this is the process each industry
wants you to
okay you have tried
now I want you to take a look at this
document and let me know what they are
actioning
and the statistic
problem is a problem M options each
options offers reward with a
given
problem then sampling is that learning
strategy solve this
problem the stas band
problem solve from the strategy the D
sampling this paper will discuss
sampling in detail explaining
theoretical foundation and focusing on
practical
application upper conference is a
learning strategy for solving the
stochastic Bandit problem a multi option
Deion problemas
problem
Sol strateg this strategy is designed
both to explore options that have not
yet been explored and exploit the best
option based on existing
knowledge in this paper we will cover
the basic concept of UCP algorithm and
explain in detail how it works this
paper aims to provide a broad overview
of reinforcement learning from the basic
concept to Advanced application and
future
perspectives so what they going to do
with UCB and
th okay
okay basic
concept reinforcement learning is
fundamentally based on the concept ofion
process mdp is the mathematical model in
which certain states of an
the
action the actions an agent can take and
the reward that
follow each
DET
process equation from the basis of mdp
and show how to calculate the optimal
policy and Val op policies and
values
addresses
problem
th
address the basing model is
constructed the that uncertainity
estimate the true reward distribution of
each Bandit bit and each step AG
based
okay band meaning
in uh
[Music]
reinforc be in
reinforcement what is
other meaning
just go ahead multi
armed multiarmed
Bandit problem imagine you are in a Cino
with a row of slot machines each with a
different probability of paying out
what say
I
mean so it is a Cas know with the row of
slot machines each with a different
probability of paying out so these slot
machines are called arms so as as each
machine as a mechanical arm you pull you
pull to play so your goal is to maximize
the total reward you get by pulling the
arms okay so you have to get a maximum
total
points but the challenge here is that
you don't initially know the payout
probabilities of the machines per
something you have to push the
LI
have I just learning about the
mission okay
they got the
trick leave the CH where in the game 2D
game 3D games in the game 3D games
shootout games or any other games I'm
not fond of playing
games okay
okay you will be getting some reward
points for each time
so they just improved a
lot you are just trying to understand
how this application works
first maximal
reward you won't get it the same kind of
on here in multi-armed Bandit problem
okay so each time you play a mission you
learn a little more about its payout
probability but you also lose the
opportunity to try another other
machines that may pay out better so this
creates a tradeoff between exploration
trying out different machines to gather
more information about their potentials
so explore
for that is one the second second thing
is exploitation playing the mission that
you believe gives the highest reward
based on the information you have so
far okay that
means explo okay so playing the machion
that you believe gives you the highest
reward based on the information we have
so far
so so meaning of bandit in this context
comes from the idea that each slot
machine is like a bandit trying to take
your money while
Bandit just band it
here okay so this is what the real
meaning is but in this
context we are getting the maximum
payout maximum
okay so this is
what in this context trying to take the
money okay the multi armed Bandit
problem is a metaphor for making
decisions in situations where you must
choose between different uncertain
options with limited information
balancing the tradeoff between learning
more learning more
exp and then making the best choice
based on what you know that means
exploiting
but okay
next we'll put you know maximum effort
to get the rewards get the point
that is your the
maximum how you are going to
explore how you are getting some kind of
input
okay especially
context so it does this by assigning
each on a confidence bound that accounts
for both the average reward and the
uncertainty
okay the particular opposite person
reinforc
learning
GES still you have to explore
those
characters will stop you
there you have to
explore you have to break through
so the arm with the highest upper
conference bound is selected which
encourages trying less explode arms but
also focuses on arms that have shown
good results
maybe some other
times maybe that needs more
Focus also more learning or
exploration you
have will explore more options and
opportunities and you will exploit that
means you achieve the maximum upper B I
mean the upper
now just go to
the
confence rewards by number of
sections deltore equal to math do square
root of 3x2
star
just it started
working so total underscore reward
selection so number of times each
wased Instagram
Facebook Instagram Facebook Instagram
Facebook
inst Facebook
Facebook
sponsored
sometimes just going and searching for
something okay
how many times the customers
clicking right I want to
umle students
presses and experienced working
Prof whatever
they will try to
click how many times they have
selected email ID
200 or something
we just and
check we are doing we are shopping like
business
cont we will never be able to visualize
what what
10 columns so you you never know
that but
it will be recorded as I
mean even though
you uh doing something
okay right
so statement
but this is what is
happening maximum
selection so number of times each
wased number of times
10,000 ENT
6000 just
imagine depends it depends on the
geography matter lot okay
right all that
is now just go to the
next
C click through rate the adore CTR
optimization
we have to spend lot of
money
[Music]
okay
next th
yes
e e
okay
so what is thums and something
the Thon
sampling
Med Thompson sampling addresses theistic
banded problem using basian statistical
methods a basian model is constructed
that uncertainty estimates the true
reward distribution of each Bandit arm
at each step the agent selects a bandit
based on the current estimates and
updates its estimates using the observe
reward
information what is B statistical
meths statistical
methods next explain basan statistical
methods
in Thomson
s e
I
e e
what did that
[Music]
[Music]
uh
okay so in the Bas
statistics B
all you Bas steps
prior distribution and likelihood
function poster
distribution it is very critical it is
playing very
vital likelihood as you pull an arm and
observe its reward you update your
beliefs about that arms reward
distribution using the likelihood
function so the likelihood is the
probability of observing the data given
your current belief about
the likelihood
function whatever the
process even right from
your um
Max
distribu
right is not
it makes lot of things know there are so
many other
reasons there are so many
things at the same time the maximum
occurrence of
head
likelihood how many times it
appear 50 times head 40 times tail 50
times ta 40 times head maximum
likelihood same kind
of
reinforc What Not only game even any
kind of a situation even your chess
board game
okay opposite person what the maximum
lik
observing
Maxim that is called as likelihood
occurrences right
through
this so that algorithm you'll never
forget about that algorithm
okay that is what that's called th and
distribution
th okay this
is what
is
import
[Music]
sampling dat
random methodology random Li
important so the random
Behavior beta variate numbers of rewards
in the iteration itations same kind of
concept but
samping random
section it is not a it is not that you
are selecting instead the system is
selting
sampling it is quite higher the number
of times each ad was selected
Thon sampling
process doing the
randoming Because of three
factors one the prior distribution
sampling post posterior distribution of
sampling and
maximum occurences
likelihood
urces that is
what reinforcement
learning it is not
famous frequently used algorithms and
Thomson reinforc learning
what are the applications of the
enforcement learnings
autonomous navigation game
s games Health Care Financial Trading
supply chain
Logistics right Energy Management
manufacturing
Industries can you can have a lot of
things marketing smart cities
education education
[Music]
adaptive
learning ad learning
Bas ask
question I
me just in one question paper
mathematics
mathematics it will give it's giving me
a
report the report Maxim
100 out of
10 next
customer so that I can go for the
next Learning System will identify what
kind of a learning method I have to
choose so that I know I can make I mean
make more
engagements
lefor
okay not only this
onfor is pouring like anything
but it's slow
Lear a huge amount of
things Facebook is not like
that more money
so okay right any
questions sir
okay
okay so just to focus on the
project
[Music]
even just the
possibilities focus on the project
okay
sir thank you so much
and lot of things okay thank you
