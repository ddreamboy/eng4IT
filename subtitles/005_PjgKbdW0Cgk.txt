hello there welcome to your tutorial on
lenet 5 one of the pioneering
convolutional neural networks designed
for handwritten digit recognition in
this video we'll walk you through the
architecture of lanet 5 demonstrate how
to implement it in Python and show you
how to train the model using Azure ml
before we begin with anything I really
want to take some time to talk about the
significance of lenet 5 lenet 5 is like
the hello world in the domain of CN n
that's convolutional neural network
lenet 5 is a gradient based learning
algorithm which was introduced in 1998
and it uses backward propagation which
was first introduced by itself in
1989 to solve the very popular problem
or dilemma of the time that stochastic
gradient descent where the computational
or the compute and the algorithm are in
a stalemate and was for a long time
thought to be an unsolvable problem
and it is thanks to lenet 5 that we have
deep neural networks as we know it today
it was lenet 5 that proved that it was
possible to build and train models with
layers and layers of depth and that is
what we have or we know it today as
neural networks deep neural
networks so to Summit up lenet 5 is the
foundational step in the direction of
deep neural networks and it demonstrated
that it's possible to build depth in
neural networks convolutional neural
networks and for that it used backward
back propagation in its gradient based
learning now let's talk about the
architecture of lenet 5 model so if we
exclude the input layer we are left with
seven layers which comprises lenet 5
three of them are convolutional layers
which are basically kernels or filters
that perform the mathematical
convolutional operation
and let's skip the details you can look
that up on convolutional operations in
mathematics then we have two subsampling
layers which basically are used to
reduce the dimensions of the image and
why do we want to do that is we want to
reduce the computational complexity
because there are a lot of pixels and we
do not just want to compute uh
brainlessly we do want to reduce our
sampling size uh we do call it in image
processing the process of down sampling
and that's what we do to reduce the cost
of computation and then we have the
fully connected networks whose role is
to learn the complex patterns and make
the predictions that's the
output so we usually train our models on
a huge data set from msit that's the
standard and it consists of lots and
lots of handwritten
training uh data for data set so this is
a example of how lnet 8 Works visually
if we were to do so we have L layer one
three and five as the convolutional
layers layer one being the input we are
able to understand human human in a
human manner that it's the number that
we are passing but as you go into depth
layer three and layer five the details
that are extracted from the neural
network are more computational and it
stops making sense for
us chello now let's get hands-on
experience on lenet 5 before we do that
there is a prequisite and that's that
you have your workspace ready in Azure
machine Learning Studio and in case you
do not have it uh there's a link in the
description for a video which you can
check out to set up your uh workspace it
hardly takes 15 minutes and the video is
hardly 6 minutes go through it and set
it up and you ready to do the exercise
with me so I'm going to assume that you
have it ready so first of all we need a
compute on which we want to perform the
machine learning or training of the
model so in the compute I already have
my compute ready and it's a GPU with
this specs you can also create this byck
clicking on new select GPU and you can
select anyone I would uh I'm sticking
with a very cheap one but you can
according to your needs and your credit
of course you can
schedule and uh actually once you
schedule uh it's uh it's their option
you can just review and create and
create the resource for yourself so I
already have that so I'm not going to do
that so now we will head to notebook in
authoring section and here here uh we
will create a new
file and that's going to be a python
notebook so now I'm going to be very
concentrate about you and ensure that
you have a good experience while you
follow along with this video so I'm
going to show you that the library that
I have on my system so for this exercise
we will need torch library from Python
and also torch Vision so
first of all uh let's import CIS and
check the environment uh that this
notebook is running
on and to do that we can just import CIS
in Python and CIS stands for system and
then we can just print sis. executable
and that will show us the environment
that this notebook is
picking so this is the environment and
uh now I I'll go to terminal from here
so let's make sure we are on the right
computer if you are if you have multiple
compute you just want to click on this
drop down and select your
compute so I'm going to check first of
all the list of environments that exist
on this compute so the command for that
is cond EnV list
so we have five to six environments
showing up
and Jupiter notebook is this one but are
we using this let's double check it with
what we got on our
notebook so we are having SDK V2 and
that's not this
surprisingly uh
we have this right here so we are
currently on Azure ml P30 and we want to
move to Azure ml Pi 310 SDK V2 so let's
pick this up and the command to move to
this environment is
cond activate followed by the
environment that we just
copied so now here it shows that we have
successfully moved to the environment we
were we wish to move and since we are
now in this environment we can and make
the library changes so it's very knively
uh it's a KN mistake to pip install the
library in uh the default environment
and it's not being reflected and you are
scratching your heads what's happening
so now that we are in that environment
that notebook is running on we can just
make sure that we are installing torch
and torch vision for me it's already
installed on my environment in this
computer for for you it will be the
first time and it will actually install
it for me it's it's just showing that
um requirement already exists so it's
not installing uh let's go ahead and
install torch Vision as well and we'll
get a
similar uh already installed no response
and that's
there so now let's head back to our
notebook and put in the base code that's
required so I'll just paste it and the
code is all about fetching the MN
data set
and uh splitting it into training and
testing data sets so that we can
actually train our model and then test
how it's performing and evaluate it give
it a score so that's all being done here
we have downloaded all the data and it
has handwriting from all over the world
and it's a huge huge data set and some
of them frankly are really difficult for
even me as a human to identify but let's
see how my model do
so we do need to refresh our directory
if we are expecting some new folders or
files so let's
see uh there's a data folder MN and then
we
have uh we had we have images in
compressed format Let's Not Disturb
that uh so we are going to now Define
our line 5 model in this section
and to do that we the approach for the
video will be I'll just paste the code
and explain what I have written or it's
it's pretty much very standard what we
are doing is we are just um coding it
coding the picture of the architecture
in this section so from the picture we
have input as 32 cross 32 then we have
the convolution with six feature maps of
28 cross 28 and then next we have six
feature map maps of 14 cross 4 14 and so
on we have the layers so if we focus on
layer one we have neural network nn. con
convolution 2D so we are doing
performing 2D convolution and we have 1
comma 6 comma kernel size equal to 5
stride equal to 1 padding equal to zero
so stride is the movement of Kernel will
be by one pixel and padding will be zero
so on the borders we are not excluding
any pixels this is the first
convolutional layer with six feature
Maps that's what six is and kernel size
equal to 5 is that we are keeping it 5
cross
5 so interestingly you might be thinking
why the kernel size is 5 cross 5 and not
32 cross 32 or not 28 cross 28 in the
next convolutional n we have 2 cross two
kernel size and then again we have five
cross five what's happening
well uh the thing is that the way kernel
kernel size is the operation we are
performing so we are having six kernels
of 5 cross 5 which will on acting on top
of 32 cross 32 which which is the input
image will make the output as size of 28
cross 28 and when 28 cross 28 is fed to
2 cross2 Cal size of six uh six of them
it will become 14 cross 14 and how it
happens I'd love to show that but let's
not do it here it's related to the
operation of convolution in mathematics
again other than that we also have tanh
which is the activation function so we
have t uh curve which we use to either
uh activate or meaning just we want the
output as one or zero decisive how
confident you are and we convert the
value to one and zero depend uh using
the activation function right now as T
and for output in the very last layer we
will be using softmax which is very
popular for
uh uh its implementation on the output
specifically we implement it softmax
function which is a mathematical
function as activation function in lots
of machine learning models it has its
significance and background which we
will skip sorry uh but that's the model
that we have and now we can proceed and
go ahead to train and test them so again
I'm just going to pick up the code that
I have already written on my local and
drop it on the notebook and execute
it so this will take some time and let's
run it the first thing that you should
observe is that CPU is going to go from
0 to 100% usage and that's because
computation of training of these models
is really complex if you don't feel like
it's just the hello world of uh machine
learning CNN uh go ahead and try it on
your local uh you'll see your local
heating up and all the fans getting
warmed up uh you can also try on Google
collab and you'll see it's much much
slower than what we have here on Azure
ml Studio the reason being we had we
have a strong compute supporting this uh
notebook and we can always use a
stronger compute we have the option
right we we right now are using a very
standard compute with standard GPU but
you can always go for more expensive
ones which are much more powerful and
that's not the limit there you can uh
right now we are using compute instance
you can use compute clusters which are
basically a cluster of compute and then
train really really complex models on
your own sitting at home which you
couldn't not have imagined before this
without this
platform uh so specifically if you are
into training complex models which could
be related to image image processing
models like single image super
resolution
um uh this is the platform that really
really empowers you so basically what
I'm trying to say is I really love this
platform it really empowers me to try
out my own models train them which I
would not have thought possible without
uh at least not sitting at home and
paying nothing so it comes with a trial
version where I can test things out and
see if it feels good um but since this
training is taking time and we are
seeing AO let's talk about what's
happening on the schol uh so Epoch is
like we train the model on our data set
training set from uh input to output and
then we have back propagation algorithm
which comes back and retrains the
weights and uh with the complete
training over we have the value of the
weights that we obtained from
feedback and after the epoch we actually
update the weights and then train again
train again train again make those
weight changes train again make those
and that's basically building a stronger
more accurate model
and we have the score of
98.78% accuracy and that's great and
with that uh thank you for joining me on
this video I hope you learned something
if you did do give give this video a
thumbs up and subscribe for more such
content thanks and have a good day
bye-bye up next you can check out
another fun video about where we are
basically comparing azure ml model
training experience with the Google
collab and see the differences in terms
of compute performance
