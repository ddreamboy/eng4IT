welcome to artificial intelligence
tutorial my name is richard kirschner
i'm with the simply learn team that's
www.simplylearn.com
get certified and get ahead what's in it
for you today what is artificial
intelligence so we'll start with a
general concept types of artificial
intelligence covering the four main
areas ways of achieving artificial
intelligence and some general
applications of artificial intelligence
in today's world finally we'll dive into
a use case predicting if a person has
diabetes or not and we'll be using
tensorflow for that in the python
environment what is artificial
intelligence and today's world is
probably one of the most exciting
advancements that we're in the middle of
experiencing as humans so what is
artificial intelligence and here we have
a robot with nice little clampy hands
hey what am i you are what we call
artificial intelligence i am your
creator reminding him who programmed him
and who he's supposed to take care of
artificial intelligence is a branch of
computer science dedicated to creating
intelligent machines that work and react
like humans in today's place where we're
at with artificial intelligence i really
want to highlight the fact that they
work and react like humans because that
is where the development of artificial
intelligence is and that's what we're
comparing it to is how it looks like
next to a human thanks any tasks you
want me to do for you get me a cup of
coffee poof here you go he brings him a
cup of coffee that's my kind of robot i
love my coffee in the morning you'll see
there's kind of a side theme of coffee
today's tutorial so here we have a robot
that's able to bring him a cup of coffee
seems pretty far out there you know that
we have a walking robot that's doing
this but it's not as far out there as
you think we have automatic coffee pots
we have devices that can move an object
from one point to the other you know
anything from amazon delivering packages
or whatever you want all these things
are in today's world we're right on the
edge of all this that's what makes this
so exciting such an exciting topic and a
place of study so let's take a look a
real general look at types of artificial
intelligence in the really big picture i
mean we drill into it there's like
machine learning and all kinds of
different aspects but just a generic
level of artificial intelligence so hi
there discovered four different types
come have a look so we have our kind of
einstein looking guy or professor at
some college so the very first part that
we're really this is uh as reactive
machines they've been around a long time
this kind of ai are purely reactive and
do not hold the ability to form memories
or use past experiences to make
decisions these machines are designed to
do specific jobs remember i talked about
the programmable coffee maker that makes
coffee in the morning it doesn't
remember yesterday from tomorrow it runs
its program even going back to our
washing machines they have automatic
load balancers that have been around for
decades so reactive machines we program
to do certain tasks and they have no
memory but they're very functional then
we have limited memory this is kind of
right where we're at right now this kind
of ai uses past experience and the
present data to make a decision
self-driving cars are kind of limited
memory ai we bring up self-driving cars
because that's a big thing especially in
today's market they have all these
images that they brought in and videos
of what's gone on before and they use
that to teach the automatic car what to
do so it's based on a limited memory
limited memory means it's not evolving
new ideas they have to actually when
they need to make a change they have the
programming built on the memory but then
they have to make those changes outside
of that and then put the new setup in
there so it's continually reprogramming
itself theory of mind these ai machines
can socialize and understand human
emotions machines with such abilities
are yet to be developed of course that's
under debate there's a lot of places
that are working on the theory of mind
and having it be able to cognitively
understand somebody based on the
environment their
facial features all kinds of things and
evolve with them so their own they have
some kind of reflective ability to
evolve with that and finally
self-awareness this is the future of ai
these machines will be super intelligent
sentient and conscious so they'll be
able to react very much like a human
being although they'll have their own
flavor i'm sure achieving artificial
intelligence so how in today's world
right now are we going to achieve
artificial intelligence well the main
arena right now is machine learning
machine learning provides artificial
intelligence with the ability to learn
this is achieved by using algorithms to
discover patterns and generate insights
from the data they are exposed to and
here we have a computer as we get more
and more to the human realm of art and
official intelligence you see this guy
splits in two and he's inside his hidden
networks and machine learning programs
deep learning which is a subcategory of
machine learning deep learning provides
artificial intelligence the ability to
mimic a human brain's neural network it
can make sense of patterns noise and
sources of confusion in the data let's
try to segregate different kinds of
photos using deep learning so first we
have our pile of photographs much more
organized than my boxes in my closet of
photographs the machine goes through the
features of every photo to distinguish
them this is called feature extraction
bingo figures out the different features
in the photos and so based on those
different features labels of photos it
says these are landscapes these are
portraits these are others so it
separates them in there if you've ever
been on google photos a favorite of mine
i go through there and i type in dog and
i get all the images of my dog it's
pretty amazing how it's able to pull
those features out so when we're
achieving artificial intelligence and
the deep learning let's take a closer
look and see just how deep learning
works there are a lot of models out
there this is the most basic model used
this is a neural network there are three
main layers in a neural network the
photos that we want to segregate go into
the input layer and so we have a picture
of mona lisa it looks like in a couple
of people when it goes into the first
input layer the arrows are drawn to like
individual dots each one of those white
dots in the yellow layer or in the input
layer would be a pixel in the picture
maybe a value for that pixel so the
picture of the mountains goes in there
and it fills in that whole input layer
and then the next picture of the
nightscape goes in there the hidden
layers are responsible for all the
mathematical computations or feature
extraction on our inputs so when you see
here we have the two uh kind of orangish
red layers here and there's all these
lines in there those lines are the
weights each one of those represents a
usually a float number or a decimal
number and then it multiplies it by the
value in the input layer and you'll see
that as it adds all these up in the
hidden layer each one of those dots in
the hidden layer then has a value based
on the sum of the weights and then it
takes those and puts it into another
hidden layer and you might ask well why
do we have multiple hidden layers well
the hidden layers function as different
alternatives to some degree so the more
hidden layers you have the more complex
the data that goes in and what can they
can produce coming out the accuracy of
the predicted output generally depends
on the number of hidden layers we have
so there we go the accuracy is based on
how many hidden layers we have and again
it has to do with how complex the data
is going in the output layer gives us
the segregated photos so once it adds up
all these weights and you'll see there's
weights also going into the output layer
based on those weights it'll say yes
it's a portrait no it's a portrait yes
it's a landscape no it's a landscape and
that's how we get our setup in there so
now we were able to label our photos
let's take a look and see what that
looks like in another domain we have
photograph domain now let's look at it
in the airline ticket so let's predict
the airline ticket prices using machine
learning these are the factors based on
which we're going to make the
predictions and choosing your factors is
so important but for right here we'll
just go ahead and take a look what we
got we have airlines we have the origin
airport the destination airport the
departure date here are some historical
data of ticket prices to train the
machine so we pull in the old data this
is what's happened over the years now
that our machine is trained let's give
it new data for which it will predict
the prices and if you remember from our
four different kinds of machines we have
machines with memory well this is the
memory part it remembers all the old
data and then it compares what you put
in to produce the new data to predict
the new prices the price is 1 000 that's
an expensive flight of course
if that is a us dollars if it's india i
don't know what the price range is on
that hopefully it's a good deal for
wherever you're going so we predict the
prices and this is kind of nice because
if you're looking way ahead it'd be nice
to know if you're planning a trip for
next year
how much those tickets are going to cost
and they certainly fluctuate a lot so
let's take a look at the applications of
artificial intelligence we're going to
dive just a little deeper because we
talked about photos we've talked about
airline ticket prices kind of very
specific you get one specific number but
let's look at some more things that are
probably more in-home more common right
now speaking of home this young
gentleman is entering his room of course
makes a comment like we all do we walk
into a room this room is dark isn't it
let's see what happens when i enter it
the sensors in my room detect my
presence and switch on the lights
this is an example of non-memory
machines okay you know it senses you it
doesn't have a memory whether you've
gone in or not some of the new models
start running a prediction as to whether
you're in the room or not when you show
up when you don't so they turn things on
before you come down the stairs in the
morning especially if you're trying to
save energy you might have one of those
fancy thermostats which starts guessing
when you get up in the morning so it
doesn't start the heater until it knows
you're going to get up so here he comes
in here and this is one of the examples
of smart machine and that is one of the
many applications of artificial
intelligence one of the things we're
developing here in our homes okay bye
abruptly he leaves leaving his nice
steaming cup of coffee there on the
table and when he leaves the sensors
detect he's gone and turn off the lights
let's watch some tv did someone say tv
the sound sensors on the tv detect my
voice and turn on the tv sounds kind of
strange but with the google dongle and a
google home mini you can actually do
just that you can ask it to play a movie
downstairs on your downstairs tv true
also with the amazon fire stick and all
the different artificial intelligent
home appliances that are coming out
pretty amazing time to be alive and in
this industry here you have one more
application of artificial intelligence
and you can probably think of dozens of
others that are right now on the cutting
edge of development so let's jump into
my favorite part which is a use case
predict if a person has diabetes and in
the medical domain i mean if you read
any of these they say predictive a
person has diabetes but in the medical
domain we would want to restate this as
what is the risk is a person a high risk
of diabetes should just be something on
their radar to be looking out for and
we'll be helping out with the use case
there we are with a cup of coffee again
i forgot to shave as you can see we'll
start with the problem statement the
problem statement is to predict if a
person has diabetes or not and we might
start with this prediction statement but
if you were actually using this in a
real case again you would say your
higher risk of diabetes would be the
proper way to present that to somebody
if you ran their test data through here
but that's very domain specific which is
outside of the problem statement as far
as the computer programmers involved so
we have a look at the features these are
the things that have been recorded and
they already have this data from the
hospitals one of them would be number of
times pregnant obviously if you're a guy
that would be zero glucose concentration
so these are people who've had their
glucose measured blood pressure age age
is a big factor an easy thing to look at
insulin level so if someone's on insulin
they probably have diabetes otherwise
they wouldn't be taking insulin but that
would affect everything else and we add
that in there if they're if they're
using insulin let's start off with the
code so we're going to start off by
importing parts of our data set and if
we're going to do this let's jump into
one of our favorite tools we're going to
use the anaconda jupiter notebook so let
me flip over there and we'll talk just
briefly about that and then we'll look
over this code so here we are in the
jupiter notebook and
this is an inline editor which is just
really cool for messing with python on
the fly you can do demos in it it's very
visual you can add pieces of code it has
cells so you can run each cell
individually you can delete them but you
can tell the cell to be a comment so
that instead of running it it just skips
over it there's all kinds of cool things
you can do with jupyter notebook we're
not going to go into that we're actually
going to go with the tensorflow and you
do have to import all the different
modules in your python now if you're in
a different python ide that's fine it'll
work in just about any of your python
ides and i'll point out the one
difference in code when we get to that
which is the inline for doing our graph
and in this code we're going to go
through we're going to load our data up
we're going to explore it we're going to
label it and then we'll use the
tensorflow and then we'll get down to
the end where we're going to take a look
at how good the model is does it work so
let's start with the top part here and
let me go ahead and let's paste that
code in there i've added a line in at
the top i've added the folder because i
didn't put it in the same folder as the
program that's running you don't need to
worry too much about that but if you
have a folder issue or says file doesn't
exist you probably have it in the wrong
folder or you need to add the folder
path and then we're going to import
pandas and let me just one of the cool
things since it's in internet chrome we
can just do that control plus and zoom
right in there and we have the import
pandas as pd so go ahead and draw a line
of there you can see that the pandas as
pd add a little drawing thing in there
to make it easier to see pandas is a
data set it's a really nice package you
can add into your python usually it's
done as pandas as pd that's very common
to see the pd here let's circle that
it's basically like an excel spreadsheet
it adds columns it adds headers it adds
a lot of functionality to look at your
data and the first thing we're going to
do with that is we're going to come down
here and we're going to read and this is
a csv it's a csv file you can open up
the file on your computer if you want if
you need access to the file you can
either search it and download it from
the main thing or type a note in down
below on the youtube video and simply
learn will help you get that file also
and that's true of any questions you
have on this you can add comments down
there and somebody at simplylearn
actually keeps an eye on that and we'll
try to answer those questions for you i
put in the full path you don't have to
if you have your data files saved in the
same folder you're running your program
in and this is just a csv file comma
separated variables and with the pandas
we can read it in there and we're going
to give it put it right in a variable
called diabetes and then finally we take
diabetes and you'll see diabetes.head
this is a pandas command and it's really
nice because it just displays the data
for us let me go ahead and erase that
and so we go up to the run button up
here in our jupyter notebook which runs
the script in this that's a cell we're
in and you can see with thediabetes.head
since it's a pandas data frame it prints
everything out nice and neat for us this
is really great and if i go ahead and do
a control minus i can get it all to fit
on the same screen and this is the first
five lines when you do the head of the
data just prints out the first five
lines in programming of course we start
with zero so we have zero one two three
and four there we go we have yeah here
we go we start with zero we have zero
one two three and four we have our
titles going across the top and of
course the first column is number of
pregnancies glucose concentration
for the second one blood pressure
measurements of triceps as we keep going
you'll see you can guess what most of
these things are group i'm not sure this
is probably the test group i didn't look
it up to see specifically what that is
anytime you start exploring data and for
this example we don't really need to get
too much in detail you want to know the
domain what does this information mean
are we duplicating information going in
that's beyond the scope of this for
right now though we're just going to
look at this data and we're going to
take apart the different pieces of this
data so let's jump in there and take a
look at what the next set of code is so
in our next setup or our next step we
got to start looking at cleaning the
data we got to start looking at these
different columns and how are we going
to bring them in which columns are what
i'm going to jump ahead a little bit and
also as we look at the columns we're
going to do our import our tensorflow as
tf that's a common import that's our
tensorflow model tensorflow was
developed by google and then they put it
into open source so that it's free for
everybody to use which is always a nice
thing so let's take a look at what these
two steps look like in our jupiter
notebook so let's paste this code in
here and this is something that happens
when you're messing with data is you'll
repeat yourself numerous times we
already have diabetes head so i'm going
to put the little pound sign which tells
python that this is just going to be a
comment we're not going to run it a
second time in here we have diabetes dot
columns and then diabetes columns to
norm equals diabetes columns to
norm.apply lambda x let's talk about
that but let me first run that and let's
see that comes out with that and then
let's put the next set of code in also
and i'm going to run that let me just
hit the run button it doesn't really
have an output but we did a lot of stuff
here so let's go over what we did on
this so i've turned on my drawing
implement to help go through all this
there's a lot going on here the first
thing is we have all of our columns up
here all of our column names let me just
highlight that and draw a circle around
that like we did earlier and we want to
look at just specific columns and we're
going to start let me change the color
on this so it really sticks out i'll use
like a blue i'm going to look at these
columns and we're not going to do age
class or group we're going to look at
those in a different way and i'll
explain in a little bit what that's
about so we're looking at number of
pregnancies
uh glu basically anything that can be
read as a float number and you might say
age could be read as a float number
we're going to address that differently
because when you're doing statistics we
usually take the ages and we group them
into buckets and we'll talk about that
and so we're going to take these columns
and we're going to do what they call
normalize them call them to normalize
what is normalize if you're using the sk
learn module one of their neural
networks they call it scaling or scalar
this is in all of these neural networks
what happens is if i have two pieces of
data and let's say
one of them is in this case zero to six
and one of them is in insulin level is
zero to maybe point two would be a very
high level i don't know what they
actually go to a neural network we'll
look at this six and it'll go zero to
six and as you get into zero six here's
an eight even a higher number it will
weight those heavier and so it'll skew
the results based more on the number of
pregnancies than based on the insulin or
based on the blood pressure so we want
to level the playing field we want these
values to all be in the same area we do
that by normalizing it here and we use a
lambda function this is always a kind of
a fun thing we take the diabetes it's a
panda set up and let me just erase all
that so we can go down here put it back
to red and we take our diabetes which is
a panda data set and we only want to
look at the columns to normalize because
that's what we built we built a list of
those columns and we're going to apply
a lambda function and you'll see lambda
and all kinds of python programming it
just means it's a function we put x in
and whatever is outside of the x over
here it then takes that and returns that
value so
the new value is going to be whatever x
is minus x min again it's a panda's data
set so we can get by with that which is
really cool makes it easy to read so we
take x we look for the minimum value of
x and then we divide that by the maximum
value x minus the x min or the width and
what this essentially does is if you're
going from 0
to 15
it's going to divide by 15 and then we
subtract it let's make this 2 instead of
0 or 2 20 to 115 there we go first off
we set this to zero so we subtract x min
so right off the bat the minimal value
is going to be zero and then we divide
it by the difference here x min minus x
max or x max minus x min this basically
sets all the values between zero to one
and that's very important if we want to
make sure that it's not going to be a
skew in the results if it's not going to
weight the values one direction or the
other zero to one that's what this is
doing and again there's like so many
different ways to scale our data this is
the most basic scale it's standard
scaling and it's the most common and we
spelled it out in the lambda you can
there's actual um modules that do that
uh but lambda is just it's such an easy
thing to do and you can see really see
what we're doing here so now we've taken
these columns we've scaled them all and
changed them to a zero to one value we
now need to let the program know the
tensorflow model that we're going to
create we need to let it know what these
things are so to do that i create a
variable called number pregnancy keep it
simple and we've imported the tensorflow
as tf one line of code brings our
tensorflow in for us awesome love python
so you get number of pregnancies in
tf.feature column.numeric column we're
going to tell it's a numeric column so
it knows that this is a float value zero
to one and then number underscore
pregnant so we're taking that column and
we've reshaped that column from zero to
one and no that doesn't mean you have a
point one pregnancy it just means zero
point one equals one or something number
pregnant so we're just mapping this data
so tensorflow knows what to do with it
and we go through all of these we go
through all the way up to again we're
not doing age let me just separate h
down here these have all been adjusted
age we're going to handle differently we
still put it as a numerical column
because it is so let me just circle age
and group we didn't even touch group yet
we're going to look at group and h and
we're going to do some special stuff
with that class we're going to look at
last why because this is whether they
have diabetes or not that's what we're
testing for so this is our history we
know these people have diabetes or not
and we want to find out we want to
create a model and then we want to test
that model predicting whether somebody
new has diabetes or not so here i am
still with my cup of coffee working away
refill number three let's explore both
the categorical group which is going to
be the b c and d on the end and also the
age we're going to talk about those a
little bit more and then we're going to
combine all those features and we'll
jump into splitting the data although
that's kind of the next step but we'll
put that all together what are we doing
with the age and what are we doing with
the group down there so let's flip on
over and take a look at our
jupiter notebook so the first thing is
let's put this new set of code in here
and run it and let's talk about what
we're doing on this set of code in i
actually want to go one more step
forward on the next set of code or part
of it there we go and i can go and just
run that while we have it that's fine
let's just scroll up a little bit here
and let's go through what we just did
with this set of code if we go back up
here to the top part we have group b c b
b c we learned from the header so when i
come down here we're going to create a
signed group and let me get my drawing
pad out so we're looking at this first
one up here assigned group tf feature
column categorical column with
vocabulary list that is a mouthful this
is saying that this is a categorical
list in this case we have a b c d you
see this a lot in tensorflow a lot of
times tensorflow is used to analyze text
or logs error logs and they're just full
of all this information and they take
these in this case a b c d but in other
cases it'd be words and they create
numbers out of them so it has 0 this is
one column this is another column this
is another column this is another column
and it's just this way of being able to
look at this in a different light and
assigning them different values you
really don't want to assign this a float
value first thought might be let's
assign this 0 to 3 0 1 2 3 for a b c d
but if you did that it would try to add
1 plus 2 to get 3 as part of its math
and functions and that just isn't true c
does not equal a plus b c is just a
categorical name it could have been the
frank group and laura's group in a bids
group but it's not you know these are
they're not float numbers so very
important you have that distinction in
your data the next step we're looking at
is our map plot and we're going to do
this
this is a cool useful tool we're going
to import matplotlibrary.pi
plot as plt that's standard import and
this next line here is really important
we're doing the matplot library we want
it to be inline that's because we're in
a jupyter notebook remember i told you
before that if you're running this in a
different ide you might get a different
result
this is the line you need if you want to
see the graph on this page and then we
do diabetes we're going to look at just
the age and dot hist bins equals 20.
what the heck is that well it turns out
that because this is remember it's a
pandas there's our pd pandas as pd
because this is a pandas panda
automatically knows to look for the
matplot library and a hist just means
it's going to be a histogram and we're
going to separate it into 20 bins and
that's what this graph is here so when i
take the diabetes and i do a histogram
of it it produces this really nice graph
we can see that
at 22 most of the participants in this
probably around
174 of the people that were
recorded were of this age bracket
they're right here in this this first
column here and as they get further and
further down they have less and less and
less until when you're at 80 you can
actually see down here there's almost
none in a couple of these categories and
this is important to know because when
you're doing census you know the older
the the group is the more the people
have passed away so you're going to have
this in any of your senses as you take
you're always going to have a much
larger group in the younger crowd and
then it gets lower and lower as they get
older and i mentioned the word buckets
here we go we're going to create an age
bucket we're going to put people in
buckets can you imagine people sitting
in buckets kind of a funny way of
looking at it this just makes it easier
for us to separate it when i go to the
doctor's office i don't want to be told
well your age 22 this is you know you'll
get a decent one at 22.
here we are back to my cup of coffee i
told you coffee was an underlying theme
these next couple steps are very
specific to tensorflow up until now we
had some tensorflow as we set the
categories up but you'd have to set that
up with any model you use to make sure
they're set correctly they'd be set up a
little differently but we run input
functions and in tensorflow this allows
for some really cool things to happen
and this is why tensorflow is so
predominant in a lot of areas so let's
take a look at these next couple lines
of code here we're going to create the
input function and we're going to go
ahead and create the model and let me go
ahead and put these codes in here i went
ahead and split it up so it's different
lines so we can talk a little bit about
that and then the actual model and let
me go ahead and run this so we can see
what that looks like and in my
particular environment it just prints
out a little bit of information about
the model not too worried about looking
at that but we do want to take a closer
look at what we did here so we've
created an input function and again this
is very specific to tensorflow with the
input function we have our train we have
our x equals x train and our y equals y
train because we want to train it with a
particular information but we have these
other settings in here these two
settings and the number of epics is how
many times it's going to go over our
training model epic means large that
means all the data so we're going to go
over it a thousand times that's actually
a huge overkill for this amount of data
usually it only needs probably about 200
but you know when we're putting it
together and you're trying things out
you just kind of throw the numbers in
there and then you go back and fine-tune
it sometimes the batch size is really
important this is where tensorflow does
some really cool things if you're
processing this over a huge amount of
data and you try to batch everything at
once you end up with a problem this
means we're only going to read 10 lines
at a time through our data so each one
of those rows of testing they've done
we're only going to look at 10 of them
at a time and put that through our model
and train it and then shuffle
self-explanatory we're just moving we're
just randomly selecting which data and
what order we go in that way if there's
like you know five in a row that are
kind of weighted one way and vice versa
it mixes them up and then finally we
create our model so the model goes in
there and goes okay i have a
tf.estimator.linearclassifier
we're going to put in the feature
columns equals feature columns we
defined all our columns up above and
then we have in classes equal 2 and that
just means we have our out result is
zero or one you have diabetes or you
don't have diabetes or in this case we
actually call it high risk of diabetes
and then i put one more line of code in
there which i forgot we've set up our
model we set up our feature columns now
we need to actually train it model.train
you'll see this
so common in so many different neural
network models this is like a standard
what's different though is we have to
feed it the function remember we created
this function with all this information
on it and then we have steps in uh steps
similar to number of batches and batch
size it's more like a individual lines
we step through a thousand is a lot more
common for steps than epics but steps is
used you probably leave this out in this
particular example and let's go ahead
and run this all together because it has
a site when we start training it we get
a different output so here we go i've
run it it's given me the information
from when i created the model and now it
just starts going through and we get
this information tensor loss equals
global step all kinds of stuff going on
here and if you're following this it's
just going through the steps and
training it it gives you information you
could dig deep into here but for this
particular setup we're not going to go
too deep on what's going on just know
that we've trained our model this model
now has the information we need in it to
start running predictions so as we sip
our next um take our next step of coffee
or maybe it's tea or
if you're one of those strange late
night workers maybe it's a sip of wine
we go into the next step and we actually
want to run some predictions on here but
we don't want to run the training we
want to run the test on there we want to
take our test data and see what it did
and so that's what we're going to do
next is we're going to run the test
through and actually get some answers so
if you were actually deploying it you
would pull the answers out of the data
it's bringing back let's take a look at
that in our jupyter notebook so here we
go let's paste it in there i'm going to
go ahead and run it and you'll see that
as it goes it's actually putting the
answers out if you remember correctly
well we'll walk through this here in
just a second but it goes through and it
runs each line and it gives you a
prediction for each line one at a time
and prints them out so let's take a look
and see what that actually looks like
let's start with this first part we've
created another function this is just
like the other function except for
x equals x test and there's no y why is
there no y because we don't know what
the answer is on this yet we don't want
to tell it the answer we wanted to guess
what the answer is so we can evaluate
that and see how good it did on that 33
percent of the data so this is our x
test batch size is 10 again so if we
were watching this roll down here we
would see that it actually processes it
10 lines at a time it's only going to go
through once it goes through all the x
test data one time we don't need to have
it predict multiple times and shuffle
equals false
very important we set the shuffle to
false because if we were tracking this
and actually giving people answers we
want to make sure it connects to the
right person so they get the right
results of course we're just doing this
to evaluate it so let's take a look down
here what i put out and as i scroll down
to my jupiter notebook we have some
information as far as a tensorflow
running and then the actual output and
if we look at the output we know by this
first bracket in python it's an array we
know
by this squiggly bracket that this is a
dictionary so that this is a label the
dictionary has logistic probabilities
class ids classes and so this whole
first part let me redo that this whole
first part is one
output and we know that because there is
the bracket there and there is this
bracket here for the dictionary and it's
a dictionary of terms so if i pulled
this out and i looked at object 0 in
here i would go down to and let me just
find it here it is classes remember how
we define classes we define classes as
our answer and so it's guessing our
tensorflow says based on all the
information you gave me i'm guessing
this first entry of our first test data
is high risk diabetes uh oh go get
tested change your diet watch what
you're eating you know high risk one and
if we go down far enough we can see down
here is another one where classes equal
zero i skipped a couple because they're
all ones up here the b
this particular output b
in front of the one means it's a binary
output it only comes out as zero or one
and there's a lot of other information
in here you can dig deep into tensorflow
and explain these different numbers
that's way beyond the scope of what
we're working on today so the basics of
it though is you get an output and we
have an output of whether the person has
diabetes or not well in this case it's
high risk of diabetes or not so now that
we've run our predictions take a sip of
coffee a little short break and we say
well what do we need to do well we need
to know how good was our predictions we
need to evaluate our model so if you're
going to publish this to a company or
something like that they want to know
how good you did let's take a look at
what that looks like in the code so
let's paste that in here and
just real quick go back over this by now
this function should look very
this is we're going to call it eval
input function it should be pretty
straightforward here we have our tf
estimator inputs pandas input function
and then we have our x test our y test
because we this time we want to give it
the answer so it has something to see
how good it did on batch is 10
processing 10 at a time we're only going
once through the data we're not
shuffling it although it doesn't really
matter with this and then we're going to
do results equals
model.evaluate and we put our evaluation
function in there this should all look
familiar because we're repeating the
same thing it's very similar with a
couple different changes as far as what
we're feeding it and the fact that we're
doing an evaluation let's see what that
looks like when we run it and we go up
here to our run model you'll see
warnings on some of these because i
didn't install this on its own install
so a lot of it is just temporary files
because i'm using the jupyter notebook
instead of setting it up on a regular
machine and we get our output and we'll
go ahead and just look at this output
real quick and then we'll flip over and
from here you'll see that it generates
an accuracy a baseline average loss the
mean gives you a precision prediction it
gives you all kinds of information on
here so let's flip over and see what's
important and we'll look at the slide
here we are in this slide and this
should be exciting because we just about
wrapped up our whole tensor flow and
tensorflow is one of the more
complicated models out there so give
yourself a pat on the back for getting
all the way through this when we look at
this output we have an accuracy of
0.7165
that's really what we want to look at
that means that we have an accuracy if
you're just truncating it of 71 percent
that's quite good for our model you know
given a small amount of data we came up
with the 71 percent of letting people
know they're high risk or not with
diabetes so we created a model that can
predict if a person has diabetes based
on some previous records of people who
were diagnosed with diabetes and we've
managed to have an accuracy of 71
percent which is quite good the model
was implemented on python using
tensorflow again pat yourself on the
back because tensorflow is one of the
more complicated scripts out there it's
also one of the more diverse and useful
ones so the key takeaways today is we've
covered what is artificial intelligence
with our robot that brings us coffee and
we noted that we are comparing it to how
it reacts and looks like humans very
important to note that in today's world
where we're at and we looked at types of
artificial intelligence from the
reactive machines to limited memory and
looking into the future of theory of
mind and self awareness then we went in
there and took a look at taking photos
and how artificial machine learning work
we took a glance at deep learning with
our neural networks and how we have
hidden layers in our input layer and our
output layer we then looked at a use
case of somebody walking into a room and
activating their tv using artificial
intelligence or part of the ai category
and finally we dug in deep and we did
some coding in the tensorflow in python
with that let's wrap it up i'd like to
thank you for joining us today for more
information visit www.simplylearn.com
get certified get ahead again if you
have any questions or would like some
verifications or or more information
please feel free to add a note in the
youtube video comment section we look
forward to hearing from you and i wish
you a wonderful day
hi there if you like this video
subscribe to the simply learn youtube
channel and click here to watch similar
videos turn it up and get certified
click here
